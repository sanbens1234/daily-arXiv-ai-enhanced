<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Contact-aware Path Planning for Autonomous Neuroendovascular Navigation](https://arxiv.org/abs/2601.07945)
*Aabha Tamhankar,Ron Alterovitz,Ajit S. Puri,Giovanni Pittiglio*

Main category: cs.RO

TL;DR: 提出了一种确定性和时间效率高的接触感知路径规划器，用于神经血管导航。通过利用术前和术中血管图像信息来智能预测和利用与解剖结构的交互作用，实现预弯被动工具的导航。在不同的代表性血管解剖结构中，该算法表现出了100%的收敛率，并且在最坏情况下也仅需22.8秒完成计算，具有次毫米级跟踪误差（小于0.64毫米），适用于约94%患者的解剖模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高神经血管手术过程中工具导航的准确性与时效性，同时考虑到了工具与解剖结构之间可能发生的接触及相互作用。

Method: 基于从术前和术中的血管影像获取的信息，开发了一种结合了简化运动基元的基于采样的规划器来进行树扩展。这种方法通过智能地预测并利用与解剖学上的互动来引导预弯曲的被动工具。

Result: 该方法能够在多种多样且具有代表性的血管解剖结构中快速计算出可行路径，同时保持极高的精确度。实验结果显示，在最差的情况下也能在22.8秒内达到100%的收敛率，跟踪误差小于0.64毫米。此外，此方案对大约94%的患者具有适用性。

Conclusion: 本研究提出的接触感知路径规划算法不仅提高了神经血管导航过程中的时间和空间效率，还确保了高精度定位。它为使用预弯曲被动工具进行复杂脑血管手术提供了一个有效的新途径。

Abstract: We propose a deterministic and time-efficient contact-aware path planner for neurovascular navigation. The algorithm leverages information from pre- and intra-operative images of the vessels to navigate pre-bent passive tools, by intelligently predicting and exploiting interactions with the anatomy. A kinematic model is derived and employed by the sampling-based planner for tree expansion that utilizes simplified motion primitives. This approach enables fast computation of the feasible path, with negligible loss in accuracy, as demonstrated in diverse and representative anatomies of the vessels. In these anatomical demonstrators, the algorithm shows a 100% convergence rate within 22.8s in the worst case, with sub-millimeter tracking errors (less than 0.64 mm), and is found effective on anatomical phantoms representative of around 94% of patients.

</details>


### [2] [Fiducial Exoskeletons: Image-Centric Robot State Estimation](https://arxiv.org/abs/2601.08034)
*Cameron Smith,Basile Van Hoorick,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 提出了Fiducial Exoskeletons，这是一种基于单张图像的3D机器人状态估计方法，通过在每个机械臂链接上安装已知几何形状的标志物，从而简化了设置并提高了校准、状态准确性及下游3D控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统的方法特别是机器人-相机外参估计往往依赖于高精度执行器，并且需要耗时的手眼校准等程序。相比之下，现代基于学习的机器人控制越来越多地从RGB观察中训练和部署到低成本硬件上。

Method: 将机器人状态估计视为从单个RGB图像对每个链接进行6D位姿估计：直接将估计的基础链接位姿作为机器人-摄像机基变换获得，并通过轻量级全局优化恢复关节状态以确保与观测到的链接位姿运动学一致性（可选择使用编码器读数预热启动）。此外，通过引入fiducial exoskeleton——一种带有每个链接上的标志物且已知标记-链接几何形状的轻质3D打印支架，使每个链接的6D位姿估计变得鲁棒而简单。

Result: 该设计仅需一张图片即可得到稳健的摄像机-机器人外部参数、每个链接的SE(3)姿态以及关节角度状态，即使是在未插电的机器人上也能实现稳健的状态估计。在一个低成本机器人手臂上的演示表明，标志物外骨骼显著简化了设置，同时提高了校准、状态准确性及后续3D控制性能。

Conclusion: 这项工作展示了如何利用Fiducial Exoskeletons来简化机器人的设置过程，提高其状态估计的准确性和控制性能，特别是在低成本硬件平台上。此外还发布了代码和可打印的硬件设计方案，以促进进一步的算法-硬件协同设计。

Abstract: We introduce Fiducial Exoskeletons, an image-based reformulation of 3D robot state estimation that replaces cumbersome procedures and motor-centric pipelines with single-image inference. Traditional approaches - especially robot-camera extrinsic estimation - often rely on high-precision actuators and require time-consuming routines such as hand-eye calibration. In contrast, modern learning-based robot control is increasingly trained and deployed from RGB observations on lower-cost hardware.
  Our key insight is twofold. First, we cast robot state estimation as 6D pose estimation of each link from a single RGB image: the robot-camera base transform is obtained directly as the estimated base-link pose, and the joint state is recovered via a lightweight global optimization that enforces kinematic consistency with the observed link poses (optionally warm-started with encoder readings). Second, we make per-link 6D pose estimation robust and simple - even without learning - by introducing the fiducial exoskeleton: a lightweight 3D-printed mount with a fiducial marker on each link and known marker-link geometry.
  This design yields robust camera-robot extrinsics, per-link SE(3) poses, and joint-angle state from a single image, enabling robust state estimation even on unplugged robots. Demonstrated on a low-cost robot arm, fiducial exoskeletons substantially simplify setup while improving calibration, state accuracy, and downstream 3D control performance. We release code and printable hardware designs to enable further algorithm-hardware co-design.

</details>


### [3] [Efficient Incremental SLAM via Information-Guided and Selective Optimization](https://arxiv.org/abs/2601.08110)
*Reza Arablouei*

Main category: cs.RO

TL;DR: 该论文提出了一种高效的增量SLAM后端方法，结合了基于信息理论标准的信息引导门控(IGG)和选择性部分优化(SPO)两个互补思想。此方法在保持全局一致性的同时大大减少了计算成本，并且在基准SLAM数据集上的实验表明它与批处理求解器的估计精度相匹配，同时相比传统增量方法实现了显著的计算节省。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种既准确又高效的SLAM后端解决方案，特别是在动态且数据丰富的环境中实时操作时。

Method: 通过引入信息引导门控(IGG)来量化新测量值的贡献，并仅当观察到显著信息增益时触发全局优化；同时采用选择性部分优化(SPO)，针对受新测量影响最大的变量子集执行多迭代高斯-牛顿更新，直到收敛。

Result: 提出的方案在保持与全批量优化相同精度的同时，显著降低了计算成本。实验结果表明，该方法在多个基准SLAM数据集中都能达到与批处理求解器相同的估计精度，同时还比传统的增量方法节省了大量计算资源。

Conclusion: 这种结合了IGG与SPO的新方法为实时操作提供了一个兼顾准确性和效率的原则性平衡解决方案，适用于动态且数据丰富的环境。

Abstract: We present an efficient incremental SLAM back-end that achieves the accuracy of full batch optimization while substantially reducing computational cost. The proposed approach combines two complementary ideas: information-guided gating (IGG) and selective partial optimization (SPO). IGG employs an information-theoretic criterion based on the log-determinant of the information matrix to quantify the contribution of new measurements, triggering global optimization only when a significant information gain is observed. This avoids unnecessary relinearization and factorization when incoming data provide little additional information. SPO executes multi-iteration Gauss-Newton (GN) updates but restricts each iteration to the subset of variables most affected by the new measurements, dynamically refining this active set until convergence. Together, these mechanisms retain all measurements to preserve global consistency while focusing computation on parts of the graph where it yields the greatest benefit. We provide theoretical analysis showing that the proposed approach maintains the convergence guarantees of full GN. Extensive experiments on benchmark SLAM datasets show that our approach consistently matches the estimation accuracy of batch solvers, while achieving significant computational savings compared to conventional incremental approaches. The results indicate that the proposed approach offers a principled balance between accuracy and efficiency, making it a robust and scalable solution for real-time operation in dynamic data-rich environments.

</details>


### [4] [A Pin-Array Structure for Gripping and Shape Recognition of Convex and Concave Terrain Profiles](https://arxiv.org/abs/2601.08143)
*Takuya Kato,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本研究开发了一种新型夹爪，能够适应并抓取不规则地形，并同时测量地形形状。通过引入针阵结构，该夹爪不仅能够抓取凸凹地形，还能够准确地进行三维地形测绘。


<details>
  <summary>Details</summary>
Motivation: 在极端环境中工作的多足攀爬机器人由于未知自然环境中的表面误抓或可抓点丢失而容易摔倒或卡住。为了克服这些问题，需要一种能够自适应于不规则地形的夹爪，不仅能抓取还能准确测量地形表面的形状。

Method: 研究人员开发了一种带有针阵结构的夹爪，这种设计使得夹爪能够抓住凸面和凹面地形，并且同时能够测量地形形状。他们通过原型机展示了夹爪的工作机制，并对其抓取能力和地形识别性能进行了评估。

Result: 实验结果表明，所提出的针阵设计夹爪在3D地形测绘以及对不规则地形的自适应抓取方面表现良好。

Conclusion: 这项工作为移动机器人在复杂环境下提供了更有效的抓握与地形识别解决方案，特别是对于那些需要在悬崖或洞穴墙壁等粗糙地形上作业的机器人而言。

Abstract: This paper presents a gripper capable of grasping and recognizing terrain shapes for mobile robots in extreme environments. Multi-limbed climbing robots with grippers are effective on rough terrains, such as cliffs and cave walls. However, such robots may fall over by misgrasping the surface or getting stuck owing to the loss of graspable points in unknown natural environments. To overcome these issues, we need a gripper capable of adaptive grasping to irregular terrains, not only for grasping but also for measuring the shape of the terrain surface accurately. We developed a gripper that can grasp both convex and concave terrains and simultaneously measure the terrain shape by introducing a pin-array structure. We demonstrated the mechanism of the gripper and evaluated its grasping and terrain recognition performance using a prototype. Moreover, the proposed pin-array design works well for 3D terrain mapping as well as adaptive grasping for irregular terrains.

</details>


### [5] [Robust Subpixel Localization of Diagonal Markers in Large-Scale Navigation via Multi-Layer Screening and Adaptive Matching](https://arxiv.org/abs/2601.08161)
*Jing Tao,Banglei Guan,Yang Shang,Shunkun Liang,Qifeng Yu*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的高精度定位方法，通过多层角点筛选和自适应模板匹配来解决大规模飞行导航中的定位失败问题以及传统滑动窗口匹配技术的计算效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决在复杂背景干扰下大规模飞行导航中出现的定位失败问题以及传统滑动窗口匹配技术固有的计算效率低下的问题。

Method: 采用了一个三层框架，包括多层角点筛选和自适应模板匹配。首先通过光照均衡化和结构信息提取降低维度；然后使用从粗到细的候选选择策略减少滑动窗口的计算成本，快速估计标记位置；最后，为候选点生成自适应模板，并通过改进的模板匹配与相关系数极值拟合达到亚像素级精度。

Result: 实验结果表明，该方法能够有效地在复杂的大型环境中提取并定位对角标记，适用于导航任务中的视场测量。

Conclusion: 所提出的方法对于在复杂的大规模环境下进行精确地标记定位是有效的，特别是在导航任务中具有很好的应用前景。

Abstract: This paper proposes a robust, high-precision positioning methodology to address localization failures arising from complex background interference in large-scale flight navigation and the computational inefficiency inherent in conventional sliding window matching techniques. The proposed methodology employs a three-tiered framework incorporating multi-layer corner screening and adaptive template matching. Firstly, dimensionality is reduced through illumination equalization and structural information extraction. A coarse-to-fine candidate selection strategy minimizes sliding window computational costs, enabling rapid estimation of the marker's position. Finally, adaptive templates are generated for candidate points, achieving subpixel precision through improved template matching with correlation coefficient extremum fitting. Experimental results demonstrate the method's effectiveness in extracting and localizing diagonal markers in complex, large-scale environments, making it ideal for field-of-view measurement in navigation tasks.

</details>


### [6] [FSAG: Enhancing Human-to-Dexterous-Hand Finger-Specific Affordance Grounding via Diffusion Models](https://arxiv.org/abs/2601.08246)
*Yifan Han,Pengfei Yi,Junyan Li,Hanqing Wang,Gaojing Zhang,Qi Peng Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: 提出了一种数据高效框架，通过利用预训练生成扩散模型中的丰富语义先验来绕过机器人抓取数据收集，从而实现灵巧手的抓取合成。该系统能够从原始人类视频演示中提取精细的抓取可行性，并与深度图像的3D场景几何融合以推断基于语义的接触目标。此外，还引入了一个运动学感知重定向模块，将这些可行性表示映射到不同的灵巧手上而无需针对每个手重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有的灵巧抓取方法通常依赖于大规模、硬件特定的数据集，这限制了它们随着新设计出现时的可扩展性。因此，需要一种更高效且能跨不同灵巧手设计通用的方法。

Method: 开发了一个数据高效框架，它利用预训练生成扩散模型中的对象中心语义先验来避免直接收集机器人抓取数据。该框架可以从人类视频演示中提取时间对齐的精细抓取可行性，并将其与来自深度图像的3D场景几何信息相结合，以确定具有语义基础的接触点。随后，使用一个运动学感知的重新定位模块将这些可行性表示转换为适用于多种灵巧手的形式。

Result: 实验结果表明，所提系统能够在常见物体和工具上产生稳定且功能适当的多点接触抓握，并且对于同一类别内未见过的对象实例、姿势变化以及多个手部实体表现出良好的泛化能力。

Conclusion: 本研究介绍了一种新的语义可行性提取流程，展示了无需构建硬件特定抓取数据集即可实现跨手部泛化的可能性，并证明单深度模态结合基础模型语义足以支持高性能抓取合成，指出了未来可能的发展方向——由人类演示和预训练生成模型驱动的可扩展、硬件无关的灵巧操作。

Abstract: Dexterous grasp synthesis remains a central challenge: the high dimensionality and kinematic diversity of multi-fingered hands prevent direct transfer of algorithms developed for parallel-jaw grippers. Existing approaches typically depend on large, hardware-specific grasp datasets collected in simulation or through costly real-world trials, hindering scalability as new dexterous hand designs emerge. To this end, we propose a data-efficient framework, which is designed to bypass robot grasp data collection by exploiting the rich, object-centric semantic priors latent in pretrained generative diffusion models. Temporally aligned and fine-grained grasp affordances are extracted from raw human video demonstrations and fused with 3D scene geometry from depth images to infer semantically grounded contact targets. A kinematics-aware retargeting module then maps these affordance representations to diverse dexterous hands without per-hand retraining. The resulting system produces stable, functionally appropriate multi-contact grasps that remain reliably successful across common objects and tools, while exhibiting strong generalization across previously unseen object instances within a category, pose variations, and multiple hand embodiments. This work (i) introduces a semantic affordance extraction pipeline leveraging vision-language generative priors for dexterous grasping, (ii) demonstrates cross-hand generalization without constructing hardware-specific grasp datasets, and (iii) establishes that a single depth modality suffices for high-performance grasp synthesis when coupled with foundation-model semantics. Our results highlight a path toward scalable, hardware-agnostic dexterous manipulation driven by human demonstrations and pretrained generative models.

</details>


### [7] [ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation](https://arxiv.org/abs/2601.08325)
*Zhenyang Liu,Yongchong Gu,Yikai Wang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: 本文提出了一种新的视觉-语言-动作框架ActiveVLA，通过主动感知能力来提高机器人在长时任务和精细操纵场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数方法忽视了主动感知的重要性，通常依赖于提供末端执行器视角的静态腕部安装摄像头，这导致模型在任务执行过程中无法自适应地选择最佳视角或分辨率，从而大大限制了它们在长时间任务和精细操控场景中的表现。

Method: ActiveVLA采用由粗到细的方法，分为两个阶段：1) 关键区域定位。将3D输入投影到多视图2D投影上，识别关键3D区域，并支持动态空间意识。2) 主动感知优化。基于已定位的关键区域，使用主动视角选择策略挑选出最优视角，这些视角旨在最大化非模式相关性和多样性同时最小化遮挡。此外，ActiveVLA还应用3D放大技术以提高关键区域的分辨率。

Result: 广泛的实验表明，ActiveVLA能够实现精确的3D操纵，在三个模拟基准测试中优于最先进的基线。此外，ActiveVLA可以无缝转移到现实世界场景中，使机器人能够在复杂环境中学习高精度的任务。

Conclusion: 通过引入主动感知能力，ActiveVLA为机器人提供了更高效、更准确的操作可能性，特别是在需要高精度和长期规划的任务中。

Abstract: Recent advances in robot manipulation have leveraged pre-trained vision-language models (VLMs) and explored integrating 3D spatial signals into these models for effective action prediction, giving rise to the promising vision-language-action (VLA) paradigm. However, most existing approaches overlook the importance of active perception: they typically rely on static, wrist-mounted cameras that provide an end-effector-centric viewpoint. As a result, these models are unable to adaptively select optimal viewpoints or resolutions during task execution, which significantly limits their performance in long-horizon tasks and fine-grained manipulation scenarios. To address these limitations, we propose ActiveVLA, a novel vision-language-action framework that empowers robots with active perception capabilities for high-precision, fine-grained manipulation. ActiveVLA adopts a coarse-to-fine paradigm, dividing the process into two stages: (1) Critical region localization. ActiveVLA projects 3D inputs onto multi-view 2D projections, identifies critical 3D regions, and supports dynamic spatial awareness. (2) Active perception optimization. Drawing on the localized critical regions, ActiveVLA uses an active view selection strategy to choose optimal viewpoints. These viewpoints aim to maximize amodal relevance and diversity while minimizing occlusions. Additionally, ActiveVLA applies a 3D zoom-in to improve resolution in key areas. Together, these steps enable finer-grained active perception for precise manipulation. Extensive experiments demonstrate that ActiveVLA achieves precise 3D manipulation and outperforms state-of-the-art baselines on three simulation benchmarks. Moreover, ActiveVLA transfers seamlessly to real-world scenarios, enabling robots to learn high-precision tasks in complex environments.

</details>


### [8] [Large Language Models to Enhance Multi-task Drone Operations in Simulated Environments](https://arxiv.org/abs/2601.08405)
*Yizhan Feng,Hichem Snoussi,Jing Teng,Abel Cherouat,Tian Wang*

Main category: cs.RO

TL;DR: 本文提出了一种将微调后的CodeT5模型与基于虚幻引擎的AirSim无人机模拟器结合的方法，实现了通过自然语言命令高效执行多任务操作，并展示了在模拟环境中出色的任务执行效率和命令理解能力。


<details>
  <summary>Details</summary>
Motivation: 借助大型语言模型（LLMs）的快速发展，人-无人机交互达到了前所未有的机会。为了降低操作门槛并让用户能够通过自然语言轻松访问和控制无人机状态，研究者们探索了新的方法。

Method: 通过将微调过的CodeTTL模型与AirSim无人机模拟器集成，使用ChatGPT生成的大规模(自然语言, 程序代码)命令执行对数据集以及开发者编写的无人机代码作为训练数据，实现从自然语言到可执行代码的自动转换。

Result: 实验结果表明，在模拟环境中，所提出的方法显示出了优异的任务执行效率和命令理解能力。

Conclusion: 未来工作包括以模块化方式扩展模型功能，增强其对复杂场景的适应性，推动无人机技术在现实世界环境中的应用。

Abstract: Benefiting from the rapid advancements in large language models (LLMs), human-drone interaction has reached unprecedented opportunities. In this paper, we propose a method that integrates a fine-tuned CodeT5 model with the Unreal Engine-based AirSim drone simulator to efficiently execute multi-task operations using natural language commands. This approach enables users to interact with simulated drones through prompts or command descriptions, allowing them to easily access and control the drone's status, significantly lowering the operational threshold. In the AirSim simulator, we can flexibly construct visually realistic dynamic environments to simulate drone applications in complex scenarios. By combining a large dataset of (natural language, program code) command-execution pairs generated by ChatGPT with developer-written drone code as training data, we fine-tune the CodeT5 to achieve automated translation from natural language to executable code for drone tasks. Experimental results demonstrate that the proposed method exhibits superior task execution efficiency and command understanding capabilities in simulated environments. In the future, we plan to extend the model functionality in a modular manner, enhancing its adaptability to complex scenarios and driving the application of drone technologies in real-world environments.

</details>


### [9] [Teaching Robots Like Dogs: Learning Agile Navigation from Luring, Gesture, and Speech](https://arxiv.org/abs/2601.08422)
*Taerim Yoon,Dongho Kang,Jin Cheng,Fatemeh Zargarbashi,Yijiang Huang,Minsung Ahn,Stelian Coros,Sungjoon Choi*

Main category: cs.RO

TL;DR: 提出了一种人机循环框架，使腿部机器人能够通过物理人类指导学习理解和响应社交线索，并以数据高效的方式习得导航行为。该方法结合了手势和语音命令的多模态自然人类输入，通过基于物理的模拟重建交互场景来缓解有限演示数据带来的分布偏移问题。采用渐进目标提示策略自适应地在训练过程中提供适当的命令和导航目标，从而实现更准确的导航和更强的人机行为一致性。实验结果表明，在六个现实世界敏捷导航场景中，该方法几乎在所有试验中都取得了成功，总任务成功率达到了97.15%，所需演示数据不到1小时。


<details>
  <summary>Details</summary>
Motivation: 让腿部机器人学会理解人类社交信号并产生适当的行为，同时减少对大量人工提供数据的需求，减轻用户负担。

Method: 开发了一种包含人类反馈机制的框架，允许机器人使用手势和口头指令作为控制信号，通过物理模拟重建互动场景来收集数据，以此解决由于演示数据量少而导致的数据分布变化问题。此外，实施了逐步目标指示策略，根据训练过程动态调整给予机器人的指令与导航目标。

Result: 在六个真实的灵活导航情况下进行了测试，包括跳过或避开障碍物等任务。结果显示，所提出的方法在几乎所有尝试中均取得成功，仅需不到一小时的人类演示数据即可达到97.15%的任务完成率。

Conclusion: 本文介绍的方法证明了利用较少的人类演示数据，通过结合物理引导、多模式自然输入以及智能训练策略，可以有效教会腿式机器人理解社会线索并执行复杂的导航任务。

Abstract: In this work, we aim to enable legged robots to learn how to interpret human social cues and produce appropriate behaviors through physical human guidance. However, learning through physical engagement can place a heavy burden on users when the process requires large amounts of human-provided data. To address this, we propose a human-in-the-loop framework that enables robots to acquire navigational behaviors in a data-efficient manner and to be controlled via multimodal natural human inputs, specifically gestural and verbal commands. We reconstruct interaction scenes using a physics-based simulation and aggregate data to mitigate distributional shifts arising from limited demonstration data. Our progressive goal cueing strategy adaptively feeds appropriate commands and navigation goals during training, leading to more accurate navigation and stronger alignment between human input and robot behavior. We evaluate our framework across six real-world agile navigation scenarios, including jumping over or avoiding obstacles. Our experimental results show that our proposed method succeeds in almost all trials across these scenarios, achieving a 97.15% task success rate with less than 1 hour of demonstration data in total.

</details>


### [10] [Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?](https://arxiv.org/abs/2601.08434)
*Long Zhang,Yuchen Xia*

Main category: cs.RO

TL;DR: 本文介绍了一种新的语义和策略双驱动的混合决策框架，结合了大型多模态模型（LMMs）用于语义理解和认知表示，以及深度强化学习（DRL）实现实时策略优化，以解决自主驾驶中的持续学习和联合决策问题。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶设计在开放世界场景中面临挑战，需要持续的环境理解与逻辑推理能力；而仅依靠LMMs来增强具身智能（EI）驾驶能力存在局限性。

Method: 提出了一种结合LMMs和DRL的新框架，旨在通过语义理解和实时策略优化促进连续学习和联合决策。

Result: 实验案例研究表明，在完成车道变换规划任务方面，所提出的框架表现出了优越性能。

Conclusion: 除了展示新框架的有效性外，文章还探讨了未来研究方向，以进一步推动EI驾驶的发展。

Abstract: The advent of Large Multimodal Models (LMMs) offers a promising technology to tackle the limitations of modular design in autonomous driving, which often falters in open-world scenarios requiring sustained environmental understanding and logical reasoning. Besides, embodied artificial intelligence facilitates policy optimization through closed-loop interactions to achieve the continuous learning capability, thereby advancing autonomous driving toward embodied intelligent (El) driving. However, such capability will be constrained by relying solely on LMMs to enhance EI driving without joint decision-making. This article introduces a novel semantics and policy dual-driven hybrid decision framework to tackle this challenge, ensuring continuous learning and joint decision. The framework merges LMMs for semantic understanding and cognitive representation, and deep reinforcement learning (DRL) for real-time policy optimization. We starts by introducing the foundational principles of EI driving and LMMs. Moreover, we examine the emerging opportunities this framework enables, encompassing potential benefits and representative use cases. A case study is conducted experimentally to validate the performance superiority of our framework in completing lane-change planning task. Finally, several future research directions to empower EI driving are identified to guide subsequent work.

</details>


### [11] [Real2Sim based on Active Perception with automatically VLM-generated Behavior Trees](https://arxiv.org/abs/2601.08454)
*Alessandro Adami,Sebastian Zudaire,Ruggero Carli,Pietro Falco*

Main category: cs.RO

TL;DR: 本文提出了一种从现实到模拟(Real2Sim)的框架，该框架能够自主生成并执行行为树以获取特定任务所需的物理参数，而无需依赖预定义的任务模板或专家设计的探索程序。通过多模态推理识别相关物体、推断所需物理参数，并生成由基本机器人动作组成的行为树。实验结果表明，该方法能够在多个场景下估计物体质量、表面高度和与摩擦相关的量。


<details>
  <summary>Details</summary>
Motivation: 传统的从现实到模拟(Real2Sim)管道依赖于手动测量或固定预先编程的探索例程，这限制了它们对不同任务和用户意图的适应性。因此，需要一种更灵活的方法来自动获取针对给定模拟目标所需的物理参数。

Method: 采用视觉-语言模型进行多模态推理，基于高层次用户请求、不完整的模拟描述以及场景RGB观察，确定相关对象、推断必要物理参数，并创建由基础机器人动作构成的行为树。使用Franka Emika Panda力控机械臂执行生成的行为树，通过接触丰富的互动收集用于参数估计的数据。

Result: 实验结果展示了在真实操作器上，对于包括遮挡物体和不完全先验模型在内的多种情况下，成功实现了物体质量、表面高度及摩擦相关量的估计。

Conclusion: 提出的方法促进了可解释性、意图驱动且自主的Real2Sim流程的发展，将高层次推理与基于物理的机器人交互相结合，为构建准确的仿真环境提供了新的解决方案。

Abstract: Constructing an accurate simulation model of real-world environments requires reliable estimation of physical parameters such as mass, geometry, friction, and contact surfaces. Traditional real-to-simulation (Real2Sim) pipelines rely on manual measurements or fixed, pre-programmed exploration routines, which limit their adaptability to varying tasks and user intents. This paper presents a Real2Sim framework that autonomously generates and executes Behavior Trees for task-specific physical interactions to acquire only the parameters required for a given simulation objective, without relying on pre-defined task templates or expert-designed exploration routines. Given a high-level user request, an incomplete simulation description, and an RGB observation of the scene, a vision-language model performs multi-modal reasoning to identify relevant objects, infer required physical parameters, and generate a structured Behavior Tree composed of elementary robotic actions. The resulting behavior is executed on a torque-controlled Franka Emika Panda, enabling compliant, contact-rich interactions for parameter estimation. The acquired measurements are used to automatically construct a physics-aware simulation. Experimental results on the real manipulator demonstrate estimation of object mass, surface height, and friction-related quantities across multiple scenarios, including occluded objects and incomplete prior models. The proposed approach enables interpretable, intent-driven, and autonomously Real2Sim pipelines, bridging high-level reasoning with physically-grounded robotic interaction.

</details>


### [12] [AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization](https://arxiv.org/abs/2601.08491)
*Mohamed Afouene Melki,Mohammad Shehab,Mohamed-Slim Alouini*

Main category: cs.RO

TL;DR: 本文提出了一种通过自主水下航行器(AUV)对水下物联网(IoUT)设备进行声能传输(AET)和信息上传的可持续方法，以实现设备的无限运行。为此开发了两种深度强化学习(DRL)算法，分别提供高性能FDD方案和中等性能TDD方案，并证明所提方案显著降低了平均信息时效性(AoI)，提高了收集能量与数据公平性。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越关注监测海洋生物、深海环境以及水下安装设施的维护，传统的依靠电池供电的IoUT设备面临寿命限制且废弃后会造成环境污染问题。为了解决这些问题并实现IoUT设备的长期甚至永久运作，提出了新的方法。

Method: 采用年龄信息（AoI）处理时间敏感性问题，并使用Jain's公平指数衡量系统性能。基于此，开发了两个深度强化学习（DRL）算法：一个针对高复杂度、高性能需求设计的频分双工（FDD）解决方案；另一个是面向低复杂度、中等性能需求的时间分双工（TDD）策略。

Result: 实验结果表明，相较于基线方法，所提出的FDD和TDD方案能够显著降低平均AoI，同时提高采集到的能量量级及数据收集过程中的公平性。

Conclusion: 通过引入AUV来实现AET与IoUT设备的信息上行同步，结合专门设计的DRL算法，可以有效延长IoUT系统的使用寿命，改善其性能指标如AoI和能量收获效率。

Abstract: Internet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultaneous information uplink from the IoUT devices and acoustic energy transfer (AET) to the devices via an autonomous underwater vehicle (AUV), potentially enabling them to operate indefinitely. To tackle the time-sensitivity, we adopt age of information (AoI), and Jain's fairness index. We develop two deep-reinforcement learning (DRL) algorithms, offering a high-complexity, high-performance frequency division duplex (FDD) solution and a low-complexity, medium-performance time division duplex (TDD) approach. The results elucidate that the proposed FDD and TDD solutions significantly reduce the average AoI and boost the harvested energy as well as data collection fairness compared to baseline approaches.

</details>


### [13] [Simplifying ROS2 controllers with a modular architecture for robot-agnostic reference generation](https://arxiv.org/abs/2601.08514)
*Davide Risi,Vincenzo Petrone,Antonio Langella,Lorenzo Pagliara,Enrico Ferrentino,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 本文提出了一种新的ROS2模块化架构，通过引入一个名为参考生成器的独立组件来处理从外部节点接收的参考信息，并以控制器采样周期将单点参考写入下游控制器。实现了两种参考生成器及一组新的控制器，并在仿真和真实机器人上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高ROS2中控制器的可重用性和减少重复的参考处理代码，本文提出了一个新的模块化架构，该架构分离了获取、验证和插值参考所需的逻辑与跟踪这些参考的控制律。

Method: 设计并实现了一个名为参考生成器的专门组件，能够接收来自外部节点（如规划器）的单一数据点或轨迹形式的参考信息，并利用现有的ros2_control链式机制按照控制器的采样周期向下游控制器提供单点参考。此外，还开发了针对关节空间参考和笛卡尔参考的两个参考生成器以及一套新的控制器（PD加重力补偿、笛卡尔姿态和顺应性控制器）。

Result: 实验结果表明：(i) 在所有测试场景下都能可靠地跟踪参考；(ii) 参考生成器减少了跨链接控制器中的重复参考处理代码，有利于构建和复用复杂的控制器管道；(iii) 控制器实现保持专注于控制律本身。

Conclusion: 提出的模块化架构成功提高了ROS2控制器的灵活性和可重用性，同时简化了控制器内部结构，使其更加专注于执行控制任务。

Abstract: This paper introduces a novel modular architecture for ROS2 that decouples the logic required to acquire, validate, and interpolate references from the control laws that track them. The design includes a dedicated component, named Reference Generator, that receives references, in the form of either single points or trajectories, from external nodes (e.g., planners), and writes single-point references at the controller's sampling period via the existing ros2_control chaining mechanism to downstream controllers. This separation removes duplicated reference-handling code from controllers and improves reusability across robot platforms. We implement two reference generators: one for handling joint-space references and one for Cartesian references, along with a set of new controllers (PD with gravity compensation, Cartesian pose, and admittance controllers) and validate the approach on simulated and real Universal Robots and Franka Emika manipulators. Results show that (i) references are tracked reliably in all tested scenarios, (ii) reference generators reduce duplicated reference-handling code across chained controllers to favor the construction and reuse of complex controller pipelines, and (iii) controller implementations remain focused only on control laws.

</details>


### [14] [Keyframe-based Dense Mapping with the Graph of View-Dependent Local Maps](https://arxiv.org/abs/2601.08520)
*Krzysztof Zielinski,Dominik Belter*

Main category: cs.RO

TL;DR: 提出了一种基于关键帧的新映射系统，利用RGB-D传感器数据更新局部NDT地图，并通过姿态图存储这些局部地图以进行全局校正。此外，还提出了一种合并和过滤局部地图以获得环境全局地图的方法。


<details>
  <summary>Details</summary>
Motivation: 为了更好地利用RGB-D相机的特性和不确定性模型，提高靠近相机原点的对象表示精度，同时允许在检测到闭环后修正全局地图。

Method: 采用基于关键帧的方法来更新使用RGB-D传感器数据的局部NDT地图；将NDT单元格存储于2D视图依赖结构中；局部地图被保存在一个姿态图里，这有助于在检测到闭环后调整全球地图；另外开发了一套流程用于合并与过滤局部地图从而生成环境的整体地图。

Result: 该方法与Octomap和NDT-OM进行了比较，并提供了所提制图方法的一些应用示例。

Conclusion: 本文介绍的新方法能够更有效地利用RGB-D传感器的信息，为环境构建出更加准确的全局地图。

Abstract: In this article, we propose a new keyframe-based mapping system. The proposed method updates local Normal Distribution Transform maps (NDT) using data from an RGB-D sensor. The cells of the NDT are stored in 2D view-dependent structures to better utilize the properties and uncertainty model of RGB-D cameras. This method naturally represents an object closer to the camera origin with higher precision. The local maps are stored in the pose graph which allows correcting global map after loop closure detection. We also propose a procedure that allows merging and filtering local maps to obtain a global map of the environment. Finally, we compare our method with Octomap and NDT-OM and provide example applications of the proposed mapping method.

</details>


### [15] [QP-Based Control of an Underactuated Aerial Manipulator under Constraints](https://arxiv.org/abs/2601.08523)
*Nesserine Laribi,Mohammed Rida Mokhtari,Abdelaziz Benallegue,Abdelhafid El-Hadri,Mehdi Benallegue*

Main category: cs.RO

TL;DR: 本文提出了一种针对欠驱动空中操纵器的约束感知控制框架，通过二次规划求解动力学一致的广义加速度，同时考虑了欠驱动、执行器界限和系统约束。为了提高鲁棒性，引入了基于无源性的积分动作而不影响可行性。高保真物理模拟验证了该方法在真实操作条件下的有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决欠驱动空中操纵器在终端执行器轨迹跟踪时面临的准确度、安全性和可行性问题，同时增强对扰动、建模不确定性以及稳态误差的鲁棒性。

Method: 通过构建一个二次规划模型来计算满足欠驱动、执行器限制及系统约束的动力学一致广义加速度，并在扭矩层面整合基于无源性的积分作用以增加系统的鲁棒性。

Result: 高逼真度的物理仿真结果显示，所提方法能够在参数扰动、粘性关节摩擦以及实际传感与状态估计效应存在的情况下实现精确跟踪、平滑控制输入并可靠地满足约束条件。

Conclusion: 本研究提出的约束感知控制策略成功实现了欠驱动空中操纵器在复杂环境下的高效、安全操作，为未来相关领域的发展提供了新的思路和技术支持。

Abstract: This paper presents a constraint-aware control framework for underactuated aerial manipulators, enabling accurate end-effector trajectory tracking while explicitly accounting for safety and feasibility constraints. The control problem is formulated as a quadratic program that computes dynamically consistent generalized accelerations subject to underactuation, actuator bounds, and system constraints. To enhance robustness against disturbances, modeling uncertainties, and steady-state errors, a passivity-based integral action is incorporated at the torque level without compromising feasibility. The effectiveness of the proposed approach is demonstrated through high-fidelity physics-based simulations, which include parameter perturbations, viscous joint friction, and realistic sensing and state-estimation effects. This demonstrates accurate tracking, smooth control inputs, and reliable constraint satisfaction under realistic operating conditions.

</details>


### [16] [Real-Time Localization Framework for Autonomous Basketball Robots](https://arxiv.org/abs/2601.08713)
*Naren Medarametla,Sreejon Mondal*

Main category: cs.RO

TL;DR: 本文提出了一种结合经典技术和基于学习方法的混合定位算法，仅依赖于场地地面的视觉数据来实现篮球场上的自我定位。


<details>
  <summary>Details</summary>
Motivation: 在Robocon 2025中，准确可靠的定位对于提高射击精度、避免与其他机器人发生碰撞以及高效地穿越比赛场地至关重要。

Method: 提出了一种混合定位算法，该算法整合了经典技术与单纯依靠来自球场地面的视觉数据的学习型方法。

Result: 该论文主要提出了新方法的概念，并没有提供具体的结果或性能指标。

Conclusion: 该研究为自主机器人的定位问题提供了一个新的解决方案，特别是针对需要在动态环境中操作的情况。

Abstract: Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. In this paper, we propose a hybrid localization algorithm that integrates classical techniques with learning based methods that rely solely on visual data from the court's floor to achieve self-localization on the basketball field.

</details>


### [17] [Older Adults' Preferences for Feedback Cadence from an Exercise Coach Robot](https://arxiv.org/abs/2601.08819)
*Roshni Kaushik,Reid Simmons*

Main category: cs.RO

TL;DR: 研究了老年人对机器人教练不同节奏的口头和非口头反馈的反应，发现改变一种沟通方式的节奏会影响对两种方式的感知，从而为更好地设计针对这一人群的运动课程中机器人教练的反馈频率提供了依据。


<details>
  <summary>Details</summary>
Motivation: 了解老年人如何响应机器人教练在运动过程中提供的不同节奏的口头与非口头反馈，以优化人机交互体验。

Method: 通过在线研究的方式，让参与者评估机器人以不同节奏提供反馈的视频片段。

Result: 结果显示，改变任一沟通模式（口头或非口头）的节奏不仅会影响到该模式本身的感知，也会影响到另一种模式的感知。

Conclusion: 本研究表明，为了提升老年人与机器人教练互动的质量，需要综合考虑并调整口头及非口头反馈的节奏。

Abstract: People can respond to feedback and guidance in different ways, and it is important for robots to personalize their interactions and utilize verbal and nonverbal communication cues. We aim to understand how older adults respond to different cadences of verbal and nonverbal feedback of a robot exercise coach. We conducted an online study of older adults, where participants evaluated videos of the robot giving feedback at different cadences for each modality. The results indicate that changing the cadence of one modality affects the perception of both it and the other modality. We can use the results from this study to better design the frequency of the robot coach's feedback during an exercise session with this population.

</details>
