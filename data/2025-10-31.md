<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 本文提出了一种基于泊松方程和拉普拉斯引导场的数学方法，用于开发能够识别环境语义并据此做出安全行动决策的风险感知安全过滤器。通过解决狄利克雷问题来生成安全函数，并结合可调通量边界条件合成引导场，从而在确保系统安全的同时优先避开高风险障碍物。


<details>
  <summary>Details</summary>
Motivation: 机器人系统在现实环境中导航时需要对其环境具有语义理解能力，以正确判断安全行动。本文旨在为此类表示法奠定数学基础，特别是开发出具备风险意识的安全过滤器。

Method: 采用两步走的方法：首先，通过求解泊松方程的狄利克雷问题生成一个编码了系统安全性的安全函数；其次，单独求解拉普拉斯方程的狄利克雷问题来合成一个可以围绕障碍物编码不同谨慎级别的安全“引导场”，通过施加可调节的通量边界条件实现。最终将安全函数与引导场结合起来定义安全约束，并利用它来合成一个风险感知的安全过滤器。

Result: 该方法能够在模拟环境中展示如何直接将障碍物风险的事先理解融入到安全过滤器中，生成既安全又具有风险意识的行为。

Conclusion: 通过结合安全函数与根据环境特征相关联的风险水平所合成的引导场，本研究提出的方法能够保证安全性同时优先避开较高风险的障碍物，为机器人在复杂多变的真实世界设置中提供了更智能、更安全的导航策略。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a
representation--specifically, the goal is to develop safety filters that are
risk-aware. To this end, we take a two step approach: encoding an understanding
of the environment via Poisson's equation, and associated risk via Laplace
guidance fields. That is, we first solve a Dirichlet problem for Poisson's
equation to generate a safety function that encodes system safety as its
0-superlevel set. We then separately solve a Dirichlet problem for Laplace's
equation to synthesize a safe \textit{guidance field} that encodes variable
levels of caution around obstacles -- by enforcing a tunable flux boundary
condition. The safety function and guidance fields are then combined to define
a safety constraint and used to synthesize a risk-aware safety filter which,
given a semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [2] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 本文提出了一种新的姿态控制律，该方法更有效地利用了姿态误差欧拉轴角信息，确保闭环(Closed-Loop, CL)系统中存在唯一平衡姿态误差四元数，并通过数值模拟和实际飞行测试验证了其相较于高性能四元数控制器在稳定时间上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于连续四元数的姿态控制方法虽然有效，但未能保证闭环系统中存在唯一的平衡姿态误差四元数（AEQ），并且当绕姿态误差欧拉轴的旋转误差超过π弧度时，比例控制效果减弱。因此，研究旨在开发一种新类型的姿态控制律来解决这些问题。

Method: 介绍了一种新型姿态控制律，它更好地利用了姿态误差的欧拉轴角信息以确保闭环系统中有唯一的平衡点，并允许更加灵活地运用比例控制努力。此外，通过构建严格的Lyapunov函数证明了所提出的控制律能够使得闭环旋转系统的独特平衡状态达到一致渐近稳定。

Result: 通过数值仿真以及在一个小型四旋翼无人机上执行数十次实时翻滚恢复操作，实验结果表明，基于轴角的方法相比高性能量子控制器，在稳定时间方面表现出更优的飞行性能。

Conclusion: 提出的新姿态控制方法不仅解决了传统四元数控制方法存在的问题，还显示出在快速稳定飞行器姿态方面的显著优势。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [3] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: 开发了一种基于无人机和AI的实时交通事件检测系统DARTS，它结合了高机动性、热成像以及轻量级深度学习框架，实现了99%的检测准确率，并且在实际测试中比当地交通管理中心更早地检测到事故。


<details>
  <summary>Details</summary>
Motivation: 传统的交通事故检测方法灵活性有限，需要密集的基础设施或高渗透率，这限制了它们对变化中的事故热点地区的适应性和可扩展性。为了克服这些挑战，提出了DARTS系统。

Method: DARTS系统利用无人机的高移动性和空中视角进行自适应监控，使用热成像技术提高低可见度条件下的性能并保护隐私，采用轻量级深度学习框架实现实时车辆轨迹提取与事故检测。

Result: DARTS系统在自收集的数据集上达到了99%的检测准确率，并支持通过网页界面同时进行在线视觉验证、严重程度评估及事故引发的交通拥堵传播监测。实地测试表明，该系统比当地交通管理中心提前12分钟检测到了一起追尾碰撞事件。

Conclusion: DARTS展示了一个更加灵活集成的实时交通事件检测系统的潜力，对于提升现代交通管理的操作效率和响应速度具有重要意义，特别是在偏远地区和资源受限环境下显示出了潜在的可扩展性和成本效益。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [4] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 本研究提出了一种利用微型空中飞行器（MAVs）协作定位放射性物质的新方法，通过使用轻量级的康普顿相机作为探测器，并在机载直接处理数据来实时估计辐射源的位置。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种新的放射性物质定位方法，该方法能够利用轻便且灵敏的探测器并通过多个协作的微型飞行器实现实时定位甚至追踪移动中的辐射源。

Method: 采用先进的单探测器康普顿相机作为探测工具，其重量仅为40克；设计了一种新的基本概念来融合康普顿相机测量结果，以从极其稀疏的数据中实时估算辐射源位置；数据读出与处理均在机载进行，处理结果用于动态反馈控制飞行器运动；微型飞行器组成紧密合作群组以最大化获取信息、快速定位及追踪移动辐射源。

Result: 研究表明，所提出的方法能够在实际应用中有效地定位和追踪放射性物质来源。

Conclusion: 本研究展示了一种创新性的放射性物质定位技术，通过使用轻质康普顿相机和协作微型飞行器群实现了对辐射源的有效检测与跟踪。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [5] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究探讨了不同拟人化程度的机器人如何影响人们对机器人虐待的保护反应，发现中等拟人化的机器人引发了最强的生理愤怒表达，并且随着拟人化程度的增加，道德推理从对财产损失的技术评估转向对施虐者性格的谴责。


<details>
  <summary>Details</summary>
Motivation: 探索不同水平的拟人化如何影响人们对于机器人遭受虐待时的保护性反应，扩展了计算机作为社会行为者（CASA）理论和恐怖谷理论至道德领域。

Method: 通过实验邀请201名参与者观看展示针对低（蜘蛛型）、中（两足型）或高（类人型）拟人化程度机器人的虐待视频；结合自我报告调查、自动化面部表情分析获得的生理数据以及定性反思三种方式来进行综合分析。

Result: 结果显示，保护性反应并非线性变化。中等拟人化的两足机器人，在诡异感和“脊背发凉”的感觉上得分最高，与恐怖谷现象一致，引发最强烈的生理愤怒表达。相较于蜘蛛型机器人，两足型和类人型机器人在自报愤怒和内疚感方面显著更高。定性研究进一步揭示，随着拟人化程度增加，道德推理从对财产损害的技术评价转变为对施虐者个性的谴责，治理建议也从财产法扩展到呼吁准动物权利及更广泛的社会责任。

Conclusion: 研究表明，恐怖谷效应并未减弱道德关怀，反而反常地增强了保护冲动，为机器人设计、政策制定及未来法律框架提供了重要启示。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [6] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种基于混合状态树的运动学TAMP框架，通过将符号和数值状态统一表示来共同决定任务和运动决策。该方法利用现成的动作规划器和物理模拟器验证TAMP问题中的运动学约束，并使用VLM根据状态的视觉渲染引导探索TAMP解决方案并回溯搜索。实验表明，与传统的和基于LLM的TAMP规划器相比，本方法提高了平均成功率并减少了复杂问题上的规划时间。


<details>
  <summary>Details</summary>
Motivation: 现有的任务与运动规划（TAMP）方法在长时域问题中由于过度采样动作而成本高昂；虽然大型语言模型提供了常识先验，但缺乏3D空间推理能力且不能保证几何或动力学可行性。

Method: 开发了一种基于混合状态树的运动学TAMP框架，能够统一表示规划过程中的符号和数值状态，让任务与动作决策可以联合决定。此框架利用外部动作规划器及物理仿真软件检验嵌入TAMP问题中的动力学约束，并采用视觉-语言模型(VLM)来指导探索TAMP解法及依据状态可视化进行搜索回溯。

Result: 在模拟环境和真实世界测试中，相较于传统以及基于大型语言模型(LLMs)的任务与运动规划(TAMP)计划者，所提方法显示了32.14%到1166.67%不等的平均成功率提升，并且在处理复杂问题时减少了规划所需时间。消融研究进一步强调了VLM指引带来的益处。

Conclusion: 这项工作介绍了一个新的TAMP框架，它有效地结合了符号和数值状态以实现更高效的任务与运动规划。通过引入VLM指导，该框架不仅提高了成功率，还降低了解决复杂问题所需的规划时间。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [7] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种自适应轨迹精化算法，通过分段保守碰撞测试和基于穿透方向及线搜索的姿态校正来提高移动机器人在复杂环境中的轨迹规划成功率和速度。


<details>
  <summary>Details</summary>
Motivation: 在狭窄通道中，传统方法往往无法为移动机器人提供有效的路径规划或生成的路径不够理想。

Method: 本研究提出了自适应轨迹精化算法，包括两个主要阶段：1) 在路径段级别上应用分段保守碰撞测试，对存在风险的轨迹段进行递归细分直到消除碰撞风险；2) 为了保证姿态级别的安全性，采用基于穿透方向和线搜索的姿态校正方法，确保轨迹中的每个姿态都是无碰撞且与障碍物保持最大距离。

Result: 仿真结果显示，所提方法比现有最先进方法的成功率提高了最多1.69倍，并且规划时间加快了至多3.79倍。此外，实际实验验证了机器人能够安全快速地穿越狭窄区域。

Conclusion: 该算法有效提升了移动机器人在拥挤环境中规划安全高效路径的能力。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [8] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 本文提出了一种名为PHUMA的物理基础人形行走数据集，它通过大规模利用人类视频并结合仔细的数据管理和受物理限制的目标调整来解决现有方法中的物理缺陷。实验表明，使用PHUMA训练的策略在模仿多样动作方面优于现有的Humanoid-X和AMASS数据集。


<details>
  <summary>Details</summary>
Motivation: 当前基于运动捕捉数据集（如AMASS）的方法因数据稀缺且成本高而受到限制，同时从互联网视频转换而来的尝试又常引入影响稳定模仿的物理缺陷。

Method: 开发了PHUMA数据集，该数据集不仅能够大规模地利用人类视频，还通过精心的数据管理和符合物理约束的目标调整来消除关节限制、确保地面接触以及避免脚滑动等问题。

Result: PHUMA训练出的模型在模仿未见动作及仅以骨盆为指导的路径跟随任务上表现优于Humanoid-X和AMASS数据集。

Conclusion: PHUMA为人形机器人模仿学习提供了一个新的高质量数据源，有助于提高动作模仿的多样性和稳定性。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [9] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 提出了一种名为Thor的人形框架，旨在提高机器人在接触密集环境中的全身反应能力。通过力自适应躯干倾斜（FAT2）奖励函数和分层强化学习架构的设计，Thor能够显著改善机器人的力量交互任务表现，包括后退时达到167.7N的最大拉力、前进时145.5N的拉力，并且能够拉动载重架子及单手开启防火门等实际应用。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在服务、工业和救援应用中需要保持全身稳定的同时执行高强度、接触丰富的与环境互动的任务。然而，让人形机器人在这种条件下产生类似人类的适应性反应仍然是一个重大挑战。

Method: 提出了名为Thor的人形框架，基于对机器人受力分析设计了力自适应躯干倾斜（FAT2）奖励函数来鼓励机器人在进行力量互动任务时表现出类似人类的行为。为了减轻人形控制的高维度难题，Thor引入了一个将上身、腰部和下身解耦的强化学习架构，每个组件共享整个身体的全局观察并联合更新其参数。

Result: 实验结果表明，在力量互动任务中，使用Thor框架的Unitree G1机器人相比最佳基准分别提高了后退时最大拉力至167.7牛顿（约为G1体重的48%）和前进时拉力至145.5牛顿，分别提升了68.9%和74.7%。此外，该机器人还能拉动装载有130牛顿重量的架子以及单手打开需施加60牛顿力的防火门。

Conclusion: 研究结果证明了Thor框架在提升人形机器人力量互动能力方面的有效性。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [10] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: 本文介绍了一种名为AgriGS-SLAM的视觉-激光雷达同步定位与建图框架，该框架结合了直接激光雷达里程计和闭环操作以及多摄像头3D高斯渲染。它能够在果园中实现更清晰、更稳定的重建和更平滑的轨迹，并且在拖拉机上实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 为了使果园中的自主机器人能够实时理解3D场景，尽管存在重复的行几何形状、季节性外观变化和由风引起的树叶运动等挑战。

Method: 提出了一种名为AgriGS-SLAM的视觉-激光雷达SLAM框架，该框架整合了直接激光雷达里程计和环路闭合技术，以及多相机3D高斯点绘（3DGS）渲染。通过不同视角下的批量光栅化来恢复遮挡下的果园结构，同时，在关键帧之间执行统一的基于梯度的地图生命周期管理，以保留细节并限制内存使用。姿态优化受到一个基于激光雷达的概率深度一致性项引导，通过反向传播到相机投影进一步加强了几何-外观耦合。

Result: 在苹果和梨园中部署系统，跨越休眠期、开花期和收获期，并采用标准化轨迹协议评估训练视图和新视图合成，减少了3DGS过拟合。AgriGS-SLAM在整个季节和地区都提供了比最近的3DGS-SLAM基准更为清晰稳定地重建效果和平稳轨迹，同时保持了车上实时表现。

Conclusion: AgriGS-SLAM不仅在果园监控中表现出色，还可以应用于其他需要强大多模态感知的户外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [11] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了基于共形几何代数定义的几何基元来推导多臂机器人系统的协作任务空间的理论基础，通过相似变换抽象出复杂系统，使其能够直接对应单臂系统，并展示了如何将此方法集成到经典控制技术中。


<details>
  <summary>Details</summary>
Motivation: 为了解决在人类环境中需要多个运动链之间协作执行任务的问题，特别是针对具有大量自由度的复杂系统，本文旨在提供一种新的方法来简化这些系统的协调运动建模。

Method: 利用共形几何代数定义的几何基元，推导了多臂机器人系统协作任务空间的理论基础。接着，通过相似变换抽象出了一个可以代表复杂系统的模型，并且与单臂系统直接对应。进一步地，通过推导相关的解析和几何雅可比矩阵，展示了如何将该方法无缝集成进以操作空间控制为基础的经典控制技术之中。

Result: 本研究成功展示了一种新颖的方法论，可用于简化多臂机器人系统的控制问题，包括双臂操纵器、类人机器人以及多指手部的操作。此外，还讨论了如何自然地将零空间结构嵌入控制器中，以便引入次级控制目标。

Conclusion: 本文所提出的基于共形几何代数的协作操控控制框架理论基础为处理复杂的多臂机器人系统提供了新思路，不仅简化了这类系统的运动协调问题，而且也为未来的研究应用指明了方向。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [12] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: 本文提出了一种名为Hi-ORS的后训练方法，通过拒绝采样来实现训练稳定性和高鲁棒性。该方法在在线微调过程中过滤掉负奖励样本，并采用基于奖励加权的监督训练目标提供密集的中间步骤监督。实验表明，Hi-ORS能够在真实世界任务中以更高效的方式超越RL和IL基线方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）广泛用于生成稳健的机器人操作策略，但使用RL对视觉-语言-动作（VLA）模型进行微调时会因为价值估计不准确及中间步骤监督稀疏而不稳定。另一方面，模仿学习（IL）易于训练但由于其离线性质往往表现不佳。为了解决这些问题，提出了一个简单而有效的方法。

Method: 提出的方法叫做Hi-ORS，它利用拒绝采样技术来同时确保训练过程的稳定性和最终模型的鲁棒性。此方法通过剔除在线微调阶段带有负面奖励的样本以稳定价值估计，并且采取了基于奖励权重的监督学习目标来为中间步骤提供密集的指导信息。此外，还开发了一个支持灵活在线人机交互修正的异步推理-训练框架，这为人机互动提供了明确的学习错误恢复行为的指引。

Result: 在三个现实世界任务与两种具体应用形态下，Hi-ORS能够在一个半小时内完成对基础策略(pi-base)的微调，使其掌握接触丰富的操作技能，显著优于RL和IL基准方法，在效果和效率上均有大幅度提升。值得注意的是，经过微调后的策略表现出强大的测试时间可扩展性，能够可靠地执行复杂的错误恢复行为，从而达到更好的性能。

Conclusion: Hi-ORS作为一种新的后训练方法，在解决RL和IL固有问题方面展现出了巨大潜力，不仅提高了训练稳定性，也增强了模型应对复杂任务时的表现力。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [13] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种名为RoboOS-NeXT的统一内存框架，旨在实现多机器人系统的长期适应性、可扩展性和稳健协作。通过引入新的Spatio-Temporal-Embodiment Memory (STEM)作为核心组件，它整合了空间场景几何、时间事件历史和实体配置文件，以支持动态任务分配、容错协作和一致的状态同步。实验结果表明，在不同应用场景下，RoboOS-NeXT对于促进异构机器人间的终生合作表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人在各种任务和形态中的广泛应用，如何实现多智能体系统中的终身适应性、可扩展协调以及稳健调度成为了一个中心挑战。当前的方法如视觉-语言-行动模型及层次化框架因依赖于有限或个体化的记忆而无法满足长时学习、适应多样化团队或从失败中恢复的需求，这突显了开发一种统一的记忆表示方法的重要性。

Method: 为了解决上述限制，研究人员提出了RoboOS-NeXT，这是一个基于统一内存的框架，专门设计用于增强多机器人之间的终生合作能力。其核心是新颖的Spatio-Temporal-Embodiment Memory (STEM)，它能够将空间场景几何、时间上的事件历史以及身体特征整合到一个共享表示中。这种以记忆为中心的设计被融入到了一个大脑-小脑架构中，其中高级的大脑模型通过检索与更新STEM来进行全局规划，而低级控制器则负责局部执行动作。

Result: 通过一系列涵盖餐厅、超市及家庭等复杂协调任务的广泛实验，研究者们展示了RoboOS-NeXT能够在不同的物理形态下提供卓越的表现，验证了其在促进终生、可扩展且健壮的多机器人协作方面的有效性。

Conclusion: RoboOS-NeXT作为一种创新性的解决方案，成功地解决了多机器人系统中长期存在的适应性、可扩展性和稳定性问题。它通过引入统一的记忆表示法——STEM，并将其应用于一个模仿人脑工作机制的架构内，实现了更高效的任务分配、更强的错误容忍度以及更好的状态一致性。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [14] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 本文提出了一种新的框架，通过扩展机器人的逆运动学解算器能力，使机器人能够使用不同长度的工具执行一系列动作。该方法结合了从模拟学习到的动作轨迹与工具的实际应用，并展示了将学到的技能从模拟环境转移到现实世界中的可行性。实验表明，扩展后的逆运动学解算器误差小于1厘米，训练策略在模拟中平均误差为8厘米。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人对其自身运动学的理解有限，只能执行预先编程的任务，这限制了它们有效利用工具的能力。为了克服这一局限性，研究旨在开发一种新方法，让机器人能够更好地掌握工具使用的四个基本方面：理解期望结果、选择合适工具、确定最佳工具方向以及执行精确操作。

Method: 研究者们介绍了一种创新框架，它通过增强机器人逆运动学解算器的功能来实现对各种长度工具的有效使用。该方法首先在仿真环境中学习工具的动作轨迹，然后将这些知识应用于实际场景中，证明了所学技能可以在真实世界中得到很好的迁移。

Result: 实验结果显示，改进后的逆运动学解算器达到了小于1厘米的误差率，在模拟环境下训练的策略平均误差为8厘米。更重要的是，当使用两种不同长度的工具时，模型表现几乎无差异。

Conclusion: 本研究表明，在探索工具使用的所有四个基本方面上取得了潜在进展，使得机器人能够在多种任务中精通复杂的工具操控艺术。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [15] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种针对连续体机器人（CRs）的滑动窗口滤波器（SWF），该方法在保持在线运行的同时，提高了状态估计的准确性，并实现了比实时更快的速度。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人的随机状态估计方法难以同时兼顾准确性和计算效率。尽管已有研究探索了适用于CRs的滑窗公式化方法，但这些方法仅限于简化的离散时间近似，并且不提供随机表示。另一方面，当前的随机滤波器方法必须以测量的速度运行，这限制了它们发挥全部潜力。最近，在连续时间估计技术方面的工作为解决运行时约束提供了一个有原则的方法，但目前仅限于离线操作。

Method: 本文介绍了一种用于连续体机器人连续时间状态估计的滑动窗口滤波器(SWF)，该方法在提高滤波方法准确性的同时，使连续时间方法能够在线运行，并且运行速度超过了实时速度。

Result: 所提出的滑动窗口滤波器是专门为CRs设计的第一款随机SWF，它不仅提升了过滤方法的精度，还允许连续时间方法进行在线操作，同时以超过实时的速度运行。

Conclusion: 这项工作代表了连续体机器人领域内首次专门设计的随机滑动窗口滤波器，为未来的研究提供了有希望的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [16] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 提出了一种名为Hybrid Consistency Policy (HCP)的方法，通过结合短随机前缀和一步一致性跳跃来生成最终动作，并采用时变一致性蒸馏以保持预测一致性和提高局部保真度。实验表明，HCP在减少延迟的同时达到了与80步DDPM教师模型相近的准确率和模式覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有的基于普通和随机去噪过程的方法难以同时实现快速采样和强大的多模态表现。

Method: HCP方法首先运行一段短随机前缀直至自适应切换时间点，之后执行一步一致性跳跃生成最终动作；并通过一种时变的一致性蒸馏方法，该方法结合了轨迹一致性目标（确保相邻预测的一致性）和去噪匹配目标（提升局部保真度）。

Result: 在模拟环境及真实机器人上进行测试的结果显示，仅使用25个SDE步骤加上一次跳跃的HCP接近了需要80步的DDPM教师模型在精度和模式覆盖上的表现，同时显著降低了延迟。

Conclusion: 研究结果表明，维持多模态表现并不一定需要慢速推理过程，通过调整切换时间可以在保留模式多样性的同时加快速度，从而为机器人策略提供了一个实用的准确性和效率之间的权衡方案。

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [17] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 本研究展示了如何使用单个消费级GPU以30Hz的帧率和最高480Hz的轨迹频率运行pi0级别的多视图VLA，通过引入一系列策略消除了模型推理中的开销，使得动态和实时任务成为可能。实验结果表明，在抓取掉落笔的任务中达到了100%的成功率，并进一步提出了一个用于VLA实时机器人控制的全流式推理框架。


<details>
  <summary>Details</summary>
Motivation: 旨在克服大型VLA模型在执行动态及实时任务时遇到的挑战，特别是提高处理速度与效率的问题。

Method: 采用了一系列优化策略来减少模型推理过程中的延迟问题，包括但不限于算法优化、硬件充分利用等方法。

Result: 成功地实现了以30Hz帧率和高达480Hz轨迹频率运行pi0级多视角VLA的目标；在实际测试中，对于捕捉下落物体（如笔）的任务获得了100%成功率。

Conclusion: 通过实施特定优化策略，证明了即使是大规模VLA模型也能完成以前被认为不可能实现的动态和实时任务。此外，还提出了一种适用于VLA实时控制的新颖全流式推理架构。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>
