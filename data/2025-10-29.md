<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 27]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [RoboOmni: Proactive Robot Manipulation in Omni-modal Context](https://arxiv.org/abs/2510.23763)
*Siyin Wang,Jinlan Fu,Feihong Liu,Xinzhe He,Huangxuan Wu,Junhao Shi,Kexin Huang,Zhaoye Fei,Jingjing Gong,Zuxuan Wu,Yugang Jiang,See-Kiong Ng,Tat-Seng Chua,Xipeng Qiu*

Main category: cs.RO

TL;DR: The paper introduces RoboOmni, a framework for robotic manipulation that recognizes user intentions through cross-modal contextual instructions. It excels in intention recognition and proactive assistance by fusing auditory and visual signals. The OmniAction dataset is also introduced to support the training of such models.


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉-语言-动作模型中取得了快速进展，但这些方法主要依赖于明确的指令。在现实世界的人机交互中，人类很少直接发出指令，因此需要机器人能够主动推断用户的意图。

Method: 本文提出了RoboOmni框架，该框架基于端到端全模态LLM，整合了意图识别、交互确认和动作执行。RoboOmni通过时空融合听觉与视觉信号来实现鲁棒的意图识别，并支持直接语音互动。此外，还构建了一个名为OmniAction的数据集以解决缺乏训练数据的问题。

Result: 实验结果表明，在模拟环境和真实环境中，RoboOmni在成功率、推理速度、意图识别以及主动协助方面均优于基于文本和自动语音识别的基础模型。

Conclusion: 这项工作展示了如何利用跨模态上下文指令提升机器人操作中的意图理解能力，为更自然流畅的人机协作提供了新的解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid
progress in Vision-Language-Action (VLA) models for robotic manipulation.
Although effective in many scenarios, current approaches largely rely on
explicit instructions, whereas in real-world interactions, humans rarely issue
instructions directly. Effective collaboration requires robots to infer user
intentions proactively. In this work, we introduce cross-modal contextual
instructions, a new setting where intent is derived from spoken dialogue,
environmental sounds, and visual cues rather than explicit commands. To address
this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor
framework based on end-to-end omni-modal LLMs that unifies intention
recognition, interaction confirmation, and action execution. RoboOmni fuses
auditory and visual signals spatiotemporally for robust intention recognition,
while supporting direct speech interaction. To address the absence of training
data for proactive intention recognition in robotic manipulation, we build
OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640
backgrounds, and six contextual instruction types. Experiments in simulation
and real-world settings show that RoboOmni surpasses text- and ASR-based
baselines in success rate, inference speed, intention recognition, and
proactive assistance.

</details>


### [2] [Motivating Students' Self-study with Goal Reminder and Emotional Support](https://arxiv.org/abs/2510.23860)
*Hyung Chan Cho,Go-Eum Cha,Yanfu Liu,Sooyeon Jeong*

Main category: cs.RO

TL;DR: 本研究探索了社交机器人作为大学生自学同伴的角色，通过提供目标提醒和积极情绪支持来影响学生的专注度、生产力和参与度。结果显示，与仅提供物理存在的机器人相比，参与者认为有目标提醒和情感支持的机器人更易于使用，并且对机器人的满意度与其被视为社交对象的程度相关，这对他们的学习目标达成有预测作用。


<details>
  <summary>Details</summary>
Motivation: 虽然社交机器人在支持人们完成学习任务方面的有效性已经被广泛研究，但它们在帮助学生自学方面的影响尚未得到充分探讨。

Method: 进行了一个探索性的巫师实验（Wizard-of-Oz study），以探究这些机器人支持行为如何影响学生感知到的专注度、生产力以及与仅提供物理存在（对照组）的机器人相比的参与度。

Result: 结果表明，在目标提醒条件下的参与者报告了更高的易用性感受，并表达了在未来学习会话中使用该机器人的更大意愿。此外，发现参与者对机器人的满意程度与他们将机器人视为社交他者的感觉有关，这种感觉被发现是他们在自学任务中实现目标水平的一个预测因素。

Conclusion: 这些发现突出了社会辅助机器人通过功能性和情感性互动来支持自我学习的潜力。

Abstract: While the efficacy of social robots in supporting people in learning tasks
has been extensively investigated, their potential impact in assisting students
in self-studying contexts has not been investigated much. This study explores
how a social robot can act as a peer study companion for college students
during self-study tasks by delivering task-oriented goal reminder and positive
emotional support. We conducted an exploratory Wizard-of-Oz study to explore
how these robotic support behaviors impacted students' perceived focus,
productivity, and engagement in comparison to a robot that only provided
physical presence (control). Our study results suggest that participants in the
goal reminder and the emotional support conditions reported greater ease of
use, with the goal reminder condition additionally showing a higher willingness
to use the robot in future study sessions. Participants' satisfaction with the
robot was correlated with their perception of the robot as a social other, and
this perception was found to be a predictor for their level of goal achievement
in the self-study task. These findings highlight the potential of socially
assistive robots to support self-study through both functional and emotional
engagement.

</details>


### [3] [Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped](https://arxiv.org/abs/2510.23902)
*Jans Solano,Diego Quiroz*

Main category: cs.RO

TL;DR: 本文提出了一种低成本轮式四足机器人上的恢复感知视觉惯性导航系统，利用深度相机的视觉感知和深度强化学习策略实现不同地形上的鲁棒运动与自主恢复。


<details>
  <summary>Details</summary>
Motivation: 现有的许多先进的轮腿机器人依赖于昂贵的执行器和传感器，并且很少集成跌倒恢复功能，特别是对于轮腿形态。这限制了这类机器人在成本受限平台中的应用。

Method: 本研究开发了一个结合视觉感知（使用深度相机）和深度强化forcement学习策略的导航系统，以促进轮式四足机器人的鲁棒移动及自动从多种地形上恢复的能力。

Result: 仿真实验表明，该系统能够在不规则地形上使用低扭矩执行器实现敏捷移动，并能可靠地从外部扰动和自身引起的故障中恢复过来。此外，在结构化的室内空间中也展示了目标导向的导航能力。

Conclusion: 通过这种方法，降低了预算有限的机器人平台上部署自主导航和鲁棒运动策略的门槛。

Abstract: Wheeled-legged robots combine the efficiency of wheels with the obstacle
negotiation of legs, yet many state-of-the-art systems rely on costly actuators
and sensors, and fall-recovery is seldom integrated, especially for
wheeled-legged morphologies. This work presents a recovery-aware
visual-inertial navigation system on a low-cost wheeled quadruped. The proposed
system leverages vision-based perception from a depth camera and deep
reinforcement learning policies for robust locomotion and autonomous recovery
from falls across diverse terrains. Simulation experiments show agile mobility
with low-torque actuators over irregular terrain and reliably recover from
external perturbations and self-induced failures. We further show goal directed
navigation in structured indoor spaces with low-cost perception. Overall, this
approach lowers the barrier to deploying autonomous navigation and robust
locomotion policies in budget-constrained robotic platforms.

</details>


### [4] [A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons](https://arxiv.org/abs/2510.23954)
*Pejman Kheradmand,Behnam Moradkhani,Raghavasimhan Sankaranarayanan,Kent K. Yamamoto,Tanner J. Zachem,Patrick J. Codd,Yash Chitalia,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 提出了一种基于Cosserat杆框架的模型，用于描述n个由m_i条肌腱驱动的同心管机械系统。该模型允许每个管子扭转和伸长，同时保持弯曲时共享中心线，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的肌腱驱动连续体机器人和同心管机器人都存在各自的局限性，如自由度受限和不稳定等问题。本文旨在为这些系统提供一个完整且通用的力学模型。

Method: 采用基于Cosserat杆的方法建立了一个针对n个同心管（每个由m_i条肌腱驱动）的一般情况下的建模框架。模型设计使得每根管子能够扭曲和拉伸，同时在弯曲过程中维持共同的中心轴线。

Result: 通过两管和三管组件的不同肌腱布线配置实验，证实所提出的框架的有效性，达到尖端预测误差小于机器人总长度的4%。此外，将此模型应用于现有机器人中，最大尖端偏差约为总长度的5%左右。

Conclusion: 本研究提供的模型为精确估计及控制高级肌腱驱动同心管机器人形状奠定了基础。

Abstract: Tendon-actuated concentric tube mechanisms combine the advantages of
tendon-driven continuum robots and concentric tube robots while addressing
their respective limitations. They overcome the restricted degrees of freedom
often seen in tendon-driven designs, and mitigate issues such as snapping
instability associated with concentric tube robots. However, a complete and
general mechanical model for these systems remains an open problem. In this
work, we propose a Cosserat rod-based framework for modeling the general case
of $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \{1,
\ldots, n\}$. The model allows each tube to twist and elongate while enforcing
a shared centerline for bending. We validate the proposed framework through
experiments with two-tube and three tube assemblies under various tendon
routing configurations, achieving tip prediction errors $<4\%$ of the robot's
total length. We further demonstrate the model's generality by applying it to
existing robots in the field, where maximum tip deviations remain around $5\%$
of the total length. This model provides a foundation for accurate shape
estimation and control of advanced tendon-actuated concentric tube robots.

</details>


### [5] [Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping](https://arxiv.org/abs/2510.23963)
*Hiroki Ishikawa,Kyosuke Ishibashi,Ko Yamamoto*

Main category: cs.RO

TL;DR: 本文介绍了一种能够自适应扭曲变形以包裹物体的软体机器人手指，通过单一驱动源实现，并展示了其抓取不同物体的基本实验结果。


<details>
  <summary>Details</summary>
Motivation: 为了使软手能从密集排列的多个物体中抓取并拾起一个物体，需要一种能够在平面内和平面外方向上自适应扭曲变形的软手指。这种能力使得手指可以深入到物体间的有限缝隙中，并在接触表面保持适当的抓握力来维持扭曲形态。

Method: 提出了一种可变刚度机制，该机制能够随着压力增加自适应地改变刚度。基于有限元分析（FEA）确定了所提机制的设计参数。

Result: 使用开发出的软手指进行了基本实验和演示，证明了它抓取各种物体的能力。

Conclusion: 本研究提出的软手指成功实现了自适应扭曲变形功能，对于提高软手处理复杂环境下的抓取任务具有重要意义。

Abstract: This paper presents a soft robot finger capable of adaptive-twist deformation
to grasp objects by wrapping them. For a soft hand to grasp and pick-up one
object from densely contained multiple objects, a soft finger requires the
adaptive-twist deformation function in both in-plane and out-of-plane
directions. The function allows the finger to be inserted deeply into a limited
gap among objects. Once inserted, the soft finger requires appropriate control
of grasping force normal to contact surface, thereby maintaining the twisted
deformation. In this paper, we refer to this type of grasping as grasping by
wrapping. To achieve these two functions by a single actuation source, we
propose a variable stiffness mechanism that can adaptively change the stiffness
as the pressure is higher. We conduct a finite element analysis (FEA) on the
proposed mechanism and determine its design parameter based on the FEA result.
Using the developed soft finger, we report basic experimental results and
demonstrations on grasping various objects.

</details>


### [6] [VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion](https://arxiv.org/abs/2510.23997)
*Stanley Wu,Mohamad H. Danesh,Simon Li,Hanna Yurchyk,Amin Abyaneh,Anas El Houssaini,David Meger,Hsiu-Chin Lin*

Main category: cs.RO

TL;DR: 本文提出了一种名为VOCALoco的模块化技能选择框架，该框架能够基于感知输入动态调整腿部机器人的运动策略。相比传统的端到端深度强化学习方法，VOCALoco在楼梯行走任务中表现出更高的安全性和能效。


<details>
  <summary>Details</summary>
Motivation: 尽管目前腿部机器人运动技术取得了进展，但许多现有方法依赖于端到端深度强化学习（DRL），这在安全性与可解释性方面存在局限，尤其是在适应新地形时。为解决这些问题，研究者开发了VOCALoco。

Method: VOCALoco通过评估预训练运动策略的安全性和能耗来动态调整策略。它预测执行安全性和固定规划范围内的运输成本，从而选择既安全又节能的策略。

Result: 实验结果表明，在模拟和真实世界场景下的楼梯攀爬任务中，VOCALoco相较于传统端到端DRL策略实现了更好的鲁棒性和安全性。

Conclusion: VOCALoco提供了一种更安全、更节能的方法来改进腿部机器人在复杂地形中的移动性能。

Abstract: Recent advancements in legged robot locomotion have facilitated traversal
over increasingly complex terrains. Despite this progress, many existing
approaches rely on end-to-end deep reinforcement learning (DRL), which poses
limitations in terms of safety and interpretability, especially when
generalizing to novel terrains. To overcome these challenges, we introduce
VOCALoco, a modular skill-selection framework that dynamically adapts
locomotion strategies based on perceptual input. Given a set of pre-trained
locomotion policies, VOCALoco evaluates their viability and energy-consumption
by predicting both the safety of execution and the anticipated cost of
transport over a fixed planning horizon. This joint assessment enables the
selection of policies that are both safe and energy-efficient, given the
observed local terrain. We evaluate our approach on staircase locomotion tasks,
demonstrating its performance in both simulated and real-world scenarios using
a quadrupedal robot. Empirical results show that VOCALoco achieves improved
robustness and safety during stair ascent and descent compared to a
conventional end-to-end DRL policy

</details>


### [7] [Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model](https://arxiv.org/abs/2510.24029)
*Andrew Gerstenslager,Bekarys Dukenbaev,Ali A. Minai*

Main category: cs.RO

TL;DR: 本研究通过在边界向量细胞（BVCs）模型中加入垂直角度敏感性，解决了二维模型在水平对称环境中的空间模糊问题，从而提高了三维环境中生物启发式机器人模型的空间定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数计算BVC模型局限于二维环境，在存在水平对称性的环境中容易产生空间上的歧义。为了解决这一局限性，研究者们希望开发一种能够处理三维空间的BVC模型，以提高在复杂环境下的空间定位准确性。

Method: 研究者提出了一种新的BVC框架，该框架加入了垂直角敏感性，允许在三维空间内进行鲁棒的边界检测。新模型使用LiDAR数据来捕捉垂直轮廓，从而区分了仅依靠二维表示无法区分开来的地点。

Result: 实验结果显示，在垂直变化很小的环境中，所提出的3D模型与2D基线性能相当；但随着3D复杂度的增加，它产生了更加明显的场所场，并显著减少了空间混淆现象。

Conclusion: 通过给基于BVC的定位添加一个垂直维度，可以显著增强真实世界3D空间中的导航和映射能力，同时保持在较简单、近乎平面场景下的性能一致性。

Abstract: Boundary Vector Cells (BVCs) are a class of neurons in the brains of
vertebrates that encode environmental boundaries at specific distances and
allocentric directions, playing a central role in forming place fields in the
hippocampus. Most computational BVC models are restricted to two-dimensional
(2D) environments, making them prone to spatial ambiguities in the presence of
horizontal symmetries in the environment. To address this limitation, we
incorporate vertical angular sensitivity into the BVC framework, thereby
enabling robust boundary detection in three dimensions, and leading to
significantly more accurate spatial localization in a biologically-inspired
robot model.
  The proposed model processes LiDAR data to capture vertical contours, thereby
disambiguating locations that would be indistinguishable under a purely 2D
representation. Experimental results show that in environments with minimal
vertical variation, the proposed 3D model matches the performance of a 2D
baseline; yet, as 3D complexity increases, it yields substantially more
distinct place fields and markedly reduces spatial aliasing. These findings
show that adding a vertical dimension to BVC-based localization can
significantly enhance navigation and mapping in real-world 3D spaces while
retaining performance parity in simpler, near-planar scenarios.

</details>


### [8] [Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation](https://arxiv.org/abs/2510.24055)
*Xiucheng Zhang,Yang Jiang,Hongwei Qing,Jiashuo Bai*

Main category: cs.RO

TL;DR: 本文提出了一种结合语言条件视觉表示模块和语言条件混合专家密度策略的框架，以解决多任务机器人操作中的感知模糊性和任务冲突问题。实验结果表明，该方法在实际机器人基准测试中显著提高了操作成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决模仿学习中由于感知模糊性和任务冲突限制了多任务机器人操作的问题，作者提出了一个新框架。

Method: 所提出的框架包括两个主要组成部分：一个是语言条件视觉表示（LCVR）模块，它通过将视觉特征与语言指令相结合来解决感知上的不确定性；另一个是语言条件混合专家密度策略（LMoE-DP），采用稀疏专家架构针对不同的动作分布进行专门化处理，并通过梯度调节增强稳定性。

Result: 实验结果显示，在真实机器人基准测试上，LCVR能够使得基于Transformer的动作分块（ACT）以及扩散策略（DP）的成功率分别提高33.75%和25%。整个框架平均达到了79%的成功率，比先进的基线方法高出21%。

Conclusion: 研究表明，通过结合语义基础和专家特化可以实现鲁棒且高效的多任务操作。

Abstract: Perceptual ambiguity and task conflict limit multitask robotic manipulation
via imitation learning. We propose a framework combining a Language-Conditioned
Visual Representation (LCVR) module and a Language-conditioned
Mixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual
ambiguities by grounding visual features with language instructions, enabling
differentiation between visually similar tasks. To mitigate task conflict,
LMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal
action distributions, stabilized by gradient modulation. On real-robot
benchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion
Policy (DP) success rates by 33.75% and 25%, respectively. The full framework
achieves a 79% average success, outperforming the advanced baseline by 21%. Our
work shows that combining semantic grounding and expert specialization enables
robust, efficient multi-task manipulation

</details>


### [9] [Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition](https://arxiv.org/abs/2510.24067)
*Tianyi Ding,Ronghao Zheng,Senlin Zhang,Meiqin Liu*

Main category: cs.RO

TL;DR: 该论文提出了一种新的拓扑地图结构，用于多机器人在障碍物密集的非凸环境中进行在线探索。通过分布式加权拓扑图Voronoi算法实现探索区域的均衡划分，并且优化了探索目标访问顺序以减少行进距离。实验结果表明这种方法在探索效率、完整性和工作负载平衡方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多机器人系统在复杂环境下的自主在线探索问题，特别是如何有效地进行探索区域划分和任务分配，以达到动态平衡的目标。

Method: 提出了一种能够同时描述空间连通性和全局探索完整性的新拓扑地图结构；引入了分布式加权拓扑图Voronoi算法来实现融合后的拓扑地图中图空间的均衡划分；局部规划器优化了探索目标访问顺序，减少了行进距离并生成了安全平滑且动态可行的动作轨迹。

Result: 与最先进方法相比，在探索效率、完成度以及机器人团队间的工作负荷平衡上取得了显著改进。

Conclusion: 本研究为多机器人系统提供了有效的在线探索策略，特别是在处理障碍物密集型非凸环境时显示出了优越性。

Abstract: This work addresses the collaborative multi-robot autonomous online
exploration problem, particularly focusing on distributed exploration planning
for dynamically balanced exploration area partition and task allocation among a
team of mobile robots operating in obstacle-dense non-convex environments.
  We present a novel topological map structure that simultaneously
characterizes both spatial connectivity and global exploration completeness of
the environment. The topological map is updated incrementally to utilize known
spatial information for updating reachable spaces, while exploration targets
are planned in a receding horizon fashion under global coverage guidance.
  A distributed weighted topological graph Voronoi algorithm is introduced
implementing balanced graph space partitions of the fused topological maps.
Theoretical guarantees are provided for distributed consensus convergence and
equitable graph space partitions with constant bounds.
  A local planner optimizes the visitation sequence of exploration targets
within the balanced partitioned graph space to minimize travel distance, while
generating safe, smooth, and dynamically feasible motion trajectories.
  Comprehensive benchmarking against state-of-the-art methods demonstrates
significant improvements in exploration efficiency, completeness, and workload
balance across the robot team.

</details>


### [10] [Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition](https://arxiv.org/abs/2510.24069)
*Sangmin Kim,Hajun Kim,Gijeong Kim,Min-Gyu Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 本文提出了一种基于相位的轨迹优化方法，能够同时计算机器人的路径和接触序列，并在问题公式中精确地考虑了动力学。该方法利用线性微分方程的叠加性质解耦每个接触点的平移动力学，并通过Bézier多项式的微分矩阵确保了机器人位置与力之间的一致关系，满足平移动力学。此外，借助Bézier多项式的凸闭包性质，本方法保证了摩擦锥约束的遵守。


<details>
  <summary>Details</summary>
Motivation: 为了通过轨迹优化为腿式机器人生成可靠的运动，必须同时计算机器人的路径和接触序列，并且在问题公式中准确考虑动力学因素。

Method: 研究者们提出了一个基于相位的轨迹优化框架，该框架利用线性微分方程的叠加特性来解耦各个接触点的平移动力学，这些接触点在不同的阶段序列下工作。此外，通过使用Bézier多项式的微分矩阵来推导出机器人位置与力之间的解析关系，从而确保平移动力学始终得到满足。再者，通过利用Bézier多项式的凸闭包属性，该方法确保了摩擦锥约束在整个轨迹上的遵循。

Result: 所提出的轨迹优化框架能够为腿式机器人生成具有各种步态序列的动态可靠动作。研究团队采用四足机器人模型对该框架进行了验证，重点放在动力学可行性和动作生成上。

Conclusion: 本文介绍的方法提供了一种新的途径，用于解决腿式机器人运动规划过程中遇到的动力学挑战，特别是在同时处理路径规划、接触序列确定以及保持动力学约束方面。

Abstract: To generate reliable motion for legged robots through trajectory
optimization, it is crucial to simultaneously compute the robot's path and
contact sequence, as well as accurately consider the dynamics in the problem
formulation. In this paper, we present a phase-based trajectory optimization
that ensures the feasibility of translational dynamics and friction cone
constraints throughout the entire trajectory. Specifically, our approach
leverages the superposition properties of linear differential equations to
decouple the translational dynamics for each contact point, which operates
under different phase sequences. Furthermore, we utilize the differentiation
matrix of B{\'e}zier polynomials to derive an analytical relationship between
the robot's position and force, thereby ensuring the consistent satisfaction of
translational dynamics. Additionally, by exploiting the convex closure property
of B{\'e}zier polynomials, our method ensures compliance with friction cone
constraints. Using the aforementioned approach, the proposed trajectory
optimization framework can generate dynamically reliable motions with various
gait sequences for legged robots. We validate our framework using a quadruped
robot model, focusing on the feasibility of dynamics and motion generation.

</details>


### [11] [ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring](https://arxiv.org/abs/2510.24108)
*Zhenxin Li,Wenhao Yao,Zi Wang,Xinglong Sun,Jingde Chen,Nadine Chang,Maying Shen,Jingyu Song,Zuxuan Wu,Shiyi Lan,Jose M. Alvarez*

Main category: cs.RO

TL;DR: 提出了ZTRS框架，该框架完全基于强化学习从原始传感器数据中进行端到端的自动驾驶学习，无需模仿学习。通过使用离线强化学习和详尽策略优化（EPO）方法，ZTRS在三个基准测试中表现出色，特别是在Navhard上达到了最先进的结果，并在HUGSIM上超过了基于模仿学习的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶系统要么依赖于可能受到次优演示和部署期间协变量偏移限制的模仿学习（IL），要么受限于低维度符号输入的强化学习（RL）。为了克服这些局限性，本研究旨在开发一种新的方法，能够直接处理高维传感器数据同时仅依靠奖励来学习，从而提高规划鲁棒性并充分利用感知信息。

Method: ZTRS框架结合了无损失信息的传感器输入与强化学习训练以实现稳健规划。它采用了离线强化学习及一种为可枚举动作和奖励定制的策略梯度变体——详尽策略优化（EPO）。这种方法允许模型直接从原始传感器数据中学习而不需要任何模仿学习成分。

Result: ZTRS在Navtest、Navhard以及HUGSIM这三个不同难度级别的基准测试中均表现出色。特别地，在具有挑战性的Navhard场景中，ZTRS达到了最先进水平；而在模拟闭环驾驶环境HUGSIM中，其性能也优于基于模仿学习的方法。

Conclusion: ZTRS代表了一种全新的端到端自动驾驶学习范式，它通过去除模仿学习部分并专注于直接从奖励中学习来处理复杂的感官输入。这不仅提高了系统对于新环境的适应能力，还展示了在多个实际和合成驾驶场景下的优越性能。

Abstract: End-to-end autonomous driving maps raw sensor inputs directly into
ego-vehicle trajectories to avoid cascading errors from perception modules and
to leverage rich semantic cues. Existing frameworks largely rely on Imitation
Learning (IL), which can be limited by sub-optimal expert demonstrations and
covariate shift during deployment. On the other hand, Reinforcement Learning
(RL) has recently shown potential in scaling up with simulations, but is
typically confined to low-dimensional symbolic inputs (e.g. 3D objects and
maps), falling short of full end-to-end learning from raw sensor data. We
introduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory
Scoring), a framework that combines the strengths of both worlds: sensor inputs
without losing information and RL training for robust planning. To the best of
our knowledge, ZTRS is the first framework that eliminates IL entirely by only
learning from rewards while operating directly on high-dimensional sensor data.
ZTRS utilizes offline reinforcement learning with our proposed Exhaustive
Policy Optimization (EPO), a variant of policy gradient tailored for enumerable
actions and rewards. ZTRS demonstrates strong performance across three
benchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop
planning in challenging real-world and synthetic scenarios), and HUGSIM
(simulated closed-loop driving). Specifically, ZTRS achieves the
state-of-the-art result on Navhard and outperforms IL-based baselines on
HUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.

</details>


### [12] [LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation](https://arxiv.org/abs/2510.24118)
*Haotian Zhou,Xiaole Wang,He Li,Fusheng Sun,Shengyu Guo,Guolei Qi,Jianghuan Xu,Huijing Zhao*

Main category: cs.RO

TL;DR: 提出了LagMemo，一种利用语言3D高斯喷绘记忆实现多模态、开放词汇和多目标视觉导航的系统。实验结果表明，LagMemo在多目标视觉导航上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统视觉导航方法局限于单一目标、单一模式以及封闭目标集设置的问题，并满足多模态、开放词汇目标查询及多目标视觉导航的实际需求。

Method: 开发了LagMemo系统，该系统通过构建统一的3D语言记忆，在接收任务目标时能够查询记忆、预测候选目标位置，并结合基于局部感知的验证机制来动态匹配与确认导航过程中的目标。

Result: 实验结果显示，LagMemo的记忆模块能够有效地定位多模态开放词汇的目标，并且在多目标视觉导航方面超过了最先进的方法。

Conclusion: LagMemo提供了一种新的方式来处理多模态、开放词汇的多目标视觉导航问题，其表现优于当前最先进方法。

Abstract: Navigating to a designated goal using visual information is a fundamental
capability for intelligent robots. Most classical visual navigation methods are
restricted to single-goal, single-modality, and closed set goal settings. To
address the practical demands of multi-modal, open-vocabulary goal queries and
multi-goal visual navigation, we propose LagMemo, a navigation system that
leverages a language 3D Gaussian Splatting memory. During exploration, LagMemo
constructs a unified 3D language memory. With incoming task goals, the system
queries the memory, predicts candidate goal locations, and integrates a local
perception-based verification mechanism to dynamically match and validate goals
during navigation. For fair and rigorous evaluation, we curate GOAT-Core, a
high-quality core split distilled from GOAT-Bench tailored to multi-modal
open-vocabulary multi-goal visual navigation. Experimental results show that
LagMemo's memory module enables effective multi-modal open-vocabulary goal
localization, and that LagMemo outperforms state-of-the-art methods in
multi-goal visual navigation. Project page:
https://weekgoodday.github.io/lagmemo

</details>


### [13] [Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames](https://arxiv.org/abs/2510.24194)
*Ev Zisselman,Mirco Mutti,Shelly Francis-Meretzki,Elisei Shafer,Aviv Tamar*

Main category: cs.RO

TL;DR: 本文提出了一种让演示者在不完全信息的情况下进行任务演示的方法，称为'蒙眼专家'。通过模仿这种'蒙眼专家'的行为，学习到的策略相比完全知情情况下的策略能够更好地泛化到未见过的任务。理论分析和实验结果均表明，这种方法可以减少所需演示任务的数量同时提高泛化性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高行为克隆方法在物理世界中对于多种不同任务的泛化能力，研究者们探索了限制给演示者的任务信息量这一途径。目的是促使演示者采用更复杂的探索策略来完成任务，从而可能促进所学模型对于新任务有更好的适应性。

Method: 设计实验让人类或智能体在有限的信息条件下（即‘蒙眼’）完成指定任务，并记录其行为作为训练数据；然后使用这些数据训练模型，比较其与传统全信息条件下的行为克隆模型在处理新任务时的表现差异。此外，还提供了支持该发现的理论分析。

Result: 实验证明，在机器人钉子插入任务及Procgen基准测试中的视频游戏中，模仿‘蒙眼专家’的行为比模仿拥有全部信息的专家更能增强对未知任务的泛化能力。理论上也证明了泛化误差与演示者可获得的任务信息量I以及演示任务数量m之间存在特定关系。

Conclusion: 通过限制演示者可以获得的任务相关信息量，强迫其采取更加多样化的探索方式解决问题，这样的做法确实有助于提高从演示中学习到的行为策略对于新情境下的适应性和泛化能力。

Abstract: Behavioral cloning is a simple yet effective technique for learning
sequential decision-making from demonstrations. Recently, it has gained
prominence as the core of foundation models for the physical world, where
achieving generalization requires countless demonstrations of a multitude of
tasks. Typically, a human expert with full information on the task demonstrates
a (nearly) optimal behavior. In this paper, we propose to hide some of the
task's information from the demonstrator. This ``blindfolded'' expert is
compelled to employ non-trivial exploration to solve the task. We show that
cloning the blindfolded expert generalizes better to unseen tasks than its
fully-informed counterpart. We conduct experiments of real-world robot peg
insertion tasks with (limited) human demonstrations, alongside videogames from
the Procgen benchmark. Additionally, we support our findings with theoretical
analysis, which confirms that the generalization error scales with
$\sqrt{I/m}$, where $I$ measures the amount of task information available to
the demonstrator, and $m$ is the number of demonstrated tasks. Both theory and
practice indicate that cloning blindfolded experts generalizes better with
fewer demonstrated tasks. Project page with videos and code:
https://sites.google.com/view/blindfoldedexperts/home

</details>


### [14] [DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation](https://arxiv.org/abs/2510.24261)
*Jingyi Tian,Le Wang,Sanping Zhou,Sen Wang,Jiayi Li,Gang Hua*

Main category: cs.RO

TL;DR: 本文提出了一种名为DynaRend的表示学习框架，通过差异化的体积渲染进行遮罩重建和未来预测来学习3D感知和动态信息的三平面特征。该方法能够联合捕捉空间几何、未来动态和任务语义，并且在下游机器人操作任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作策略的学习面临挑战，主要是因为缺乏多样化的现实世界训练数据。虽然最近的方法试图通过自我监督表示学习来缓解这一问题，但大多数方法要么依赖于主要关注静态语义或场景几何的2D视觉预训练范式，要么使用强调2D动态的大规模视频预测模型，因此无法共同学习有效操作所需的几何、语义和动态特性。

Method: 提出了DynaRend，一种通过差异化体积渲染来进行遮罩重建和未来预测以学习具有3D意识和动态信息的三平面特性的表示学习框架。它利用多视角RGB-D视频数据进行预训练，在统一的三平面表示中同时捕捉空间几何、未来动态及任务语义。所学得的表示可以通过动作值图预测有效地转移到下游的机器人操作任务中。

Result: 在RLBench和Colosseum两个具有挑战性的基准测试以及真实世界的机器人实验中评估了DynaRend，结果表明该方法在政策成功率、对环境扰动的泛化能力以及跨多种操作任务的实际应用性方面均有显著改进。

Conclusion: DynaRend为机器人操纵提供了一个有效的解决方案，通过其独特的3D感知和动态信息学习能力，不仅提高了操作策略的成功率，还增强了对新环境的适应能力和实际应用场景中的灵活性。

Abstract: Learning generalizable robotic manipulation policies remains a key challenge
due to the scarcity of diverse real-world training data. While recent
approaches have attempted to mitigate this through self-supervised
representation learning, most either rely on 2D vision pretraining paradigms
such as masked image modeling, which primarily focus on static semantics or
scene geometry, or utilize large-scale video prediction models that emphasize
2D dynamics, thus failing to jointly learn the geometry, semantics, and
dynamics required for effective manipulation. In this paper, we present
DynaRend, a representation learning framework that learns 3D-aware and
dynamics-informed triplane features via masked reconstruction and future
prediction using differentiable volumetric rendering. By pretraining on
multi-view RGB-D video data, DynaRend jointly captures spatial geometry, future
dynamics, and task semantics in a unified triplane representation. The learned
representations can be effectively transferred to downstream robotic
manipulation tasks via action value map prediction. We evaluate DynaRend on two
challenging benchmarks, RLBench and Colosseum, as well as in real-world robotic
experiments, demonstrating substantial improvements in policy success rate,
generalization to environmental perturbations, and real-world applicability
across diverse manipulation tasks.

</details>


### [15] [Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation](https://arxiv.org/abs/2510.24315)
*Baozhe Zhang,Xinwei Chen,Qingcheng Chen,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 本文提出了一种名为CoNi-OA的新型避障算法，专为无人机-地面车辆(UAV-UGV)协作场景设计，无需依赖全局状态估计或障碍物预测。该算法利用来自UAV的单帧原始LiDAR数据生成调制矩阵，直接调整四旋翼的速度以实现避障，在非惯性参考系中实现实时无碰撞轨迹生成，显著降低了计算需求，并能够适应静态和动态环境。


<details>
  <summary>Details</summary>
Motivation: 现有的CoNi-MPC框架虽然为UAV控制提供了有效手段，但缺乏对环境信息的考虑，导致在避障方面存在挑战。为了克服这一问题，特别是针对UAV与UGV合作执行任务时不需要全局状态估计的情况，研究者们开发了新的解决方案。

Method: 提出了一种基于调制的方法——Cooperative Non-inertial frame-based Obstacle Avoidance (CoNi-OA)，它使用UAV提供的单帧LiDAR数据来创建一个调制矩阵，该矩阵用于即时调整无人机速度，从而避开障碍物。此方法能够在UGV的非惯性坐标系下快速（每次迭代少于5毫秒）生成无障碍路径。

Result: 实验结果表明，CoNi-OA算法可以有效地在不依赖全局状态估计的情况下，帮助UAV-UGV系统避免障碍物。此外，这种方法仅需依靠单一帧的LiDAR数据即可完成操作，无需对障碍物进行建模或预测，同时还能适应特征缺失或未知环境。

Conclusion: 通过引入CoNi-OA算法，本研究成功地解决了UAV-UGV协同作业中面临的避障难题，不仅提高了系统的响应速度（每次迭代处理时间低于5ms），还增强了其在多样化环境中的适用性和安全性。

Abstract: CoNi-MPC provides an efficient framework for UAV control in air-ground
cooperative tasks by relying exclusively on relative states, eliminating the
need for global state estimation. However, its lack of environmental
information poses significant challenges for obstacle avoidance. To address
this issue, we propose a novel obstacle avoidance algorithm, Cooperative
Non-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for
UAV-UGV cooperative scenarios without reliance on global state estimation or
obstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data
from the UAV to generate a modulation matrix, which directly adjusts the
quadrotor's velocity to achieve obstacle avoidance. This modulation-based
method enables real-time generation of collision-free trajectories within the
UGV's non-inertial frame, significantly reducing computational demands (less
than 5 ms per iteration) while maintaining safety in dynamic and unpredictable
environments. The key contributions of this work include: (1) a
modulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV
cooperation in non-inertial frames without global states; (2) rapid, real-time
trajectory generation based solely on single-frame LiDAR data, removing the
need for obstacle modeling or prediction; and (3) adaptability to both static
and dynamic environments, thus extending applicability to featureless or
unknown scenarios.

</details>


### [16] [NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation](https://arxiv.org/abs/2510.24335)
*Mingyu Jeong,Eunsung Kim,Sehun Park,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: This paper introduces NVSim, a system that can automatically create large-scale, navigable indoor simulators using only common image sequences. It overcomes the limitations of traditional 3D scanning in terms of cost and scalability by adapting 3D Gaussian Splatting to address visual artifacts on sparsely observed floors, introducing Floor-Aware Gaussian Splatting for a clean ground plane, and developing a new mesh-free traversability checking algorithm.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is to overcome the cost and scalability issues associated with traditional 3D scanning methods when creating large-scale, navigable indoor simulators. The authors aim to make the process more efficient and accessible by utilizing common image sequences as input.

Method: The method proposed in this paper involves adapting 3D Gaussian Splatting to deal with visual artifacts, particularly on sparsely observed floors. They also introduce a technique called Floor-Aware Gaussian Splatting to ensure a clear, navigable ground surface. Additionally, they develop a novel mesh-free algorithm for assessing traversability, which constructs a topological graph directly from the rendered views without needing to generate a 3D mesh.

Result: The results show that the system, NVSim, is capable of generating valid, large-scale navigation graphs from real-world data. This demonstrates the effectiveness and practicality of their approach in creating navigable indoor environments from simple image sequences.

Conclusion: In conclusion, NVSim represents an innovative solution for constructing large, navigable indoor simulators efficiently and at scale, relying solely on common image sequences. Its ability to produce high-quality, usable navigation graphs from real-world data highlights its potential in various applications, including robotics and virtual reality.

Abstract: We present NVSim, a framework that automatically constructs large-scale,
navigable indoor simulators from only common image sequences, overcoming the
cost and scalability limitations of traditional 3D scanning. Our approach
adapts 3D Gaussian Splatting to address visual artifacts on sparsely observed
floors a common issue in robotic traversal data. We introduce Floor-Aware
Gaussian Splatting to ensure a clean, navigable ground plane, and a novel
mesh-free traversability checking algorithm that constructs a topological graph
by directly analyzing rendered views. We demonstrate our system's ability to
generate valid, large-scale navigation graphs from real-world data. A video
demonstration is avilable at https://youtu.be/tTiIQt6nXC8

</details>


### [17] [Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance](https://arxiv.org/abs/2510.24457)
*Jorge Vicente-Martinez,Edgar Ramirez-Laboreo*

Main category: cs.RO

TL;DR: 本文提出了一种利用微分平坦性为3D龙门起重机生成最优轨迹的方法，该方法能够直接纳入复杂的物理和动态约束条件。通过仅在终点处限制负载摆动，允许进行激进的移动。仿真研究显示，忽略干摩擦会导致执行器饱和和碰撞，强调了摩擦建模对于实现快速且安全的起重机轨迹的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了改善3D龙门起重机的操作性能，特别是考虑到复杂物理和动态约束（如非线性摩擦及载荷与绳索避碰）的情况下，提出了一种新的最优轨迹生成方法。

Method: 采用微分平坦性的框架来生成最优轨迹，并在此过程中直接考虑了多种实际操作中的约束条件。特别地，此方法只在运动结束时对负载摆动加以限制，从而允许起重机执行更为激进的动作路径。

Result: 通过比较仿真研究表明，当不考虑干摩擦因素时，可能会引起驱动器达到饱和状态以及发生碰撞事故；而适当处理摩擦模型则被证明是实现高效且安全起重机运行轨迹的关键要素。

Conclusion: 研究表明，通过使用基于微分平坦性的方法可以有效地为3D龙门起重机设计出同时满足速度要求和安全性考量的优化轨迹方案。其中，正确处理摩擦力的影响显得尤为重要。

Abstract: This paper presents an optimal trajectory generation method for 3D overhead
cranes by leveraging differential flatness. This framework enables the direct
inclusion of complex physical and dynamic constraints, such as nonlinear
friction and collision avoidance for both payload and rope. Our approach allows
for aggressive movements by constraining payload swing only at the final point.
A comparative simulation study validates our approach, demonstrating that
neglecting dry friction leads to actuator saturation and collisions. The
results show that friction modeling is a fundamental requirement for fast and
safe crane trajectories.

</details>


### [18] [Supervisory Measurement-Guided Noise Covariance Estimation](https://arxiv.org/abs/2510.24508)
*Haoying Li,Yifan Peng,Junfeng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种通过双层优化来估计噪声协方差的方法，从贝叶斯角度分解了所谓的里程计和监督测量的联合似然性，实现了信息利用与计算效率之间的平衡。实验表明该方法比现有基线更有效。


<details>
  <summary>Details</summary>
Motivation: 准确的状态估计依赖于传感器噪声协方差的准确指定，但实践中由于环境变化、前端预处理等原因难以识别这些协方差。

Method: 将噪声协方差估计公式化为一种双层优化问题，其中从贝叶斯视角分解了里程计和监督测量的联合似然性，形成链式结构支持并行计算。底层使用状态增强的不变扩展卡尔曼滤波器估计轨迹，并且一个导数滤波器并行计算分析梯度用于上层梯度更新；上层则细化协方差以指导底层估计。

Result: 在合成数据集和真实世界数据集上的实验显示，所提出的方法相比现有基准具有更高的效率。

Conclusion: 提出的方法能够有效解决噪声协方差估计的问题，同时保持良好的计算效率，为可靠的状态估计提供了新的解决方案。

Abstract: Reliable state estimation hinges on accurate specification of sensor noise
covariances, which weigh heterogeneous measurements. In practice, these
covariances are difficult to identify due to environmental variability,
front-end preprocessing, and other reasons. We address this by formulating
noise covariance estimation as a bilevel optimization that, from a Bayesian
perspective, factorizes the joint likelihood of so-called odometry and
supervisory measurements, thereby balancing information utilization with
computational efficiency. The factorization converts the nested Bayesian
dependency into a chain structure, enabling efficient parallel computation: at
the lower level, an invariant extended Kalman filter with state augmentation
estimates trajectories, while a derivative filter computes analytical gradients
in parallel for upper-level gradient updates. The upper level refines the
covariance to guide the lower-level estimation. Experiments on synthetic and
real-world datasets show that our method achieves higher efficiency over
existing baselines.

</details>


### [19] [Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems](https://arxiv.org/abs/2510.24515)
*Malintha Fernando,Petter Ögren,Silun Zhang*

Main category: cs.RO

TL;DR: 本文提出了一个名为Stochastic Prize-Collecting Games (SPCG)的模型，作为Team Orienteering Problem (TOP)的一种扩展，用于在存在自私机器人的情况下进行规划。研究了该模型在完全图和星形图上的纯纳什均衡，并提出了两种算法：Ordinal Rank Search (ORS) 和 Fictitious Ordinal Response Learning (FORL)。实验结果表明，所学得的策略能够高效地扩展到大规模团队，并且在不均衡奖励分布下表现优于其他多智能体训练方法。


<details>
  <summary>Details</summary>
Motivation: 传统的Team Orienteering Problem (TOP) 假设所有机器人都为单一目标合作，在面对竞争环境时并不适用。因此，需要一种新的方法来解决当机器人在资源稀缺环境中互相竞争时的问题。

Method: 提出了一种称为Stochastic Prize-Collecting Games (SPCG) 的新框架，用于处理具有能量限制及随机转移条件下的自私机器人路径规划问题；通过理论分析确定了在特定类型图上存在唯一纯纳什均衡；设计了两种算法：Ordinal Rank Search (ORS) 用来决定局部邻域内的有效排名，Fictitious Ordinal Response Learning (FORL) 用来学习相对于高级别对手的最佳响应策略。

Result: 实验证明，基于ORS的状态同化可以使得学习到的策略比使用全局索引训练出的策略更有效地扩展至更大的团队规模；并且与其它多智能体训练方法相比，使用FORL训练出的策略在应对不平衡奖励分布时展现出更好的泛化能力；所学得的策略接近于通过混合整数线性规划求解得到的等效TOP解决方案，达到87%到95%的最优性。

Conclusion: SPCG模型及其相关算法为解决多机器人系统中自私个体间的竞争提供了有效的解决方案，并且在不同场景下显示出良好的性能。

Abstract: The Team Orienteering Problem (TOP) generalizes many real-world multi-robot
scheduling and routing tasks that occur in autonomous mobility, aerial
logistics, and surveillance applications. While many flavors of the TOP exist
for planning in multi-robot systems, they assume that all the robots cooperate
toward a single objective; thus, they do not extend to settings where the
robots compete in reward-scarce environments. We propose Stochastic
Prize-Collecting Games (SPCG) as an extension of the TOP to plan in the
presence of self-interested robots operating on a graph, under energy
constraints and stochastic transitions. A theoretical study on complete and
star graphs establishes that there is a unique pure Nash equilibrium in SPCGs
that coincides with the optimal routing solution of an equivalent TOP given a
rank-based conflict resolution rule. This work proposes two algorithms: Ordinal
Rank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in
temporarily-formed local neighborhoods during the games' stages, and Fictitious
Ordinal Response Learning (FORL) to obtain best-response policies against one's
senior-rank opponents. Empirical evaluations conducted on road networks and
synthetic graphs under both dynamic and stationary prize distributions show
that 1) the state-aliasing induced by OR-conditioning enables learning policies
that scale more efficiently to large team sizes than those trained with the
global index, and 2) Policies trained with FORL generalize better to imbalanced
prize distributions than those with other multi-agent training methods.
Finally, the learned policies in the SPCG achieved between 87% and 95%
optimality compared to an equivalent TOP solution obtained by mixed-integer
linear programming.

</details>


### [20] [GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots](https://arxiv.org/abs/2510.24533)
*Yuan Shen,Yuze Hong,Guangyang Zeng,Tengfei Zhang,Pui Yi Chui,Ziyang Hong,Junfeng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种名为GeVI-SLAM的重力增强立体视觉惯性SLAM系统，旨在解决水下机器人因视觉退化和IMU运动激励不足而导致的精确定位与建图挑战。通过直接深度估计能力、精确重力初始化及自适应权重分配等技术，该系统在仿真和真实数据上均表现出更高的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于视觉退化频繁发生以及惯性测量单元（IMU）提供的运动激励不足，为水下机器人实现精准的视觉惯性同步定位与建图（VI SLAM）仍面临巨大挑战。

Method: 1. 利用立体相机直接深度估计的能力，在IMU初始化时无需进行尺度估计，从而即使是在低加速度动态条件下也能稳定运行。
2. 通过精确的重力初始化来解耦姿态估计中的俯仰角和滚转角，并求解一个4自由度的透视-n-点(PnP)问题来进行姿态跟踪。
3. 提出了一种无偏4-DOF PnP估计器，具有可证明的一致性，保证随着特征数量增加相对姿态收敛于真实值。
4. 针对动态运动情况，同时估计IMU协方差并调整重力先验的权重，以优化6-DOF姿态。

Result: 广泛的实验表明，无论是基于模拟数据还是真实世界的数据集，GeVI-SLAM相比现有方法都能达到更高精度与更强稳定性。

Conclusion: 通过结合直接深度感知、精确的重力向量初始化及自适应重力先验权重调整等技术手段，GeVI-SLAM系统有效解决了水下环境中视觉惯性SLAM面临的难题，展现出优越性能。

Abstract: Accurate visual inertial simultaneous localization and mapping (VI SLAM) for
underwater robots remains a significant challenge due to frequent visual
degeneracy and insufficient inertial measurement unit (IMU) motion excitation.
In this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system
designed to address these issues. By leveraging the stereo camera's direct
depth estimation ability, we eliminate the need to estimate scale during IMU
initialization, enabling stable operation even under low acceleration dynamics.
With precise gravity initialization, we decouple the pitch and roll from the
pose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point
(PnP) problem for pose tracking. This allows the use of a minimal 3-point
solver, which significantly reduces computational time to reject outliers
within a Random Sample Consensus framework. We further propose a
bias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the
relative pose converges to the true value as the feature number increases. To
handle dynamic motion, we refine the full 6-DOF pose while jointly estimating
the IMU covariance, enabling adaptive weighting of the gravity prior. Extensive
experiments on simulated and real-world data demonstrate that GeVI-SLAM
achieves higher accuracy and greater stability compared to state-of-the-art
methods.

</details>


### [21] [An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments](https://arxiv.org/abs/2510.24554)
*Vignesh Kottayam Viswanathan,Yifan Bai,Scott Fredriksson,Sumeet Satpute,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一个分层框架，旨在支持在环境不确定性下的机器人检查任务。该框架首先基于历史地图生成初始全局视图计划，然后进行局部视图重规划以适应当前的表面形态，从而保证了对全局覆盖目标的同时能够对局部环境变化做出反应。通过在真实地下矿井中使用四足机器人部署验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于已知环境模型来规划和安全跟踪检查路线，但模型与实际现场条件之间的差异可能会改变表面形态或引入路径障碍，因此需要一种新的方法来解决这种环境不确定性问题。

Method: 提出了一种分层框架，将检查任务分为两个阶段：（a）基于历史地图为兴趣区域生成初始全局视图计划；（b）局部视图重新规划以适应检查场景的当前形态。这样既保持了全局覆盖的目标，又允许针对局部表面形态的变化作出响应。

Result: 该方法使得局部自主性在面对环境不确定性时更加稳健，并能完成检查任务。研究团队通过在现实世界的地下矿山中部署四足机器人对该方法进行了验证。

Conclusion: 所提出的分层框架有效地解决了环境不确定性带来的挑战，使机器人能够在存在未知变化的情况下成功执行检查任务。

Abstract: In this work, we present a hierarchical framework designed to support robotic
inspection under environment uncertainty. By leveraging a known environment
model, existing methods plan and safely track inspection routes to visit points
of interest. However, discrepancies between the model and actual site
conditions, caused by either natural or human activities, can alter the surface
morphology or introduce path obstructions. To address this challenge, the
proposed framework divides the inspection task into: (a) generating the initial
global view-plan for region of interests based on a historical map and (b)
local view replanning to adapt to the current morphology of the inspection
scene. The proposed hierarchy preserves global coverage objectives while
enabling reactive adaptation to the local surface morphology. This enables the
local autonomy to remain robust against environment uncertainty and complete
the inspection tasks. We validate the approach through deployments in
real-world subterranean mines using quadrupedal robot.

</details>


### [22] [Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots](https://arxiv.org/abs/2510.24571)
*Hongxu Zhao,Guangyang Zeng,Yunling Shao,Tengfei Zhang,Junfeng Wu*

Main category: cs.RO

TL;DR: 提出了一种统一迭代校准(UIC)框架，用于一般DVL传感器设置的外参和时钟偏移量校准，该方法基于最大后验估计，并使用高斯过程运动先验进行高保真运动插值。


<details>
  <summary>Details</summary>
Motivation: 当前水下SLAM系统中对于传感器间的外参及时间偏移量的校准研究不足，现有的DVL校准方法要么受限于特定的传感器配置，要么依赖过于简化的假设，且没有同时估计平移外参和时间偏移的方法。

Method: 开发了统一迭代校准（UIC）框架，采用最大后验估计法结合高斯过程作为运动先验以实现高质量运动插值。UIC交替执行基于GP的运动状态更新与基于梯度的校准变量更新，并通过统计一致性的序列初始化方案支持。

Result: 仿真测试与实际应用均验证了所提方法的有效性。此外，还发布了开源的DVL-相机校准工具箱。

Conclusion: UIC不仅适用于水下场景，其关键特性如MAP校准中的GP先验整合以及可靠初始化程序的设计，对其他多传感器校准问题也有广泛的应用价值。

Abstract: The calibration of extrinsic parameters and clock offsets between sensors for
high-accuracy performance in underwater SLAM systems remains insufficiently
explored. Existing methods for Doppler Velocity Log (DVL) calibration are
either constrained to specific sensor configurations or rely on oversimplified
assumptions, and none jointly estimate translational extrinsics and time
offsets. We propose a Unified Iterative Calibration (UIC) framework for general
DVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a
Gaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC
alternates between efficient GP-based motion state updates and gradient-based
calibration variable updates, supported by a provably statistically consistent
sequential initialization scheme. The proposed UIC can be applied to IMU,
cameras and other modalities as co-sensors. We release an open-source
DVL-camera calibration toolbox. Beyond underwater applications, several aspects
of UIC-such as the integration of GP priors for MAP-based calibration and the
design of provably reliable initialization procedures-are broadly applicable to
other multi-sensor calibration problems. Finally, simulations and real-world
tests validate our approach.

</details>


### [23] [Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning](https://arxiv.org/abs/2510.24584)
*Jørgen Anker Olsen,Lars Rønhaug Pettersen,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文提出了一种基于课程的强化学习框架，用于训练机器人'Olympus'的精确跳跃策略。通过利用抛物线运动定律来增加稀疏跳跃奖励的密度，并使用参考状态初始化方案加速动态跳跃行为的探索，同时不依赖于参考轨迹。实验验证了该方法在水平跳跃和垂直跳跃上的优异性能，且仅需少量修改即可学习全方位跳跃。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人跳跃任务中遇到的奖励稀疏问题以及加快对动态跳跃行为的有效探索，从而提高机器人跳跃动作的准确性与性能。

Method: 采用了一种基于课程的强化学习方法，先通过抛物线运动定律增加跳跃奖励密度，然后运用参考状态初始化促进快速学习而不必依靠预设轨迹。

Result: 实现了高达1.25米的水平跳跃距离和1米的垂直跳跃高度，均具有厘米级精度；证明了该方法能够有效跨越仿真到现实世界的差距（Sim2Real），并展示了其在实现全向跳跃方面的潜力。

Conclusion: 本研究提出的基于课程的强化学习框架成功地提升了机器人'Olympus'执行复杂跳跃任务的能力，不仅提高了跳跃距离和准确度，还展示了良好的适应性。

Abstract: This paper presents a curriculum-based reinforcement learning framework for
training precise and high-performance jumping policies for the robot `Olympus'.
Separate policies are developed for vertical and horizontal jumps, leveraging a
simple yet effective strategy. First, we densify the inherently sparse jumping
reward using the laws of projectile motion. Next, a reference state
initialization scheme is employed to accelerate the exploration of dynamic
jumping behaviors without reliance on reference trajectories. We also present a
walking policy that, when combined with the jumping policies, unlocks versatile
and dynamic locomotion capabilities. Comprehensive testing validates walking on
varied terrain surfaces and jumping performance that exceeds previous works,
effectively crossing the Sim2Real gap. Experimental validation demonstrates
horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to
1.0 m. Additionally, we show that with only minor modifications, the proposed
method can be used to learn omnidirectional jumping.

</details>


### [24] [Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder](https://arxiv.org/abs/2510.24671)
*Li Li,Tobias Brinkmann,Till Temmen,Markus Eisenbarth,Jakob Andert*

Main category: cs.RO

TL;DR: 本文提出了一种基于Transformer增强的条件变分自编码器(CVAE-T)模型，用于生成环岛中的多智能体交通场景。该模型不仅能准确重建原始场景，还能生成逼真的、多样化的合成场景，并通过两个关键性能指标(KPIs)评估了生成场景中的交互行为。研究结果表明，该模型能够为涉及多智能体交互的智能驾驶功能验证生成场景，并支持其开发和迭代改进。


<details>
  <summary>Details</summary>
Motivation: 随着智能驾驶功能越来越多地集成到量产车辆中，确保这些功能的有效性和鲁棒性变得越来越具有挑战性。与传统的道路测试相比，基于场景的虚拟测试在时间成本效率、可重复性和探索边缘案例方面具有显著优势。特别地，环岛由于其高动态特性和复杂布局，在当前研究中相对较少被探讨，因此需要一种新的方法来生成这类环境下的多智能体交通场景。

Method: 提出了一个名为CVAE-T（Transformer增强的条件变分自编码器）的新模型，专门设计用来生成环岛内的多智能体交通场景。该模型结合了变分自编码器与Transformer架构的优势，旨在提高生成场景的真实性与多样性。

Result: 实验结果显示，CVAE-T模型能够精确重现原始交通场景，并且能够创造出多样化且现实的合成场景。此外，通过采用两个关键性能指标对生成场景中的互动行为进行了评估。潜空间分析揭示了部分解耦现象，一些潜在维度对于场景属性如车辆进入时机、离开时机及速度分布等显示出独特且可解释的影响。

Conclusion: 研究表明，CVAE-T模型不仅能够有效地为智能驾驶系统验证生成复杂的多智能体交互场景，还可以作为数据增强工具促进相关技术的发展和完善。

Abstract: With the increasing integration of intelligent driving functions into
serial-produced vehicles, ensuring their functionality and robustness poses
greater challenges. Compared to traditional road testing, scenario-based
virtual testing offers significant advantages in terms of time and cost
efficiency, reproducibility, and exploration of edge cases. We propose a
Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for
generating multi-agent traffic scenarios in roundabouts, which are
characterized by high vehicle dynamics and complex layouts, yet remain
relatively underexplored in current research. The results show that the
proposed model can accurately reconstruct original scenarios and generate
realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators
(KPIs) are employed to evaluate the interactive behavior in the generated
scenarios. Analysis of the latent space reveals partial disentanglement, with
several latent dimensions exhibiting distinct and interpretable effects on
scenario attributes such as vehicle entry timing, exit timing, and velocity
profiles. The results demonstrate the model's capability to generate scenarios
for the validation of intelligent driving functions involving multi-agent
interactions, as well as to augment data for their development and iterative
improvement.

</details>


### [25] [Fare: Failure Resilience in Learned Visual Navigation Control](https://arxiv.org/abs/2510.24680)
*Zishuo Wang,Joel Loo,David Hsu*

Main category: cs.RO

TL;DR: 提出了一种名为Fare的框架，用于构建能够识别和从失败中恢复的模仿学习策略，无需使用明确的失败数据，并与恢复启发式方法结合。实验证明Fare可以在不同策略架构上实现故障恢复，支持在复杂环境中进行稳健的长距离导航。


<details>
  <summary>Details</summary>
Motivation: 模仿学习（IL）虽然能有效促进视觉导航能力的发展，但在面对分布外(OOD)场景时，基于IL的策略容易出现不可预测的失败。因此，需要一种能够不仅检测失败而且能够自动从中恢复的策略来解决这个问题。

Method: 本文介绍了Fare框架，该框架旨在构建具有故障弹性的模仿学习策略。它将OOD检测和故障识别嵌入到策略中，而不需要显式的故障数据，并且与恢复启发式方法相结合。通过这种方式，Fare能够让策略在遭遇失败时不仅能识别出导致失败的因素，如触发失败检测的图像区域，还能据此提供线索指导恢复过程。

Result: 真实世界实验表明，Fare能够在两种不同的策略架构上实现故障恢复，这使得在复杂的环境中可以进行更加鲁棒的长距离导航。

Conclusion: Fare框架为模仿学习策略提供了有效的故障识别与恢复机制，增强了其在面临未知或异常情况时的表现，从而提高了整体导航系统的可靠性和适应性。

Abstract: While imitation learning (IL) enables effective visual navigation, IL
policies are prone to unpredictable failures in out-of-distribution (OOD)
scenarios. We advance the notion of failure-resilient policies, which not only
detect failures but also recover from them automatically. Failure recognition
that identifies the factors causing failure is key to informing recovery: e.g.
pinpointing image regions triggering failure detections can provide cues to
guide recovery. We present Fare, a framework to construct failure-resilient IL
policies, embedding OOD-detection and recognition in them without using
explicit failure data, and pairing them with recovery heuristics. Real-world
experiments show that Fare enables failure recovery across two different policy
architectures, enabling robust long-range navigation in complex environments.

</details>


### [26] [A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers](https://arxiv.org/abs/2510.24683)
*Caleb Escobedo,Nataliya Nechyporenko,Shreyas Kadekodi,Alessandro Roncone*

Main category: cs.RO

TL;DR: 本文提出了一种用于分析物体感知控制器的框架，该框架着重于三个设计考量：运动学、运动轮廓和虚拟约束。通过基本的机器人-障碍物实验场景验证了机器人的行为，并比较了三种代表性的物体感知控制器，指出现有设计中缺乏对运动学考虑、控制点连续性和运动稳定性的问题。


<details>
  <summary>Details</summary>
Motivation: 实时控制是机器人在存在动态物体的真实世界中安全操作的重要方面。为了解决这个问题，研究提出了一个能够分析物体感知控制器的框架，旨在通过改变机器人的动作来预测并避免可能发生的碰撞。

Method: 本文介绍了一个针对物体感知控制器分析的框架，重点考虑了三个设计要素：运动学、运动轮廓和虚拟约束。此外，还利用基本的机器人-障碍物实验场景来验证机器人行为。通过对比三种典型的物体感知控制器，使用源于上述设计考量的度量标准来进行评估。

Result: 研究发现，在设计物体感知控制器时往往忽视了运动学方面的考虑、控制点的连续性以及移动轮廓中的稳定性问题。

Conclusion: 此框架可以用来设计、比较及评价避障方法，对未来开发更加有效的物体感知控制器提供了指导。

Abstract: Real-time control is an essential aspect of safe robot operation in the real
world with dynamic objects. We present a framework for the analysis of
object-aware controllers, methods for altering a robot's motion to anticipate
and avoid possible collisions. This framework is focused on three design
considerations: kinematics, motion profiles, and virtual constraints.
Additionally, the analysis in this work relies on verification of robot
behaviors using fundamental robot-obstacle experimental scenarios. To showcase
the effectiveness of our method we compare three representative object-aware
controllers. The comparison uses metrics originating from the design
considerations. From the analysis, we find that the design of object-aware
controllers often lacks kinematic considerations, continuity of control points,
and stability in movement profiles. We conclude that this framework can be used
in the future to design, compare, and benchmark obstacle avoidance methods.

</details>


### [27] [Embodying Physical Computing into Soft Robots](https://arxiv.org/abs/2510.24692)
*Jun Wang,Ziyang Zhou,Ardalan Kahak,Suyi Li*

Main category: cs.RO

TL;DR: 本文提出了一种将物理计算融入软体机器人中的框架，讨论了模拟振荡器、物理储层计算和物理算法计算三种独特策略，并展望了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 为了提高软体机器人的鲁棒性和智能性，使其更适合日常使用，研究者们正在探索如何将更柔软的计算机和控制器集成到这些设备中。物理计算通过机械计算内核编码输入并利用内部交互来计算输出，为实现这一目标提供了可能。

Method: 本文主要采用了文献综述的方法，分析了三种具体的物理计算方法：模拟振荡器、物理储层计算以及物理算法计算的工作原理及其在软体机器人中的应用现状。

Result: 研究表明，通过上述提到的物理计算方法，软体机器人能够执行复杂的任务，如带有障碍物规避功能的协调移动、负载重量及方向分类、基于逻辑规则的操作等，而无需依赖传统的CMOS电子设备。

Conclusion: 文章总结了现有技术状态，并对将物理计算嵌入软体机器人领域内的未来发展提出了展望。

Abstract: Softening and onboarding computers and controllers is one of the final
frontiers in soft robotics towards their robustness and intelligence for
everyday use. In this regard, embodying soft and physical computing presents
exciting potential. Physical computing seeks to encode inputs into a mechanical
computing kernel and leverage the internal interactions among this kernel's
constituent elements to compute the output. Moreover, such input-to-output
evolution can be re-programmable. This perspective paper proposes a framework
for embodying physical computing into soft robots and discusses three unique
strategies in the literature: analog oscillators, physical reservoir computing,
and physical algorithmic computing. These embodied computers enable the soft
robot to perform complex behaviors that would otherwise require CMOS-based
electronics -- including coordinated locomotion with obstacle avoidance,
payload weight and orientation classification, and programmable operation based
on logical rules. This paper will detail the working principles of these
embodied physical computing methods, survey the current state-of-the-art, and
present a perspective for future development.

</details>
