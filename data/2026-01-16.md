<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 10]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Interprofessional and Agile Development of Mobirobot: A Socially Assistive Robot for Pediatric Therapy Across Clinical and Therapeutic Settings](https://arxiv.org/abs/2601.09838)
*Leonie Dyck,Aiko Galetzka,Maximilian Noller,Anna-Lena Rinke,Jutta Bormann,Jekaterina Miller,Michelle Hochbaum,Julia Siemann,Jördis Alboth,Andre Berwinkel,Johanna Luz,Britta Kley-Zobel,Marcine Cyrys,Nora Flöttmann,Ariane Vogeler,Mariia Melnikova,Ira-Katharina Petras,Michael Siniatchkin,Winfried Barthlen,Anna-Lisa Vollmer*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Mobirobot的社会辅助机器人，它通过个性化运动计划支持儿童从创伤、骨折或抑郁障碍中恢复。该机器人的开发采用了敏捷的人本设计方法，并在真实世界的儿科外科和精神科环境中进行了早期整合。目前正在进行一项可行性研究以评估接受度、可用性和感知治疗效益。


<details>
  <summary>Details</summary>
Motivation: 社会辅助机器人有望提高儿科临床环境中的治疗参与度。然而，它们的成功实施不仅需要技术上的稳健性，还需要具有上下文敏感性的共同设计解决方案。

Method: 采用敏捷的人本开发方法指导了Mobirobot的迭代设计。整个共开发过程中都涉及多学科临床团队和最终用户，重点是尽早整合到现实世界中的儿科外科与精神科场景里。基于NAO平台的机器人具备简易设置、可调整的运动程序、互动引导、激励对话以及用于监控和无代码系统反馈的图形用户界面（GUI）。

Result: 在医院环境中部署帮助识别了关键的设计要求和可用性限制。利益相关者的反馈促进了交互设计、移动能力和技术配置方面的改进。当前正在开展一项可行性研究来评估接受度、可用性和感知治疗效果，数据收集包括问卷调查、行为观察以及医护人员-患者访谈。

Conclusion: Mobirobot展示了多专业、由利益相关者主导的发展如何能够产生适合动态住院环境的社会辅助系统。初期发现强调了情境整合、稳健性及最小侵入设计的重要性。尽管存在诸如传感器局限性和患者招募等挑战，但该平台为未来的研究和临床应用提供了一个有希望的基础。

Abstract: Introduction: Socially assistive robots hold promise for enhancing therapeutic engagement in paediatric clinical settings. However, their successful implementation requires not only technical robustness but also context-sensitive, co-designed solutions. This paper presents Mobirobot, a socially assistive robot developed to support mobilisation in children recovering from trauma, fractures, or depressive disorders through personalised exercise programmes.
  Methods: An agile, human-centred development approach guided the iterative design of Mobirobot. Multidisciplinary clinical teams and end users were involved throughout the co-development process, which focused on early integration into real-world paediatric surgical and psychiatric settings. The robot, based on the NAO platform, features a simple setup, adaptable exercise routines with interactive guidance, motivational dialogue, and a graphical user interface (GUI) for monitoring and no-code system feedback.
  Results: Deployment in hospital environments enabled the identification of key design requirements and usability constraints. Stakeholder feedback led to refinements in interaction design, movement capabilities, and technical configuration. A feasibility study is currently underway to assess acceptance, usability, and perceived therapeutic benefit, with data collection including questionnaires, behavioural observations, and staff-patient interviews.
  Discussion: Mobirobot demonstrates how multiprofessional, stakeholder-led development can yield a socially assistive system suited for dynamic inpatient settings. Early-stage findings underscore the importance of contextual integration, robustness, and minimal-intrusion design. While challenges such as sensor limitations and patient recruitment remain, the platform offers a promising foundation for further research and clinical application.

</details>


### [2] [How Human Motion Prediction Quality Shapes Social Robot Navigation Performance in Constrained Spaces](https://arxiv.org/abs/2601.09856)
*Andrew Stratton,Phani Teja Singamaneni,Pranav Goyal,Rachid Alami,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: 研究了人类运动预测质量对机器人导航性能的影响，发现平均位移误差不是可靠的性能预测指标，且在受限环境中人类合作的假设不成立，更高效的机器人导航往往牺牲了人类效率和舒适度。


<details>
  <summary>Details</summary>
Motivation: 为了使移动机器人更好地融入仓库、医院、制造厂和家庭等环境中，并确保在这些场景中的人类安全、舒适和效率，需要赋予机器人一种理解人类如何在其周围移动的模型。然而，由于人类行为的随机性、用户偏好的差异以及数据稀缺等问题，使得围绕机器人的人员流动预测变得特别具有挑战性。

Method: 设计了一个涉及两个受试者在受限工作空间中与机器人导航的场景，并通过用户研究（N=80）来实施，该研究使用了两种不同的机器人平台，在来自不同世界区域的两个地点进行。

Result: 1) 广泛采用的平均位移误差并不是机器人导航性能和人印象的可靠预测因子；2) 在受限环境中，人们通常不会响应机器人的合作尝试，导致性能下降，这打破了关于人类会合作的一般假设；3) 机器人导航效率的提高往往是以牺牲人类效率和舒适度为代价的。

Conclusion: 研究强调了在开发用于动态及空间受限环境中的导航系统时，需要更加细致地考虑人类因素的重要性。此外，对于评估机器人导航性能的标准提出了新的见解，指出仅依赖于技术指标可能不足以全面评价系统的有效性。

Abstract: Motivated by the vision of integrating mobile robots closer to humans in warehouses, hospitals, manufacturing plants, and the home, we focus on robot navigation in dynamic and spatially constrained environments. Ensuring human safety, comfort, and efficiency in such settings requires that robots are endowed with a model of how humans move around them. Human motion prediction around robots is especially challenging due to the stochasticity of human behavior, differences in user preferences, and data scarcity. In this work, we perform a methodical investigation of the effects of human motion prediction quality on robot navigation performance, as well as human productivity and impressions. We design a scenario involving robot navigation among two human subjects in a constrained workspace and instantiate it in a user study ($N=80$) involving two different robot platforms, conducted across two sites from different world regions. Key findings include evidence that: 1) the widely adopted average displacement error is not a reliable predictor of robot navigation performance and human impressions; 2) the common assumption of human cooperation breaks down in constrained environments, with users often not reciprocating robot cooperation, and causing performance degradations; 3) more efficient robot navigation often comes at the expense of human efficiency and comfort.

</details>


### [3] [SyncTwin: Fast Digital Twin Construction and Synchronization for Safe Robotic Grasping](https://arxiv.org/abs/2601.09920)
*Ruopeng Huang,Boyu Yang,Wenlong Gui,Jeremy Morgan,Erdem Biyik,Jiachen Li*

Main category: cs.RO

TL;DR: SyncTwin是一个数字孪生框架，结合了快速3D场景重建和实时仿真同步技术，以实现在动态和视觉遮挡条件下的准确且安全的抓取。通过VGGT从RGB图像中快速重建物体级别的3D资产，并在执行过程中持续更新数字孪生体来跟踪真实世界物体的状态，从而允许运动规划器计算无碰撞及动态可行的轨迹，进而提高抓取精度和运动安全性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的机器人操作中，在动态和视线受阻的情况下实现精确且安全的抓握仍是一大挑战。为解决这一问题并提高抓握准确性与安全性，提出了SyncTwin框架。

Method: 本研究提出了一种名为SyncTwin的数字孪生框架，该框架集成了快速3D场景重建（使用VGGT从RGB图像重建对象级3D资产）以及通过点云分割更新和彩色ICP配准实现的真实到模拟同步机制。此外，还建立了一个可重复使用的几何库用于模拟，并通过闭环控制确保虚拟环境中规划出的动作能够安全地应用于实际机器人上。

Result: 实验结果表明，在动态和遮挡场景下，SyncTwin能够显著提升抓握精度和动作安全性，验证了基于数字孪生同步方法对于改善现实世界中机器人执行任务的有效性。

Conclusion: SyncTwin提供了一种有效的方法来应对动态和视线受阻环境下机器人抓握操作中的挑战，通过将快速3D重建与实时仿真同步相结合，提高了抓握的准确性和安全性。

Abstract: Accurate and safe grasping under dynamic and visually occluded conditions remains a core challenge in real-world robotic manipulation. We present SyncTwin, a digital twin framework that unifies fast 3D scene reconstruction and real-to-sim synchronization for robust and safety-aware grasping in such environments. In the offline stage, we employ VGGT to rapidly reconstruct object-level 3D assets from RGB images, forming a reusable geometry library for simulation. During execution, SyncTwin continuously synchronizes the digital twin by tracking real-world object states via point cloud segmentation updates and aligning them through colored-ICP registration. The updated twin enables motion planners to compute collision-free and dynamically feasible trajectories in simulation, which are safely executed on the real robot through a closed real-to-sim-to-real loop. Experiments in dynamic and occluded scenes show that SyncTwin improves grasp accuracy and motion safety, demonstrating the effectiveness of digital-twin synchronization for real-world robotic execution.

</details>


### [4] [In-the-Wild Compliant Manipulation with UMI-FT](https://arxiv.org/abs/2601.09988)
*Hojung Choi,Yifan Hou,Chuer Pan,Seongheon Hong,Austin Patel,Xiaomeng Xu,Mark R. Cutkosky,Shuran Song*

Main category: cs.RO

TL;DR: 本文介绍了一种手持数据收集平台UMI-FT，它在每个手指上安装了紧凑型六轴力/扭矩传感器，可以测量指级力矩，并结合RGB、深度和姿态数据。基于这些多模态数据训练出的自适应顺应性策略，在接触丰富且对力量敏感的任务中表现出色，优于缺乏顺应性或力量感知的基线方法。


<details>
  <summary>Details</summary>
Motivation: 许多操作任务需要精细的力量调节，但商用F/T传感器的成本高、体积大及易碎性限制了大规模力量感知策略的学习。为解决这一问题，作者们开发了UMI-FT平台。

Method: 通过一个名为UMI-FT的手持设备来收集包含RGB图像、深度信息、位姿以及指级力矩测量的数据。使用这些多模态数据训练能够预测位置目标、抓握力和刚度的自适应顺应性策略，以便于在标准顺应控制器上执行。

Result: 在白板擦拭、穿刺西葫芦和灯泡插入这三项接触密集且对力量敏感的任务测试中，UMI-FT支持的策略能可靠地调节外部接触力和内部抓握力，表现优于没有顺应性或力量感知能力的基线方法。

Conclusion: UMI-FT提供了一个从野外演示学习顺应性操控的可扩展路径，并且其硬件和软件已开源，以促进更广泛的应用。

Abstract: Many manipulation tasks require careful force modulation. With insufficient force the task may fail, while excessive force could cause damage. The high cost, bulky size and fragility of commercial force/torque (F/T) sensors have limited large-scale, force-aware policy learning. We introduce UMI-FT, a handheld data-collection platform that mounts compact, six-axis force/torque sensors on each finger, enabling finger-level wrench measurements alongside RGB, depth, and pose. Using the multimodal data collected from this device, we train an adaptive compliance policy that predicts position targets, grasp force, and stiffness for execution on standard compliance controllers. In evaluations on three contact-rich, force-sensitive tasks (whiteboard wiping, skewering zucchini, and lightbulb insertion), UMI-FT enables policies that reliably regulate external contact forces and internal grasp forces, outperforming baselines that lack compliance or force sensing. UMI-FT offers a scalable path to learning compliant manipulation from in-the-wild demonstrations. We open-source the hardware and software to facilitate broader adoption at:https://umi-ft.github.io/.

</details>


### [5] [CoCoPlan: Adaptive Coordination and Communication for Multi-robot Systems in Dynamic and Unknown Environments](https://arxiv.org/abs/2601.10116)
*Xintong Zhang,Junfeng Chen,Yuxiao Zhu,Bing Luo,Meng Guo*

Main category: cs.RO

TL;DR: 提出了一种名为CoCoPlan的新框架，该框架同时优化了多机器人系统的协作任务规划和团队间断通信。通过集成分支定界架构、自适应目标函数以及通信事件优化模块，实现了更高的任务完成率、降低了通信开销，并支持多达100个机器人在动态环境中的操作。


<details>
  <summary>Details</summary>
Motivation: 现有的多机器人系统方法在有限通信条件下难以有效应对动态时空任务分布，导致协调效果不佳。

Method: 提出了CoCoPlan框架，该框架结合了任务分配与通信事件的编码、平衡任务效率与通信延迟的自适应目标函数，以及用于策略性确定全局连接应何时何地重新建立的通信事件优化模块。

Result: 实验表明，与现有最先进方法相比，所提方法的任务完成率提高了22.4%，通信开销减少了58.6%，并且能够支持多达100个机器人在动态环境下的运行。硬件实验涵盖了复杂的2D办公环境和大规模3D灾害响应场景。

Conclusion: CoCoPlan为多机器人系统提供了更优的解决方案，在提高任务完成率的同时显著降低了通信成本，并且展现出良好的扩展性和适应性。

Abstract: Multi-robot systems can greatly enhance efficiency through coordination and collaboration, yet in practice, full-time communication is rarely available and interactions are constrained to close-range exchanges. Existing methods either maintain all-time connectivity, rely on fixed schedules, or adopt pairwise protocols, but none adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination. To address this gap, we propose CoCoPlan, a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication. Our approach integrates a branch-and-bound architecture that jointly encodes task assignments and communication events, an adaptive objective function that balances task efficiency against communication latency, and a communication event optimization module that strategically determines when, where and how the global connectivity should be re-established. Extensive experiments demonstrate that it outperforms state-of-the-art methods by achieving a 22.4% higher task completion rate, reducing communication overhead by 58.6%, and improving the scalability by supporting up to 100 robots in dynamic environments. Hardware experiments include the complex 2D office environment and large-scale 3D disaster-response scenario.

</details>


### [6] [Terrain-Adaptive Mobile 3D Printing with Hierarchical Control](https://arxiv.org/abs/2601.10208)
*Shuangshan Nors Li,J. Nathan Kutz*

Main category: cs.RO

TL;DR: 该论文提出了一种结合AI驱动的干扰预测、多模态传感器融合和分层硬件控制的框架，实现了在不规则地形上的移动3D打印，同时保持了亚厘米级的打印精度和平台的完全机动性。


<details>
  <summary>Details</summary>
Motivation: 移动3D打印在非结构化地形上面临平台移动性和沉积精度之间的矛盾。现有基于龙门架的系统虽然可以实现高精度，但缺乏移动性；而移动平台则难以在不平坦地面上维持打印质量。

Method: 作者们开发了一个紧密结合AI驱动干扰预测与多模态传感器（IMU、视觉及深度传感器）融合以及层级硬件控制于一体的闭环感知-学习-执行系统。此智能模块从传感器数据中学习地形到扰动映射，从而能够进行主动补偿而非被动校正，并将这一智能集成到了一个三层控制架构中：路径规划、预测性的底盘-机械臂协调以及精确硬件执行。

Result: 通过在具有坡度和表面不规则性的户外地形上进行实验，证明了即使在保持平台完全机动性的同时，也能达到亚厘米级别的打印准确度。

Conclusion: 这种AI-硬件集成方法为在非结构化环境中实现自主建造奠定了实用基础。

Abstract: Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI module learns terrain-to-perturbation mappings from IMU, vision, and depth sensors, enabling proactive compensation rather than reactive correction. This intelligence is embedded into a three-layer control architecture: path planning, predictive chassis-manipulator coordination, and precision hardware execution. Through outdoor experiments on terrain with slopes and surface irregularities, we demonstrate sub-centimeter printing accuracy while maintaining full platform mobility. This AI-hardware integration establishes a practical foundation for autonomous construction in unstructured environments.

</details>


### [7] [A Unified Framework for Kinematic Simulation of Rigid Foldable Structures](https://arxiv.org/abs/2601.10225)
*Dongwook Kwak,Geonhee Cho,Jiook Chung,Jinkyu Yang*

Main category: cs.RO

TL;DR: 本文提出了一种自动生成任意刚性可折叠结构的Pfaffian约束矩阵的方法，通过构建面-铰链图和提取最小循环基来捕捉所有约束，并利用螺旋理论组装一个速度级约束矩阵，从而简化了复杂的约束计算。


<details>
  <summary>Details</summary>
Motivation: 由于受到折纸启发的结构现在包括厚实、剪纸及多层实现方式，因此统一的动力学分析变得至关重要。但目前缺乏一种可以整合这些环路约束的一般方法。

Method: 研究者们开发了一个自动化工具，该工具从最小扩展的数据模式开始，构造面-铰链图，提取能够捕捉所有约束条件的最小循环基，并通过螺旋理论在速度层面组装约束矩阵以编码耦合旋转和平移闭合环。

Result: 该框架能够在多种刚性可折叠结构中计算并可视化展开与折叠运动，同时避免了繁琐且容易出错的约束计算过程。

Conclusion: 本研究提供了一种针对任意刚性可折叠结构进行动力学分析的有效手段，促进了该领域内设计与分析工作的效率提升。

Abstract: Origami-inspired structures with rigid panels now span thick, kirigami, and multi-sheet realizations, making unified kinematic analysis essential. Yet a general method that consolidates their loop constraints has been lacking. We present an automated approach that generates the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS). From a minimally extended data schema, the tool constructs the facet-hinge graph, extracts a minimum cycle basis that captures all constraints, and assembles a velocity-level constraint matrix via screw theory that encodes coupled rotation and translation loop closure. The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations.

</details>


### [8] [The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation](https://arxiv.org/abs/2601.10268)
*Eszter Birtalan,Miklós Koller*

Main category: cs.RO

TL;DR: 本研究通过模拟评估了6种不同密度和布局的触觉传感器配置对强化学习的影响，确定了一种在两种设置下均表现最佳的配置，有助于未来机器人手设计包括假肢的研究。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器为机器人提供接触表面的直接信息，对于提高抓握稳定性尤其重要。然而，目前大多数机器人手设计中，这些传感器的密度和布局差异很大，且往往占用了大部分可用空间。

Method: 使用模拟来评估6种不同密度和布局的触觉传感器配置，并基于它们对强化学习的影响进行比较。采用两套系统以确保结果不依赖于特定的物理模拟器、机器人手模型或机器学习算法。

Result: 结果显示了特定设置及跨六种传感模拟的一般性影响，并识别出一种配置在两种设置下始终表现出最好的性能。

Conclusion: 该研究表明，特定触觉传感器配置能够显著提升机器人手（含假肢）的性能，为未来的设计提供了指导方向。

Abstract: Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available space. We used simulations to evaluate 6 different tactile sensor configurations with different densities and layouts, based on their impact on reinforcement learning. Our two-setup system allows for robust results that are not dependent on the use of a given physics simulator, robotic hand model or machine learning algorithm. Our results show setup-specific, as well as generalized effects across the 6 sensorized simulations, and we identify one configuration as consistently yielding the best performance across both setups. These results could help future research aimed at robotic hand designs, including prostheses.

</details>


### [9] [CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing](https://arxiv.org/abs/2601.10340)
*David Morilla-Cabello,Eduardo Montijano*

Main category: cs.RO

TL;DR: 提出了一种集成语义感知框架CHORAL，用于协调异构机器人团队执行复杂环境监测任务。通过侦察飞行构建度量-语义地图，识别需要更仔细检查的区域，并为每个平台规划基于能力的路径。实验表明该方法能有效规划更安全、高效的路线。


<details>
  <summary>Details</summary>
Motivation: 在使用异构机器人团队监控大型、未知和复杂环境时，现有方法往往假设同质化团队或只关注离散任务兼容性，而没有充分整合场景理解到路由决策中，限制了适应环境及利用各机器人优势的能力。

Method: 开发了一个名为CHORAL的集成语义感知框架，首先通过侦察飞行创建一个度量-语义地图，然后利用该地图来确定需要进一步检查的区域，并为每种类型的机器人设计符合其能力特点的路径。这些信息被整合进一个异构车辆路径规划公式中，共同分配检查任务并计算机器人轨迹。

Result: 仿真与实际检验任务中的实验结果证明了所提方法能够通过明确考虑每个平台的导航能力来规划更加安全且高效的路径。

Conclusion: 提出的CHORAL框架有效地解决了异构机器人团队在复杂环境中执行任务时面临的挑战，通过更好地整合场景理解和机器人的特定能力，实现了更优的任务分配与路径规划。

Abstract: Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.

</details>


### [10] [FastStair: Learning to Run Up Stairs with Humanoid Robots](https://arxiv.org/abs/2601.10365)
*Yan Liu,Tao Yu,Haolin Song,Hongbo Zhu,Nianzong Hu,Yuzhi Hao,Xiuyong Yao,Xizhe Zang,Hua Chen,Jie Zhao*

Main category: cs.RO

TL;DR: FastStair, a planner-guided, multi-stage learning framework, combines the strengths of model-based foothold planning and model-free reinforcement learning to achieve fast and stable stair ascent for humanoid robots. It was successfully deployed on the Oli robot, enabling it to ascend stairs at high speeds, and won first place in the Canton Tower Robot Run Up Competition.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to address the challenge faced by humanoid robots in running up stairs, which requires both high agility and strict stability. The authors aim to integrate the benefits of model-free reinforcement learning (for dynamic locomotion) and model-based foothold planning (for ensuring contact feasibility and stability) to create a solution that can enable fast and safe stair ascent for robots.

Method: The method introduced is FastStair, a planner-guided, multi-stage learning framework. It incorporates a parallel model-based foothold planner into the RL training loop to promote exploration towards feasible contacts and pretrain a safety-focused base policy. To reduce conservatism from the planner and adapt to different speed requirements, the base policy undergoes fine-tuning to become speed-specialized experts, followed by integration through Low-Rank Adaptation (LoRA) for smooth operation across various speeds.

Result: The resulting controller was implemented on the Oli humanoid robot, allowing it to ascend stairs stably at commanded speeds reaching 1.65 m/s. Moreover, the robot managed to traverse a 33-step spiral staircase with a 17 cm rise per step in just 12 seconds, showcasing its capability for robust, high-speed performance on long staircases. This approach also secured the championship in the Canton Tower Robot Run Up Competition.

Conclusion: FastStair effectively merges the advantages of model-based and model-free techniques, leading to significant advancements in enabling humanoid robots to run up stairs quickly and safely. The demonstrated success in both controlled experiments and a real-world competition highlights the potential of this approach for enhancing robotic mobility in complex environments.

Abstract: Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition.

</details>
