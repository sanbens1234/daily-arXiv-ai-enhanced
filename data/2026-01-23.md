<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Designing Persuasive Social Robots for Health Behavior Change: A Systematic Review of Behavior Change Strategies and Evaluation Methods](https://arxiv.org/abs/2601.15309)
*Jiaxin Xu,Chao Zhang,Raymond H. Cuijpers,Wijnand A. IJsselsteijn*

Main category: cs.RO

TL;DR: 本系统综述总结了在使用社交机器人促进健康行为改变的研究中采用的行为改变策略及评估方法，指出了社交机器人的独特优势，并为未来的人机交互研究提出了建议。


<details>
  <summary>Details</summary>
Motivation: 尽管社交机器人越来越多地被用作健康行为改变的干预手段，但关于如何指导其设计和评估的可操作知识仍然有限。

Method: 通过系统的数据库搜索和手动搜索确定相关文献，分析了39项研究，从中归纳出四类主要的行为改变策略：辅导策略、咨询策略、社会影响策略以及增强说服力的策略。同时，还分析了当前评估实践的关键特征，包括研究设计、环境、持续时间及结果测量等方面。

Result: 发现社交机器人作为行为改变干预措施具有独特的适用性，并提供了宝贵的设计启发式方法。此外，还基于现有评估实践提出了未来人机交互研究的几个方向。

Conclusion: 本文强调了社交机器人在促进健康行为改变方面的潜力，并呼吁加强针对其设计与效果评估的研究。

Abstract: Social robots are increasingly applied as health behavior change interventions, yet actionable knowledge to guide their design and evaluation remains limited. This systematic review synthesizes (1) the behavior change strategies used in existing HRI studies employing social robots to promote health behavior change, and (2) the evaluation methods applied to assess behavior change outcomes. Relevant literature was identified through systematic database searches and hand searches. Analysis of 39 studies revealed four overarching categories of behavior change strategies: coaching strategies, counseling strategies, social influence strategies, and persuasion-enhancing strategies. These strategies highlight the unique affordances of social robots as behavior change interventions and offer valuable design heuristics. The review also identified key characteristics of current evaluation practices, including study designs, settings, durations, and outcome measures, on the basis of which we propose several directions for future HRI research.

</details>


### [2] [Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray](https://arxiv.org/abs/2601.15349)
*Jiaqing Chang,Song Gao,Chaowei Dong,zhaobang Li,Yang Liu*

Main category: cs.RO

TL;DR: 本研究设计并制造了一种基于鲼鲼游泳原理的磁响应微型软体机器人，通过三维亥姆霍兹线圈产生振荡谐波磁场进行驱动，并探索了磁场参数对机器人游泳性能的影响。实验结果表明，在B=5mT和f=11Hz时游泳速度最快，可达5.25mm/s。此外，通过调整线圈电流方向和频率，机器人能够实现直线游泳、转弯游泳和定向游泳等不同模式。


<details>
  <summary>Details</summary>
Motivation: 在狭窄且无结构的水下环境中，如环境监测和微创医疗程序中，微型软体机器人由于其灵活的移动能力和小尺寸而显示出独特的优势。同时，将仿生技术应用于微型软体机器人的结构设计可以显著提高它们的游泳性能。然而，这些机器人受限于小型化，难以内部供电，通常采用无线供电方式。

Method: 设计与制造了一个模仿鲼鲼游泳机制的磁响应微型软体机器人，该机器人由特定比例的钕铁硼（NdFeB）和聚二甲基硅氧烷（PDMS）制成。使用三维亥姆霍兹线圈来生成振荡谐波磁场以驱动机器人进行游泳实验，探讨了磁场参数对机器人游泳性能的影响。

Result: 当磁场强度B为5毫特斯拉(mT)、频率f为11赫兹(Hz)时，游泳速度达到最大值5.25毫米/秒(mm/s)，相当于每秒约0.5个身体长度的速度。另外，通过改变线圈中的电流方向和频率，可以使机器人完成直线游泳、转弯游泳以及定向游泳等多种游泳模式。

Conclusion: 这项研究表明了一种磁驱动微型软体机器人的方法，为无线驱动机器人在水下狭小空间的应用奠定了基础。

Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.

</details>


### [3] [Learning a Unified Latent Space for Cross-Embodiment Robot Control](https://arxiv.org/abs/2601.15419)
*Yashuai Yan,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出了一种可扩展的框架，通过学习一种共享的潜在表示来统一人类和各种类人机器人平台（包括单臂、双臂和腿部类人机器人）之间的动作。该方法分两个阶段进行：首先使用对比学习构建一个解耦的潜在空间，捕捉不同身体部位的局部运动模式；然后直接在此潜在空间中训练以目标为条件的控制策略。实验结果表明，该方法能够在多种类人机器人平台上实现稳健、可扩展且与具体形态无关的机器人控制。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发一种能够跨越不同人体形态（如单臂、双臂及有腿的人形机器人）实现一致运动控制的方法。希望通过创建一个通用但又能适应特定机器人特性的潜在表示，使得从人类到多样化的机器人平台的动作转移变得更加准确与灵活。

Method: 本研究采用了两步法：第一步利用对比学习建立了一个分离式的潜空间模型，用于识别并编码不同身体部分间的独立运动模式，并通过结合关节旋转与末端执行器定位设计了针对关键区段（例如手臂）的定制化相似度量标准来加强不同实体间的一致性。第二步则是在这个潜空间内基于人类数据训练出一个依赖于目标设定的控制策略，借助条件变分自动编码器让该策略学会根据预期的目标方向预测潜空间内的位移变化。

Result: 实验结果显示，所训练出的策略可以直接应用于多个机器人而无需额外调整，并且新机器人的加入只需学习一个轻量级的、针对特定机器人的嵌入层即可。这证明了提出的方法能够促进跨多种人形平台的稳健、可扩展以及对具体实体形式不敏感的机器人控制。

Conclusion: 本文介绍了一种新颖的框架，它通过学习共享的潜在表征来实现跨不同形态的人形机器人控制。该框架不仅支持在无需任何调整的情况下将训练好的策略直接部署到多个机器人上，还允许高效地添加新的机器人到潜在空间中去，从而展示了其在实现广泛适用性、灵活性以及鲁棒性方面的能力。

Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.

</details>


### [4] [A Universal Large Language Model -- Drone Command and Control Interface](https://arxiv.org/abs/2601.15486)
*Javier N. Ramos-Silva,Peter J. Burke*

Main category: cs.RO

TL;DR: 本研究提出了一种新的模型上下文协议（MCP）标准，实现了大型语言模型（LLMs）与无人机控制的无缝对接。通过云基Linux机器上托管的支持Mavlink协议的MCP服务器，成功展示了对真实及模拟无人机的飞行控制和规划能力，为现代AI技术与无人机技术的融合提供了一个通用、多功能且易于使用的接口。


<details>
  <summary>Details</summary>
Motivation: 随着物理AI领域的不断扩展，如何将大型语言模型（LLMs）有效地应用于无人机控制成为一个亟待解决的问题。尽管LLMs在大规模训练下表现出色，并能处理包括全球地理拓扑在内的详细信息，但在将这些知识实际应用于无人机指挥和控制时面临着接口兼容性差、工作量大等挑战。

Method: 研究团队开发了一种名为模型上下文协议（MCP）的新标准，旨在作为一种开放标准让AI系统能够访问外部数据、工具和服务。基于此，他们搭建了一个支持广泛使用的Mavlink协议的云端Linux机器作为MCP服务器，从而实现与大多数无人机（如Ardupilot和PX4框架下的无人机）之间的通讯。

Result: 通过该解决方案，研究人员不仅成功地实现了对一架真实无人驾驶飞机的飞行控制，还进一步展示了模拟环境中无人机广泛的飞行计划与控制能力。此外，结合Google Maps MCP服务器提供的最新实时导航信息，证明了这种方法在集成LLMs与无人机指挥控制系统方面的普遍适用性。

Conclusion: 这项研究介绍了一种创新的方法来连接大型语言模型与无人机控制，通过引入模型上下文协议标准解决了长期以来存在的接口问题。这不仅简化了自然语言到无人机指令转换的过程，也为未来AI技术与无人机技术更深层次的融合奠定了基础。

Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.

</details>


### [5] [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](https://arxiv.org/abs/2601.15541)
*Heng Zhang,Wei-Hsing Huang,Qiyi Tong,Gokhan Solak,Puze Liu,Sheng Liu,Jan Peters,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种CompliantVLA适配器，通过视觉-语言模型指导的上下文感知可变阻抗控制（VIC）来增强最先进的视觉-语言-动作（VLA）模型，以提高接触丰富机器人操作任务的安全性和有效性。该方法利用VLM从图像和自然语言中解释任务背景，调整VIC控制器的刚度和阻尼参数，并结合实时力/扭矩反馈进一步调节这些参数，确保交互力保持在安全阈值内。实验结果表明，在模拟环境和实际硬件上，该方法在一系列复杂的接触丰富任务中优于VLA基线方法，提高了成功率并减少了力违规情况。


<details>
  <summary>Details</summary>
Motivation: 当前的VLA系统通常只输出位置信息，缺乏对力敏感的适应能力，导致在涉及接触、柔顺性或不确定性的物理任务中容易出现不安全或失败的互动。为了改善这种情况，研究者们旨在开发一种能够理解任务背景并根据实际情况调整执行策略的方法，从而提高操作的安全性和成功率。

Method: 本研究提出了一种名为CompliantVLA-adaptor的新方法，它通过视觉-语言模型（VLM）来解析来自图像和自然语言的任务上下文信息，据此调整可变阻抗控制器（VIC）的刚度与阻尼参数。此外，还采用了实时力/扭矩反馈机制来动态校正这些参数，保证互动过程中施加的力量处于预设的安全界限之内。

Result: 实验结果显示，所提出的方法在多种复杂且富含接触的任务场景下均表现优异，无论是仿真测试还是实际设备操作中，相较于基础VLA方案，不仅提升了整体任务完成的成功率（从9.86%增长到17.29%），同时也显著降低了超出安全范围的力作用次数。

Conclusion: CompliantVLA适配器为实现更安全有效的接触丰富型机器人操作提供了一个有前景的方向。通过整合视觉-语言理解和力反馈控制，该方法能够更好地适应具有挑战性的物理任务需求，展示出比现有VLA系统更高的性能。

Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

</details>


### [6] [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](https://arxiv.org/abs/2601.15545)
*Zhifan Yan,Chang Liu,Yiyang Jiang,Wenxuan Zheng,Xinhao Chen,Axel Krieger*

Main category: cs.RO

TL;DR: 本文介绍了一种基于深度强化学习的紧凑且低成本的移动磁操作平台，用于胃肠道内磁性机器人的精准控制。通过使用软演员-评论家算法，并结合模拟到现实的训练流程，该系统能够在15分钟内部署有效策略，显著减少了设置时间。实验验证了此平台在2D路径跟踪和大工作空间中的精确操控能力。


<details>
  <summary>Details</summary>
Motivation: 针对胃肠道内靶向药物递送时，磁性机器人控制面临的挑战，即固定磁系统的工作空间有限，而移动系统则需要复杂的预先校准物理模型，耗时且计算成本高。

Method: 提出一种低成本、紧凑型移动磁操纵平台，利用深度强化学习（特别是软演员-评论家算法）来克服上述限制。该平台由安装于UR5协作机器人上的四电磁铁阵列组成，并通过模拟到真实的管道进行训练。

Result: 实验结果表明，基于DRL的控制器能够实现对7毫米磁胶囊的有效控制，在方形路径上达到1.18毫米、圆形路径上达到1.50毫米的均方根误差。此外，还在临床上相关的30厘米*20厘米工作区域内展示了成功的轨迹追踪性能。

Conclusion: 这项研究表明了一个快速部署、无需建模的控制框架，能够在较大的工作空间内实现精准的磁力操纵，为胃肠道内的靶向治疗提供了一种新的解决方案。

Abstract: Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suffer from a "model-calibration bottleneck", requiring complex, pre-calibrated physical models that are time-consuming to create and computationally expensive. This paper presents a compact, low-cost mobile magnetic manipulation platform that overcomes this limitation using Deep Reinforcement Learning (DRL). Our system features a compact four-electromagnet array mounted on a UR5 collaborative robot. A Soft Actor-Critic (SAC)-based control strategy is trained through a sim-to-real pipeline, enabling effective policy deployment within 15 minutes and significantly reducing setup time. We validated the platform by controlling a 7-mm magnetic capsule along 2D trajectories. Our DRL-based controller achieved a root-mean-square error (RMSE) of 1.18~mm for a square path and 1.50~mm for a circular path. We also demonstrated successful tracking over a clinically relevant, 30 cm * 20 cm workspace. This work demonstrates a rapidly deployable, model-free control framework capable of precise magnetic manipulation in a large workspace,validated using a 2D GI phantom.

</details>


### [7] [Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor](https://arxiv.org/abs/2601.15607)
*Lenworth Thomas,Tjaden Bridges,Sarah Bergbreiter*

Main category: cs.RO

TL;DR: 本文提出了一种结合气流源寻找行为的化学羽流跟踪方法，使用一种定制的可以感知气流大小和方向的传感器，并实现了一种改进版的'Cast and Surge'算法来定位并导航至气流源头。


<details>
  <summary>Details</summary>
Motivation: 随着环境灾难发生得越来越频繁和严重，利用羽流追踪寻找污染物或有害颗粒物来源变得愈发重要。在小型四旋翼无人机上进行羽流追踪能够使这些系统在人类周围及更狭小的空间内操作，但由于适合小型四旋翼无人机的气体传感器灵敏度低且响应时间长，这给羽流追踪带来了挑战。

Method: 研究者们开发了一个定制的流传感器，它可以在重量小于100克的小型四旋翼无人机上同时感知气流大小和方向。他们使用这个传感器实现了修改版的“投掷与冲刺”算法，该算法利用了流向感应能力来找到并朝向气流源头导航。

Result: 通过一系列特性实验验证了该系统能够在飞行中检测到气流，并重新定向四旋翼机朝向气流。此外，从随机起始位置和方向出发的多次试验证明了所提出的源搜寻算法能够可靠地找到流动源头。

Conclusion: 本研究旨在为未来能将流传感器与其他传感器结合使用的平台提供基础，以实现更丰富的羽流追踪数据收集和源搜寻功能。

Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors < 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.

</details>


### [8] [AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning](https://arxiv.org/abs/2601.15614)
*Zichen Yan,Yuchen Hou,Shenao Wang,Yichao Gao,Rui Huang,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出了AION，一种用于基于视觉的空中ObjectNav的端到端双策略强化学习框架，在AI2-THOR基准测试中表现出色，并在IsaacSim中进行了实时性能评估。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要集中在2D移动下的零样本ObjectNav上，而将它扩展到具有3D移动能力的空中平台仍处于未充分探索的状态。空中机器人提供了优越的机动性和搜索效率，但也带来了新的挑战，如空间感知、动态控制和安全保障。

Method: AION是一种端到端的双策略强化学习（RL）框架，将探索行为和目标到达行为分解为两个专门的策略，不依赖外部定位或全局地图。

Result: 实验结果表明，AION在探索、导航效率和安全性等方面的综合评价指标上取得了优异的表现。

Conclusion: 通过引入AION框架，研究成功地解决了基于视觉的空中ObjectNav问题，且该方法在多种评价标准下均优于现有方法。

Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.

</details>


### [9] [Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV](https://arxiv.org/abs/2601.15775)
*Amir Habel,Ivan Snegirev,Elizaveta Semenyakina,Miguel Altamirano Cabrera,Jeffrin Sam,Fawad Mehboob,Roohan Ahmed Khan,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Glove2UAV的可穿戴IMU手套界面，它通过手势控制无人机，并在超过预设速度阈值时提供振动触觉警告。


<details>
  <summary>Details</summary>
Motivation: 为了促进在动态飞行中的更安全和更可预测的互动，设计了Glove2UAV作为轻量级且易于部署的实时操作可穿戴界面。

Method: Glove2UAV 实时流式传输惯性测量数据，并使用结合中位数异常抑制与Madgwick姿态估计的紧凑处理流程来估算手掌和手指的方向。所得到的动作估计被映射到一组有限的控制原语，用于方向飞行（前进/后退和侧向移动）以及平台支持的对象交互命令。当飞行速度超过预定义阈值时，会触发振动触觉反馈。

Result: 通过将手套信号与无人机遥测同步，在模拟和实际飞行中验证了其实时可行性。结果显示，基于手势的命令执行快速、手势动态与平台运动之间耦合稳定、核心命令集在试验中正确运作并且及时提供了振动警告提示。

Conclusion: Glove2UAV 提供了一种直观且响应迅速的方法来通过手势控制无人机，同时利用振动触觉反馈增强了安全性。

Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.

</details>


### [10] [Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems](https://arxiv.org/abs/2601.15946)
*Zijie Chen,Xiaowei Liu,Yong Xu,Shenghai Yuan,Jianping Li,Lihua Xie*

Main category: cs.RO

TL;DR: 提出了一种无需目标的LiDAR-电机校准方法（LM-Calibr）和一种环境自适应的LiDAR-惯性里程计（EVA-LIO），以解决旋转式LiDAR应用中的校准泛化能力和定位鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要根据不同的安装配置参数化外在参数，限制了其通用性；同时，旋转式LiDAR不可避免地会扫描无特征区域，这使得扫描覆盖范围与定位鲁棒性之间的平衡变得复杂。

Method: 基于Denavit-Hartenberg约定开发了无需目标的LiDAR-电机校准系统(LM-Calibr)，以及能够根据空间尺度自适应选择下采样率和地图分辨率的环境自适应LiDAR-惯性里程计(EVA-LIO)。

Result: 广泛的实验表明，LM-Calibr在不同场景、安装角度和初始值情况下都具有准确性和收敛性。此外，EVA-LIO通过使执行器以最高速度运行来提高扫描完整性，同时确保即使在LiDAR短暂扫描无特征区域时也能保持强大的定位能力。

Conclusion: 该研究为旋转驱动LiDAR的应用提供了更加灵活可靠的校准及定位解决方案，并且开源了相关代码和硬件设计。

Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}

</details>


### [11] [PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour](https://arxiv.org/abs/2601.15995)
*Liang Wang,Kanzhong Yao,Yang Liu,Weikai Qin,Jun Wu,Zhe Sun,Qiuguo Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种端到端的学习框架PUMA，它将视觉感知和落脚点先验集成在一个阶段的训练过程中，以提高四足机器人在跑酷任务中的灵活性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于遵循预计算落脚点的分层控制器，这限制了机器人的实时适应性和强化学习的探索潜力。为了克服这些挑战，作者提出了新的解决方案。

Method: PUMA是一种端到终的学习框架，通过利用地形特征估计自我中心极坐标落脚点先验（包括相对距离和方向），指导机器人主动调整姿态以完成跑酷任务。

Result: 在模拟环境和真实世界的各种复杂离散地形上进行了广泛的实验，证明了PUMA在具有挑战性场景下的出色灵活性和鲁棒性。

Conclusion: PUMA提供了一个有效的解决方案来增强四足机器人的动态适应能力，并展示了其在面对困难环境时执行跑酷任务的能力。

Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

</details>


### [12] [Collision-Free Humanoid Traversal in Cluttered Indoor Scenes](https://arxiv.org/abs/2601.16035)
*Han Xue,Sikai Liang,Zhikai Zhang,Zicheng Zeng,Yun Liu,Yunrui Lian,Jilong Wang,Qingtao Liu,Xuesong Shi,Li Yi*

Main category: cs.RO

TL;DR: 本文提出了一种名为Humanoid Potential Field (HumanoidPF)的方法，用于在充满障碍物的室内环境中实现人形机器人无碰撞穿越。通过将障碍物与人形机器人之间的关系编码为无碰撞运动方向，简化了基于强化学习的穿越技能的学习过程，并且发现HumanoidPF作为感知表示，在模拟到现实中的转换差距极小。此外，还提出了一种混合场景生成方法以增强穿越技能的泛化能力。实验结果表明该方法的有效性，并已成功应用于真实世界中的人形机器人控制。


<details>
  <summary>Details</summary>
Motivation: 在复杂的室内环境中，人形机器人需要能够安全地穿越各种障碍物，比如跨过地板上的物体、蹲下穿过低挂障碍物或挤过狭窄通道。然而，由于缺乏有效的表示方法来捕捉避障过程中人形机器人与障碍物间的关系，直接学习这种映射变得十分困难。

Method: 提出了Humanoid Potential Field（HumanoidPF），它将人形机器人与其周围障碍物之间的关系编码成无碰撞的移动方向；开发了一种结合实际3D室内场景裁剪和程序合成障碍物的混合场景生成方法；设计了一个远程操作系统，用户只需单击即可指挥人形机器人在复杂室内环境中穿行。

Result: HumanoidPF极大地促进了基于强化学习的穿越技能学习，并表现出很小的模拟到现实差距；所提出的混合场景生成方法进一步增强了穿越技能的泛化能力；实验证明了方法的有效性，并且策略已成功转移到真实世界应用中。

Conclusion: 本研究为人形机器人在复杂室内环境下的无碰撞穿行提供了解决方案，通过引入HumanoidPF以及混合场景生成技术，显著提高了机器人适应不同障碍布局的能力。

Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.

</details>


### [13] [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](https://arxiv.org/abs/2601.16046)
*Junha Lee,Eunha Park,Minsu Cho*

Main category: cs.RO

TL;DR: DextER, a model for dexterous grasp generation, uses contact-based embodied reasoning to predict hand-object interactions, achieving a 67.14% success rate on DexGYS and outperforming the state-of-the-art by 3.83 percentage points.


<details>
  <summary>Details</summary>
Motivation: 现有方法直接将观察映射到抓取参数，而没有对物理交互进行中间推理。DextER通过引入基于接触的具身推理来解决这一问题，旨在桥接任务语义与物理约束。

Method: DextER使用自回归方式生成体现接触标记，指定手指链接在物体表面上的接触位置，然后是编码手部配置的抓取标记。

Result: 在DexGYS上，DextER达到了67.14%的成功率，比最先进方法提高了3.83个百分点，并且在意图一致性上提高了96.4%。此外，还展示了通过部分接触规范实现可控生成的能力。

Conclusion: DextER通过采用基于接触点的具身推理方法，在灵巧抓握生成方面取得了显著进步，不仅提高了成功率，还增强了意图一致性和抓握合成的精细控制能力。

Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.

</details>


### [14] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis](https://arxiv.org/abs/2601.16062)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文分析了基于SE2(3)李群的高精度导航模型在不同参考系下的自治性问题，并提出了一种新的构建方法来减少科里奥利力项的影响，从而使得导航模型更接近完全自治。


<details>
  <summary>Details</summary>
Motivation: 尽管基于SE2(3)李群框架的导航建模在低精度应用中表现良好，但在考虑地球自转和惯性器件偏差时，难以保持高精度导航状态估计所需的自治性。研究旨在解决这一挑战，提高导航模型的自治性。

Method: 通过对基于SE2(3)李群的高精度导航模型在惯性、地球以及世界坐标系下的理论分析，识别出传统建模方法中存在的由非惯性参考系速度引入的科里奥利力项限制。随后提出了改进的SE2(3)李群导航模型构建方法。

Result: 发现传统SE2(3)李群导航建模方式因存在由非惯性参考系速度导致的科里奥利力项而限制了模型自治性；提出的新构建方法有助于减少这种影响，使导航模型趋向于更加自治。

Conclusion: 本研究通过理论分析揭示了传统SE2(3)李群导航模型存在的局限性，并提出了解决方案以改善模型自治性，为实现高精度自主导航提供新思路。

Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.

</details>


### [15] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application](https://arxiv.org/abs/2601.16078)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本论文通过实际的SINS/里程计实验和蒙特卡洛模拟，展示了改进后的基于SE2(3)群的高精度导航模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高非惯性导航模型的完全自主性，提出了一种构建SE2(3)群导航模型的方法。

Method: 进行了实际的SINS/里程计实验以及蒙特卡洛模拟来展示基于改进后SE2(3)群的高精度导航模型的表现。

Result: 实验证明了改进后的基于SE2(3)群的导航模型具有良好的性能。

Conclusion: 通过实验和仿真结果表明，所提出的改进SE2(3)群导航模型在实现高精度导航方面是有效的。

Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.

</details>


### [16] [Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision](https://arxiv.org/abs/2601.16109)
*Yashuai Yan,Tobias Egle,Christian Ott,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出了一种结合基于模型的双足运动与残差强化学习（RL）的控制框架，通过引入具有特权访问真实动态信息的基于模型的oracle策略来监督残差策略的学习，从而实现对未建模效应的有效补偿，提高鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了在存在现实世界不确定性的情况下实现稳健和适应性强的行走，作者们开发了一个将基于模型的控制器与残差强化学习相结合的框架，旨在解决由于动力学建模不准确和传感器噪声带来的问题。

Method: 采用一个基于模型的控制器作为基础策略，并引入了通过领域随机化训练的残差策略。此外，利用一个可以访问训练期间地面真实动态数据的基于模型的oracle策略，通过一种新的监督损失函数来指导残差策略的学习。

Result: 该方法展示出在一系列随机条件下改进的鲁棒性和泛化能力，为双足运动中的模拟到现实迁移提供了一个可扩展解决方案。

Conclusion: 研究证明了结合基于模型的方法与残差RL可以在面对不确定性和未建模效应时有效提升双足机器人的行走性能。

Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.

</details>


### [17] [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](https://arxiv.org/abs/2601.16207)
*Jongwoo Park,Kanchana Ranasinghe,Jinhyeok Jang,Cristina Mata,Yoo Sung Jang,Michael S Ryoo*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级、无需训练的方法IVRA，通过利用模型内置视觉编码器中的亲和性提示来增强空间理解能力，从而在不需外部编码器或重新训练的情况下改善了视觉-语言-动作模型的性能。实验表明，该方法在多个2D和3D操作基准测试中均有显著改进，并且代码和模型将公开发布。


<details>
  <summary>Details</summary>
Motivation: 当前许多视觉-语言-动作（VLA）模型将图像块展平为一维标记序列，这样会削弱精确操作所需的二维空间线索。为了克服这一问题并提高模型的空间理解能力，作者提出了IVRA方法。

Method: IVRA是一种轻量级且无需额外训练的技术，它利用现有VLA模型内置视觉编码器内的亲和性信息，选择性地将这些信号注入到包含实例级别特征的语言模型层中。此过程在推理阶段执行，旨在重新调整视觉标记之间的交互作用，同时更好地保持几何结构，而无需更改任何模型参数。

Result: 研究者们在不同的VLA架构（如LLaRA、OpenVLA和FLOWER）上应用了IVRA，并在涵盖2D和3D操纵任务的模拟基准测试（VIMA和LIBERO）以及多种真实机器人任务中进行了验证。结果显示，在2D VIMA低数据环境下，与基线LLaRA相比，IVRA使平均成功率提高了4.2%；而在3D LIBERO上，即使是在基线准确率接近饱和时，IVRA也能够持续提供增益（从96.3%提高到了97.1%）。

Conclusion: IVRA作为一种简单有效的解决方案，能够显著提升VLA模型的空间感知能力，其优势在于无需对现有模型进行修改或额外训练即可实现性能提升。此外，这种方法适用于多种VLA架构，并已在不同类型的操纵任务中展示了其有效性。

Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA

</details>
