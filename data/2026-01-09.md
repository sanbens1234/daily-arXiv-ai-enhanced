<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 14]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization](https://arxiv.org/abs/2601.04334)
*Amit Jain,Richard Linares*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习的制导与控制方法，结合了具有推理能力的大规模语言模型（LLM）和组相对策略优化（GRPO）。通过监督微调(SFT)学习格式化和控制原语，然后使用GRPO进行交互驱动的策略改进。该框架在从线性系统到非线性振荡动力学以及三维航天器姿态控制等四个控制问题上进行了演示。结果表明，在一致的训练设置下，经过GRPO优化、具备显式推理能力的LLM能够为线性和非线性系统合成可行的稳定策略。两阶段训练方法让模型能够生成控制序列的同时提供人类可读的决策过程解释。


<details>
  <summary>Details</summary>
Motivation: 探索将大规模语言模型的推理能力应用于自动控制系统中，以期在航空航天及其他安全关键领域开发出更智能、更可靠的控制器。

Method: 采用一种两阶段训练过程：首先通过监督微调让LLM学会基础的格式化信息及控制指令；随后利用组相对策略优化进一步提升其根据环境反馈做出反应的能力。

Result: 实验显示，所提方法能够在不同复杂度的动力学环境下有效地生成稳定控制策略，并且能够给出易于理解的操作理由。

Conclusion: 本研究表明，通过结合LLM的推理能力和GRPO算法，可以为各种类型的控制系统设计出既能执行任务又能自我解释的智能控制器，为未来在高风险领域的应用奠定了基础。

Abstract: This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.

</details>


### [2] [UNIC: Learning Unified Multimodal Extrinsic Contact Estimation](https://arxiv.org/abs/2601.04356)
*Zhengtong Xu,Yuki Shirai*

Main category: cs.RO

TL;DR: 本文提出了UNIC，一种无需先验知识或相机校准的多模态框架，用于外在接触估计。它通过直接编码视觉观察并与本体感觉和触觉模式整合来实现数据驱动的操作，并引入了一种基于场景适应性图的统一接触表示法。实验表明UNIC在未见过的接触位置、新物体上表现良好，且在缺少某些模态及动态相机视角下也能保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往依赖于预定义的接触类型、固定的抓握配置或相机校准等限制性假设，这阻碍了对新对象的泛化以及在非结构化环境中的部署。因此，需要一种更通用的方法来进行外在接触估计，以支持接触丰富的操作任务。

Method: UNIC是一个多模态框架，它直接在相机帧中编码视觉观测结果，并以完全数据驱动的方式与本体感受和触觉模式相结合。该框架引入了一个基于场景适用性映射的统一接触表示，能够捕捉多种接触形式，并采用随机遮罩的多模态融合机制，促进稳健的多模态表征学习。

Result: 广泛的实验表明，UNIC对于未见的接触位置平均查分距离误差达到9.6毫米，在面对未知物体时表现优秀，即使是在缺少某种模态信息的情况下也依然保持强健性能，并且能够适应动态变化的相机视点。

Conclusion: UNIC为接触丰富操控提供了一种实用且多功能的外在接触估计能力，其在新颖情境下的可靠性、对未知物体的有效处理能力以及对不同工作条件的适应性得到了验证。

Abstract: Contact-rich manipulation requires reliable estimation of extrinsic contacts-the interactions between a grasped object and its environment which provide essential contextual information for planning, control, and policy learning. However, existing approaches often rely on restrictive assumptions, such as predefined contact types, fixed grasp configurations, or camera calibration, that hinder generalization to novel objects and deployment in unstructured environments. In this paper, we present UNIC, a unified multimodal framework for extrinsic contact estimation that operates without any prior knowledge or camera calibration. UNIC directly encodes visual observations in the camera frame and integrates them with proprioceptive and tactile modalities in a fully data-driven manner. It introduces a unified contact representation based on scene affordance maps that captures diverse contact formations and employs a multimodal fusion mechanism with random masking, enabling robust multimodal representation learning. Extensive experiments demonstrate that UNIC performs reliably. It achieves a 9.6 mm average Chamfer distance error on unseen contact locations, performs well on unseen objects, remains robust under missing modalities, and adapts to dynamic camera viewpoints. These results establish extrinsic contact estimation as a practical and versatile capability for contact-rich manipulation.

</details>


### [3] [Fast Continuum Robot Shape and External Load State Estimation on SE(3)](https://arxiv.org/abs/2601.04493)
*James M. Ferguson,Alan Kuntz,Tucker Hermans*

Main category: cs.RO

TL;DR: 本文提出了一种新的连续体机器人状态估计框架，该框架可以处理包括驱动输入、外力和力矩、过程噪声、边界条件以及任意骨架测量在内的不确定性模型。通过在时空域内进行联合估计，并利用因子图表示法实现快速批量稀疏非线性优化，适用于广泛的连续体机器人类型。


<details>
  <summary>Details</summary>
Motivation: 先前的连续体机器人状态估计方法通常采用简化的Cosserat杆模型，这种模型无法直接考虑驱动输入或外部负载的影响。为了克服这一限制，作者提出了一个更通用的状态估计框架。

Method: 所提出的方法结合了对驱动（如肌腱张力）、施加的力和力矩、过程噪声、边界条件及任意骨架测量的不确定性建模。通过在时间步骤之间添加时间先验，该方法能够在空间（弧长）和时间域上进行联合估计，从而实现全时空状态估计。将弧长域离散化后，可以获得连续体机器人模型的因子图表示，进而用于类似SLAM中的快速批处理稀疏非线性优化。

Result: 该框架被证明是通用的，可应用于广泛的连续体机器人；作为示例案例，展示了(i)仿真的肌腱驱动机器人中，实现了带有不确定性的实时运动学、基于位置反馈的尖端力感知以及基于骨架应变的分布式载荷估计；(ii)实验中的外科同心管机器人，验证了精确的运动学和尖端力估计，强调了其在外科触诊方面的潜力。

Conclusion: 这项工作展示了一个新的连续体机器人状态估计框架，它能够综合考虑多种类型的不确定性，并通过时空联合估计提供更加准确的状态估计结果，具有广泛的应用前景。

Abstract: Previous on-manifold approaches to continuum robot state estimation have typically adopted simplified Cosserat rod models, which cannot directly account for actuation inputs or external loads. We introduce a general framework that incorporates uncertainty models for actuation (e.g., tendon tensions), applied forces and moments, process noise, boundary conditions, and arbitrary backbone measurements. By adding temporal priors across time steps, our method additionally performs joint estimation in both the spatial (arclength) and temporal domains, enabling full \textit{spacetime} state estimation. Discretizing the arclength domain yields a factor graph representation of the continuum robot model, which can be exploited for fast batch sparse nonlinear optimization in the style of SLAM. The framework is general and applies to a broad class of continuum robots; as illustrative cases, we show (i) tendon-driven robots in simulation, where we demonstrate real-time kinematics with uncertainty, tip force sensing from position feedback, and distributed load estimation from backbone strain, and (ii) a surgical concentric tube robot in experiment, where we validate accurate kinematics and tip force estimation, highlighting potential for surgical palpation.

</details>


### [4] [Design and Development of Modular Limbs for Reconfigurable Robots on the Moon](https://arxiv.org/abs/2601.04541)
*Gustavo H. Diaz,A. Sejal Jain,Matteo Brugnera,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文介绍了4-DOF机器人肢体（称为Moonbots）的开发，这些模块化组件可以以多种配置相互连接和轮式模块组合，以适应不同的环境和任务。统一的驱动器设计简化了不同模块类型的开发和维护。文章还描述了硬件实现、机械设计以及用于控制和协调的整体软件架构，并通过九种功能配置展示了系统的适应性。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的太空任务中增加灵活性和多功能性，特别是在月球探测和建设中的应用。

Method: 开发了一种具有高扭矩与速度比的通用驱动器来支持精确控制和动态运动；设计了可互连的模块化组件；并构建了用于控制和协调这些模块的软件架构。

Result: 成功地创建了九种功能配置（例如4DOF肢体、8DOF肢体、车辆等），证明了该系统能够根据需要调整其结构以执行不同类型的任务。

Conclusion: 这种模块化机器人设计为太空探索提供了新的可能性，特别是对于需要灵活应对不同挑战的任务来说。

Abstract: In this paper, we present the development of 4-DOF robot limbs, which we call Moonbots, designed to connect in various configurations with each other and wheel modules, enabling adaptation to different environments and tasks. These modular components are intended primarily for robotic systems in space exploration and construction on the Moon in our Moonshot project. Such modular robots add flexibility and versatility for space missions where resources are constrained. Each module is driven by a common actuator characterized by a high torque-to-speed ratio, supporting both precise control and dynamic motion when required. This unified actuator design simplifies development and maintenance across the different module types. The paper describes the hardware implementation, the mechanical design of the modules, and the overall software architecture used to control and coordinate them. Additionally, we evaluate the control performance of the actuator under various load conditions to characterize its suitability for modular robot applications. To demonstrate the adaptability of the system, we introduce nine functional configurations assembled from the same set of modules: 4DOF-limb, 8DOF-limb, vehicle, dragon, minimal, quadruped, cargo, cargo-minimal, and bike. These configurations reflect different locomotion strategies and task-specific behaviors, offering a practical foundation for further research in reconfigurable robotic systems.

</details>


### [5] [Data-Driven Terramechanics Approach Towards a Realistic Real-Time Simulator for Lunar Rovers](https://arxiv.org/abs/2601.04547)
*Jakob M. Kern,James M. Hurrell,Shreya Santra,Keisuke Takehana,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文介绍了一种结合高视觉保真度和现实地形互动的月球表面模拟器，通过数据驱动的方法解决了轮-土壤交互模拟计算成本高的问题，实现了对平地及至20度斜坡上稳态与动态打滑以及沉陷行为的准确再现，并提升了地形变形和车轮轨迹可视化的逼真度。


<details>
  <summary>Details</summary>
Motivation: 现有的月球表面模拟器要么侧重于视觉真实感，要么注重物理准确性，但无法全面复制月球条件。本研究旨在填补这一空白，提供一个既能实现高视觉保真又能准确反映地形相互作用的解决方案。

Method: 采用基于回归模型的数据驱动方法来模拟轮-土壤之间的交互作用，这些模型基于全车实验、单轮实验及仿真收集到的数据建立。此方法特别针对模拟轮子在不同地形条件下的打滑和沉陷行为进行了优化。

Result: 开发出的基于回归的地形力学模型能够精确再现平地以及最大20度倾斜角度下稳态和动态打滑、沉陷现象，并且与实地测试结果相吻合。此外，还改进了地形变形和轮迹可视化效果，增强了模拟的真实感。

Conclusion: 所提出的方法成功地将高视觉保真度与真实的地形响应相结合，支持需要实时应用同时要求物理合理性的场景。

Abstract: High-fidelity simulators for the lunar surface provide a digital environment for extensive testing of rover operations and mission planning. However, current simulators focus on either visual realism or physical accuracy, which limits their capability to replicate lunar conditions comprehensively. This work addresses that gap by combining high visual fidelity with realistic terrain interaction for a realistic representation of rovers on the lunar surface. Because direct simulation of wheel-soil interactions is computationally expensive, a data-driven approach was adopted, using regression models for slip and sinkage from data collected in both full-rover and single-wheel experiments and simulations. The resulting regression-based terramechanics model accurately reproduced steady-state and dynamic slip, as well as sinkage behavior, on flat terrain and slopes up to 20 degrees, with validation against field test results. Additionally, improvements were made to enhance the realism of terrain deformation and wheel trace visualization. This method supports real-time applications that require physically plausible terrain response alongside high visual fidelity.

</details>


### [6] [Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain](https://arxiv.org/abs/2601.04551)
*Riku Suzuki,Ayumi Umemura,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种新的点云地图压缩方法，通过离散傅里叶变换（DFT）将数字高程模型（DEM）转换为频域2D图像，并省略高频成分，适用于渐变地形如行星表面和沙漠的探索。


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机器人探索任务中SLAM处理的点云数据量大与车载计算能力和通信带宽有限之间的矛盾，研究了针对点云数据的有效压缩方法。

Method: 采用离散傅里叶变换（DFT）技术，将数字高程模型转化为二维频域图像，并忽略对渐变地形影响较小的高频部分，从而实现数据压缩。

Result: 该方法在两个不同海拔轮廓的地形上进行了评估，在保证点云质量的同时达到了较好的压缩率。

Conclusion: 所提基于DFT的点云地图压缩方法对于渐变地形特别有效，能够在不显著降低点云质量的前提下大幅减少数据量，有助于提高无人机器人探索任务中的效率与可靠性。

Abstract: Simultaneous Localization and Mapping (SLAM) is an essential technology for the efficiency and reliability of unmanned robotic exploration missions. While the onboard computational capability and communication bandwidth are critically limited, the point cloud data handled by SLAM is large in size, attracting attention to data compression methods. To address such a problem, in this paper, we propose a new method for compressing point cloud maps by exploiting the Discrete Fourier Transform (DFT). The proposed technique converts the Digital Elevation Model (DEM) to the frequency-domain 2D image and omits its high-frequency components, focusing on the exploration of gradual terrains such as planets and deserts. Unlike terrains with detailed structures such as artificial environments, high-frequency components contribute little to the representation of gradual terrains. Thus, this method is effective in compressing data size without significant degradation of the point cloud. We evaluated the method in terms of compression rate and accuracy using camera sequences of two terrains with different elevation profiles.

</details>


### [7] [UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation](https://arxiv.org/abs/2601.04629)
*Zhongxuan Li,Zeliang Guo,Jun Hu,David Navarro-Alarcon,Jia Pan,Hongmin Wu,Peng Zhou*

Main category: cs.RO

TL;DR: 介绍了一个名为UniBiDex的机器人双臂灵巧操作远程操作框架，该框架支持基于VR和领导者-跟随者输入模式，并通过集成不同的输入设备到一个共享控制堆栈中来实现实时接触丰富的双臂遥控操作。


<details>
  <summary>Details</summary>
Motivation: 为了实现对机器人的实时、接触丰富且安全的双臂遥控操作，同时支持多种输入模式（如VR和领导者-跟随者）。

Method: 通过开发UniBiDex框架，集成了异构输入设备至共享控制堆栈中，并使用零空间控制优化双臂配置以确保任务执行过程中的平滑无碰撞运动。

Result: 在一项长期厨房整理任务中进行了验证，涉及五个连续的操作子任务，结果表明与强大的基线相比，该方法具有更高的任务成功率、更平滑的轨迹以及更好的鲁棒性。

Conclusion: UniBiDx提供了一种新的统一遥控操作解决方案，旨在降低收集大规模高质量人类演示数据集的门槛，并加速机器人学习领域的进展。

Abstract: We present UniBiDex a unified teleoperation framework for robotic bimanual dexterous manipulation that supports both VRbased and leaderfollower input modalities UniBiDex enables realtime contactrich dualarm teleoperation by integrating heterogeneous input devices into a shared control stack with consistent kinematic treatment and safety guarantees The framework employs nullspace control to optimize bimanual configurations ensuring smooth collisionfree and singularityaware motion across tasks We validate UniBiDex on a longhorizon kitchentidying task involving five sequential manipulation subtasks demonstrating higher task success rates smoother trajectories and improved robustness compared to strong baselines By releasing all hardware and software components as opensource we aim to lower the barrier to collecting largescale highquality human demonstration datasets and accelerate progress in robot learning.

</details>


### [8] [Model of Spatial Human-Agent Interaction with Consideration for Others](https://arxiv.org/abs/2601.04657)
*Takafumi Sakamoto,Yugo Takeuchi*

Main category: cs.RO

TL;DR: 研究构建了一个考虑他人的计算空间交互模型，通过VR环境中人与虚拟机器人互动的实验验证了该模型能够根据对方的行为调整自身交流活动的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决通信机器人在公共空间中发起对话时既需要与人交流又不能打扰行人的矛盾需求，研究旨在开发一种能够基于他人行为估计其沟通意愿并相应调整自身交流活动的模型。

Method: 构建了一种考虑他人的定量参数（即对自己内部状态相对于他人估计内部状态的调整量）的计算空间交互模型，并通过参与者和虚拟机器人在VR环境中的互动实验来验证模型。

Result: 结果显示，当参与者朝目标移动时，低考虑值的虚拟机器人会抑制参与者的移动；而高考虑值的机器人则不会产生这种抑制作用。此外，无论考虑值如何，当参与者接近机器人时，机器人都会展现出接近行为，从而减少了参与者的移动距离。

Conclusion: 本研究所提出的模型能够有效澄清考虑到他人的互动情况，证明了通过调节对他人状态的考量可以改善人类与机器人之间的交互体验。

Abstract: Communication robots often need to initiate conversations with people in public spaces. At the same time, such robots must not disturb pedestrians. To handle these two requirements, an agent needs to estimate the communication desires of others based on their behavior and then adjust its own communication activities accordingly. In this study, we construct a computational spatial interaction model that considers others. Consideration is expressed as a quantitative parameter: the amount of adjustment of one's internal state to the estimated internal state of the other. To validate the model, we experimented with a human and a virtual robot interacting in a VR environment. The results show that when the participant moves to the target, a virtual robot with a low consideration value inhibits the participant's movement, while a robot with a higher consideration value did not inhibit the participant's movement. When the participant approached the robot, the robot also exhibited approaching behavior, regardless of the consideration value, thus decreasing the participant's movement. These results appear to verify the proposed model's ability to clarify interactions with consideration for others.

</details>


### [9] [Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly](https://arxiv.org/abs/2601.04881)
*Kiyoung Choi,Juwon Jeong,Sehoon Oh*

Main category: cs.RO

TL;DR: 本文提出了一种动态力矩扰动观测器（DW-DOB），通过将任务空间惯性嵌入到观测器的标称模型中，实现了在接触丰富的操纵中对小力和力矩的高度敏感的零力矩控制。实验表明，该方法能够以最小的残余力矩实现更深入且更柔顺的插入，并优于传统的力矩扰动观测器和PD基线。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统观测器无法补偿惯性效应的问题，以及在接触丰富的操作场景下实现高度敏感的零力矩控制。

Method: 设计并分析了动态力矩扰动观测器（DW-DOB），它通过将任务空间惯性信息整合进其模型来区分内在动力学反应与真实的外部力矩。此外，还利用基于被动性的分析证明了DW-DOB能够在动态条件下保证稳定交互。

Result: 在工业公差级别的销钉装配实验中，DW-DOB方法展示了其优越性：不仅能够实现更深、更柔顺的装配过程，而且具有极低的残余力矩，表现超过了传统的力矩扰动观测器及PD控制器。

Conclusion: DW-DOB作为一种无需学习的解决方案，在需要高精度零力矩控制的接触丰富任务中展现出了其实用价值。

Abstract: This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.

</details>


### [10] [SKATER: Synthesized Kinematics for Advanced Traversing Efficiency on a Humanoid Robot via Roller Skate Swizzles](https://arxiv.org/abs/2601.04948)
*Junchi Gu,Feiyang Yuan,Weize Shi,Tianchen Huang,Haopeng Zhang,Xiaohu Zhang,Yu Wang,Wei Gao,Shiwu Zhang*

Main category: cs.RO

TL;DR: 研究提出了一种新型的人形机器人，每只脚装备有四个被动轮用于滑旱冰，并开发了一种深度强化学习控制框架来实现流畅且高效的滑行动作。与传统的双足步行方式相比，这种滑行方式在移动过程中显著降低了冲击强度和运输成本，分别减少了75.86%和63.34%，表明滑旱冰是提高能量效率和关节寿命的更优运动模式。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来人形机器人在行走和跑步方面取得了显著进步，但这些运动过程中频繁的脚步触地不可避免地产生了高瞬时冲击力，导致关节磨损加剧及能量利用效率低下。滑旱冰作为一种具有重大生物力学价值的运动，能够通过合理利用身体惯性实现快速连续滑动，其动能损失极小。

Method: 本研究设计了一款新型人形机器人，其特点是每只脚都装有一排四个被动轮以适应滑旱冰。同时，为滑行步态开发了一个基于滑旱冰内在特性的奖励函数设计的深度强化学习控制框架。

Result: 通过仿真分析了所学策略的有效性，并在物理机器人上部署验证了相对于传统双足行走步态而言，滑行步态在移动过程中的冲击强度和运输成本方面的平滑度和效率优势。实验结果显示这两项指标分别下降了75.86%和63.34%。

Conclusion: 研究表明，滑旱冰对于提高人形机器人的能量效率以及延长关节使用寿命是一种更为优越的运动方式。

Abstract: Although recent years have seen significant progress of humanoid robots in walking and running, the frequent foot strikes with ground during these locomotion gaits inevitably generate high instantaneous impact forces, which leads to exacerbated joint wear and poor energy utilization. Roller skating, as a sport with substantial biomechanical value, can achieve fast and continuous sliding through rational utilization of body inertia, featuring minimal kinetic energy loss. Therefore, this study proposes a novel humanoid robot with each foot equipped with a row of four passive wheels for roller skating. A deep reinforcement learning control framework is also developed for the swizzle gait with the reward function design based on the intrinsic characteristics of roller skating. The learned policy is first analyzed in simulation and then deployed on the physical robot to demonstrate the smoothness and efficiency of the swizzle gait over traditional bipedal walking gait in terms of Impact Intensity and Cost of Transport during locomotion. A reduction of $75.86\%$ and $63.34\%$ of these two metrics indicate roller skating as a superior locomotion mode for enhanced energy efficiency and joint longevity.

</details>


### [11] [When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics](https://arxiv.org/abs/2601.04982)
*Johannes A. Gaus,Winfried Ilg,Daniel Haeufle*

Main category: cs.RO

TL;DR: 本文提出了一种基于校准概率的安全关键触发框架，用于日常生活活动中的多模态下一步动作预测。通过后校准方法减少错误校准，使得预测的置信度与实际可靠性一致，并通过简单的ACT/HOLD规则来决定是否提供辅助，从而将置信度阈值转化为可验证行为的定量安全参数。


<details>
  <summary>Details</summary>
Motivation: 辅助设备在提供支持前需要准确判断用户的意图以及这种预测的可靠性。由于原始模型的置信度往往不能真实反映其正确性，这给用户安全带来了风险。

Method: 引入一种基于校准概率的方法，通过后校准处理使预测的置信度与经验上的可靠性相匹配，从而大幅降低了错误校准的情况而不影响准确性。此外，利用经过校准后的置信度来驱动一个简化的ACT/HOLD决策规则，仅在可靠性高时才采取行动。

Result: 后校准技术成功地将预测置信度与实证可靠性对齐，大约减少了数量级级别的误校准情况，同时保持了原有的预测准确性不受影响。通过设定置信度阈值作为安全参数，能够实现辅助控制循环中可验证的行为。

Conclusion: 采用校准概率的方法可以有效提高辅助设备决策过程的安全性和可靠性，为用户提供更恰当的支持。

Abstract: Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.

</details>


### [12] [The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms](https://arxiv.org/abs/2601.05014)
*Lingdong Kong,Shaoyuan Xie,Zeying Gong,Ye Li,Meng Chu,Ao Liang,Yuhao Dong,Tianshuai Hu,Ronghe Qiu,Rong Li,Hanjiang Hu,Dongyue Lu,Wei Yin,Wenhao Ding,Linfeng Li,Hang Song,Wenwei Zhang,Yuexin Ma,Junwei Liang,Zhedong Zheng,Lai Xing Ng,Benoit R. Cottereau,Wei Tsang Ooi,Ziwei Liu,Zhanpeng Zhang,Weichao Qiu,Wei Zhang,Ji Ao,Jiangpeng Zheng,Siyu Wang,Guang Yang,Zihao Zhang,Yu Zhong,Enzhu Gao,Xinhan Zheng,Xueting Wang,Shouming Li,Yunkai Gao,Siming Lan,Mingfei Han,Xing Hu,Dusan Malic,Christian Fruhwirth-Reisinger,Alexander Prutsch,Wei Lin,Samuel Schulter,Horst Possegger,Linfeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li,Youngseok Kim,Sihwan Hwang,Hyeonjun Jeong,Aodi Wu,Xubo Luo,Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao,Shuangzhi Li,Junlong Shen,Xingyu Li,Hao Ruan,Jinliang Lin,Zhiming Luo,Yu Zang,Cheng Wang,Hanshi Wang,Xijie Gong,Yixiang Yang,Qianli Ma,Zhipeng Zhang,Wenxiang Shi,Jingmeng Zhou,Weijun Zeng,Kexin Xu,Yuchen Zhang,Haoxiang Fu,Ruibin Hu,Yanbiao Ma,Xiyan Feng,Wenbo Zhang,Lu Zhang,Yunzhi Zhuge,Huchuan Lu,You He,Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim,Faduo Liang,Zihang Wang,Yiming Peng,Guanyu Zong,Xu Li,Binghao Wang,Hao Wei,Yongxin Ma,Yunke Shi,Shuaipeng Liu,Dong Kong,Yongchun Lin,Huitong Yang,Liang Lei,Haoang Li,Xinliang Zhang,Zhiyong Wang,Xiaofeng Wang,Yuxia Fu,Yadan Luo,Djamahl Etchegaray,Yang Li,Congfei Li,Yuxiang Sun,Wenkai Zhu,Wang Xu,Linru Li,Longjie Liao,Jun Yan,Benwu Wang,Xueliang Ren,Xiaoyu Yue,Jixian Zheng,Jinfeng Wu,Shurui Qin,Wei Cong,Yao He*

Main category: cs.RO

TL;DR: RoboSense 2025 Challenge旨在通过五个互补的研究领域来提高机器人感知在不同传感场景中的鲁棒性和适应性，包括基于语言的决策、符合社会规范的导航、传感器配置泛化、跨视角和跨模式对应以及跨平台3D感知。挑战赛提供了标准化的数据集、基准模型和统一的评估协议，吸引了来自16个国家85个机构的143支队伍参与。


<details>
  <summary>Details</summary>
Motivation: 自主系统越来越多地部署在开放和动态环境中，在这些环境中，感知模型必须在传感器噪声、环境变化和平台迁移的情况下保持可靠。然而，即使是目前最先进的方法也经常在未见过的条件下表现不佳，这突显了对鲁棒且可泛化的机器人感知的需求。

Method: RoboSense 2025 Challenge通过设立五个研究方向来促进这一目标，涵盖从基于语言的决策到跨平台3D感知等多个方面，并提供标准数据集、基线模型及统一评测流程以支持大规模可重复性的鲁棒感知方法比较。

Result: 挑战赛得到了广泛响应，共吸引了来自16个国家、85家机构的143支团队参赛。通过对23项获奖解决方案进行整合分析，报告指出了各领域内的新方法趋势、共享设计原则以及尚待解决的问题。

Conclusion: RoboSense 2025 Challenge标志着朝向构建能够在现实世界环境中可靠感知、稳健行动并跨平台适应的机器人迈出了一步。

Abstract: Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.

</details>


### [13] [Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses](https://arxiv.org/abs/2601.05074)
*Julian Kulozik,Nathanaël Jarrassé*

Main category: cs.RO

TL;DR: 本研究提出了一种新的基于动作的控制范式，称为补偿效应放大控制（CEAC），利用用户的躯干屈伸作为输入来控制假肢肘部的速度。实验结果表明，使用CEAC时任务表现与自然手臂运动相当，即使改变手势速度或绘图大小也能保持良好的表现，并且不需要极端的补偿性动作，从而为上肢假肢中间关节提供了一种有前景的控制策略。


<details>
  <summary>Details</summary>
Motivation: 尽管上肢假肢设计有所进步，但对于腕部和肘部等中间关节实现直观控制仍然具有挑战性，特别是在连续和速度调节的动作中。因此，需要一种新的方法来改善这些关节的控制方式，使得用户能够更自然、更准确地操作假肢。

Method: 研究者们介绍了一种名为补偿效应放大控制（CEAC）的新颖移动控制范式，该方法将用户的躯干弯曲和伸展作为控制假肢肘部速度的输入。考虑到在执行上肢动作时，躯干既可以是功能性也可以是补偿性的关节，CEAC增强了躯干与假肢之间的自然耦合，同时引入了一个可控延迟，允许用户调整假肢关节的位置和速度。

Result: 通过十二名健康参与者使用带有主动肘部的额外假肢进行的一项通用绘画任务评估了CEAC的表现。此外，还有十个参与者完成了多目标触达任务。结果显示，使用CEAC执行任务的表现与自然手臂运动相似，即便是在改变手势速度或绘画尺寸的情况下也能够维持良好姿势。分析显示，CEAC有效地恢复了关节协调动作，在躯干和肘部之间分配了运动努力，实现了直观的轨迹控制而无需做出极端补偿动作。

Conclusion: 总体而言，CEAC为上肢假肢中间关节提供了很有前途的控制策略，特别是在需要连续和精确协调的任务中。

Abstract: Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.

</details>


### [14] [LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model](https://arxiv.org/abs/2601.05248)
*Zhuoyang Liu,Jiaming Liu,Hao Chen,Ziyu Guo,Chengkai Hou,Chenyang Gu,Jiale Yu,Xiangju Mi,Renrui Zhang,Zhengping Che,Jian Tang,Pheng-Ann Heng,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为LaST$_0$的框架，通过潜在时空链式思维（CoT）在执行前进行高效推理，从而改进了视觉-语言-动作（VLA）模型在机器人操控中的表现。该框架利用了一个高效的潜隐CoT空间来模拟未来视觉动态、3D结构信息和机器人本体感觉状态，并采用混合变压器设计实现双系统架构，允许低频潜隐推理与高频动作生成间的自适应切换。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）方法试图通过显式地生成语言推理轨迹或未来的视觉观察来提高动作准确性，但这种方法通常会导致不可忽略的推断延迟，限制了机器人操控所需的时序分辨率。此外，这种仅限于语言空间的推理难以忠实捕捉难以言喻的物理属性。

Method: 提出了LaST$_0$框架，它通过一个潜在时空链式思维（CoT）来捕捉难以表达的细微物理和机器人动态。此框架引入了一个高效利用令牌的潜在CoT空间以建模未来视觉动态、3D结构信息及机器人自身状态，并进一步扩展这些表示跨越时间以促成时间上一致的隐式推理路径。LaST$_0$采用了基于混合变压器设计的双系统架构，其中一位推理专家负责低频率的潜在推理，而另一位行动专家则根据面向机器人的潜在表征产生高频率的动作。训练过程中考虑了异构操作频率，以便于在部署期间能够灵活调整推理与动作之间的转换速率。

Result: 在十个模拟和六个真实世界的操控任务中，相比之前的VLA方法，LaST$_0$分别提高了平均成功率8%和13%，同时实现了显著更快的推断速度。

Conclusion: LaST$_0$框架通过其创新性的潜在时空链式思维方法，在保持较高推理效率的同时有效提升了机器人操控任务的成功率。

Abstract: Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0

</details>
