<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 19]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Practical and Performant Enhancements for Maximization of Algebraic Connectivity](https://arxiv.org/abs/2511.08694)
*Leonard Jung,Alan Papalia,Kevin Doherty,Michael Everett*

Main category: cs.RO

TL;DR: 本文通过改进一种名为MAC的图稀疏化算法，提高了长期图状态估计的效率和实用性。改进措施包括开发专门求解器、研究高级步长策略以及提出自动方案保证图连通性，从而使得MAC更加适合实时估计应用。


<details>
  <summary>Details</summary>
Motivation: 长期图上的状态估计由于当前图估计方法在大规模、长期图上表现不佳而面临挑战。为了解决这个问题，作者选择推进一种称为最大化代数连通度（MAC）的现有最先进的图稀疏化算法的发展。

Method: 作者从三个方面进行了改进：1. 开发了一个针对代数连通度的专业求解器，平均运行时间缩短了一半；2. 研究了MAC优化过程中的高级步长策略，以提高收敛速度和解决方案质量；3. 提出了可以保证图连接性的自动化方案，无需用户手动指定保持连接性的边集。

Result: 这些贡献共同作用下，MAC变得更加可扩展、可靠，并且更适合于实时估计应用程序。

Conclusion: 综上所述，通过上述改进措施，MAC不仅能够更高效地处理大规模数据，而且也变得更为用户友好，减少了对人工干预的需求，从而在实际场景中展现出更好的适用性。

Abstract: Long-term state estimation over graphs remains challenging as current graph estimation methods scale poorly on large, long-term graphs. To address this, our work advances a current state-of-the-art graph sparsification algorithm, maximizing algebraic connectivity (MAC). MAC is a sparsification method that preserves estimation performance by maximizing the algebraic connectivity, a spectral graph property that is directly connected to the estimation error. Unfortunately, MAC remains computationally prohibitive for online use and requires users to manually pre-specify a connectivity-preserving edge set. Our contributions close these gaps along three complementary fronts: we develop a specialized solver for algebraic connectivity that yields an average 2x runtime speedup; we investigate advanced step size strategies for MAC's optimization procedure to enhance both convergence speed and solution quality; and we propose automatic schemes that guarantee graph connectivity without requiring manual specification of edges. Together, these contributions make MAC more scalable, reliable, and suitable for real-time estimation applications.

</details>


### [2] [Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration](https://arxiv.org/abs/2511.08732)
*Marta Lagomarsino,Elena Merlo,Andrea Pupa,Timo Birr,Franziska Krebs,Cristian Secchi,Tamim Asfour,Arash Ajoudani*

Main category: cs.RO

TL;DR: 本文综述了实现直观信息交换和技能转移的关键组件，旨在促进人与机器人之间的协同合作。文章从多模态输入到机器人可理解的表示转换、自适应规划和角色分配，再到控制层和反馈机制，全面审视了交互流程，并指出了未来更适应性、更易访问的人机协作趋势和有前景的方向。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人技术和人工智能已经取得了显著成就，但人类往往仍处于被动观察者的角色，而机器人在有人类存在的环境中也无法充分发挥其潜力，除非能够有效地建模人类的状态和意图并调整自身行为。为了达到协同的人机协作（HRC），需要建立一个持续的信息流：人类必须能够直观地传达指令、分享专业知识并表达需求；同时，机器人也必须清楚地传达其内部状态及即将采取的动作，以确保用户感到知情、舒适且掌控局面。

Method: 该研究通过回顾分析方法，确定并连接起使人与机器人之间能够进行直观信息交换和技能传递的关键组成部分。整个互动流程包括从将多模式输入转化为机器人可理解的表现形式，到自适应规划与角色分配，直至控制系统以及反馈机制来闭合循环。

Result: 论文识别出了一系列支持直观人机交流的关键要素，并探讨了如何通过这些组件促进更自然、有效的双向沟通。此外，还讨论了当前领域内的主要趋势以及对于更加适应性强、易于接触的人机合作未来的展望。

Conclusion: 实现高效的人机协作依赖于建立一套允许直观信息交换与技能转移的体系。这不仅要求开发出能够准确解析人类意图的技术，也需要设计出能够让机器人清晰表达自己状态与计划的方法。随着技术进步，未来的人机协作将变得更加灵活、包容。

Abstract: Remarkable capabilities have been achieved by robotics and AI, mastering complex tasks and environments. Yet, humans often remain passive observers, fascinated but uncertain how to engage. Robots, in turn, cannot reach their full potential in human-populated environments without effectively modeling human states and intentions and adapting their behavior. To achieve a synergistic human-robot collaboration (HRC), a continuous information flow should be established: humans must intuitively communicate instructions, share expertise, and express needs. In parallel, robots must clearly convey their internal state and forthcoming actions to keep users informed, comfortable, and in control. This review identifies and connects key components enabling intuitive information exchange and skill transfer between humans and robots. We examine the full interaction pipeline: from the human-to-robot communication bridge translating multimodal inputs into robot-understandable representations, through adaptive planning and role allocation, to the control layer and feedback mechanisms to close the loop. Finally, we highlight trends and promising directions toward more adaptive, accessible HRC.

</details>


### [3] [ATOM-CBF: Adaptive Safe Perception-Based Control under Out-of-Distribution Measurements](https://arxiv.org/abs/2511.08741)
*Kai S. Yun,Navid Azizan*

Main category: cs.RO

TL;DR: 提出了一种名为ATOM-CBF的新安全控制框架，该框架能够计算并适应感知模块中由未知分布(OoD)测量引起的认知不确定性，从而在无需真实标签或分布变化信息的情况下确保系统安全。通过模拟实验证明了ATOM-CBF对于装备有LiDAR的F1Tenth车辆和使用RGB图像的四足机器人是有效的。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统中，依赖于学习感知模块从高维传感器数据推断系统状态的做法面临挑战，尤其是在遇到训练阶段未曾见过的未知分布(OoD)测量时，这些感知模块容易受到认知不确定性的负面影响而失效。为了解决这一问题，研究引入了新的方法来提高系统安全性。

Method: 提出了ATOM-CBF（自适应于未知分布测量的控制屏障函数），一种新的安全控制框架，它能明确地计算并对OoD测量引起的知识不确定性做出反应，不需要地面真实标签或分布转移的信息。该方法包括两个关键组成部分：(1) 一个对OoD敏感的自适应感知误差范围；(2) 一个整合了这种自适应误差范围的安全过滤器，允许过滤器实时调整其保守程度。

Result: 通过仿真实验验证了所提方法的有效性，证明ATOM-CBF能够在面对装备LiDAR的F1Tenth车辆及使用RGB图像的四足机器人时保持系统的安全性。

Conclusion: 本研究表明，通过采用ATOM-CBF框架，可以有效地处理因未知分布数据导致的认知不确定性问题，进而增强基于学习的感知组件之系统的安全性。

Abstract: Ensuring the safety of real-world systems is challenging, especially when they rely on learned perception modules to infer the system state from high-dimensional sensor data. These perception modules are vulnerable to epistemic uncertainty, often failing when encountering out-of-distribution (OoD) measurements not seen during training. To address this gap, we introduce ATOM-CBF (Adaptive-To-OoD-Measurement Control Barrier Function), a novel safe control framework that explicitly computes and adapts to the epistemic uncertainty from OoD measurements, without the need for ground-truth labels or information on distribution shifts. Our approach features two key components: (1) an OoD-aware adaptive perception error margin and (2) a safety filter that integrates this adaptive error margin, enabling the filter to adjust its conservatism in real-time. We provide empirical validation in simulations, demonstrating that ATOM-CBF maintains safety for an F1Tenth vehicle with LiDAR scans and a quadruped robot with RGB images.

</details>


### [4] [CENIC: Convex Error-controlled Numerical Integration for Contact](https://arxiv.org/abs/2511.08771)
*Vince Kurtz,Alejandro Castro*

Main category: cs.RO

TL;DR: CENIC, a novel continuous-time integrator, combines the advantages of continuous integration and discrete time-stepping to offer fast, real-time simulation speeds with accuracy and convergence guarantees, addressing the limitations of traditional error-controlled integrators in handling stiff contact dynamics.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to address the critical challenge faced by state-of-the-art robotics simulators, which run in discrete time, forcing users to select a time step that can either lead to non-physical artifacts or slow down the simulation. The aim is to introduce an integrator capable of automatic time step adjustment for desired accuracy while overcoming the difficulties posed by stiff dynamics of contact, and to meet the speed and scalability demands of modern robotics workflows.

Method: The method introduced in this paper is CENIC, a new continuous-time integrator that merges recent advancements in convex time-stepping and error-controlled integration. This approach aims to inherit the benefits from both continuous integration (such as adaptive time stepping) and discrete time-stepping (such as computational efficiency and stability).

Result: CENIC demonstrates fast real-time performance on par with leading discrete-time robotics simulators, including MuJoCo, Drake, and Isaac Sim. It also provides assurances regarding the accuracy and convergence of the simulations, effectively solving the issues related to stiff contact dynamics and maintaining the required speed and scalability for contemporary robotics applications.

Conclusion: In conclusion, CENIC represents a significant advancement in robotics simulation, offering a solution that not only matches the speed of current discrete-time simulators but also ensures accurate and convergent results, thus providing a robust alternative for simulating complex robotic systems.

Abstract: State-of-the-art robotics simulators operate in discrete time. This requires users to choose a time step, which is both critical and challenging: large steps can produce non-physical artifacts, while small steps force the simulation to run slowly. Continuous-time error-controlled integration avoids such issues by automatically adjusting the time step to achieve a desired accuracy. But existing error-controlled integrators struggle with the stiff dynamics of contact, and cannot meet the speed and scalability requirements of modern robotics workflows. We introduce CENIC, a new continuous-time integrator that brings together recent advances in convex time-stepping and error-controlled integration, inheriting benefits from both continuous integration and discrete time-stepping. CENIC runs at fast real-time rates comparable to discrete-time robotics simulators like MuJoCo, Drake and Isaac Sim, while also providing guarantees on accuracy and convergence.

</details>


### [5] [Dual-Arm Whole-Body Motion Planning: Leveraging Overlapping Kinematic Chains](https://arxiv.org/abs/2511.08778)
*Richard Cheng,Peter Werner,Carolyn Matl*

Main category: cs.RO

TL;DR: 提出了一种新的方法来减少高自由度双臂机器人在未知变化环境中的实时运动规划难度，通过利用共享关节（如躯干关节）的结构，构建了两个动态路线图，并展示了如何有效搜索这两个路线图的组合以避开维度灾难。实际测试中，在一个19自由度移动操作机器人上执行杂货配送任务时达到了平均0.4秒的规划时间和99.9%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决高自由度双臂机器人在未知和变化环境中实时进行运动规划的问题，特别是由于配置空间的高维性和必须遵守的复杂避碰约束所带来的挑战。

Method: 通过为每个运动链（即左臂+躯干、右臂+躯干）建立具有由共享关节引起的特定结构的两个动态路线图(DRM)，然后利用这种结构有效地搜索两个路线图的组合，从而大大避免了维度灾难。

Result: 在一个真实的杂货店环境中对19个自由度的移动操纵机器人进行了多次实验，实现了平均0.4秒的规划时间以及超过2000次运动计划中99.9%的成功率。

Conclusion: 该研究提出的方法能够有效提高高自由度双臂机器人在复杂环境下的实时运动规划效率与成功率。

Abstract: High degree-of-freedom dual-arm robots are becoming increasingly common due to their morphology enabling them to operate effectively in human environments. However, motion planning in real-time within unknown, changing environments remains a challenge for such robots due to the high dimensionality of the configuration space and the complex collision-avoidance constraints that must be obeyed. In this work, we propose a novel way to alleviate the curse of dimensionality by leveraging the structure imposed by shared joints (e.g. torso joints) in a dual-arm robot. First, we build two dynamic roadmaps (DRM) for each kinematic chain (i.e. left arm + torso, right arm + torso) with specific structure induced by the shared joints. Then, we show that we can leverage this structure to efficiently search through the composition of the two roadmaps and largely sidestep the curse of dimensionality. Finally, we run several experiments in a real-world grocery store with this motion planner on a 19 DoF mobile manipulation robot executing a grocery fulfillment task, achieving 0.4s average planning times with 99.9% success rate across more than 2000 motion plans.

</details>


### [6] [XPRESS: X-Band Radar Place Recognition via Elliptical Scan Shaping](https://arxiv.org/abs/2511.08863)
*Hyesu Jang,Wooseong Yang,Ayoung Kim,Dongje Lee,Hanguen Kim*

Main category: cs.RO

TL;DR: 本文提出了一种专为X波段雷达设计的地点识别算法，通过基于物体密度的规则进行高效的候选选择，并有意降低雷达检测的质量以实现鲁棒的检索性能，从而推进了仅使用X波段雷达在海事环境中的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: X波段雷达作为海上船只的主要传感器，但其在自主导航中的应用受到了低分辨率和信息量不足的限制。为了克服这些限制并实现仅依靠X波段雷达的海上自主导航，研究者们开发了一个特别针对这种雷达优化的地点识别算法。

Method: 提出了一种新的地点识别算法，该算法利用基于对象密度的规则来提高候选点的选择效率，并且通过故意降低雷达探测质量的方法来确保即使在恶劣条件下也能保持良好的检索性能。

Result: 所提出的算法在公开的海事雷达数据集以及研究团队自己收集的数据集上进行了评估，并与当前最先进的雷达地点识别方法进行了比较。此外，还进行了消融研究来分析关键参数对算法性能的影响。

Conclusion: 实验结果表明，本研究提出的针对X波段雷达优化的地点识别算法能够有效提升自主导航系统在海事环境下的表现，特别是在面对低分辨率和信息量有限的情况下。

Abstract: X-band radar serves as the primary sensor on maritime vessels, however, its application in autonomous navigation has been limited due to low sensor resolution and insufficient information content. To enable X-band radar-only autonomous navigation in maritime environments, this paper proposes a place recognition algorithm specifically tailored for X-band radar, incorporating an object density-based rule for efficient candidate selection and intentional degradation of radar detections to achieve robust retrieval performance. The proposed algorithm was evaluated on both public maritime radar datasets and our own collected dataset, and its performance was compared against state-of-the-art radar place recognition methods. An ablation study was conducted to assess the algorithm's performance sensitivity with respect to key parameters.

</details>


### [7] [MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror](https://arxiv.org/abs/2511.08865)
*Cong Tai,Hansheng Wu,Haixu Long,Zhengbin Long,Zhaoyu Zheng,Haodong Xiang,Tao Shen*

Main category: cs.RO

TL;DR: 本研究提出了一种基于PICO的机器人远程操作框架，能够以低成本实时获取手势和姿态数据，并且天然兼容RealMirror生态系统，在Isaac模拟环境中提供稳定的机器人轨迹记录功能，支持多种末端执行器机器人的实时遥控操作，旨在降低上肢机器人操作的研究技术门槛，加速视觉-语言-动作相关研究的发展。


<details>
  <summary>Details</summary>
Motivation: 为了提高手势和姿态数据采集的成本效益，同时降低上肢机器人操作研究的技术障碍，加速视觉-语言-行动（VLA）领域内的科研进展。

Method: 开发了一种基于PICO的机器人远程操作框架，该框架与RealMirror生态系统自然兼容，能够在Isaac模拟环境下稳定、精确地记录机器人轨迹，并支持配备有灵活手部及机械夹爪等多种末端执行器机器人的实时远程控制。

Result: 所提出的框架在成本效益方面优于主流的视觉跟踪和运动捕捉解决方案，能够促进VLA数据集的构建，并允许对不同类型的机器人进行实时遥操作。

Conclusion: 通过引入这种新颖的PICO基础架构，研究者们得以利用更加经济高效的方法来收集手部运动与姿态信息，同时简化了复杂机器人操控任务的学习过程，为VLA相关领域的进一步探索提供了强有力的支持。

Abstract: In this work, we present a PICO-based robot remote operating framework that enables low-cost, real-time acquisition of hand motion and pose data, outperforming mainstream visual tracking and motion capture solutions in terms of cost-effectiveness. The framework is natively compatible with the RealMirror ecosystem, offering ready-to-use functionality for stable and precise robotic trajectory recording within the Isaac simulation environment, thereby facilitating the construction of Vision-Language-Action (VLA) datasets. Additionally, the system supports real-time teleoperation of a variety of end-effector-equipped robots, including dexterous hands and robotic grippers. This work aims to lower the technical barriers in the study of upper-limb robotic manipulation, thereby accelerating advancements in VLA-related research.

</details>


### [8] [A Shared Control Framework for Mobile Robots with Planning-Level Intention Prediction](https://arxiv.org/abs/2511.08912)
*Jinyu Zhang,Lijun Han,Feng Jian,Lingxi Zhang,Hesheng Wang*

Main category: cs.RO

TL;DR: 本文提出了一种新的共享控制框架，通过深度强化学习预测人的运动意图，并据此重新规划机器人路径，从而减少操作员的工作量并提高安全性。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人共享控制中，有效地理解人类的运动意图对于无缝的人机协作至关重要。

Method: 本文引入了意图域的概念来表示未来的运动意图，并将意图域预测和路径重新规划问题联合表述为一个马尔可夫决策过程（MDP），并通过深度强化学习解决。此外，开发了一种基于Voronoi图的人类轨迹生成算法，使得模型可以在没有人类参与或示教数据的情况下完全在仿真环境中训练。

Result: 广泛的模拟和实际用户研究表明，所提出的方法显著减少了操作者的工作负担并提高了安全性，同时与现有的辅助遥操作方法相比不会牺牲任务效率。

Conclusion: 该研究提供了一种新颖有效的解决方案，用于改善人机共融环境下的协作质量，特别适用于需要高度互动性的场景。

Abstract: In mobile robot shared control, effectively understanding human motion intention is critical for seamless human-robot collaboration. This paper presents a novel shared control framework featuring planning-level intention prediction. A path replanning algorithm is designed to adjust the robot's desired trajectory according to inferred human intentions. To represent future motion intentions, we introduce the concept of an intention domain, which serves as a constraint for path replanning. The intention-domain prediction and path replanning problems are jointly formulated as a Markov Decision Process and solved through deep reinforcement learning. In addition, a Voronoi-based human trajectory generation algorithm is developed, allowing the model to be trained entirely in simulation without human participation or demonstration data. Extensive simulations and real-world user studies demonstrate that the proposed method significantly reduces operator workload and enhances safety, without compromising task efficiency compared with existing assistive teleoperation approaches.

</details>


### [9] [Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation](https://arxiv.org/abs/2511.08935)
*Ningnan Wang,Weihuang Chen,Liming Chen,Haoxuan Ji,Zhongyu Guo,Xuchong Zhang,Hongbin Sun*

Main category: cs.RO

TL;DR: 本文提出了SCOPE，一种零样本框架，通过利用边界信息来驱动基于潜力的探索，从而在视觉导航中实现更知情和目标相关的决策。实验表明，SCOPE相比现有方法在准确率上提高了4.6%。


<details>
  <summary>Details</summary>
Motivation: 当前的零样本研究虽然通过记忆机制增强了目标导向行为的表现，但忽略了对视觉边界（影响未来轨迹和观察的关键因素）的有效利用，以及部分视觉观察与导航目标之间关系的理解。

Method: 提出了一种名为SCOPE (Semantic Cognition Over Potential-based Exploration) 的新方法，该方法利用视觉-语言模型估计探索潜力，并构建时空潜力图来捕捉边界动态；此外，引入了自我反思机制以重新审视和完善先前决定，提高决策质量和可靠性。

Result: 在两个不同的具身导航任务上的实验证明，SCOPE比最先进基线方法的准确性高出4.6%。进一步分析显示，其核心组件促进了更好的校准、更强的泛化能力和更高的决策质量。

Conclusion: 通过明确地利用前沿信息来指导基于潜力的探索，SCOPE能够做出更加明智且与目标相关联的决定，在长期规划支持下展现出色性能。

Abstract: Embodied visual navigation remains a challenging task, as agents must explore unknown environments with limited knowledge. Existing zero-shot studies have shown that incorporating memory mechanisms to support goal-directed behavior can improve long-horizon planning performance. However, they overlook visual frontier boundaries, which fundamentally dictate future trajectories and observations, and fall short of inferring the relationship between partial visual observations and navigation goals. In this paper, we propose Semantic Cognition Over Potential-based Exploration (SCOPE), a zero-shot framework that explicitly leverages frontier information to drive potential-based exploration, enabling more informed and goal-relevant decisions. SCOPE estimates exploration potential with a Vision-Language Model and organizes it into a spatio-temporal potential graph, capturing boundary dynamics to support long-horizon planning. In addition, SCOPE incorporates a self-reconsideration mechanism that revisits and refines prior decisions, enhancing reliability and reducing overconfident errors. Experimental results on two diverse embodied navigation tasks show that SCOPE outperforms state-of-the-art baselines by 4.6\% in accuracy. Further analysis demonstrates that its core components lead to improved calibration, stronger generalization, and higher decision quality.

</details>


### [10] [A Quantum Tunneling and Bio-Phototactic Driven Enhanced Dwarf Mongoose Optimizer for UAV Trajectory Planning and Engineering Problem](https://arxiv.org/abs/2511.09020)
*Mingyang Yu,Haorui Yang,Kangning An,Xinjian Wei,Xiaoxuan Xu,Jing Xu*

Main category: cs.RO

TL;DR: 该论文提出了一种增强的多策略侏儒猫鼬优化(EDMO)算法，用于无人机在动态和障碍物丰富的环境中的三维轨迹规划。通过整合三种新策略，EDMO在基准测试中超越了14种先进算法，并在实际应用中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机(UAV)的广泛应用，有效的路径规划变得越来越重要。尽管传统搜索方法已被广泛使用，但元启发式算法因其效率和针对特定问题的启发式而受到欢迎。然而，在复杂场景下，这些算法仍面临过早收敛和解多样性不足等挑战。

Method: 本文提出了一种增强的多策略侏儒猫鼬优化(EDMO)算法，专门针对动态及充满障碍物环境中无人机的三维轨迹规划。EDMO集成了三种新颖策略：(1) 动态量子隧穿优化策略(DQTOS)，使粒子能够概率性地逃离局部最优；(2) 受微生物趋光性启发的生物光敏动态聚焦搜索策略(BDFSS)，以实现自适应局部精炼；以及(3) 正交镜像对立学习(OLOBL)策略，通过结构化的维度重组来加强全局探索。

Result: EDMO在CEC2017和CEC2020的39个标准测试函数上进行了基准测试，结果显示它在收敛速度、鲁棒性和优化精度方面优于14种先进的算法。此外，通过对无人机三维路径规划及三个工程设计任务的实际验证，进一步确认了其在需要智能、适应性强且时间效率高的领域机器人任务中的实用适用性和有效性。

Conclusion: 本研究提出的EDMO算法不仅在理论性能上表现出色，而且在解决实际问题时也展现了强大的潜力，为无人机及其他相关领域的路径规划提供了新的解决方案。

Abstract: With the widespread adoption of unmanned aerial vehicles (UAV), effective path planning has become increasingly important. Although traditional search methods have been extensively applied, metaheuristic algorithms have gained popularity due to their efficiency and problem-specific heuristics. However, challenges such as premature convergence and lack of solution diversity still hinder their performance in complex scenarios. To address these issues, this paper proposes an Enhanced Multi-Strategy Dwarf Mongoose Optimization (EDMO) algorithm, tailored for three-dimensional UAV trajectory planning in dynamic and obstacle-rich environments. EDMO integrates three novel strategies: (1) a Dynamic Quantum Tunneling Optimization Strategy (DQTOS) to enable particles to probabilistically escape local optima; (2) a Bio-phototactic Dynamic Focusing Search Strategy (BDFSS) inspired by microbial phototaxis for adaptive local refinement; and (3) an Orthogonal Lens Opposition-Based Learning (OLOBL) strategy to enhance global exploration through structured dimensional recombination. EDMO is benchmarked on 39 standard test functions from CEC2017 and CEC2020, outperforming 14 advanced algorithms in convergence speed, robustness, and optimization accuracy. Furthermore, real-world validations on UAV three-dimensional path planning and three engineering design tasks confirm its practical applicability and effectiveness in field robotics missions requiring intelligent, adaptive, and time-efficient planning.

</details>


### [11] [D-AWSIM: Distributed Autonomous Driving Simulator for Dynamic Map Generation Framework](https://arxiv.org/abs/2511.09080)
*Shunsuke Ito,Chaoran Zhao,Ryo Okamura,Takuya Azumi*

Main category: cs.RO

TL;DR: 本文提出了一种名为D-AWSIM的分布式模拟器，能够支持大规模传感器部署和密集交通环境的仿真，通过在多台机器间分配工作负载来提高处理吞吐量。该模拟器集成了动态地图生成框架，有助于研究者探索信息共享策略，而无需依赖物理测试平台。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统已经取得了显著的进步，但为了扩展其操作领域以适应更多样化的条件，需要解决安全保障问题。车辆间及车辆与基础设施之间的信息共享是潜在解决方案之一，但由于现实世界实验的成本高且存在监管挑战，以及传统单一主机模拟器无法胜任大规模城市交通场景的局限性，促使了对新方法的需求。

Method: 论文介绍了一种名为D-AWSIM的新式分布式模拟器，它通过跨多个计算节点分配任务来克服单机模拟器的限制。此外，D-AWSIM还包含了一个动态地图生成框架，这使得研究人员能够在不使用实际测试设施的情况下评估不同的信息共享策略。

Result: 评估结果显示，相较于单机设置，在处理车辆数量和激光雷达传感器数据方面，D-AWSIM能够大幅提高吞吐量。同时，与Autoware系统的集成证明了其在自动驾驶研究中的应用潜力。

Conclusion: D-AWSIM为自动驾驶领域的研究提供了一个强大的工具，特别是在需要考虑大规模传感器部署和复杂交通状况的信息共享策略研究中。

Abstract: Autonomous driving systems have achieved significant advances, and full autonomy within defined operational design domains near practical deployment. Expanding these domains requires addressing safety assurance under diverse conditions. Information sharing through vehicle-to-vehicle and vehicle-to-infrastructure communication, enabled by a Dynamic Map platform built from vehicle and roadside sensor data, offers a promising solution. Real-world experiments with numerous infrastructure sensors incur high costs and regulatory challenges. Conventional single-host simulators lack the capacity for large-scale urban traffic scenarios. This paper proposes D-AWSIM, a distributed simulator that partitions its workload across multiple machines to support the simulation of extensive sensor deployment and dense traffic environments. A Dynamic Map generation framework on D-AWSIM enables researchers to explore information-sharing strategies without relying on physical testbeds. The evaluation shows that D-AWSIM increases throughput for vehicle count and LiDAR sensor processing substantially compared to a single-machine setup. Integration with Autoware demonstrates applicability for autonomous driving research.

</details>


### [12] [APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots](https://arxiv.org/abs/2511.09091)
*Shivam Sood,Laukik Nakhwa,Sun Ge,Yuhong Cao,Jin Cheng,Fatemah Zargarbashi,Taerim Yoon,Sungjoon Choi,Stelian Coros,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 介绍了APEX，一种结合了专家演示和强化学习的新型方法，旨在提高腿部机器人在不同环境下的运动学习效率和适应性，同时减少对参考数据和参数调整的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的腿部机器人运动学习方法通常需要大量的调参工作，并且在部署时严重依赖参考数据，这限制了它们的适应能力。

Method: 通过引入逐渐衰减的动作先验（action priors），APEX将专家演示直接整合进强化学习过程中，同时采用多评判框架来平衡任务执行与动作风格之间的关系。

Result: 实验表明，无论是模拟环境还是实际应用于Unitree Go2机器人上，APEX都能有效提升机器人的稳定性、学习效率以及泛化能力。

Conclusion: 该研究为指导驱动型强化学习开辟了新路径，有望促进从移动到操作等广泛机器人任务中自然技能的学习。

Abstract: Learning natural, animal-like locomotion from demonstrations has become a core paradigm in legged robotics. Despite the recent advancements in motion tracking, most existing methods demand extensive tuning and rely on reference data during deployment, limiting adaptability. We present APEX (Action Priors enable Efficient Exploration), a plug-and-play extension to state-of-the-art motion tracking algorithms that eliminates any dependence on reference data during deployment, improves sample efficiency, and reduces parameter tuning effort. APEX integrates expert demonstrations directly into reinforcement learning (RL) by incorporating decaying action priors, which initially bias exploration toward expert demonstrations but gradually allow the policy to explore independently. This is combined with a multi-critic framework that balances task performance with motion style. Moreover, APEX enables a single policy to learn diverse motions and transfer reference-like styles across different terrains and velocities, while remaining robust to variations in reward design. We validate the effectiveness of our method through extensive experiments in both simulation and on a Unitree Go2 robot. By leveraging demonstrations to guide exploration during RL training, without imposing explicit bias toward them, APEX enables legged robots to learn with greater stability, efficiency, and generalization. We believe this approach paves the way for guidance-driven RL to boost natural skill acquisition in a wide array of robotic tasks, from locomotion to manipulation. Website and code: https://marmotlab.github.io/APEX/.

</details>


### [13] [Decoupling Torque and Stiffness: A Unified Modeling and Control Framework for Antagonistic Artificial Muscles](https://arxiv.org/abs/2511.09104)
*Amirhossein Kazemipour,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出了一种统一框架，能够实时独立控制不同类型软执行器的扭矩和刚度。该框架通过共收缩/偏置坐标来模拟生物阻抗策略，使得控制器可以独立调节扭矩和刚度。仿真验证了该方法在动态接触瞬态下保持了良好的解耦性能，并且比固定策略更稳定。


<details>
  <summary>Details</summary>
Motivation: 现有的软肌肉控制器难以在动态接触瞬态中保持独立控制。为了解决这个问题，研究者们希望开发一种能够实现不同类型的软执行器在实际应用中独立控制扭矩和刚度的新方法。

Method: 研究人员建立了一个统一的力量定律模型，能够以亚毫秒级的速度计算多种软肌肉物理特性。此外，他们还设计了一个级联控制器，利用分析逆动力学即使在存在模型误差和干扰的情况下也能保持解耦。通过使用共收缩/偏置坐标系，控制器模仿了生物阻抗策略，从而实现了对扭矩和刚度的独立调节。

Result: 实验结果表明，该控制器在软表面上的响应速度提高了200倍，在硬表面上作用力减少了81%，并且相比固定策略（稳定性为22-54%），其与环境的交互更加稳定。

Conclusion: 这项工作为实现安全的人机交互提供了基础，使肌肉骨骼对抗系统能够执行适应性阻抗控制。

Abstract: Antagonistic soft actuators built from artificial muscles (PAMs, HASELs, DEAs) promise plant-level torque-stiffness decoupling, yet existing controllers for soft muscles struggle to maintain independent control through dynamic contact transients. We present a unified framework enabling independent torque and stiffness commands in real-time for diverse soft actuator types. Our unified force law captures diverse soft muscle physics in a single model with sub-ms computation, while our cascaded controller with analytical inverse dynamics maintains decoupling despite model errors and disturbances. Using co-contraction/bias coordinates, the controller independently modulates torque via bias and stiffness via co-contraction-replicating biological impedance strategies. Simulation-based validation through contact experiments demonstrates maintained independence: 200x faster settling on soft surfaces, 81% force reduction on rigid surfaces, and stable interaction vs 22-54% stability for fixed policies. This framework provides a foundation for enabling musculoskeletal antagonistic systems to execute adaptive impedance control for safe human-robot interaction.

</details>


### [14] [Data Assessment for Embodied Intelligence](https://arxiv.org/abs/2511.09119)
*Jiahao Xiao,Bowen Yan,Jianbo Zhang,Jia Wang,Chunyi Li,Zhengxue Cheng,Guangtao Zhai*

Main category: cs.RO

TL;DR: 本文提出了两种数据驱动的工具来解决数据集多样性和可学习性评估的问题。首先，通过构建统一的多模态表示并提出多样性熵作为信息量的连续度量；其次，引入了首个可解释的数据驱动算法，无需训练即可有效量化数据集的可学习性。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要集中在通过计算任务和场景数量或评估孤立模态来衡量数据集多样性，但这种方法无法提供全面视角。同时，数据集的可学习性往往被忽视，通常在模型训练后进行评估，这不仅耗时且缺乏解释性。为了解决这些问题，作者开发了新的方法来更好地评估和理解数据集特性。

Method: 1. 为每个数据样本构建一个统一的多模态表示，并基于此提出多样性熵，这是一种表征数据集中包含的信息量的连续度量。
2. 引入了一种新的、可解释的数据驱动算法，能够在不需训练的情况下高效地量化数据集的可学习性。

Result: 所提出的算法在模拟和真实世界的数据集上得到了验证，证明它可以提供忠实而可行的见解，帮助研究人员同时提高数据集的多样性和可学习性。

Conclusion: 这项研究为设计更高质量的数据集奠定了基础，这些数据集能够促进具身智能的发展。

Abstract: In embodied intelligence, datasets play a pivotal role, serving as both a knowledge repository and a conduit for information transfer. The two most critical attributes of a dataset are the amount of information it provides and how easily this information can be learned by models. However, the multimodal nature of embodied data makes evaluating these properties particularly challenging. Prior work has largely focused on diversity, typically counting tasks and scenes or evaluating isolated modalities, which fails to provide a comprehensive picture of dataset diversity. On the other hand, the learnability of datasets has received little attention and is usually assessed post-hoc through model training, an expensive, time-consuming process that also lacks interpretability, offering little guidance on how to improve a dataset. In this work, we address both challenges by introducing two principled, data-driven tools. First, we construct a unified multimodal representation for each data sample and, based on it, propose diversity entropy, a continuous measure that characterizes the amount of information contained in a dataset. Second, we introduce the first interpretable, data-driven algorithm to efficiently quantify dataset learnability without training, enabling researchers to assess a dataset's learnability immediately upon its release. We validate our algorithm on both simulated and real-world embodied datasets, demonstrating that it yields faithful, actionable insights that enable researchers to jointly improve diversity and learnability. We hope this work provides a foundation for designing higher-quality datasets that advance the development of embodied intelligence.

</details>


### [15] [LODESTAR: Degeneracy-Aware LiDAR-Inertial Odometry with Adaptive Schmidt-Kalman Filter and Data Exploitation](https://arxiv.org/abs/2511.09142)
*Eungchang Mason Lee,Kevin Christiansen Marsim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种新的LiDAR惯性里程计方法LODESTAR，通过两个关键模块：退化感知自适应Schmidt-Kalman滤波器（DA-ASKF）和退化感知数据利用（DA-DE），解决了在长走廊和高空飞行等退化环境中由于激光雷达测量不平衡或稀疏导致的状态估计问题。实验结果表明，LODESTAR在各种退化条件下比现有的基于激光雷达的里程计方法具有更高的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决激光雷达-惯性里程计（LIO）在长走廊、高空飞行等退化环境下性能下降的问题，这些环境特征表现为激光雷达测量不平衡或稀疏，进而导致状态估计不良。

Method: 本文提出了LODESTAR，一种新颖的LIO方法，它包含两个核心组件：退化感知自适应Schmidt-Kalman滤波器(DA-ASKF)和退化感知数据利用(DA-DE)。DA-ASKF采用滑动窗口技术来利用过去的状态和测量作为额外约束，并引入了能够根据退化程度自适应地区分活动状态与固定状态的机制。DA-DE则从活动状态中剔除信息量较少的测量值，并基于局部可定位贡献度及雅可比矩阵条件数选择性地使用来自固定状态的数据。

Result: 实验结果显示，在多种退化条件下，LODESTAR相比现有基于激光雷达的里程计算法以及针对退化的特定模块而言，在精度和鲁棒性方面表现更优。

Conclusion: LODESTAR作为一种创新性的LIO解决方案，有效地应对了由于环境因素引起的激光雷达数据稀疏性和不均衡性挑战，从而提高了系统在复杂场景下的定位准确性与稳定性。

Abstract: LiDAR-inertial odometry (LIO) has been widely used in robotics due to its high accuracy. However, its performance degrades in degenerate environments, such as long corridors and high-altitude flights, where LiDAR measurements are imbalanced or sparse, leading to ill-posed state estimation. In this letter, we present LODESTAR, a novel LIO method that addresses these degeneracies through two key modules: degeneracy-aware adaptive Schmidt-Kalman filter (DA-ASKF) and degeneracy-aware data exploitation (DA-DE). DA-ASKF employs a sliding window to utilize past states and measurements as additional constraints. Specifically, it introduces degeneracy-aware sliding modes that adaptively classify states as active or fixed based on their degeneracy level. Using Schmidt-Kalman update, it partially optimizes active states while preserving fixed states. These fixed states influence the update of active states via their covariances, serving as reference anchors--akin to a lodestar. Additionally, DA-DE prunes less-informative measurements from active states and selectively exploits measurements from fixed states, based on their localizability contribution and the condition number of the Jacobian matrix. Consequently, DA-ASKF enables degeneracy-aware constrained optimization and mitigates measurement sparsity, while DA-DE addresses measurement imbalance. Experimental results show that LODESTAR outperforms existing LiDAR-based odometry methods and degeneracy-aware modules in terms of accuracy and robustness under various degenerate conditions.

</details>


### [16] [Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots](https://arxiv.org/abs/2511.09241)
*Yuxi Wei,Zirui Wang,Kangning Yin,Yue Hu,Jingbo Wang,Siheng Chen*

Main category: cs.RO

TL;DR: 本文提出了Humanoid-Union，一个通过自主管道生成的大规模数据集，包含超过260小时的多样化高质量人形机器人运动数据，并基于此提出了一种可扩展学习框架SCHUR，实验证明该方法在数据和模型扩展下提高了机器人动作生成的质量和文本-动作对齐效果。


<details>
  <summary>Details</summary>
Motivation: 长久以来，数据扩展一直是机器人学习中的关键瓶颈。对于人形机器人来说，人类视频和运动数据丰富且广泛可用，提供了一个免费且大规模的数据源。此外，与运动相关的语义能够实现模态对齐和高级机器人控制学习。然而，如何有效地挖掘原始视频、提取可供机器人学习的表示，并利用它们进行可扩展的学习仍然是一个开放性问题。

Method: 为了解决上述问题，研究者们引入了Humanoid-Union，这是一个通过自动化流程生成的大规模数据集，包括超过260小时多样化的高质量人形机器人运动数据，这些数据带有从人类运动视频中派生出的语义注释。基于这一数据资源，他们提出了SCHUR，一种旨在探索大规模数据对人形机器人高层次控制影响的可扩展学习框架。

Result: 实验结果显示，SCHUR在数据和模型扩展的情况下达到了高机器人动作生成质量以及强文本-动作对齐效果，相较于先前的方法，在MPJPE上重建改进了37%，在FID上的对齐改进了25%。其有效性还通过部署到真实世界的人形机器人得到了进一步验证。

Conclusion: 本研究表明，通过有效利用大规模人类运动数据，可以显著提升人形机器人的学习性能。提出的SCHUR框架不仅证明了使用大规模数据进行训练的好处，同时也为人形机器人领域提供了新的研究方向。

Abstract: Data scaling has long remained a critical bottleneck in robot learning. For humanoid robots, human videos and motion data are abundant and widely available, offering a free and large-scale data source. Besides, the semantics related to the motions enable modality alignment and high-level robot control learning. However, how to effectively mine raw video, extract robot-learnable representations, and leverage them for scalable learning remains an open problem. To address this, we introduce Humanoid-Union, a large-scale dataset generated through an autonomous pipeline, comprising over 260 hours of diverse, high-quality humanoid robot motion data with semantic annotations derived from human motion videos. The dataset can be further expanded via the same pipeline. Building on this data resource, we propose SCHUR, a scalable learning framework designed to explore the impact of large-scale data on high-level control in humanoid robots. Experimental results demonstrate that SCHUR achieves high robot motion generation quality and strong text-motion alignment under data and model scaling, with 37\% reconstruction improvement under MPJPE and 25\% alignment improvement under FID comparing with previous methods. Its effectiveness is further validated through deployment in real-world humanoid robot.

</details>


### [17] [UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning](https://arxiv.org/abs/2511.09302)
*Yan Huang,Shoujie Li,Xingting Li,Wenbo Ding*

Main category: cs.RO

TL;DR: UMIGen, a framework that combines Cloud-UMI for handheld data collection and a visibility-aware optimization to generate 3D observation-action pairs, enhances cross-robot generalization and streamlines the collection of manipulation task data.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of collecting large-scale, high-quality demonstration data for robotic learning, which is often hindered by high operational costs, reliance on specialized hardware, and limited spatial generalization. UMIGen aims to make data collection more efficient and transferable across different robot platforms.

Method: UMIGen consists of two main parts: (1) Cloud-UMI, a device for handheld data collection that does not require visual SLAM and records point cloud observation-action pairs, and (2) a visibility-aware optimization mechanism that modifies the DemoGen pipeline to work with egocentric 3D observations, generating only points within the camera's field of view.

Result: Experiments in both simulated and real-world settings show that UMIGen can support strong cross-embodiment generalization and accelerate the process of data collection for a variety of manipulation tasks.

Conclusion: UMIGen offers an effective solution for improving the efficiency and generalizability of data collection in data-driven robotic learning, particularly for manipulation tasks, by facilitating the generation of 3D data that closely matches real-world egocentric observations and can be easily transferred between different robot embodiments.

Abstract: Data-driven robotic learning faces an obvious dilemma: robust policies demand large-scale, high-quality demonstration data, yet collecting such data remains a major challenge owing to high operational costs, dependence on specialized hardware, and the limited spatial generalization capability of current methods. The Universal Manipulation Interface (UMI) relaxes the strict hardware requirements for data collection, but it is restricted to capturing only RGB images of a scene and omits the 3D geometric information on which many tasks rely. Inspired by DemoGen, we propose UMIGen, a unified framework that consists of two key components: (1) Cloud-UMI, a handheld data collection device that requires no visual SLAM and simultaneously records point cloud observation-action pairs; and (2) a visibility-aware optimization mechanism that extends the DemoGen pipeline to egocentric 3D observations by generating only points within the camera's field of view. These two components enable efficient data generation that aligns with real egocentric observations and can be directly transferred across different robot embodiments without any post-processing. Experiments in both simulated and real-world settings demonstrate that UMIGen supports strong cross-embodiment generalization and accelerates data collection in diverse manipulation tasks.

</details>


### [18] [SPIDER: Scalable Physics-Informed Dexterous Retargeting](https://arxiv.org/abs/2511.09484)
*Chaoyi Pan,Changhao Wang,Haozhi Qi,Zixi Liu,Homanga Bharadhwaj,Akash Sharma,Tingfan Wu,Guanya Shi,Jitendra Malik,Francois Hogan*

Main category: cs.RO

TL;DR: 提出了一种基于物理的重定向框架SPIDER，用于将仅含有人类运动学数据的演示转换为动态可行的机器人轨迹。该方法通过大规模基于物理的采样和课程式的虚拟接触指导来细化轨迹，确保动力学可行性并修正接触顺序。


<details>
  <summary>Details</summary>
Motivation: 学习灵巧且敏捷的类人机器人和灵巧手控制策略需要大规模的示范数据，但收集特定于机器人的数据成本过高。相反，来自动作捕捉、视频和虚拟现实的人体运动数据丰富易得，可以解决数据稀缺问题。然而，由于身体差异以及缺乏力和扭矩等动态信息，这些演示无法直接在机器人上执行。

Method: 提出了一个名为SPIDER（可扩展的基于物理的灵巧重定向）的框架，该框架能够将仅有运动学信息的人类演示转换成对于机器人来说动态上可行的轨迹，并且能够大规模地进行这种转换。主要思路是利用人类演示提供全局任务结构与目标，同时通过大规模基于物理的采样加上课程式虚拟接触引导来优化轨迹，以保证动力学上的可行性及正确的接触序列。

Result: SPIDER能够在不同的9个类人/灵巧手实例和6个数据集上工作，相比标准采样方法提高了18%的成功率，同时比强化学习基线快了10倍，并能生成240万帧的动力学可行机器人数据集用于策略学习。

Conclusion: 作为一种通用的基于物理的重定向方法，SPIDER可以处理不同质量的数据，并生成多样化高质量的数据来支持像强化学习这样的方法实现高效策略学习。

Abstract: Learning dexterous and agile policy for humanoid and dexterous hand control requires large-scale demonstrations, but collecting robot-specific data is prohibitively expensive. In contrast, abundant human motion data is readily available from motion capture, videos, and virtual reality, which could help address the data scarcity problem. However, due to the embodiment gap and missing dynamic information like force and torque, these demonstrations cannot be directly executed on robots. To bridge this gap, we propose Scalable Physics-Informed DExterous Retargeting (SPIDER), a physics-based retargeting framework to transform and augment kinematic-only human demonstrations to dynamically feasible robot trajectories at scale. Our key insight is that human demonstrations should provide global task structure and objective, while large-scale physics-based sampling with curriculum-style virtual contact guidance should refine trajectories to ensure dynamical feasibility and correct contact sequences. SPIDER scales across diverse 9 humanoid/dexterous hand embodiments and 6 datasets, improving success rates by 18% compared to standard sampling, while being 10X faster than reinforcement learning (RL) baselines, and enabling the generation of a 2.4M frames dynamic-feasible robot dataset for policy learning. As a universal physics-based retargeting method, SPIDER can work with diverse quality data and generate diverse and high-quality data to enable efficient policy learning with methods like RL.

</details>


### [19] [MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation](https://arxiv.org/abs/2511.09516)
*Runhao Li,Wenkai Guo,Zhenyu Wu,Changyuan Wang,Haoyuan Deng,Zhenyu Weng,Yap-Peng Tan,Ziwei Wang*

Main category: cs.RO

TL;DR: 提出了一种名为MAP-VLA的新框架，通过从历史演示中构建记忆库并使用学习的软提示来增强预训练的视觉-语言-动作模型，以改进长时序机器人操作任务的表现。实验表明，在模拟基准测试和真实机器人评估中，该方法相比现有最先进方法有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉-语言-动作模型在处理需要长期规划的任务时表现不佳，因为它们缺乏记忆能力且只依赖即时感知输入。为了解决这个问题，提出了一个新框架，旨在通过增加记忆提示来提高这些模型在执行长时序任务时的能力。

Method: MAP-VLA首先从历史演示中创建一个记忆库，每个记忆单元都捕捉了任务特定阶段的信息，并作为可学习的软提示实现。然后，在实时任务执行过程中，系统通过轨迹相似性匹配检索相关记忆，并将其动态整合到VLA模型中以生成增强的动作输出。

Result: 实验结果显示，MAP-VLA在模拟基准上实现了高达7.0%的绝对性能增益，在实际机器人评估中针对长时序任务达到了25.0%的性能提升，超过了当前最先进的方法。

Conclusion: MAP-VLA提供了一种轻量级且灵活的方法，通过插件式设计增强了冻结状态下的VLA模型处理复杂、长时序任务的能力，显示出其在提高机器人操作任务性能方面的有效性。

Abstract: Pre-trained Vision-Language-Action (VLA) models have achieved remarkable success in improving robustness and generalization for end-to-end robotic manipulation. However, these models struggle with long-horizon tasks due to their lack of memory and reliance solely on immediate sensory inputs. To address this limitation, we propose Memory-Augmented Prompting for Vision-Language-Action model (MAP-VLA), a novel framework that empowers pre-trained VLA models with demonstration-derived memory prompts to augment action generation for long-horizon robotic manipulation tasks. To achieve this, MAP-VLA first constructs a memory library from historical demonstrations, where each memory unit captures information about a specific stage of a task. These memory units are implemented as learnable soft prompts optimized through prompt tuning. Then, during real-time task execution, MAP-VLA retrieves relevant memory through trajectory similarity matching and dynamically integrates it into the VLA model for augmented action generation. Importantly, this prompt tuning and retrieval augmentation approach operates as a plug-and-play module for a frozen VLA model, offering a lightweight and flexible solution to improve task performance. Experimental results show that MAP-VLA delivers up to 7.0% absolute performance gains in the simulation benchmark and 25.0% on real robot evaluations for long-horizon tasks, surpassing the current state-of-the-art methods.

</details>
