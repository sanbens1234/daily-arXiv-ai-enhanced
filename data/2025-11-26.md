<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories](https://arxiv.org/abs/2511.19528)
*Rushuai Yang,Zhiyuan Feng,Tianxiang Zhang,Kaixin Wang,Chuheng Zhang,Li Zhao,Xiu Su,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 本文提出了一种基于信息理论的行为模式发现框架DLR，用于生成多样化的高质量操纵轨迹，以支持视觉-语言-动作模型的大规模预训练。相较于标准强化学习方法只能发现单一策略，DLR能够学习同一任务下的多种高成功率策略，从而覆盖更广泛的状态-动作空间区域。实验表明，在未见过的下游任务上，使用DLR生成的数据预训练的VLA模型表现优于使用相同大小标准RL数据集训练的模型，并且展示出了单模式RL所缺乏的正向数据扩展性。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作(VLA)模型预训练需要大量多样化、高质量的操作轨迹。当前大部分数据通过人类遥控操作获得，这种方式成本高昂且难以规模化。虽然强化学习(RL)方法可以通过自主探索学习有用的技能，但传统的RL训练往往收敛于一种狭窄的行为模式，限制了其在大规模预训练中的应用。

Method: 提出了Discover, Learn and Reinforce (DLR)，这是一种基于信息论的行为模式发现框架，旨在为VLA预训练产生多个不同的高成功率行为模式。

Result: 实验证明，DLR能够在LIBERO上生成明显更加多样化的轨迹语料库。它对于同一任务可以学到多种不同但高成功率的策略，相比之下传统RL仅能发现一个。此外，当适应到未见的任务套件时，利用DLR提供的多样化RL数据进行预训练的VLA模型超过了那些用等量标准RL数据集训练的同类。更重要的是，DLR展示了正面的数据扩展性，这是单一模式RL不具备的特点。

Conclusion: 这些结果将多模式RL定位为实体基础模型的实际可行、可扩展的数据引擎。

Abstract: Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.

</details>


### [2] [A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers](https://arxiv.org/abs/2511.19543)
*Omar Faris,Sławomir Tadeja,Fulvio Forni*

Main category: cs.RO

TL;DR: 本研究提出了一种利用虚拟模型控制和增强现实技术来提高人与机器人之间物体交接过程中机器人动作的适应性和鲁棒性的方法，并通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在协作任务中，物体交接是一种常见的互动形式，但实现高效的物体交接仍具有挑战性。特别是当人类将物体交给机器人时，如何让机器人能够适应物体姿态的复杂变化是一个需要解决的问题。

Method: 研究者提出了使用虚拟模型控制创建一个交互层来控制机器人，并使其能适应交接过程中的动态变化。此外，还提出了使用增强现实技术促进人类与机器人之间的双向沟通。

Result: 通过一系列实验评估了控制器在面对各种不确定性（包括交接过程中物体姿态的复杂变化）时的表现。另外，通过对16名参与者进行用户研究，了解了人们对不同机器人控制模式及增强现实视觉效果的偏好。结果显示，人们普遍倾向于所提出的方法。

Conclusion: 本研究表明，结合虚拟模型控制与增强现实技术可以有效提升人-机器人物体交接过程中的鲁棒性和用户体验。

Abstract: Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.

</details>


### [3] [Online Learning-Enhanced High Order Adaptive Safety Control](https://arxiv.org/abs/2511.19651)
*Lishuo Pan,Mattia Catellani,Thales C. Silva,Lorenzo Sabattini,Nora Ayanian*

Main category: cs.RO

TL;DR: 本文提出了一种使用神经ODE的在线学习增强高阶自适应控制屏障函数方法，能够在复杂时变模型扰动下实时提高CBF认证系统的安全性，并在38克纳米四旋翼无人机上成功部署，以对抗18公里/小时的风速同时保持与障碍物的安全距离。


<details>
  <summary>Details</summary>
Motivation: 随着现代控制问题复杂性的增加，控制屏障函数（CBFs）作为一种基于模型的工具，在确保系统安全方面受到了越来越多的关注。然而，将这些安全保证转移到现实世界系统中的成功很大程度上取决于模型的准确性。例如，负载或风干扰可以显著影响飞行器的动力学特性并使安全保证失效。因此，研究者们希望开发一种即使在存在复杂时变模型扰动的情况下也能实时改善CBF认证系统安全性的方法。

Method: 本文介绍的方法是通过结合神经ODE来实现一个高效的在线学习增强型高阶自适应控制屏障函数。这种方法允许控制系统根据实际运行条件动态调整其行为，从而即便面对诸如强风等外部因素造成的动力学变化时也能维持高水平的安全性。

Result: 该方法被应用于一个仅重38克的纳米四旋翼无人机上，并展示了即使在遭遇高达18公里/小时风速的情况下，也能有效地保持与障碍物之间安全距离的能力。这表明所提出的方法能够有效应对复杂的、时间变化的模型扰动。

Conclusion: 通过引入基于神经ODE的在线学习机制，本研究为提升CBF认证系统在面对不确定环境因素时的安全性能提供了新的途径。实验结果证明了该方法的有效性及其在实际应用中的潜力。

Abstract: Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.

</details>


### [4] [Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection](https://arxiv.org/abs/2511.19655)
*Shantanu Rahman,Nayeb Hasin,Mainul Islam*

Main category: cs.RO

TL;DR: 本研究提出了一种结合车道识别和模型预测控制（MPC）的新方法，旨在提高自动驾驶汽车轨迹跟踪的精确度与稳定性。通过使用边缘识别等技术进行车道线提取，并基于自行车车辆动力学模型构建了MPC控制器。实验结果表明，在模拟环境中，该控制器能够显著降低最优跟踪轨迹与目标轨迹之间的均方根误差，展示了其高鲁棒性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆在道路行驶、工业自动化、农业及军事领域的日益普及，对于提升这类车辆在低级控制层面的精度与稳定性存在迫切需求。特别是采用阿克曼转向机制的标准车辆，在执行具体动作时如何更准确地遵循预定路径成为一个关键问题。

Method: 本研究首先利用安装于车辆上的摄像头进行车道线识别，采用了边缘识别技术和基于滑动窗口的直线检测方法来实现车道线的提取；接着，基于自行车模型开发了一个模型预测控制器(MPC)，以帮助车辆更好地跟随已识别出的车道线。为验证所提方法的有效性，研究人员在ROS Gazebo中构建了一个单车道道路仿真模型来进行测试。

Result: 仿真结果显示，与传统方法相比，所提出的结合车道识别与MPC的方法可以将最优跟踪轨迹与目标轨迹之间的均方根误差减少27.65%，证明了该控制器具有较高的鲁棒性和适应性。

Conclusion: 这项工作展示了一种新的方法，通过结合车道识别技术和模型预测控制来增强自动驾驶汽车在轨迹跟踪方面的表现。实验结果证实了这种方法的有效性及其在提高车辆控制精度与稳定性方面的潜力。

Abstract: Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.

</details>


### [5] [Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility](https://arxiv.org/abs/2511.19691)
*Thomas Marshall Vielmetti,Devansh R Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出了一个多智能体守门员框架，为杂乱3D环境中的领航-跟随编队控制提供了可证明的安全保证。通过让单一领航者跟踪预计算的安全轨迹，并作为所有跟随者的共享备份轨迹集，确保了跟随者在执行标准编队保持控制器时能够始终拥有一个已知安全的备选动作。该方法在理论上保证了与静态障碍物和其他智能体之间的避碰。此外，还首次将守门员框架应用于3D环境中，并在模拟和实际四旋翼飞行器上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的在线规划器和控制器缺乏正式的安全保障，而离线规划器则缺乏对智能体数量或期望编队变化的适应性。为了填补这一空白，研究提出了一种混合架构，旨在提供一种既能适应变化又能保证安全性的多智能体系统解决方案。

Method: 设计了一个多智能体守门员算法，允许单个领航者追踪一条预先计算的安全路径，这条路径同时也作为所有跟随者的备用安全行动方案。跟随者们根据一个标准的编队维持跟踪控制器进行操作，同时确保它们总是拥有一条沿着领航者路径的已知安全备选路线。

Result: 在模拟3D城市环境中进行了测试，显示了100%的避障成功率，在100次随机试验中显著优于基线CBF（控制障碍函数）和NMPC（非线性模型预测控制）方法。此外，还在一组四旋翼无人机上展示了物理可行性。

Conclusion: 提出的多智能体守门员框架成功解决了杂乱3D环境中领航-跟随编队控制的安全性问题，不仅提供了形式化的安全性证明，而且在实际应用中也表现出色。

Abstract: We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.

</details>


### [6] [Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation](https://arxiv.org/abs/2511.19709)
*Lukas Molnar,Jin Cheng,Gabriele Fadini,Dongho Kang,Fatemeh Zargarbashi,Stelian Coros*

Main category: cs.RO

TL;DR: 本文提出了一种全身体模型预测控制（MPC）框架，通过全阶逆动力学直接优化关节扭矩，在单一层级上实现了统一的运动和力规划与执行。该方法允许出现物理一致性的全身行为，同时考虑了系统的动态性和物理约束。实验在一个配备有操作臂的四足机器人上进行，展示了如拉动重物、推箱子和擦白板等需要精细控制的任务，并以80Hz达到实时性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在移动操作中有效操纵物体的同时保持运动稳定性的挑战，研究提出了一个能够统一规划和控制运动及力量的全身体MPC框架。

Method: 采用全阶逆动力学直接优化关节扭矩，构建了一个全身体MPC框架来实现统一的运动与力规划执行。该方案使用开源软件框架Pinocchio和CasADi以及先进的内点求解器Fatrop进行实现。

Result: 在Unitree B2四足机器人及其Z1操作臂上的实际测试表明，所提出的MPC公式可以80Hz的频率实现实时表现，并成功完成了包括拉动重载、推动盒子和擦拭白板在内的多种移动操作任务。

Conclusion: 所提出的全身体MPC框架能够有效地解决移动操作中的复杂问题，展现出良好的实时性能和实用性，适用于需要精确位置与力控制的实际场景。

Abstract: Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.

</details>


### [7] [Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859)
*Xiangkai Ma,Lekai Xing,Han Zhang,Wenzhong Li,Sanglu Lu*

Main category: cs.RO

TL;DR: 提出了一个名为VITA的框架，通过学习视觉和动作之间的共享离散潜在空间来解决视觉-语言-动作模型中的模态差距和训练不稳定问题。实验表明，该方法在模拟环境和真实世界任务中都取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的思维链（CoT）难以充分捕捉复杂空间环境中的场景细节，而利用视觉先验来指导机器人动作生成的方法面临着视觉观察与低级动作之间的模态差距以及由于视觉预测与动作生成目标竞争导致的训练不稳定两大挑战。

Method: 提出了一种视觉集成轨迹对齐（VITA）框架，该框架通过学习视觉和动作的共享离散潜在空间来联合建模感知和运动控制。VITA引入了一个隐式的视觉CoT：自回归生成的令牌同时被解码为未来帧预测和机器人动作，从而将视觉动态内化为运动规划的归纳偏差。

Result: 广泛的实验表明，在CALVIN、LIBERO和SimplerEnv等数据集上，VITA相较于现有基线分别提高了14.5%、9.6%和12.1%。此外，在六个真实世界任务中，VITA达到了平均80.5%的成功率，展示了其作为通用机器人操作模型的潜力。

Conclusion: VITA框架有效地解决了视觉-语言-动作模型中存在的模态差距及训练不稳定性问题，并且在多种环境下的表现证明了它能够作为强大的通用型机器人操控解决方案。

Abstract: Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\%, 9.6\% and 12.1\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.

</details>


### [8] [Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function](https://arxiv.org/abs/2511.19869)
*Eito Sato,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出了一种结合独立于操纵杆的自主控制器与触觉共享控制（HSC）的合作框架，通过在安全区域内忽略操纵杆输入并在其他情况下启用HSC来提高远程操作水下机器人的准确性和减少所需时间。


<details>
  <summary>Details</summary>
Motivation: 当前的触觉共享控制（HSC）虽然在远程操作中有效，但其性能受到操纵杆和人手臂动态的影响而受限。为了克服这一局限性，并在不确定性或传感限制条件下提供更优的控制效果，提出了新的合作框架。

Method: 该研究提出的方法包括一个不依赖操纵杆输入的自主控制器以及基于控制屏障函数的触觉共享控制策略。当操作员实时确定的安全区域条件满足时，系统将忽略操纵杆指令；否则，则激活HSC机制以辅助控制。

Result: 通过模拟任务中的初步实验显示，对于远程操作的虚拟环境下的水下机器人而言，所提出的方法相比传统HSC方案能够实现更高的精度并减少完成任务所需的时间。

Conclusion: 新提出的结合了独立于操纵杆的自主控制器与改进版HSC的合作框架为远程操作系统提供了更高效、更准确的解决方案，特别是在面对不确定性和传感限制时。

Abstract: Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.

</details>


### [9] [CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model](https://arxiv.org/abs/2511.19914)
*Dapeng Zhang,Fei Shen,Rui Zhao,Yinda Chen,Peng Zhi,Chenyang Li,Rui Zhou,Qingguo Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种名为CoC-VLA的新型VLM引导的端到端对抗迁移框架，用于自动驾驶。该框架通过将处理长尾情况的能力从模拟环境迁移到现实世界部署，结合了教师VLM模型、学生VLM模型和判别器的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于真实世界的数据或针对罕见或困难案例场景定制的模拟数据，很少有方法能有效地整合这两种数据源的互补优势。为了解决这一局限性，作者提出了一个新的框架来增强自动驾驶系统在各种场景下的推理、可解释性和性能，特别是对于复杂和长尾情况。

Method: 提出的CoC-VLA框架包括一个教师VLM模型、一个学生VLM模型和一个判别器。教师与学生VLM模型共享一个称为因果链视觉-语言模型的基础架构（CoC VLM），它通过端到端文本适配器集成时间信息。这种架构支持链条式思维推理以推断复杂的驾驶逻辑。教师和学生VLM模型分别在模拟和真实世界数据集上进行预训练。判别器通过一种新颖的反向传播策略进行对抗性训练，帮助学生VLM模型从模拟环境转移到真实环境中时获得处理长尾情况的能力。

Result: 该研究展示了如何利用VLMs理解视觉和自然语言输入以及遵循指令的能力，从而增强了自动驾驶系统在不同场景中的表现。通过所提出的CoC-VLA框架，可以有效地将在模拟中学习到的处理复杂情况的知识迁移到实际驾驶条件中。

Conclusion: CoC-VLA提供了一个创新的方法，通过结合模拟和真实世界数据的优点，提升了自动驾驶系统应对复杂及长尾事件的能力。这种方法不仅加强了系统的推理能力，还提高了其在多样场景中的适应性和性能。

Abstract: Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.

</details>


### [10] [ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation](https://arxiv.org/abs/2511.19955)
*Jinxuan Zhu,Zihao Yan,Yangyu Xiao,Jingxiang Guo,Chenrui Tie,Xinyi Cao,Yuhang Zheng,Lin Shao*

Main category: cs.RO

TL;DR: ShapeForce, a low-cost and easy-to-use soft wrist, provides force-like signals for robotic manipulation by converting external forces into measurable deformations, offering a cost-effective alternative to six-axis force-torque sensors with comparable performance in contact-rich tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to address the high cost and fragility of six-axis force-torque sensors, which are commonly used but not widely adopted for contact-rich robotic tasks. The authors aim to provide a more accessible and affordable solution for obtaining contact feedback necessary for such tasks.

Method: The method involves designing ShapeForce, a soft wrist that can convert external force and torque into measurable deformations through its compliant core. These deformations are tracked using marker-based pose tracking and then transformed into force-like signals, without the need for complex calibration or specialized electronics.

Result: The results show that ShapeForce performs comparably to traditional six-axis force-torque sensors across various contact-rich manipulation tasks and policies, demonstrating its effectiveness as a lower-cost alternative for providing adequate contact feedback.

Conclusion: In conclusion, ShapeForce offers a viable and cost-efficient solution for enabling contact-rich robotic manipulation, making it a promising alternative to the more expensive and fragile six-axis force-torque sensors.

Abstract: Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six- axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.

</details>


### [11] [Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification](https://arxiv.org/abs/2511.20050)
*Yan Li,Yingzhao Li,Gim Hee Lee*

Main category: cs.RO

TL;DR: 本文提出了一种主动探索框架，用于高保真3D重建。该框架通过不确定性驱动的运动规划器逐步构建多层次的不确定性空间，并选择下一个最佳视点。


<details>
  <summary>Details</summary>
Motivation: 为了提高3D重建的质量和效率，特别是在复杂环境下的重建任务中，作者提出了一个结合了全局结构先验和局部观测细节捕捉的混合隐式-显式表示方法。

Method: 引入了一种融合神经场与高斯原语的混合隐式-显式表示法；基于此表示开发了一个层次化的不确定性体积来量化全局结构质量及局部表面置信度；提出了基于不确定性的关键帧选择策略以聚焦于信息量最大的区域；将下一个最佳视点的选择建模为预期混合信息增益问题，并结合风险敏感路径规划确保高效安全探索。

Result: 在具有挑战性的基准测试上进行了广泛的实验，结果表明该方法能够持续达到最先进的准确性、完整性和渲染质量。

Conclusion: 本研究提出的主动探索框架对于现实世界的主动重建和机器人感知任务非常有效。

Abstract: In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.

</details>


### [12] [Hibikino-Musashi@Home 2025 Team Description Paper](https://arxiv.org/abs/2511.20180)
*Ryohei Kobayashi,Kosei Isomoto,Kosei Yamao,Soma Fumoto,Koshun Arimura,Naoki Yamaguchi,Akinobu Mizutani,Tomoya Shiba,Kouki Kimizuka,Yuta Ohno,Ryo Terashima,Hiromasa Yamaguchi,Tomoaki Fujino,Ryoga Maruno,Wataru Yoshimura,Kazuhito Mine,Tang Phu Thien Nhan,Yuga Yano,Yuichiro Tanaka,Takeshi Nishida,Takashi Morie,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: 本文概述了Hibikino-Musashi@Home团队在参与家用标准平台联赛时采用的技术，包括开发用于训练机器人视觉系统的数据集生成器、基于大型语言模型的任务规划器以及受大脑启发的记忆模型等，以提供直观和个性化的家庭服务。


<details>
  <summary>Details</summary>
Motivation: Hibikino-Musashi@Home团队的目标是设计一个能够辅助人类在家务中的服务机器人，并通过持续参加比赛来评估和改进所开发的系统。此外，该团队还关注于提高导航系统的可重用性，特别是Pumas在RoboCup2024中开发的导航系统。

Method: 团队开发了一个数据集生成器来训练机器人视觉系统，创建了一个可在Human Support Robot模拟器上运行的开源开发环境。利用基于大语言模型的任务规划器选择合适的原始技能执行用户请求的任务。同时，研究工作集中在脑启发记忆模型上，以适应不同的家庭环境。

Result: 这些技术共同作用，旨在让家庭服务机器人更加直观地理解并个性化地满足用户需求。此外，对于Pumas在RoboCup2024期间开发的导航系统，该团队也做出了贡献，增强了其可重用性。

Conclusion: Hibikino-Musashi@Home团队通过结合多种先进技术，如数据集生成器、基于大语言模型的任务规划器及脑启发记忆模型，在开发能更好地服务于家庭环境的服务机器人方面取得了显著进展。

Abstract: This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.

</details>


### [13] [Toward generic control for soft robotic systems](https://arxiv.org/abs/2511.20226)
*Yu Sun,Yaosheng Deng,Wenjie Mei,Xiaogang Xiong,Yang Bai,Masaki Ogura,Zeyu Zhou,Mir Feroskhan,Michael Yu Wang,Qiyang Zuo,Yao Li,Yunjiang Lou*

Main category: cs.RO

TL;DR: 本文提出了一种基于控制顺应性的通用软体机器人控制框架，该框架能够跨不同形态和驱动机制的机器人实现稳定、安全且可转移的行为。


<details>
  <summary>Details</summary>
Motivation: 当前软体机器人的控制方法仍然零散，需要针对特定任务设计控制器，这阻碍了理论整合和大规模部署。文章受到人类运动控制原理的启发，认为应从抑制顺应性转向明确利用顺应性以提高软体机器人的鲁棒性和适应性。

Method: 提出了一个基于控制顺应性的通用软体机器人控制框架，并在具有多样形态与驱动机制的机器人上进行了验证。

Result: 实验结果表明，所提出的控制框架能够实现跨平台的稳定、安全行为转移。

Conclusion: 接受并利用控制顺应性而非抵抗它，可能为统一软体机器人控制提供广泛适用的基础。

Abstract: Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.

</details>


### [14] [Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes](https://arxiv.org/abs/2511.20292)
*Dong Wang,Daniel Casado Herraez,Stefan May,Andreas Nüchter*

Main category: cs.RO

TL;DR: 本文提出了一种名为Dynamic-ICP的方法，它通过结合点到平面的几何残差和旋转专用的多普勒残差来处理高度动态环境中的里程计问题。该方法不需要外部传感器或传感器-车辆校准，并直接在FMCW LiDAR范围和多普勒速度上运行，从而在高动态场景中提高了旋转稳定性和平移准确性。


<details>
  <summary>Details</summary>
Motivation: 在高度动态环境中，基于ICP的配准依赖于近静态场景，在重复性或低纹理几何中表现不佳。为解决这个问题，提出了Dynamic-ICP方法，旨在提高这种环境下里程计的可靠性。

Method: Dynamic-ICP方法包括：(i) 通过鲁棒回归从每个点的多普勒速度估计自运动并构建速度滤波器；(ii) 对动态物体进行聚类，并从补偿后的径向测量值重建物体级别的平移速度；(iii) 使用恒定速度模型预测动态点的位置；(iv) 利用结合了点到平面几何残差和仅旋转多普勒残差的紧凑目标函数对扫描进行对齐。

Result: 在HeRCULES、HeLiPR和AevaScenes三个数据集上的实验表明，与现有最先进方法相比，Dynamic-ICP在高度动态场景下一致地提高了旋转稳定性和平移准确性。此外，该方法易于集成到现有的管道中，能够实时运行，并为动态环境下的鲁棒配准提供了一个轻量级解决方案。

Conclusion: Dynamic-ICP作为一种针对高度动态环境设计的鲁棒配准框架，不仅克服了传统ICP算法在这些条件下的局限性，还提供了更好的旋转稳定性和平移准确性。其简单易用性及实时性能使其成为改善动态环境中激光雷达定位技术的有效工具。

Abstract: Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.

</details>


### [15] [How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks](https://arxiv.org/abs/2511.20299)
*Róisín Keenan,Joost C. Dessing*

Main category: cs.RO

TL;DR: 本研究通过虚拟现实技术探讨了在不同任务动态和机器人运动学下人机协作中的手交任务，发现人类受益于机器人提供的早期显著视觉信息以及类似人类的平滑机器人轨迹，这有助于提高交互过程中的预测准确性和同步性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术的进步，将其整合到有人参与的工作场所的可能性增加，因此有必要研究并优化协作环境中的人机协调。

Method: 采用基于虚拟现实（VR）的机器人交接模拟来安全且受控地评估人机交互，并通过一系列实验检查四个潜在影响人类表现的因素：对任务启动和机器人移动同步性的控制、合作伙伴外观（人类与机器人）、机器人速度曲线（最小冲击、恒定速度、恒定加速度和双相）及旋转物体运动的时间安排。

Result: 研究结果表明，当机器人提供关于任务相关物体运动的早期显著视觉信息时，人类从中获益；同时，类似于人类的平稳机器人轨迹也显示出优势。这些调整在不同程度上提高了互动期间的预测准确性和同步性。

Conclusion: 为了改善人机交互，应该设计能够让人利用其自然能力检测生物运动特征的系统，从而可能减少昂贵的机器人计算需求或降低人类的认知适应负担。

Abstract: Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.

</details>


### [16] [ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation](https://arxiv.org/abs/2511.20330)
*Yuhan Wu,Tiantian Wei,Shuo Wang,ZhiChao Wang,Yanyong Zhang,Daniel Cremers,Yan Xia*

Main category: cs.RO

TL;DR: 本文提出了ArtiBrain，一个结合了高层次推理与自适应低级控制的模块化框架，旨在解决交互式关节操作中的长期多步骤互动问题。通过使用基于VLM的任务推理器（GPT-4.1）分解和验证子目标，并采用混合控制器执行几何感知关键帧与可操作性引导扩散，实现精准且可解释的操作。此外还引入了ArtiBench基准测试来评估不同方法在关节物体操纵上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型及基于扩散策略的方法在处理关节物体时难以跨越部件、实例以及类别进行泛化。为了解决这一难题并提高对关节物体操作任务中长期多对象任务的支持，作者们开发了ArtiBrain框架。

Method: 提出了一种名为ArtiBrain的新框架，该框架整合了基于VLM的任务推理器（使用GPT-4.1）用于目标分解与验证，以及一个混合控制器负责执行具有几何意识的关键帧动作加上受可操作性指导的扩散过程。同时，建立了一个名为ArtiBench的五级评测标准，覆盖了厨房、存储、办公室和工具等环境，用以系统地评估从跨部件变化到长周期多对象任务的表现。

Result: 实验结果表明，在ArtiBench上进行的广泛测试显示，ArtiBrain在鲁棒性和泛化性能方面显著优于当前最先进的多模态和基于扩散的方法。

Conclusion: ArtiBrain作为一种新的关节物体操作方法，通过其独特的设计有效地解决了现有技术在泛化方面的局限性，特别是在处理复杂多样的关节物体时展现出更强的适应能力和操作精度。

Abstract: Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.

</details>


### [17] [Quality-guided UAV Surface Exploration for 3D Reconstruction](https://arxiv.org/abs/2511.20353)
*Benjamin Sportich,Kenza Boubakri,Olivier Simonin,Alessandro Renzaglia*

Main category: cs.RO

TL;DR: 本文提出了一种新的模块化Next-Best-View（NBV）规划框架，该框架利用重建质量目标来指导空中机器人的探索计划。通过在模拟环境中验证，该方法能够根据用户的目标调整其行为，并在覆盖范围、最终3D地图质量和路径效率方面优于传统的NBV策略。


<details>
  <summary>Details</summary>
Motivation: 现有自主机器人环境测绘中往往忽视了快速信息收集和建筑物全面结构评估的不同需求，需要不同的方法论。

Method: 提出了一个使用重建质量目标指导探索规划的新型模块化Next-Best-View（NBV）规划框架。新方法包括视图生成和视角候选选择的方法，这些方法可以根据用户定义的质量要求进行调整，并充分利用了Truncated Signed Distance field (TSDF)表示法中的不确定性。

Result: 所提方法能够在真实环境的广泛仿真中验证其有效性，成功地根据用户目标调整行为，并且在覆盖范围、最终3D地图质量和路径效率方面一致优于传统NBV策略。

Conclusion: 提出的基于自适应用户定义质量要求的NBV规划框架能够有效地为预定目标提供信息并做出高效的探索决策。

Abstract: Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.

</details>


### [18] [Improved adaptive wind driven optimization algorithm for real-time path planning](https://arxiv.org/abs/2511.20394)
*Shiqian Liu,Azlan Mohd Zain,Le-le Mao*

Main category: cs.RO

TL;DR: 本文提出了一种多层级自适应风驱动优化算法（MAWDO），通过引入层级指导机制来提高在时变环境中的适应性和鲁棒性，从而在动态路径规划中实现了更短、更平滑且无碰撞的轨迹。


<details>
  <summary>Details</summary>
Motivation: 当前路径规划技术虽然在全球搜索能力和收敛精度方面取得了显著进展，但在动态环境下的实时适应性仍是一个关键挑战。特别是当机器人需要在复杂约束下生成无碰撞、平滑且高效的轨迹时。基于这些观察，本研究重新审视了风驱动优化（WDO）原理，并提出了一个改进版本以解决上述问题。

Method: 提出了一个多层级自适应风驱动优化(MAWDO)算法，通过将群体划分为由个体、区域和全局领导者引导的多个组来平衡探索与开发，以此减轻不稳定性并避免过早收敛。

Result: 在十六个基准函数上的广泛评估表明，MAWDO相比现有元启发式算法，在优化准确性、收敛稳定性以及适应性上表现更优。具体而言，在动态路径规划任务中，相较于其他方法如MEWDO、AWDO及WDO，MAWDO能够缩短路径长度达3.51%至14.93%，同时保持最小的最优性差距(1.01)和平滑度(0.71)，证明了其在复杂环境中进行实时路径规划的有效性。

Conclusion: 所提出的MAWDO算法有效地解决了动态环境下路径规划面临的挑战，为实现更短、更平滑且无碰撞的轨迹提供了一种新方法。

Abstract: Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\%, 11.63\% and 14.93\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.

</details>
