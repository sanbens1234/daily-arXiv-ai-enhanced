<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 8]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models](https://arxiv.org/abs/2601.05336)
*Tracey Yee Hsin Tay,Xu Yan,Jonathan Ouyang,Daniel Wu,William Jiang,Jonathan Kao,Yuchen Cui*

Main category: cs.RO

TL;DR: 该论文提出了一种名为GAMMA的系统，它利用以自我为中心的注视跟踪和视觉-语言模型来推断用户意图并自主执行机器人操作任务。通过将视觉注意力映射到高级语义理解上，GAMMA能够在无需特定任务训练的情况下选择技能并参数化。实验结果表明GAMMA提供了稳健、直观且可泛化的控制方式。


<details>
  <summary>Details</summary>
Motivation: 设计直观的人机交互界面是实现有效人机互动的关键挑战，特别是在辅助护理环境中。眼睛注视提供了一种快速、非侵入性且富含意图的输入方式，使其成为传达用户目标的理想渠道。

Method: GAMMA系统结合了以自我为中心的注视追踪技术与视觉-语言模型，以此来推断用户的意图，并能够自动执行机器人操纵任务。该系统通过对场景中注视点的情境化处理，将视觉注意力转换为高层次的语义理解，从而支持无需针对特定任务进行训练的技能选择与参数设定。

Result: 在一系列桌面操作任务上的评估显示，相较于没有推理能力的基础视线控制方法，GAMMA能够提供更加稳定、直观以及广泛适用的控制体验。

Conclusion: 研究证明了结合基础模型与视线追踪技术对于开发自然且可扩展的机器人自主性具有巨大潜力。

Abstract: Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/

</details>


### [2] [Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction](https://arxiv.org/abs/2601.05491)
*Luca Nunziante,Kentaro Uno,Gustavo H. Diaz,Shreya Santra,Alessandro De Luca,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文提出了一种将视觉、控制和硬件系统整合到双臂机器人系统的自主序列中的方法，专门针对组装太阳能电池板模块的任务。实验表明，该方法能有效连接任意放置的面板，展示了在复杂空间应用中这些系统的无缝集成。


<details>
  <summary>Details</summary>
Motivation: 随着人类再次瞄准月球进行科学探索、资源开采和居住，未来几十年的重点将是建立一个月球前哨站。机器人系统将在安全高效地建立必要基础设施（如太阳能发电塔）方面发挥关键作用。类似国际空间站的建设方式，通过模块化运输并在现场组装组件是一个实际可行的方案。

Method: 论文探讨了专为组装太阳能电池板模块设计的感知与控制流程，并为此设计并测试了专用硬件。使用了模块化太阳能电池板模型及主动-被动连接器，在提出的流程中集成了抓取装置的控制。

Result: 所提出的方法成功实施，证明两台机械臂能够有效地连接任意位置的面板，突出了视觉、控制和硬件系统在复杂太空应用中的无缝集成。

Conclusion: 本研究展示了一种适用于月球环境下的自动化装配技术，强调了机器人技术在支持未来太空探索任务中的重要性。

Abstract: Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.

</details>


### [3] [TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds](https://arxiv.org/abs/2601.05499)
*Weishang Wu,Yifei Shi,Zhiping Cai*

Main category: cs.RO

TL;DR: 本文提出了一种面向任务的形状补全方法，专注于完成潜在接触区域而非整个形状，并通过多个预训练的基础模型生成候选方案，再利用3D判别自编码器评估每个候选方案的合理性并优化最可能的方案。基于优化后的形状，开发了一个名为FlowGrasp的条件流匹配模型来生成面向任务的灵巧抓握。该方法在面向任务的灵巧抓握和形状补全上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在严重的部分观察下对开放世界对象进行任务导向的灵巧抓取仍然具有挑战性，其中大量缺失的数据使得通用形状补全失效。为了解决这个问题，研究者提出了面向任务的形状补全这一新任务，旨在只完成与抓取相关的潜在接触区域，而不是整个物体形状，同时强调形状补全应由下游操作任务明确指导。

Method: 首先，利用几个预训练基础模型的零样本能力生成多个面向任务的形状补全候选。接着，提出一个3D判别自编码器来评估每个生成候选的可能性，并从全局视角优化最有可能的那个。最后，开发了名为FlowGrasp的条件流匹配模型，根据优化后的形状生成面向任务的灵巧抓取。

Result: 所提出的方法在面向任务的灵巧抓取和面向任务的形状补全方面都取得了最先进的表现，相较于现有技术，在抓取位移和Chamfer距离上分别提高了16.17%和55.26%。特别是对于严重缺失数据的对象，该方法展现了良好的抓取能力；同时，它还展示了处理开放集类别和任务的良好泛化性。

Conclusion: 本研究成功地将面向任务的概念引入到形状补全中，为机器人在高度不确定环境下执行灵巧抓取提供了新的解决方案。通过结合预训练模型的零样本能力和创新的形状补全及抓取生成策略，该方法不仅提高了抓取精度，也增强了对未知对象或任务类型的适应性。

Abstract: Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.

</details>


### [4] [Learning specifications for reactive synthesis with safety constraints](https://arxiv.org/abs/2601.05533)
*Kandai Watanabe,Nicholas Renninger,Sriram Sankaranarayanan,Morteza Lahijanian*

Main category: cs.RO

TL;DR: 本文提出了一种新的从演示中学习的方法，使机器人能够在动态环境中自主执行复杂任务。通过将潜在任务建模为概率形式语言，并引入一个定制的反应合成框架来平衡机器人成本与用户任务偏好。重点在于安全约束下的学习和推断作为概率确定性有限自动机（PDFA）的形式任务规范。此外，还介绍了一种多目标反应合成算法，以生成满足PDFA任务同时优化用户偏好与机器人成本之间权衡的确定性策略，从而得到帕累托最优解集。实验证明了该方法在各种机器人和任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人能够更有效地在动态且复杂的环境中执行任务，同时确保这些行为符合安全标准并考虑到用户偏好与机器人操作成本之间的平衡。

Method: 通过将任务表示为概率形式语言，并使用改进的基于证据的状态合并算法来学习PDFA，整个过程中考虑了安全性要求。接着，开发了一种多目标反应合成算法，用于寻找满足给定任务规格的同时，在用户偏好与机器人成本间找到最佳平衡点的解决方案集合。

Result: 实验结果表明，所学得的PDFA模型始终避免了不安全的行为模式，并且合成出的策略能够成功完成指定任务，同时很好地兼顾了机器人运行成本和用户的偏好需求。

Conclusion: 提出的方法不仅提高了机器人在动态环境下的自主性和灵活性，而且还保证了所有行动的安全性，同时有效平衡了用户期望与实际操作成本之间的关系。

Abstract: This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.

</details>


### [5] [Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures](https://arxiv.org/abs/2601.05661)
*Matija Markulin,Luka Matijević,Luka Siktar,Janko Jurdana,Branimir Caran,Marko Švaco,Filip Šuligoj,Bojan Šekoranja*

Main category: cs.RO

TL;DR: 本文开发了一个用于前列腺超声检查的机器人系统，旨在减少操作者技巧要求，并提高前列腺活检的速度、准确性和可获得性。通过使用协作机械臂自主扫描前列腺模型，并在不同运动场景下验证了系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌是男性中最常见的癌症类型之一。其诊断依赖于活检，但该过程需要外科医生具备高水平的专业知识和精确度，因此结果高度依赖于操作者。为了解决这一问题，本研究旨在开发一个辅助性的机器人系统来进行前列腺的超声（US）检查，作为活检前的一个步骤，以降低对操作者灵巧度的要求，并使前列腺活检更快捷、更准确且更容易获得。

Method: 研究人员开发并验证了一个实验室设置，包括一个能够自主扫描前列腺模型的协作式机器人手臂，并将模型连接到模拟患者移动的医疗机器人手臂上。扫描机器人保持超声探头与前列腺之间的相对位置不变，确保了一致而稳健的前列腺重建方法。为了重建前列腺，每一切片都会被分割成一系列前列腺轮廓，然后转换成3D点云用于活检规划。

Result: 前列腺平均扫描时间为30秒，平均3D重建时间为3秒。进行了四种运动场景测试：静止状态(S)、水平运动(H)、垂直运动(V)以及两者的组合(C)。系统验证通过将不同运动状态下获取的前列腺点云重建与静止状态下获取的结果进行配准来完成。ICP配准阈值为0.8毫米时，S-H配准平均适应度为83.2%，均方根误差(RMSE)为0.35毫米；S-V配准平均适应度为84.1%，RMSE为0.37毫米；S-C配准平均适应度为79.4%，RMSE同样为0.37毫米。由于前列腺模型具有弹性和柔软材料特性，机器人跟踪的最大误差为3毫米，根据医学文献这足以满足前列腺活检的需求。运动补偿的最大延迟为0.5秒。

Conclusion: 所开发的机器人系统展示了在执行前列腺超声检查时的有效性，尤其是在存在一定程度病人运动的情况下也能保持较高的精度。这意味着该技术有潜力改善前列腺活检过程，使之更加高效可靠。

Abstract: Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\% fitness and 0.35 mm RMSE for S-H registration, 84.1\% fitness and 0.37 mm RMSE for S-V registration and 79.4\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.

</details>


### [6] [InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection](https://arxiv.org/abs/2601.05805)
*Simon Archieri,Ahmet Cinar,Shu Pan,Jonatan Scharff Willners,Michele Grimald,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: 本文提出了一种名为InsSo3D的方法，它利用3D声纳和惯性导航系统实现大规模3D同步定位与建图（SLAM），能够在浑浊的水下环境中高效准确地重建自然或人工水下结构的地图。


<details>
  <summary>Details</summary>
Motivation: 传统的声纳只能生成包含距离和方位信息的2D图像而缺乏高度信息，导致在高程上存在模糊性。为解决这一问题，研究者开发了能够产生3D点云数据的3D声纳，并结合惯性导航系统作为先验信息，旨在创建一个鲁棒且现代化的SLAM框架，以适应3D声纳数据并提高定位与建图精度。

Method: 通过引入一种适合3D声纳数据的SLAM框架，该框架使用INS作为先验信息，检测回环闭合并执行位姿图优化。此外，研究团队还在测试水池内以及户外淹水采石场中对InsSo3D进行了评估，其中包含了地面真实数据对比实验。

Result: 实验结果表明，相较于参考轨迹和从水下运动跟踪系统及视觉SFM获取的地图，InsSo3D能有效地校正里程计漂移。在一个长达50分钟的任务中，平均轨迹误差低于21厘米，生成了一个10米乘20米大小的地图，其平均重建误差仅为9厘米。

Conclusion: InsSo3D方法展示出在复杂水环境条件下进行安全检查的能力，即使是在水质混浊的情况下也能提供高精度的地图重建，使得对于自然或人工水下结构的安全检查成为可能。

Abstract: This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.

</details>


### [7] [Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving](https://arxiv.org/abs/2601.05806)
*Marvin Seegert,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 该论文提出了一种将大型语言模型（LLM）与Autoware开源软件集成的框架，通过自然语言接口实现对自动驾驶系统（ADSs）的高级控制，并通过分类、领域特定语言（DSL）翻译和安全验证层三个核心组件来确保命令的有效执行。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的进步，为创建自动驾驶系统的自然语言接口提供了新的可能性，这项工作旨在解决将人类语言的复杂性映射到模块化ADS软件结构化的动作空间中的挑战。

Method: 研究者们设计了一个包含三部分关键组成的框架：1) 交互类别的分类；2) 针对应用的领域特定语言（DSL），用于指令翻译；3) 保持安全性的验证层。此外，采用两阶段的LLM架构以保证基于确切执行状态提供反馈的高度透明度。

Result: 评估结果表明了系统的时效性和转换鲁棒性。仿真测试成功地在所有五个交互类别中验证了命令执行情况。

Conclusion: 本研究为模块化且注重安全性的自主堆栈内扩展DSL辅助交互奠定了基础。

Abstract: Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.

</details>


### [8] [Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning](https://arxiv.org/abs/2601.05836)
*Sheng-Kai Chen,Jyh-Horng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种综合方法，通过集成模糊逻辑安全系统和强化学习算法来检测并避免UR10机器人手臂路径规划中的奇异点。该混合方法结合了基于可操作性度量、条件数分析及模糊逻辑决策的实时奇异点检测与用于自适应路径规划的稳定强化学习框架。实验结果表明，在保持与奇异配置的安全距离的同时，到达目标位置的成功率为90%。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中由于奇异点导致的控制丢失和潜在设备损坏问题。

Method: 采用结合了实时奇异点检测（利用可操作性度量、条件数分析和模糊逻辑决策）与稳定强化学习框架以实现自适应路径规划的混合方法。

Result: 实验结果显示，该系统在维持与奇异配置安全距离的前提下，成功到达目标位置的概率为90%。

Conclusion: 通过融合模糊逻辑安全系统与强化学习算法，本研究为UR10机器人手臂提供了一种有效避开奇异点的新途径。

Abstract: This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.

</details>
