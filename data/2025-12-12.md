<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks](https://arxiv.org/abs/2512.10116)
*Andrew Razjigaev,Hans Lohr,Alejandro Vargas-Uscategui,Peter King,Tirthankar Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种新的算法，通过任务空间分解方法、阻尼最小二乘法和Halley方法来解决六轴机器人操作中的功能冗余逆运动学问题，以实现快速稳健的解，并减少关节运动。该方法在冷喷涂涂层应用中得到验证，能有效扩大复杂路径的可行工作空间。


<details>
  <summary>Details</summary>
Motivation: 许多制造任务依赖于六轴机械臂的工业自动化，但由于工具轴对称性导致实际操作只需五轴即可完成。利用这种冗余对于提高工作空间和灵活性至关重要，从而优化路径规划。

Method: 提出的新算法结合了任务空间分解、阻尼最小二乘法以及Halley方法，旨在为具有功能性冗余的机械臂提供快速且鲁棒性强的逆运动学解决方案，同时减少关节移动。

Result: 所提算法能够在非平面表面上执行冷喷涂涂层应用时快速找到最小化关节动作的运动计划，有效扩展了复杂工具路径的可操作范围。

Conclusion: 本研究提出的针对功能冗余逆运动学求解的方法，在ABB工业机器人上进行了验证，展示了其在减少关节运动及增加操作空间方面的能力。

Abstract: Industrial automation with six-axis robotic arms is critical for many manufacturing tasks, including welding and additive manufacturing applications; however, many of these operations are functionally redundant due to the symmetrical tool axis, which effectively makes the operation a five-axis task. Exploiting this redundancy is crucial for achieving the desired workspace and dexterity required for the feasibility and optimisation of toolpath planning. Inverse kinematics algorithms can solve this in a fast, reactive framework, but these techniques are underutilised over the more computationally expensive offline planning methods. We propose a novel algorithm to solve functionally redundant inverse kinematics for robotic manipulation utilising a task space decomposition approach, the damped least-squares method and Halley's method to achieve fast and robust solutions with reduced joint motion. We evaluate our methodology in the case of toolpath optimisation in a cold spray coating application on a non-planar surface. The functionally redundant inverse kinematics algorithm can quickly solve motion plans that minimise joint motion, expanding the feasible operating space of the complex toolpath. We validate our approach on an industrial ABB manipulator and cold-spray gun executing the computed toolpath.

</details>


### [2] [Inertial Magnetic SLAM Systems Using Low-Cost Sensors](https://arxiv.org/abs/2512.10128)
*Chuan Huang,Gustaf Hendeby,Isaac Skog*

Main category: cs.RO

TL;DR: 本文提出了一种基于低成本传感器的松散耦合和紧密耦合惯性磁SLAM系统，旨在解决现有方法依赖低漂移里程计数据的问题。实验表明，紧密耦合IM-SLAM系统在多数情况下定位误差更低，具有应用于紧急救援场景如矿井/火灾救援的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于磁场的同时定位与建图（SLAM）系统通常需要依靠视觉里程计或轮式编码器等提供的低漂移里程计数据以减少未映射区域中的定位误差。为了解决这一限制，本研究提出了使用低成本传感器（IMU、磁力计阵列和气压计）的松散耦合及紧密耦合惯性磁SLAM系统，以提高对低可见度条件的鲁棒性，并降低定位误差。

Method: 开发了两种基于非视觉数据的IM-SLAM系统：一种是松散耦合系统，另一种是紧密耦合系统。两者都利用状态空间表示法以及不同尺度下的磁场模型；区别在于松散耦合系统将局部和全局磁场模型分别用于两个状态空间模型中，而紧密耦合系统则将它们集成到一个状态空间模型内。

Result: 实验结果表明，在大多数情况下，紧密耦合IM-SLAM系统的定位误差比松散耦合系统更低，典型误差大约为每行驶100米时误差几米。这证明了使用低成本传感器开发全3D IM-SLAM系统的可行性及其在紧急响应情景如矿山或火灾救援中的应用潜力。

Conclusion: 通过提出松散耦合和紧密耦合两种形式的IM-SLAM系统，本研究表明即使在不依赖昂贵传感器的情况下也能实现高精度定位。特别是紧密耦合系统展示了更优的表现，为未来在复杂环境下的导航技术提供了新的可能性。

Abstract: Spatially inhomogeneous magnetic fields offer a valuable, non-visual information source for positioning. Among systems leveraging this, magnetic field-based simultaneous localization and mapping (SLAM) systems are particularly attractive because they can provide positioning information and build a magnetic field map on the fly. Moreover, they have bounded error within mapped regions. However, state-of-the-art methods typically require low-drift odometry data provided by visual odometry or a wheel encoder, etc. This is because these systems need to minimize/reduce positioning errors while exploring, which happens when they are in unmapped regions. To address these limitations, this work proposes a loosely coupled and a tightly coupled inertial magnetic SLAM (IM-SLAM) system. The proposed systems use commonly available low-cost sensors: an inertial measurement unit (IMU), a magnetometer array, and a barometer. The use of non-visual data provides a significant advantage over visual-based systems, making it robust to low-visibility conditions. Both systems employ state-space representations, and magnetic field models on different scales. The difference lies in how they use a local and global magnetic field model. The loosely coupled system uses these models separately in two state-space models, while the tightly coupled system integrates them into one state-space model. Experiment results show that the tightly coupled IM-SLAM system achieves lower positioning errors than the loosely coupled system in most scenarios, with typical errors on the order of meters per 100 meters traveled. These results demonstrate the feasiblity of developing a full 3D IM-SLAM systems using low-cost sensors and the potential of applying these systems in emergency response scenarios such as mine/fire rescue.

</details>


### [3] [Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine](https://arxiv.org/abs/2512.10235)
*Hui Li,Akhlak Uz Zaman,Fujian Yan,Hongsheng He*

Main category: cs.RO

TL;DR: 本文提出了一种结合情境奖励机的强化学习框架，用于任务导向的抓取。通过将抓取任务分解为更易管理的子任务，并引入转换奖励来引导模型朝向理想的阶段序列，该方法在模拟和真实机器人实验中均表现出较高的成功率和学习效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高任务导向抓取过程中的学习效率与准确性，同时减少状态-动作空间大小并引导探索在明确界定的边界内进行。

Method: 开发了一个基于情境奖励机（Contextual Reward Machine）的强化学习框架，其中每个子任务都与特定阶段的情境相关联，包括奖励函数、动作空间及状态抽象函数。此外，还引入了转换奖励以鼓励或惩罚阶段间的转换，从而指导模型趋向于有利的阶段序列。

Result: 在与近端策略优化算法集成后，所提方法在1,000次包含不同对象、可承受性和抓取拓扑结构的模拟抓取任务中达到了95%的成功率，并且比现有最先进方法在学习速度和成功率上表现更好。当应用于真实机器人时，在覆盖六种可承受性的60次抓取任务中实现了83.3%的成功率。

Conclusion: 实验结果表明，该方法具有较高的准确性、数据利用效率和学习效率，展示了其在推进模拟环境和实际场景下任务导向抓取领域的潜力。

Abstract: This paper presents a reinforcement learning framework that incorporates a Contextual Reward Machine for task-oriented grasping. The Contextual Reward Machine reduces task complexity by decomposing grasping tasks into manageable sub-tasks. Each sub-task is associated with a stage-specific context, including a reward function, an action space, and a state abstraction function. This contextual information enables efficient intra-stage guidance and improves learning efficiency by reducing the state-action space and guiding exploration within clearly defined boundaries. In addition, transition rewards are introduced to encourage or penalize transitions between stages which guides the model toward desirable stage sequences and further accelerates convergence. When integrated with the Proximal Policy Optimization algorithm, the proposed method achieved a 95% success rate across 1,000 simulated grasping tasks encompassing diverse objects, affordances, and grasp topologies. It outperformed the state-of-the-art methods in both learning speed and success rate. The approach was transferred to a real robot, where it achieved a success rate of 83.3% in 60 grasping tasks over six affordances. These experimental results demonstrate superior accuracy, data efficiency, and learning efficiency. They underscore the model's potential to advance task-oriented grasping in both simulated and real-world settings.

</details>


### [4] [Lies We Can Trust: Quantifying Action Uncertainty with Inaccurate Stochastic Dynamics through Conformalized Nonholonomic Lie Groups](https://arxiv.org/abs/2512.10294)
*Luís Marques,Maani Ghaffari,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本文提出了一种基于对称性感知的保形预测算法CLAPS，它能为给定动作生成一个集合，该集合以用户定义的概率包含系统执行动作后的配置。此方法在处理不确定量化时不需要对系统动力学、不确定性来源或近似动力学模型的质量做出强假设，并且通过李群分析扩展了先前的理论保证至SE(2)，实验表明其比现有方法更有效地表示基础不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统的不确定性量化方法通常依赖于对误差分布或大小的强假设，或者依赖于未经校准的不确定性估计，这不足以实现安全控制。而保形预测作为一种统计框架能够提供与分布无关的概率保证，但现有的保形方法将机器人视为欧几里得点，未考虑许多系统具有非欧几里得配置的情况。

Method: 提出了Conformal Lie-group Action Prediction Sets (CLAPS)算法，该算法利用李群来严格分析构型错误，将之前的欧几里得空间理论保证扩展到了SE(2)。CLAPS算法能够在不对真实系统动态、不确定性来源或近似动态模型质量做强烈假设的情况下工作。

Result: 通过模拟JetBot和实际MBot上的实验表明，考虑到配置空间结构后，本研究提出的对称信息非一致性评分导致了体积效率更高的预测区域，这些区域比现有方法更好地代表了潜在的不确定性。

Conclusion: CLAPS算法能够为给定动作产生的结果构造出一个集合，并且这个集合以用户定义的概率包含了系统的新配置。此外，这种方法不仅适用于随机性和知识不确定性，而且不需要关于真实系统动态等条件的强假设，显示出对于安全控制领域的重要价值。

Abstract: We propose Conformal Lie-group Action Prediction Sets (CLAPS), a symmetry-aware conformal prediction-based algorithm that constructs, for a given action, a set guaranteed to contain the resulting system configuration at a user-defined probability. Our assurance holds under both aleatoric and epistemic uncertainty, non-asymptotically, and does not require strong assumptions about the true system dynamics, the uncertainty sources, or the quality of the approximate dynamics model. Typically, uncertainty quantification is tackled by making strong assumptions about the error distribution or magnitude, or by relying on uncalibrated uncertainty estimates - i.e., with no link to frequentist probabilities - which are insufficient for safe control. Recently, conformal prediction has emerged as a statistical framework capable of providing distribution-free probabilistic guarantees on test-time prediction accuracy. While current conformal methods treat robots as Euclidean points, many systems have non-Euclidean configurations, e.g., some mobile robots have SE(2). In this work, we rigorously analyze configuration errors using Lie groups, extending previous Euclidean Space theoretical guarantees to SE(2). Our experiments on a simulated JetBot, and on a real MBot, suggest that by considering the configuration space's structure, our symmetry-informed nonconformity score leads to more volume-efficient prediction regions which represent the underlying uncertainty better than existing approaches.

</details>


### [5] [Design of a six wheel suspension and a three-axis linear actuation mechanism for a laser weeding robot](https://arxiv.org/abs/2512.10319)
*Muhammad Usama,Muhammad Ibrahim Khan,Ahmad Hasan,Muhammad Shaaf Nadeem,Khawaja Fahad Iqbal,Jawad Aslam,Mian Ashfaq Ali,Asad Nisar Awan*

Main category: cs.RO

TL;DR: 本文介绍了一种使用低能量激光束进行除草的自主农业机器人，该机器人具有六轮设计和新型双四连杆悬架系统，以提高稳定性。在实地测试中，机器人能够有效导航并克服高达15厘米的障碍物，在42.5厘米/秒的最佳速度下达到86.2%的杂草检测率，并且每米操作时间为87秒。激光执行机构保持了1.54毫米的最小平均位置误差以及97%的命中率，确保了有效的杂草去除。


<details>
  <summary>Details</summary>
Motivation: 随着移动机器人在农业中的应用日益增多，为了自动化劳动密集型任务如除草、播种、收获和土壤分析等，研究者们开发出了可以利用机械工具或精确喷洒除草剂来检测和移除杂草的农业机器人。然而，传统的机械除草方法对于大面积田地来说效率低下，而化学除草剂对土壤生态系统有害。因此，本研究提出了一种可持续的选择——利用移动机器人配合激光技术进行精准农业中的除草工作。

Method: 研究人员设计了一个六轮自主除草机器人，采用创新的双四连杆悬挂系统以增强稳定性，并通过三维线性致动机制引导激光指向检测到的杂草。

Result: 现场测试表明，这款机器人能够有效穿越农业地形，克服高达15厘米高的障碍物；当以42.5厘米/秒的速度运行时，其杂草识别率达到86.2%，每行进一米需要87秒处理时间。激光定位精度极高，平均位置误差仅为1.54毫米，同时拥有97%的命中率，保证了除草过程既高效又准确。

Conclusion: 结合速度、准确性和效率的特点，这款基于激光技术的自主除草机器人展现了显著改善精准农业实践的巨大潜力。

Abstract: Mobile robots are increasingly utilized in agriculture to automate labor-intensive tasks such as weeding, sowing, harvesting and soil analysis. Recently, agricultural robots have been developed to detect and remove weeds using mechanical tools or precise herbicide sprays. Mechanical weeding is inefficient over large fields, and herbicides harm the soil ecosystem. Laser weeding with mobile robots has emerged as a sustainable alternative in precision farming. In this paper, we present an autonomous weeding robot that uses controlled exposure to a low energy laser beam for weed removal. The proposed robot is six-wheeled with a novel double four-bar suspension for higher stability. The laser is guided towards the detected weeds by a three-dimensional linear actuation mechanism. Field tests have demonstrated the robot's capability to navigate agricultural terrains effectively by overcoming obstacles up to 15 cm in height. At an optimal speed of 42.5 cm/s, the robot achieves a weed detection rate of 86.2\% and operating time of 87 seconds per meter. The laser actuation mechanism maintains a minimal mean positional error of 1.54 mm, combined with a high hit rate of 97\%, ensuring effective and accurate weed removal. This combination of speed, accuracy, and efficiency highlights the robot's potential for significantly enhancing precision farming practices.

</details>


### [6] [Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing](https://arxiv.org/abs/2512.10349)
*Quan Yuan,Zhenting Du,Daqian Cao,Weibang Bai*

Main category: cs.RO

TL;DR: 本文介绍了一种欠驱动肌腱驱动的机器人手指(UTRF)，通过同步肌腱路径设计，使得所有关节以固定角速度比耦合，从而实现单个执行器驱动整个手指。该设计减少了多指手所需的执行器数量，同时保持了结构的刚性和顺应性。实验验证了其在静态负载下的性能，并展示了将其集成到五指机器人手中时的有效物体操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有的欠驱动肌腱驱动机器人手指难以同时实现高负载能力和适应性顺应性，尤其是在紧凑型设计中。本研究旨在通过创新的肌腱路径设计解决这一问题，减少所需执行器的数量，同时不牺牲系统的刚性或顺应性。

Method: 提出了一种具有同步肌腱路径的欠驱动肌腱驱动机器人手指（UTRF），其中所有关节都按照固定的角速度比机械耦合，允许使用单一执行器控制整个手指。建立了考虑肌腱弹性的手指运动学和静态模型来预测结构刚度。

Result: 原型手指在静载荷测试下显示出平均偏转预测误差为1.0毫米（总手指长度的0.322%），并在3公斤尖端负载下测量到刚度为1.2×10^3 N/m。当集成到五指机器人手中时，UTRF-RoboHand展示了跨多种场景的有效物体操纵能力。

Conclusion: 提出的同步肌腱路径设计有效减少了欠驱动肌腱驱动机器人手指所需的执行器数量，同时保持了良好的刚性和顺应性。实验结果表明，所设计的手指及基于此设计的五指机器人手能够在不同情境下提供可靠的抓取表现。

Abstract: Tendon-driven under-actuated robotic fingers provide advantages for dexterous manipulation through reduced actuator requirements and simplified mechanical design. However, achieving both high load capacity and adaptive compliance in a compact form remains challenging. This paper presents an under-actuated tendon-driven robotic finger (UTRF) featuring a synchronous tendon routing that mechanically couples all joints with fixed angular velocity ratios, enabling the entire finger to be actuated by a single actuator. This approach significantly reduces the number of actuators required in multi-finger hands, resulting in a lighter and more compact structure without sacrificing stiffness or compliance. The kinematic and static models of the finger are derived, incorporating tendon elasticity to predict structural stiffness. A single-finger prototype was fabricated and tested under static loading, showing an average deflection prediction error of 1.0 mm (0.322% of total finger length) and a measured stiffness of 1.2x10^3 N/m under a 3 kg tip load. Integration into a five-finger robotic hand (UTRF-RoboHand) demonstrates effective object manipulation across diverse scenarios, confirming that the proposed routing achieves predictable stiffness and reliable grasping performance with a minimal actuator count.

</details>


### [7] [RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI](https://arxiv.org/abs/2512.10394)
*Weifan Guan,Huasen Xi,Chenxiao Zhang,Aosheng Li,Qinghao Hu,Jian Cheng*

Main category: cs.RO

TL;DR: RoboNeuron框架通过整合大型语言模型和视觉-语言-动作模型的认知能力与机器人操作系统(ROS)的实时执行能力，解决了当前实体AI系统中存在的跨场景适应性差、模块间耦合僵硬以及推理加速碎片化等问题。


<details>
  <summary>Details</summary>
Motivation: 目前的实体AI系统面临严重的工程障碍，包括较差的跨场景适应能力、僵硬的模块间耦合及碎片化的推理加速。为了解决这些问题，提出了RoboNeuron框架。

Method: RoboNeuron是首个将大型语言模型（LLMs）和视觉-语言-行动（VLA）模型的认知能力与机器人操作系统（ROS）的实时执行后端深度集成的通用部署框架。它使用模型上下文协议（MCP）作为语义桥梁，使LLM能够动态地编排底层机器人工具。该框架建立了一个高度模块化的架构，通过利用ROS统一的通信接口严格解耦感知、推理和控制。此外，还引入了一种自动化工具，可以将ROS消息转换为可调用的MCP函数，极大地简化了开发过程。

Result: RoboNeuron显著提高了跨场景适应性和组件灵活性，并为水平性能基准测试建立了系统平台，为可扩展的真实世界实体应用奠定了坚实的基础。

Conclusion: RoboNeuron代表了向更灵活、自适应强且易于扩展的实体AI系统迈进的重要一步，其设计有助于克服现有技术中的主要挑战。

Abstract: Current embodied AI systems face severe engineering impediments, primarily characterized by poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration. To overcome these limitations, we propose RoboNeuron, a universal deployment framework for embodied intelligence. RoboNeuron is the first framework to deeply integrate the cognitive capabilities of Large Language Models (LLMs) and Vision-Language-Action (VLA) models with the real-time execution backbone of the Robot Operating System (ROS). We utilize the Model Context Protocol (MCP) as a semantic bridge, enabling the LLM to dynamically orchestrate underlying robotic tools. The framework establishes a highly modular architecture that strictly decouples sensing, reasoning, and control by leveraging ROS's unified communication interfaces. Crucially, we introduce an automated tool to translate ROS messages into callable MCP functions, significantly streamlining development. RoboNeuron significantly enhances cross-scenario adaptability and component flexibility, while establishing a systematic platform for horizontal performance benchmarking, laying a robust foundation for scalable real-world embodied applications.

</details>


### [8] [Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS/UWB/IMU Fusion: A Comparison of EKF, FGO, and PF](https://arxiv.org/abs/2512.10480)
*Jiaqiang Zhang,Xianjia Yu,Sier Ha,Paola Torrico Moron,Sahar Salimpour,Farhad Kerama,Haizhou Zhang,Tomi Westerlund*

Main category: cs.RO

TL;DR: 本文提出了一种统一的GNSS/UWB/IMU融合框架，用于无缝行人定位，并比较了三种概率后端方法：误差状态扩展卡尔曼滤波器、滑动窗口因子图优化和粒子滤波器。系统以基于胸部安装IMU的PDR作为运动基础，并在户外集成GNSS绝对更新，在室内集成UWB。通过引入从OpenStreetMap建筑足迹得出的轻量级地图基可行性约束来提高过渡鲁棒性和缓解城市GNSS退化。该框架在ROS 2中实现，可在可穿戴平台上实时运行。实验结果表明ESKF在我们的实现中提供了最一致的整体性能。


<details>
  <summary>Details</summary>
Motivation: 准确且连续地跨室内外环境进行行人定位仍具有挑战性，因为GNSS、UWB和惯性PDR虽然互补但各自在信号阻塞、多路径效应以及漂移情况下表现脆弱。为了解决这些问题并提供更稳定可靠的定位解决方案。

Method: 采用一种统一的GNSS/UWB/IMU融合架构，其中基于胸部安装的IMU的PDR作为主要移动模型，结合室外环境下的GNSS绝对位置更新与室内环境中的UWB信息。同时，引入了一个基于OpenStreetMap建筑轮廓的轻量级地图为基础的可行性约束条件，以增强过渡稳健性和减少城市环境中GNSS性能下降的影响。

Result: 实现了能够实现实时操作的ROS 2框架，并在可穿戴设备上进行了测试。经过对三种情况（仅室内、仅室外及室内外连续）的评估发现，ESKF在当前实现中提供了最为一致的表现。

Conclusion: 所提出的GNSS/UWB/IMU融合框架有效提高了行人跨室内外环境定位的准确性与稳定性。特别地，当使用误差状态扩展卡尔曼滤波器作为后端处理算法时，该系统表现出最佳的整体性能。

Abstract: Accurate and continuous pedestrian positioning across outdoor-indoor environments remains challenging because GNSS, UWB, and inertial PDR are complementary yet individually fragile under signal blockage, multipath, and drift. This paper presents a unified GNSS/UWB/IMU fusion framework for seamless pedestrian localization and provides a controlled comparison of three probabilistic back-ends: an error-state extended Kalman filter, sliding-window factor graph optimization, and a particle filter. The system uses chest-mounted IMU-based PDR as the motion backbone and integrates absolute updates from GNSS outdoors and UWB indoors. To enhance transition robustness and mitigate urban GNSS degradation, we introduce a lightweight map-based feasibility constraint derived from OpenStreetMap building footprints, treating most building interiors as non-navigable while allowing motion inside a designated UWB-instrumented building. The framework is implemented in ROS 2 and runs in real time on a wearable platform, with visualization in Foxglove. We evaluate three scenarios: indoor (UWB+PDR), outdoor (GNSS+PDR), and seamless outdoor-indoor (GNSS+UWB+PDR). Results show that the ESKF provides the most consistent overall performance in our implementation.

</details>


### [9] [Contact SLAM: An Active Tactile Exploration Policy Based on Physical Reasoning Utilized in Robotic Fine Blind Manipulation Tasks](https://arxiv.org/abs/2512.10481)
*Gaozhao Wang,Xing Liu,Zhenduo Ye,Zhengxiong Liu,Panfeng Huang*

Main category: cs.RO

TL;DR: 本文提出了一种名为"Contact SLAM"的新方法，该方法仅通过触觉感知和场景先验知识来估计环境状态并实现操作。此外还设计了一种主动探索策略以提高探索效率，并在多种接触丰富的任务中验证了其有效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 由于视觉可能被遮挡，机器人无法总是依赖视觉反馈获取实时场景状态信息，导致执行接触密集型操作困难。为了解决这一问题，即所谓的“盲操作”，需要一种新的方法让机器人能够仅依靠触觉和已知的场景信息来进行有效的操作。

Method: 本文介绍了一种名为“Contact SLAM”的物理驱动接触认知方法，它利用触觉传感和场景先验知识来估计环境状态并完成操作任务。同时，为了提高探索效率，文中还提出了一种主动探索策略，旨在逐步减少操作场景中的不确定性。

Result: 实验结果表明，“Contact SLAM”方法在包括插座组装任务和推块任务在内的几种接触密集型任务中表现出了高效性和准确性。

Conclusion: 所提出的“Contact SLAM”方法证明了即使在没有视觉反馈的情况下，也能有效地估计环境状态并完成复杂的操作任务，展示了其在接触丰富场景下应用的巨大潜力。

Abstract: Contact-rich manipulation is difficult for robots to execute and requires accurate perception of the environment. In some scenarios, vision is occluded. The robot can then no longer obtain real-time scene state information through visual feedback. This is called ``blind manipulation". In this manuscript, a novel physically-driven contact cognition method, called ``Contact SLAM", is proposed. It estimates the state of the environment and achieves manipulation using only tactile sensing and prior knowledge of the scene. To maximize exploration efficiency, this manuscript also designs an active exploration policy. The policy gradually reduces uncertainties in the manipulation scene. The experimental results demonstrated the effectiveness and accuracy of the proposed method in several contact-rich tasks, including the difficult and delicate socket assembly task and block-pushing task.

</details>


### [10] [Motion Planning for Safe Landing of a Human-Piloted Parafoil](https://arxiv.org/abs/2512.10595)
*Maximillian Fainkich,Kiril Solovey,Anna Clarke*

Main category: cs.RO

TL;DR: 本研究针对滑翔伞飞行中人为判断失误导致的事故问题，提出了一种基于Stable Sparse RRT算法改进版的轨迹规划方法。该方法通过最小化倾斜角度来保证安全，并与人类飞行员的表现进行了对比，显示了计算机生成的指导方针在训练飞行员以实现更安全和成本效益更高的飞行方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于滑翔伞飞行阶段的人为判断失误导致了许多跳伞事故，且新手飞行员缺乏有效的训练模拟器，因此需要开发一种适合辅助人类训练的滑翔伞轨迹规划方案。

Method: 研究人员调整了Li等人提出的基于采样的运动规划器Stable Sparse RRT (SST)，以适应滑翔伞飞行的问题约束，并将最小化倾斜角度（控制努力）作为安全性的一个指标。然后，他们将计算机生成的解决方案与人类实际飞行数据进行比较。

Result: 实验结果显示，算法生成的飞行路径相对于人类飞行员的成本提高了20%-80%。此外，观察到人类飞行员倾向于先缩短水平距离再螺旋下降至合适的着陆高度，而算法则能平滑地逐渐下降，在保持安全约束的同时于精确的高度到达着陆区域。

Conclusion: 研究表明，相比于传统的经验法则，使用计算机生成的指南可以集成到未来的模拟器中，帮助训练飞行员执行更安全、成本更低的飞行任务。

Abstract: Most skydiving accidents occur during the parafoil-piloting and landing stages and result from human lapses in judgment while piloting the parafoil. Training of novice pilots is protracted due to the lack of functional and easily accessible training simulators. Moreover, work on parafoil trajectory planning suitable for aiding human training remains limited. To bridge this gap, we study the problem of computing safe trajectories for human-piloted parafoil flight and examine how such trajectories fare against human-generated solutions. For the algorithmic part, we adapt the sampling-based motion planner Stable Sparse RRT (SST) by Li et al., to cope with the problem constraints while minimizing the bank angle (control effort) as a proxy for safety. We then compare the computer-generated solutions with data from human-generated parafoil flight, where the algorithm offers a relative cost improvement of 20\%-80\% over the performance of the human pilot. We observe that human pilots tend to, first, close the horizontal distance to the landing area, and then address the vertical gap by spiraling down to the suitable altitude for starting a landing maneuver. The algorithm considered here makes smoother and more gradual descents, arriving at the landing area at the precise altitude necessary for the final approach while maintaining safety constraints. Overall, the study demonstrates the potential of computer-generated guidelines, rather than traditional rules of thumb, which can be integrated into future simulators to train pilots for safer and more cost-effective flights.

</details>


### [11] [LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator](https://arxiv.org/abs/2512.10605)
*Lihuang Chen,Xiangyu Luo,Jun Meng*

Main category: cs.RO

TL;DR: Researchers developed LEO-RobotAgent, a versatile and efficient framework that uses language models to control different types of robots for complex, varied tasks. It features an easy-to-use design for improved human-robot interaction and has been successfully tested on multiple robot platforms.


<details>
  <summary>Details</summary>
Motivation: The motivation behind the LEO-RobotAgent framework is to address the limitations of existing robotic task planning systems, which are often designed for specific single-task scenarios and lack generalizability across different robot types. The aim is to create a more streamlined and adaptable system that can handle unpredictable, complex tasks in various environments, improving bidirectional human-robot communication and making it easier for non-experts to interact with robots.

Method: The LEO-RobotAgent framework employs a simplified structure that allows large language models (LLMs) to think, plan, and act independently. It provides a modular toolkit that can be easily customized and registered by the LLMs according to the task requirements. Additionally, it integrates a mechanism for human-robot collaboration, enabling the LLMs to work alongside humans as partners.

Result: Experiments demonstrated that the LEO-RobotAgent framework can be effectively adapted to a wide range of mainstream robot platforms, including unmanned aerial vehicles (UAVs), robotic arms, and wheeled robots. The framework was able to efficiently carry out a variety of tasks with differing levels of complexity, showcasing its adaptability and efficiency.

Conclusion: The LEO-RobotAgent framework represents a significant advancement in the field of robotics, offering a highly generalized, robust, and efficient solution for controlling diverse types of robots through LLMs. Its ease of use and ability to facilitate better human-robot interaction make it a promising tool for both researchers and end-users. The open-source code further supports its accessibility and potential for future development.

Abstract: We propose LEO-RobotAgent, a general-purpose language-driven intelligent agent framework for robots. Under this framework, LLMs can operate different types of robots to complete unpredictable complex tasks across various scenarios. This framework features strong generalization, robustness, and efficiency. The application-level system built around it can fully enhance bidirectional human-robot intent understanding and lower the threshold for human-robot interaction. Regarding robot task planning, the vast majority of existing studies focus on the application of large models in single-task scenarios and for single robot types. These algorithms often have complex structures and lack generalizability. Thus, the proposed LEO-RobotAgent framework is designed with a streamlined structure as much as possible, enabling large models to independently think, plan, and act within this clear framework. We provide a modular and easily registrable toolset, allowing large models to flexibly call various tools to meet different requirements. Meanwhile, the framework incorporates a human-robot interaction mechanism, enabling the algorithm to collaborate with humans like a partner. Experiments have verified that this framework can be easily adapted to mainstream robot platforms including unmanned aerial vehicles (UAVs), robotic arms, and wheeled robot, and efficiently execute a variety of carefully designed tasks with different complexity levels. Our code is available at https://github.com/LegendLeoChen/LEO-RobotAgent.

</details>


### [12] [Evaluating Gemini Robotics Policies in a Veo World Simulator](https://arxiv.org/abs/2512.10675)
*Gemini Robotics Team,Coline Devin,Yilun Du,Debidatta Dwibedi,Ruiqi Gao,Abhishek Jindal,Thomas Kipf,Sean Kirmani,Fangchen Liu,Anirudha Majumdar,Andrew Marmon,Carolina Parada,Yulia Rubanova,Dhruv Shah,Vikas Sindhwani,Jie Tan,Fei Xia,Ted Xiao,Sherry Yang,Wenhao Yu,Allan Zhou*

Main category: cs.RO

TL;DR: 本报告展示了一种基于前沿视频基础模型(Veo)的生成评估系统，该系统能够支持机器人动作条件和多视图一致性，并集成了生成图像编辑和多视图补全功能，以合成沿多个泛化轴的真实世界场景的逼真变化。通过1600多次真实世界的评估验证了系统的性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索视频模型在机器人技术中的应用潜力，特别是对于政策评估用例的整个范围，包括评估标准性能、分布外(OOD)泛化以及物理和语义安全性的测试。

Method: 引入了一个基于前沿视频基础模型（Veo）构建的生成评估系统，优化了对机器人动作条件的支持和多视图一致性，同时整合了生成图像编辑与多视图完成的技术，以沿着多个泛化轴综合出真实世界场景的变化版本。

Result: 系统能够准确模拟经过编辑后包含新交互对象、新颖视觉背景及新干扰物体的场景，并且保持了视频模型的基础能力，使得可以准确预测不同策略在常规和OOD条件下的相对表现，确定不同的泛化轴对策略性能的影响程度，并进行策略对抗以揭示违反物理或语义安全约束的行为。

Conclusion: 这项研究表明，视频模型不仅限于同分布评估，在机器人领域从名义性能评估到分布外泛化，乃至物理与语义安全性探查等广泛的应用场景中都具有潜在价值。

Abstract: Generative world models hold significant potential for simulating interactions with visuomotor policies in varied environments. Frontier video models can enable generation of realistic observations and environment interactions in a scalable and general manner. However, the use of video models in robotics has been limited primarily to in-distribution evaluations, i.e., scenarios that are similar to ones used to train the policy or fine-tune the base video model. In this report, we demonstrate that video models can be used for the entire spectrum of policy evaluation use cases in robotics: from assessing nominal performance to out-of-distribution (OOD) generalization, and probing physical and semantic safety. We introduce a generative evaluation system built upon a frontier video foundation model (Veo). The system is optimized to support robot action conditioning and multi-view consistency, while integrating generative image-editing and multi-view completion to synthesize realistic variations of real-world scenes along multiple axes of generalization. We demonstrate that the system preserves the base capabilities of the video model to enable accurate simulation of scenes that have been edited to include novel interaction objects, novel visual backgrounds, and novel distractor objects. This fidelity enables accurately predicting the relative performance of different policies in both nominal and OOD conditions, determining the relative impact of different axes of generalization on policy performance, and performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints. We validate these capabilities through 1600+ real-world evaluations of eight Gemini Robotics policy checkpoints and five tasks for a bimanual manipulator.

</details>


### [13] [How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning](https://arxiv.org/abs/2512.10698)
*Jianbo Wang,Galina Sidorenko,Johan Thunberg*

Main category: cs.RO

TL;DR: 本文探讨了如何利用深度强化学习（DRL）结合车对车通信来提高多车辆跟随场景下的安全性，特别是在紧急制动情况下选择能减少整体伤害或避免碰撞的策略。提出了一种将DRL与基于解析表达式选择最优恒定减速的方法相结合的混合方法，以增加可靠性并实现更优的整体表现。


<details>
  <summary>Details</summary>
Motivation: 为了提高联网和自动驾驶汽车(CAVs)的安全性，尤其是在涉及紧急制动的多车辆跟随情景中，通过寻找一种既能有效避免碰撞又能显著减轻不可避免碰撞时损害的方法，同时克服过于保守的控制策略带来的灵活性降低问题。

Method: 采用深度强化学习(DRL)结合车辆间通信技术，并将其与一个基于解析公式选取最佳恒定减速率的方法相融合，开发出一种新型的混合方法。

Result: 该混合方法相比单独使用DRL提高了可靠性，在总体伤害减少及避免碰撞方面表现出了更优异的性能。

Conclusion: 通过结合DRL与现有基于解析解的方法，可以有效地在多车辆跟随情境下改善安全状况，特别是在需要集体考虑三辆车的情况下进行紧急制动决策时。

Abstract: Connected and automated vehicles (CAVs) have the potential to enhance driving safety, for example by enabling safe vehicle following and more efficient traffic scheduling. For such future deployments, safety requirements should be addressed, where the primary such are avoidance of vehicle collisions and substantial mitigating of harm when collisions are unavoidable. However, conservative worst-case-based control strategies come at the price of reduced flexibility and may compromise overall performance. In light of this, we investigate how Deep Reinforcement Learning (DRL) can be leveraged to improve safety in multi-vehicle-following scenarios involving emergency braking. Specifically, we investigate how DRL with vehicle-to-vehicle communication can be used to ethically select an emergency breaking profile in scenarios where overall, or collective, three-vehicle harm reduction or collision avoidance shall be obtained instead of single-vehicle such. As an algorithm, we provide a hybrid approach that combines DRL with a previously published method based on analytical expressions for selecting optimal constant deceleration. By combining DRL with the previous method, the proposed hybrid approach increases the reliability compared to standalone DRL, while achieving superior performance in terms of overall harm reduction and collision avoidance.

</details>


### [14] [On the Stabilization of Rigid Formations on Regular Curves](https://arxiv.org/abs/2512.10700)
*Mohamed Elobaid,Shinkyu Park,Eric Feron*

Main category: cs.RO

TL;DR: 该研究解决了在一般平面曲线上稳定多智能体刚性编队的问题，特别是通过路径扫描后在闭合可微平面上稳定正多边形编队。采用了一种随机多起点的类牛顿算法来寻找感兴趣的点处内切正多边形，并设计了连续反馈律确保收敛到目标编队顶点的同时避免智能体间碰撞。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决如何在各种平面曲线环境下实现并保持一个多智能体组成的刚性几何图形，具体是让这些智能体能够沿着给定的闭合曲线移动，最终形成一个等边多边形阵型。

Method: 采用了随机多起点的类牛顿算法来定位需要形成的正多边形的位置；接着设计了一个连续反馈控制律，用以确保所有智能体可以沿着指定曲线移动直至达到各自的目标位置，同时保证在整个过程中智能体之间不会发生碰撞。

Result: 通过数值模拟验证了所提出方法的有效性，对于不同类型的曲线和不同的刚性编队结构都展示了良好的性能。

Conclusion: 本研究为在复杂环境下的多智能体系统提供了一种有效的方法，使其能够在保持预定几何形状的同时完成对特定路径的探索任务。

Abstract: This work deals with the problem of stabilizing a multi-agent rigid formation on a general class of planar curves. Namely, we seek to stabilize an equilateral polygonal formation on closed planar differentiable curves after a path sweep. The task of finding an inscribed regular polygon centered at the point of interest is solved via a randomized multi-start Newton-Like algorithm for which one is able to ascertain the existence of a minimizer. Then we design a continuous feedback law that guarantees convergence to, and sufficient sweeping of the curve, followed by convergence to the desired formation vertices while ensuring inter-agent avoidance. The proposed approach is validated through numerical simulations for different classes of curves and different rigid formations. Code: https://github.com/mebbaid/paper-elobaid-ifacwc-2026

</details>


### [15] [Iterative Compositional Data Generation for Robot Control](https://arxiv.org/abs/2512.10891)
*Anh-Quan Pham,Marcel Hussing,Shubhankar P. Patankar,Dani S. Bassett,Jorge Mendez-Mendez,Eric Eaton*

Main category: cs.RO

TL;DR: 提出了一种语义组合扩散变换器，可以将转换分解为机器人、物体、障碍物和目标特定的组件，并通过注意力机制学习它们之间的交互。该模型在有限的任务子集上训练后，能够零样本生成高质量的转换，从而学习未见过的任务组合的控制策略。


<details>
  <summary>Details</summary>
Motivation: 由于收集机器人操作数据的成本很高，因此无法为多对象、多机器人和多环境设置中出现的大量任务获取演示。虽然最近的生成模型可以为单个任务合成有用的数据，但它们没有利用机器人领域的组合结构，难以泛化到未见过的任务组合。

Method: 提出了一种语义组合扩散变换器，它将转换分解成与机器人、物体、障碍物以及目标相关的部分，并通过注意力机制来学习这些组成部分间的相互作用。接着，介绍了一个迭代自我改进过程，在这个过程中，通过离线强化学习验证合成数据，并将其纳入后续训练轮次。

Result: 相比整体式和硬编码的组合基线方法，所提出的方法显著提高了零样本性能，几乎解决了所有保留的任务，并展示了学习表征中出现了有意义的组合结构。

Conclusion: 本研究提出的语义组合扩散变换器不仅能够在有限的任务子集上进行训练，还能对未见过的任务组合产生高质量的结果。此外，通过一种迭代自我改进的过程，进一步提升了模型性能，表明了这种方法在处理复杂机器人任务时的巨大潜力。

Abstract: Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.

</details>


### [16] [Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit](https://arxiv.org/abs/2512.10934)
*Zamirddine Mari,Jérôme Pasquet,Julien Seinturier*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的方法，使无人机能够在未知的三维管道中导航。通过结合LiDAR和管道中心的视觉检测，该方法不需要任何几何信息预知，并且在高逼真度3D环境中的实验表明其性能优于依赖于明确几何模型的传统算法。


<details>
  <summary>Details</summary>
Motivation: 由于管道受限的几何形状、墙壁的接近以及感知限制，在狭窄管状环境中实现自主无人机导航仍是一个重大挑战。为了克服这些困难，特别是对于那些没有事先了解其几何结构的情况，提出了一个仅依赖局部观察（如LiDAR）和条件性视觉识别管道中心的方法。

Method: 采用一种基于强化学习的方法来训练无人机，使其能够根据本地传感器数据（包括LiDAR及对管道中心点的视觉检测）自主导航未知三维管道。训练过程中实施了渐进式课程学习策略，逐步增加曲率复杂度，同时开发了一种基于直接可见性、方向记忆与LiDAR对称线索相结合的转弯协商机制以处理部分可观测情况下的稳定导航问题。

Result: 实验结果显示，PPO策略学会了稳健且可泛化的飞行行为，即使在有限获取几何信息的情况下也始终优于确定性控制器的表现。此外，在高保真3D环境下验证了所学行为向连续物理动力学迁移的能力。

Conclusion: 提出的方法为未知管状环境中的自主导航提供了一个完整的框架，并为工业、地下或医疗应用中穿越狭窄且感知能力较弱的通道开辟了前景。

Abstract: Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics.
  The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.

</details>


### [17] [ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning](https://arxiv.org/abs/2512.10946)
*Wendi Chen,Han Xue,Yi Wang,Fangyuan Zhou,Jun Lv,Yang Jin,Shirun Tang,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: 本文提出了一种名为ImplicitRDP的视觉-力扩散策略，通过结构化慢速-快速学习机制和基于虚拟目标的表示正则化技术，有效整合了视觉规划与反应式力控制，从而在接触丰富的任务中显著优于仅依赖视觉或分层基线方法。


<details>
  <summary>Details</summary>
Motivation: 人类级别的接触丰富操作依赖于视觉和力感测两种关键模态，但它们之间存在频率和信息上的根本差异，使得信号整合变得困难。为了解决这一问题，并充分利用这两种模态的优点，研究者开发了新的方法。

Method: 提出了一个统一端到端的视觉-力扩散策略框架ImplicitRDP，该框架利用结构化慢速-快速学习机制来处理异步视觉与力令牌，同时引入基于虚拟目标的表示正则化以防止模态崩溃，加强物理基础的学习信号。

Result: 实验结果表明，在接触丰富的任务上，ImplicitRDP相比纯视觉或分层基线方法展现了更好的反应性和成功率，且训练流程更加简化。

Conclusion: 本研究表明，通过巧妙地结合视觉与触觉信息，可以有效地提高机器人在接触密集型操作中的性能。提出的ImplicitRDP不仅克服了传统方法中存在的挑战，还展示了其在实际应用中的巨大潜力。

Abstract: Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.

</details>
