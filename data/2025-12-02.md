<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 37]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [RSPECT: Robust and Scalable Planner for Energy-Aware Coordination of UAV-UGV Teams in Aerial Monitoring](https://arxiv.org/abs/2511.21957)
*Cahit Ikbal Er,Amin Kashiri,Yasin Yazicioglu*

Main category: cs.RO

TL;DR: 该论文研究了在不确定性条件下（如未知障碍物/地形、风等），如何规划能量受限的无人机(UAV)和作为移动充电站的无人地面车辆(UGV)的轨迹，以最小化时间完成长距离空中监控任务。提出了一个名为RSPECT的有效且可扩展的启发式算法，并通过仿真和实验展示了其性能。


<details>
  <summary>Details</summary>
Motivation: 为了使能量受限的无人机能够执行长时间的空中监测任务，同时减少面对不确定性因素时计划需要大幅度调整的情况，提高任务完成效率。

Method: 将问题形式化为一个混合整数规划(MIP)问题，但由于该问题是NP难的，使用精确解法计算上不可行，因此提出了一种名为RSPECT的高效可扩展启发式算法来解决这个问题。

Result: 理论分析证明了所提算法的复杂度以及生成计划的可行性和鲁棒性；通过仿真和实际实验验证了方法的有效性。

Conclusion: 提出的RSPECT算法能够在不确定环境下有效地为无人机-无人车团队规划出鲁棒性强的任务路径，有助于提升长周期空中监测任务的执行效率。

Abstract: We consider the robust planning of energy-constrained unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs), which act as mobile charging stations, to perform long-horizon aerial monitoring missions. More specifically, given a set of points to be visited by the UAVs and desired final positions of the UAV-UGV teams, the objective is to find a robust plan (the vehicle trajectories) that can be realized without a major revision in the face of uncertainty (e.g., unknown obstacles/terrain, wind) to complete this mission in minimum time. We provide a formal description of this problem as a mixed-integer program (MIP), which is NP-hard. Since exact solution methods are computationally intractable for such problems, we propose RSPECT, a scalable and efficient heuristic. We provide theoretical results on the complexity of our algorithm and the feasibility and robustness of resulting plans. We also demonstrate the performance of our method via simulations and experiments.

</details>


### [2] [Constant-Volume Deformation Manufacturing for Material-Efficient Shaping](https://arxiv.org/abs/2511.22042)
*Lei Li,Jiale Gong,Ziyang Li,Hong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种体积保持的数字模具范式，通过实时体积一致性建模、基于几何的变形预测及误差补偿策略，实现对塑料材料的高度可预测性塑形。实验表明，该方法能够高保真地再现目标形状，并达到超过98%的材料利用率，为下一代可持续和可定制制造提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 增材和减材制造技术虽然能够制造复杂的几何形状，但依赖于分层堆叠或局部去除的方式，限制了连续可控的变形，并导致体积损失和形状偏差。为了克服这些局限，本研究旨在开发一种能保持体积一致性的新方法，以实现更加高效且环保的成型工艺。

Method: 研究者们提出了一种结合实时体积一致性建模、基于几何形状的变形预测以及错误补偿策略的体积保持型数字模具模式。通过对成形后点云数据中变形模式与误差趋势的分析，这种方法能够纠正弹性回弹和累积误差，确保体积的一致性和表面连续性。

Result: 在五个代表性几何形状上的实验显示，所提出的系统能够以高度保真的方式再现目标形状，并且实现了超过98%的材料使用率。这表明新方法不仅提高了成品的质量，还极大地减少了材料浪费。

Conclusion: 本研究所介绍的方法建立了一个数字化驱动的、可重复生产的路径，用于用户定义设计的零浪费成型，连接了数字建模、实时感知与自适应成型领域，推动了下一代可持续且可定制化制造的发展。

Abstract: Additive and subtractive manufacturing enable complex geometries but rely on discrete stacking or local removal, limiting continuous and controllable deformation and causing volume loss and shape deviations. We present a volumepreserving digital-mold paradigm that integrates real-time volume-consistency modeling with geometry-informed deformation prediction and an error-compensation strategy to achieve highly predictable shaping of plastic materials. By analyzing deformation patterns and error trends from post-formed point clouds, our method corrects elastic rebound and accumulation errors, maintaining volume consistency and surface continuity. Experiments on five representative geometries demonstrate that the system reproduces target shapes with high fidelity while achieving over 98% material utilization. This approach establishes a digitally driven, reproducible pathway for sustainable, zero-waste shaping of user-defined designs, bridging digital modeling, real-time sensing, and adaptive forming, and advancing next-generation sustainable and customizable manufacturing.

</details>


### [3] [SwordRiding: A Unified Navigation Framework for Quadrotors in Unknown Complex Environments via Online Guiding Vector Fields](https://arxiv.org/abs/2511.22043)
*Xuchen Liu,Ruocheng Li,Bin Xin,Weijia Yao,Qigeng Duan,Jinqiang Cui,Ben M. Chen,Jie Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于在线构建引导向量场（GVF）的四旋翼无人机实时导航框架，该框架能够适应未知复杂环境，并通过闭环导航模式显著增强了对外部干扰的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管四旋翼无人机在轨迹规划和控制方面取得了很高的性能，但在未知复杂环境中实现实时适应性仍然是一个核心挑战。现有大多数规划框架以开环方式运行，难以应对如风扰或外部扰动等环境不确定性。

Method: 本研究提出的框架基于从离散参考路径点在线构建引导向量场（GVFs）。首先利用机载感知模块建立环境的欧几里得符号距离场（ESDF）表示，以实现障碍物意识和路径距离评估；接着使用全局规划器生成无碰撞路径点，并通过均匀B样条参数化这些点来创建平滑且物理上可行的参考轨迹；最后综合ESDF与优化后的B样条轨迹合成自适应GVF。

Result: 广泛的模拟和实际实验表明，所提出的方法相比传统方法具有更好的抗外部干扰鲁棒性和更优的实时性能。

Conclusion: 这项工作展示了一种新的四旋翼无人机导航方案，它不仅能够直接处理离散化的路径，而且保持了与标准规划算法的兼容性，从而为无人机在复杂动态环境下提供了更为稳健可靠的导航解决方案。

Abstract: Although quadrotor navigation has achieved high performance in trajectory planning and control, real-time adaptability in unknown complex environments remains a core challenge. This difficulty mainly arises because most existing planning frameworks operate in an open-loop manner, making it hard to cope with environmental uncertainties such as wind disturbances or external perturbations. This paper presents a unified real-time navigation framework for quadrotors in unknown complex environments, based on the online construction of guiding vector fields (GVFs) from discrete reference path points. In the framework, onboard perception modules build a Euclidean Signed Distance Field (ESDF) representation of the environment, which enables obstacle awareness and path distance evaluation. The system first generates discrete, collision-free path points using a global planner, and then parameterizes them via uniform B-splines to produce a smooth and physically feasible reference trajectory. An adaptive GVF is then synthesized from the ESDF and the optimized B-spline trajectory. Unlike conventional approaches, the method adopts a closed-loop navigation paradigm, which significantly enhances robustness under external disturbances. Compared with conventional GVF methods, the proposed approach directly accommodates discretized paths and maintains compatibility with standard planning algorithms. Extensive simulations and real-world experiments demonstrate improved robustness against external disturbances and superior real-time performance.

</details>


### [4] [Design of an Adaptive Modular Anthropomorphic Dexterous Hand for Human-like Manipulation](https://arxiv.org/abs/2511.22100)
*Zelong Zhou,Wenrui Chen,Zeyun Hu,Qiang Diao,Qixin Gao,Yaonan Wang*

Main category: cs.RO

TL;DR: 本文提出了一种具有4个自由度、由2个执行器驱动的人形手指拓扑结构，开发了一种适应性强的模块化灵巧手，并通过初步实验验证了所提设计的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管生物协同作用已成为灵巧手设计中广泛采用的一种范式，但过度耦合往往会降低手的灵巧性。本研究旨在解决执行器复杂性和灵巧性之间的权衡问题。

Method: 研究者们探索了手部协同作用的生物学基础和人类手势分析，将关节层面的协调与结构特性转化为模块化的手指架构。基于这些仿生映射，设计了一个五指模块化手，并建立了其运动学模型来分析自适应抓取和手内操作。

Result: 最后，研究人员构建了一个物理原型并进行了初步实验，验证了所提出的灵巧手设计及其分析方法的有效性。

Conclusion: 通过提出一种新的手指拓扑结构和开发适应性强的模块化灵巧手，这项工作为使用较少执行器实现类似人类的操作提供了有效途径。

Abstract: Biological synergies have emerged as a widely adopted paradigm for dexterous hand design, enabling human-like manipulation with a small number of actuators. Nonetheless, excessive coupling tends to diminish the dexterity of hands. This paper tackles the trade-off between actuation complexity and dexterity by proposing an anthropomorphic finger topology with 4 DoFs driven by 2 actuators, and by developing an adaptive, modular dexterous hand based on this finger topology. We explore the biological basis of hand synergies and human gesture analysis, translating joint-level coordination and structural attributes into a modular finger architecture. Leveraging these biomimetic mappings, we design a five-finger modular hand and establish its kinematic model to analyze adaptive grasping and in-hand manipulation. Finally, we construct a physical prototype and conduct preliminary experiments, which validate the effectiveness of the proposed design and analysis.

</details>


### [5] [Bayesian Decentralized Decision-making for Multi-Robot Systems: Sample-efficient Estimation of Event Rates](https://arxiv.org/abs/2511.22225)
*Gabriel Aguirre,Simay Atasoy Bingöl,Heiko Hamann,Jonas Kuckling*

Main category: cs.RO

TL;DR: 提出了一种去中心化的贝叶斯框架，使一群简单的机器人能够在危险环境中有效地识别更安全的区域。该方法通过减少对危险事件的暴露，提高了采样效率，并在安全性和收敛速度方面优于基线启发式方法。


<details>
  <summary>Details</summary>
Motivation: 在群体机器人中实现有效的集体决策，特别是在危险环境中平衡探索、通信和个体不确定性估计的需求。

Method: 采用去中心化的贝叶斯框架，其中机器人使用共轭先验逐步预测事件之间的时间，并据此调整行为以适应环境。这种方法旨在让机器人能够识别出具有较低危险事件发生率的区域。

Result: 仿真结果表明，所提出的机器人集群能够一致地选择正确的区域，同时减少了对危险事件的暴露，并且在安全性和收敛速度方面优于基准策略。

Conclusion: 该研究为群体决策提供了新的基准场景，并展示了其方法在适应性风险感知采样和探索中的应用潜力，特别是在危险和动态环境中。

Abstract: Effective collective decision-making in swarm robotics often requires balancing exploration, communication and individual uncertainty estimation, especially in hazardous environments where direct measurements are limited or costly. We propose a decentralized Bayesian framework that enables a swarm of simple robots to identify the safer of two areas, each characterized by an unknown rate of hazardous events governed by a Poisson process. Robots employ a conjugate prior to gradually predict the times between events and derive confidence estimates to adapt their behavior. Our simulation results show that the robot swarm consistently chooses the correct area while reducing exposure to hazardous events by being sample-efficient. Compared to baseline heuristics, our proposed approach shows better performance in terms of safety and speed of convergence. The proposed scenario has potential to extend the current set of benchmarks in collective decision-making and our method has applications in adaptive risk-aware sampling and exploration in hazardous, dynamic environments.

</details>


### [6] [MLATC: Fast Hierarchical Topological Mapping from 3D LiDAR Point Clouds Based on Adaptive Resonance Theory](https://arxiv.org/abs/2511.22238)
*Ryosuke Ofuchi,Yuichiro Toda,Naoki Masuyama,Takayuki Matsuno*

Main category: cs.RO

TL;DR: 提出了一种名为多层ATC(MLATC)的分层扩展方法，以解决ATC-DT在构建全局拓扑地图时存在的可扩展性限制问题。MLATC通过从粗到细的分辨率层次结构来减少每次查询的距离评估数量，从而加速了大型环境中的实时全局拓扑地图构建过程。


<details>
  <summary>Details</summary>
Motivation: 在使用3D LiDAR点云为自主移动机器人构建全局拓扑地图时，现有的ATC-DT方法面临着由于其赢家选择机制依赖于对所有现有节点进行详尽的最近邻搜索而导致的可扩展性问题。随着地图的增长，这种方法变得效率低下。为了克服这一挑战，提出了新的解决方案。

Method: 提出的方法是多层ATC（MLATC），它将节点组织成一个层次结构，允许最近邻搜索从粗略到精细地进行，从而大幅减少了每个查询所需的距离评估次数。此外，MLATC采用自适应层级增加机制，在较低层级饱和时自动加深层级结构，保持用户定义的超参数数量较少。

Result: 仿真实验表明，与原始ATC-DT相比，MLATC能够加速拓扑图构建，并且搜索时间相对于节点数量呈亚线性近似对数增长。实际校园规模的LiDAR数据集上的测试也证实了MLATC能够在毫秒级每帧运行时间内实现实时全局拓扑图构建，显著提高了计算效率。

Conclusion: 研究结果证明了MLATC在处理大规模、动态和未知环境中3D LiDAR点云以构建全局拓扑地图方面具有优越性，特别是在提高计算效率方面表现突出。

Abstract: This paper addresses the problem of building global topological maps from 3D LiDAR point clouds for autonomous mobile robots operating in large-scale, dynamic, and unknown environments. Adaptive Resonance Theory-based Topological Clustering with Different Topologies (ATC-DT) builds global topological maps represented as graphs while mitigating catastrophic forgetting during sequential processing. However, its winner selection mechanism relies on an exhaustive nearest-neighbor search over all existing nodes, leading to scalability limitations as the map grows. To address this challenge, we propose a hierarchical extension called Multi-Layer ATC (MLATC). MLATC organizes nodes into a hierarchy, enabling the nearest-neighbor search to proceed from coarse to fine resolutions, thereby drastically reducing the number of distance evaluations per query. The number of layers is not fixed in advance. MLATC employs an adaptive layer addition mechanism that automatically deepens the hierarchy when lower layers become saturated, keeping the number of user-defined hyperparameters low. Simulation experiments on synthetic large-scale environments show that MLATC accelerates topological map building compared to the original ATC-DT and exhibits a sublinear, approximately logarithmic scaling of search time with respect to the number of nodes. Experiments on campus-scale real-world LiDAR datasets confirm that MLATC maintains a millisecond-level per-frame runtime and enables real-time global topological map building in large-scale environments, significantly outperforming the original ATC-DT in terms of computational efficiency.

</details>


### [7] [Soft Fluidic Sheet Transistor for Soft Robotic System Enabling Fluid Logic Operations](https://arxiv.org/abs/2511.22318)
*Yuki Origane,Koya Cho,Hideyuki Tsukagoshi*

Main category: cs.RO

TL;DR: 本研究提出了一种软性聚氨酯片状阀门，该阀门结合了放大器功能，能够仅使用气动信号执行逻辑操作。这种阀门被命名为流体片晶体管（FST），可以单独或组合实现多种逻辑操作如非、与非及或非等，并且展示了一个利用FST构建的锁存电路原型，证明了通过单个管道的空气压力即可实现机器人姿态主动变化的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在软体机器人系统中同时实现高功能性和灵活性，研究人员开发出一种新型软性阀门，它能够在不依赖电子元件的情况下进行逻辑运算。

Method: 设计并制造了一种当控制腔室加压时会沿中心轴压缩从而导致主路径堵塞的软性聚氨酯片状阀门。这种阀门模仿了电子电路中的晶体管行为，多个这样的阀门（FST）结合起来可以执行更复杂的逻辑操作。

Result: 成功展示了如何通过整合多个FST来执行包括正逻辑、NAND和NOR在内的不同逻辑操作，并且构建了一个包含触觉管作为流体检测器和流体致动器的流体机器人系统的原型，证实了仅依靠单一管道提供的空气压力就能使机器人在遇到障碍物时主动改变姿势的可能性。

Conclusion: 提出的流体片晶体管（FST）为软体机器人提供了一种新颖的方法来执行逻辑操作而无需传统的电子组件，这为创建更加灵活和功能强大的软体机器人系统开辟了新的道路。

Abstract: Aiming to achieve both high functionality and flexibility in soft robot system, this paper presents a soft urethane sheet-like valve with an amplifier that can perform logical operations using only pneumatic signals. When the control chamber in the valve is pressurized, the main path is compressed along its central axis, buckling and being pressed,resulting in blockage. This allows control by a pressure signal smaller than that within the main channel. Furthermore, similar to transistors in electrical circuits, when combined, the proposed valve can perform a variety of logical operations. The basic type operates as a NOT logic element, which is named the fluidic sheet transistor (FST). By integrating multiple FSTs, logical operations such as positive logic, NAND, and NOR can be performed on a single sheet. This paper describes the operating principle, fabrication method, and characteristics of the FST,followed by a method for configuring logical operations.Moreover, we demonstrate the construction of a latch circuit(self-holding logic circuit) using FST, introducing a prototype of a fluid robot system that combines a tactile tube as a fluidic detector and fluid actuators. This demonstrates that it is possible to generate behavior that actively changes posture when hitting an obstacle using only air pressure from a single pipe, which verifies the effectiveness of the proposed methods.

</details>


### [8] [Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning](https://arxiv.org/abs/2511.22338)
*Denghan Xiong,Yanzhe Zhao,Yutong Chen,Zichun Wang*

Main category: cs.RO

TL;DR: 该论文研究了Ackermann车辆在非完整约束下的狭窄死胡同中的逃脱问题，提出了生成器、训练环境和策略学习三部分解决方案。实验结果表明，所学策略比经典规划器能解决更多实例，并减少了操作次数，同时保持了相当的路径长度和规划时间。


<details>
  <summary>Details</summary>
Motivation: 对于类似汽车的机器人来说，非完整约束限制了可行速度而没有减少配置空间维度，这使得无碰撞几何路径通常不可行。Ackermann转向进一步施加曲率限制并禁止原地旋转，因此从狭窄死胡同中逃脱通常需要紧密排列的前进和后退操作。传统规划器在这种情况下表现不佳，因为狭窄通道占据了低度量区域，而非完整可达性缩小了有效连接集合，从而降低了采样效率并增加了对间隙的敏感性。

Method: 1. 构造一个能够采样与Ackermann运动学兼容的多阶段前进-后退轨迹的生成器，并放大它们的包络以合成保证至少存在一种可行逃脱方式的狭窄死胡同家族。
2. 构建了一个执行运动学约束的训练环境，并使用软行动者-评论家算法训练策略。
3. 评估对比了结合全局搜索与非完整转向的经典规划器的表现。

Result: 相对于参数化的死胡同家族，学到的策略解决了更大比例的问题实例，减少了机动数量，并且在相同的感知和控制限制下维持了可比较的路径长度和规划时间。

Conclusion: 本文提出的方法为Ackermann型车辆在具有挑战性的狭窄死胡同环境中提供了有效的逃避策略。通过生成特定条件下的可行驶路径、训练智能体以及与现有方法进行比较，证明了新方法的有效性和优越性。

Abstract: Nonholonomic constraints restrict feasible velocities without reducing configuration-space dimension, which makes collision-free geometric paths generally non-executable for car-like robots. Ackermann steering further imposes curvature bounds and forbids in-place rotation, so escaping from narrow dead ends typically requires tightly sequenced forward and reverse maneuvers. Classical planners that decouple global search and local steering struggle in these settings because narrow passages occupy low-measure regions and nonholonomic reachability shrinks the set of valid connections, which degrades sampling efficiency and increases sensitivity to clearances. We study nonholonomic narrow dead-end escape for Ackermann vehicles and contribute three components. First, we construct a generator that samples multi-phase forward-reverse trajectories compatible with Ackermann kinematics and inflates their envelopes to synthesize families of narrow dead ends that are guaranteed to admit at least one feasible escape. Second, we construct a training environment that enforces kinematic constraints and train a policy using the soft actor-critic algorithm. Third, we evaluate against representative classical planners that combine global search with nonholonomic steering. Across parameterized dead-end families, the learned policy solves a larger fraction of instances, reduces maneuver count, and maintains comparable path length and planning time while under the same sensing and control limits. We provide our project as open source at https://github.com/gitagitty/cisDRL-RobotNav.git

</details>


### [9] [LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning](https://arxiv.org/abs/2511.22354)
*Suraj Borate,Bhavish Rai B,Vipul Pardeshi,Madhu Vadali*

Main category: cs.RO

TL;DR: 本文介绍了一种名为CoMuRoS的协作多机器人系统，该系统结合了集中式决策和分布式执行，并支持事件驱动的重新规划。通过任务管理LLM解释自然语言目标、分类任务并分配子任务，每个机器人运行本地LLM以从基本技能生成可执行Python代码，同时持续监控并区分与任务相关或不相关的事件。硬件和模拟研究表明，CoMuRoS能够实现对干扰事件的自主恢复、过滤无关干扰以及紧密协调的运输，展现出强大的人机协作能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决异构机器人团队在面对复杂环境时需要高效协作的问题，本文提出了CoMuRoS系统，旨在通过结合集中式决策与分布式执行的优势，增强机器人团队处理突发事件的能力及灵活性。

Method: 采用层级架构设计，利用大型语言模型（LLM）进行任务管理和子任务分配；每台机器人配备本地LLM负责将基础技能转化为具体操作指令；视觉语言模型（VLMs）/图像处理技术用于实时监测周围环境变化，并根据任务需求判断这些变化的重要性；当遇到任务失败或用户意图变更等情况时，系统会自动触发重新规划流程。

Result: 实验结果表明，在物理机器人上的测试中，CoMuRoS能够成功地从破坏性事件中恢复过来，有效过滤掉与当前任务无关的信息干扰，并且在多人-机器人协作场景下表现出了高度协调一致的行为模式。此外，仿真研究也验证了该系统具备基于意图识别的重新规划能力。

Conclusion: CoMuRoS提供了一个通用框架，适用于不同类型机器人组成的团队，能够在实际操作过程中灵活应对各种突发状况，显著提升了多机器人系统及人机交互中的协同工作效率。

Abstract: This paper introduces CoMuRoS (Collaborative Multi-Robot System), a generalizable hierarchical architecture for heterogeneous robot teams that unifies centralized deliberation with decentralized execution, and supports event-driven replanning. A Task Manager LLM interprets natural-language goals, classifies tasks, and allocates subtasks using static rules plus dynamic contexts (task, history, robot and task status, and events).Each robot runs a local LLM that composes executable Python code from primitive skills (ROS2 nodes, policies), while onboard perception (VLMs/image processing) continuously monitors events and classifies them into relevant or irrelevant to the task. Task failures or user intent changes trigger replanning, allowing robots to assist teammates, resume tasks, or request human help. Hardware studies demonstrate autonomous recovery from disruptive events, filtering of irrelevant distractions, and tightly coordinated transport with emergent human-robot cooperation (e.g., multirobot collaborative object recovery success rate: 9/10, coordinated transport: 8/8, human-assisted recovery: 5/5).Simulation studies show intention-aware replanning. A curated textual benchmark spanning 22 scenarios (3 tasks each, around 20 robots) evaluates task allocation, classification, IoU, executability, and correctness, with high average scores (e.g., correctness up to 0.91) across multiple LLMs, a separate replanning set (5 scenarios) achieves 1.0 correctness. Compared with prior LLM-based systems, CoMuRoS uniquely demonstrates runtime, event-driven replanning on physical robots, delivering robust, flexible multi-robot and human-robot collaboration.

</details>


### [10] [BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands](https://arxiv.org/abs/2511.22364)
*Seongwon Cho,Daechul Ahn,Donghyun Shin,Hyeonbeom Choi,San Kim,Jonghyun Choi*

Main category: cs.RO

TL;DR: 本文提出了一种名为BINDER的双过程框架，该框架通过将策略规划与连续环境监控解耦来解决开放词汇移动操作(OVMM)中的问题。BINDER结合了用于任务规划的深思熟虑响应模块(DRM)和用于持续监控的即时响应模块(IRM)，二者协同工作以提高动态条件下的适应性和效率。在真实世界环境测试中，BINDER相比现有方法表现出更高的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇移动操作（OVMM）方法仅在特定点更新其世界表示，导致机器人在这些更新之间处于'盲区'状态，从而引发一系列问题如遗漏物体、错误检测迟缓及重新规划滞后等。为了解决这些问题，提出了新的解决方案。

Method: 提出的方法是BINDER，一个双过程框架，它将策略性规划与连续环境监测分开。此框架包含两个模块：深思熟虑响应模块（DRM），利用多模态大型语言模型进行任务规划；以及即时响应模块（IRM），使用VideoLLM进行连续监控。这两个模块相互补充，共同作用于保持意识的同时避免昂贵的更新成本。

Result: 通过在三个具有动态物体布置的真实环境中评估，BINDER比最先进基线方法实现了显著更高的成功率和效率。

Conclusion: BINDER通过双向协调机制解决了维持意识与避免高成本更新之间的权衡问题，在动态条件下展现了强大的适应能力，并证明了其实用价值。

Abstract: Open-vocabulary mobile manipulation (OVMM) requires robots to follow language instructions, navigate, and manipulate while updating their world representation under dynamic environmental changes. However, most prior approaches update their world representation only at discrete update points such as navigation targets, waypoints, or the end of an action step, leaving robots blind between updates and causing cascading failures: overlooked objects, late error detection, and delayed replanning. To address this limitation, we propose BINDER (Bridging INstant and DEliberative Reasoning), a dual process framework that decouples strategic planning from continuous environment monitoring. Specifically, BINDER integrates a Deliberative Response Module (DRM, a multimodal LLM for task planning) with an Instant Response Module (IRM, a VideoLLM for continuous monitoring). The two modules play complementary roles: the DRM performs strategic planning with structured 3D scene updates and guides what the IRM attends to, while the IRM analyzes video streams to update memory, correct ongoing actions, and trigger replanning when necessary. Through this bidirectional coordination, the modules address the trade off between maintaining awareness and avoiding costly updates, enabling robust adaptation under dynamic conditions. Evaluated in three real world environments with dynamic object placement, BINDER achieves substantially higher success and efficiency than SoTA baselines, demonstrating its effectiveness for real world deployment.

</details>


### [11] [Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion](https://arxiv.org/abs/2511.22445)
*Yikai Tang,Haoran Geng,Sheng Zang,Pieter Abbeel,Jitendra Malik*

Main category: cs.RO

TL;DR: 提出了一种名为VGDP的多模态模仿学习框架，通过互补感知融合模块强制RGB和点云线索的平衡使用，以提高在视觉和空间扰动下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉和空间随机化下难以泛化，容易过拟合。为解决这一问题，提出了VGDP以增强策略的一般性和鲁棒性。

Method: 开发了Visual Geometry Diffusion Policy (VGDP)，它基于一个互补意识融合模块，该模块利用模态级dropout来强制RGB图像与点云数据之间的均衡使用，并将交叉注意力机制作为轻量级交互层。

Result: 实验结果表明，在18个模拟任务和4个现实世界任务中，VGDP相较于七个基线策略平均表现提升了39.1%；尤其在不同的视觉条件下平均提升了41.5%，不同空间设置下平均提升了15.2%。

Conclusion: VGDP证明了其在多种视觉和空间扰动情况下的强大鲁棒性，优于多个基准策略，为视觉运动技能的学习提供了一个新的有效解决方案。

Abstract: Imitation learning has emerged as a crucial ap proach for acquiring visuomotor skills from demonstrations, where designing effective observation encoders is essential for policy generalization. However, existing methods often struggle to generalize under spatial and visual randomizations, instead tending to overfit. To address this challenge, we propose Visual Geometry Diffusion Policy (VGDP), a multimodal imitation learning framework built around a Complementarity-Aware Fusion Module where modality-wise dropout enforces balanced use of RGB and point-cloud cues, with cross-attention serving only as a lightweight interaction layer. Our experiments show that the expressiveness of the fused latent space is largely induced by the enforced complementarity from modality-wise dropout, with cross-attention serving primarily as a lightweight interaction mechanism rather than the main source of robustness. Across a benchmark of 18 simulated tasks and 4 real-world tasks, VGDP outperforms seven baseline policies with an average performance improvement of 39.1%. More importantly, VGDP demonstrates strong robustness under visual and spatial per turbations, surpassing baselines with an average improvement of 41.5% in different visual conditions and 15.2% in different spatial settings.

</details>


### [12] [RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion](https://arxiv.org/abs/2511.22505)
*Xiujian Liang,Jiacheng Liu,Mingyang Sun,Qichen He,Cewu Lu,Jianhua Sun*

Main category: cs.RO

TL;DR: 本文提出了一种名为RealD$^2$iff的新方法，通过模拟学习来合成噪声深度图，从而解决视觉仿真与现实之间的差距。该方法采用从粗到细的层次结构，并结合了频率引导监督和差异引导优化两种策略，以更好地学习全局结构和局部细节。实验证明，这种方法不仅能够生成类似真实世界的深度图，还能实现零样本的仿真到现实的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人在实际应用中由于仿真与真实传感器之间存在视觉差异而导致的问题，研究者受到扩散模型去噪能力的启发，提出了一个由干净到噪声的范式转变。

Method: 提出了一个名为RealD$^2$iff的框架，它将深度噪声分解成全局结构失真和精细局部位移两部分处理。此外，还开发了两种互补策略：频率引导监督（FGS）用于建模全局结构，以及差异引导优化（DGO）专注于局部改进。整个过程被设计成包含六个阶段的工作流，以便于模仿学习中的整合。

Result: 通过全面的经验和实验验证表明，所提出的方法能够有效缩小视觉仿真与现实间的差距。RealD$^2$iff支持两个主要应用：1. 无需手动收集传感器数据即可创建出类似于真实环境的深度图对；2. 实现零样本迁移，显著提升机器人在未经额外微调情况下的真实世界表现。

Conclusion: 本研究表明，通过采用RealD$^2$iff这样一种新颖的学习方式，可以有效地弥合视觉仿真与实际操作之间的鸿沟，进而促进机器人技术在更广泛场景下的应用。

Abstract: Robot manipulation in the real world is fundamentally constrained by the visual sim2real gap, where depth observations collected in simulation fail to reflect the complex noise patterns inherent to real sensors. In this work, inspired by the denoising capability of diffusion models, we invert the conventional perspective and propose a clean-to-noisy paradigm that learns to synthesize noisy depth, thereby bridging the visual sim2real gap through purely simulation-driven robotic learning. Building on this idea, we introduce RealD$^2$iff, a hierarchical coarse-to-fine diffusion framework that decomposes depth noise into global structural distortions and fine-grained local perturbations. To enable progressive learning of these components, we further develop two complementary strategies: Frequency-Guided Supervision (FGS) for global structure modeling and Discrepancy-Guided Optimization (DGO) for localized refinement. To integrate RealD$^2$iff seamlessly into imitation learning, we construct a pipeline that spans six stages. We provide comprehensive empirical and experimental validation demonstrating the effectiveness of this paradigm. RealD$^2$iff enables two key applications: (1) generating real-world-like depth to construct clean-noisy paired datasets without manual sensor data collection. (2) Achieving zero-shot sim2real robot manipulation, substantially improving real-world performance without additional fine-tuning.

</details>


### [13] [BUDD-e: an autonomous robotic guide for visually impaired users](https://arxiv.org/abs/2511.22541)
*Jinyang Li,Marcello Farina,Luca Mozzarelli,Luca Cattaneo,Panita Rattamasanaprapai,Eleonora A. Tagarelli,Matteo Corno,Paolo Perego,Giuseppe Andreoni,Emanuele Lettieri*

Main category: cs.RO

TL;DR: 本文介绍了一种为视障用户设计的新型引导机器人BUDD-e的原型设计与实现，并通过实际场景测试展示了其卓越性能和用户接受度。


<details>
  <summary>Details</summary>
Motivation: 为了帮助视障人士，开发了一款名为BUDD-e的引导机器人，旨在提高他们的生活独立性。

Method: 通过构建BUDD-e机器人的原型并在米兰ASST Grande Ospedale Metropolitano Niguarda医院的真实环境中进行测试，该测试包括了视障志愿者的实际使用情况。

Result: 实验结果表明，BUDD-e机器人在实际应用中表现出色，得到了用户的高度认可。

Conclusion: BUDD-e机器人的成功测试证明了它对于视障用户支持的有效性及实用性。

Abstract: This paper describes the design and the realization of a prototype of the novel guide robot BUDD-e for visually impaired users. The robot has been tested in a real scenario with the help of visually disabled volunteers at ASST Grande Ospedale Metropolitano Niguarda, in Milan. The results of the experimental campaign are throughly described in the paper, displaying its remarkable performance and user-acceptance.

</details>


### [14] [Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention](https://arxiv.org/abs/2511.22555)
*Yanbo Mao,Jianlong Fu,Ruoxuan Zhang,Hongxia Xie,Meibao Yao*

Main category: cs.RO

TL;DR: 本文引入了LIBERO-Elegant基准，通过明确的标准来评估执行质量，并开发了一种解耦精炼框架，在不改变或重新训练基础VLA策略的情况下提高执行质量。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型在通用机器人操作中取得了显著进展，但其学习到的策略往往表现出执行质量不稳定的问题。这种变异性归因于人类演示的质量参差不齐，其中控制动作应该如何执行的隐含原则仅部分得到满足。为了解决这一挑战，研究者们提出了新的方法来改善这种情况。

Method: 提出LIBERO-Elegant基准，它带有用于评估执行质量的具体标准。基于这些标准，研究者开发了一个解耦精炼框架，该框架能够在不修改或重新训练基础VLA策略的前提下提升执行质量。他们将优雅执行形式化定义为满足隐式任务约束(ITCs)，并通过离线校准Q学习训练一个优雅评判器来估计候选动作的预期质量。在推理时，即时干预机制(JITI)监控评判器的信心水平，并只在决策关键时刻介入，提供选择性、按需精炼。

Result: 实验表明，在LIBERO-Elegant和真实世界操作任务上，所学得的优雅评判器能够显著提高执行质量，即使对于未见过的任务也是如此。提出的模型不仅关注任务是否成功完成，还重视它们是如何被执行的。

Conclusion: 本研究表明，通过引入LIBERO-Elegant基准及相应的解耦精炼框架，可以有效提高机器人操作任务中的执行质量，同时保持对任务完成方式的关注。

Abstract: Vision-Language-Action (VLA) models have enabled notable progress in general-purpose robotic manipulation, yet their learned policies often exhibit variable execution quality. We attribute this variability to the mixed-quality nature of human demonstrations, where the implicit principles that govern how actions should be carried out are only partially satisfied. To address this challenge, we introduce the LIBERO-Elegant benchmark with explicit criteria for evaluating execution quality. Using these criteria, we develop a decoupled refinement framework that improves execution quality without modifying or retraining the base VLA policy. We formalize Elegant Execution as the satisfaction of Implicit Task Constraints (ITCs) and train an Elegance Critic via offline Calibrated Q-Learning to estimate the expected quality of candidate actions. At inference time, a Just-in-Time Intervention (JITI) mechanism monitors critic confidence and intervenes only at decision-critical moments, providing selective, on-demand refinement. Experiments on LIBERO-Elegant and real-world manipulation tasks show that the learned Elegance Critic substantially improves execution quality, even on unseen tasks. The proposed model enables robotic control that values not only whether tasks succeed, but also how they are performed.

</details>


### [15] [Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation](https://arxiv.org/abs/2511.22685)
*Haoyi Wang,Licheng Luo,Yiannis Kantaros,Bruno Sinopoli,Mingyu Cai*

Main category: cs.RO

TL;DR: 本文提出了一种混合框架，将基于强化学习的反应式导航与按需多智能体路径查找（MAPF）无缝集成，以解决拓扑死锁问题。该方法通过安全层监测智能体进展来检测死锁，并使用协调控制器和全局可行轨迹构建来减少导航期间的智能体间冲突，从而显著提高了任务完成率并减少了死锁和碰撞。


<details>
  <summary>Details</summary>
Motivation: 在拥挤环境中进行多机器人导航时，如何平衡反应式避撞与远距离目标实现是一个基本挑战。当穿过狭窄通道或封闭空间时，经常会出现阻碍智能体到达目的地的死锁情况，特别是当强化学习控制策略遇到训练分布外的新配置时。现有的基于RL的方法在未见过的环境中的泛化能力有限。

Method: 本文提出的是一种混合框架，它将基于强化学习的反应式导航与按需多智能体路径寻找(MAPF)相结合，专门用来解决拓扑死锁问题。该框架中有一个安全层监控着智能体的进程，一旦检测到死锁，就会为受影响的智能体触发一个协调控制器。然后，该框架通过MAPF构建全局可行的轨迹，并且调控航点进展，以此来减少导航过程中的智能体间冲突。

Result: 密集多智能体基准测试的广泛评估表明，该方法将任务完成度从边缘提升到了接近普遍成功，显著减少了死锁和碰撞。此外，与分层任务规划结合后，它能够支持异构机器人的协调导航，证明了将反应式RL导航与选择性MAPF干预相结合可以产生强大的零样本性能。

Conclusion: 研究结果表明，所提混合框架能有效提高多机器人系统在复杂环境下的导航成功率，同时降低死锁及碰撞事件的发生概率。这说明结合反应式RL导航与选择性的MAPF干预是一种有效增强系统鲁棒性和适应未知场景能力的方法。

Abstract: Multi-robot navigation in cluttered environments presents fundamental challenges in balancing reactive collision avoidance with long-range goal achievement. When navigating through narrow passages
  or confined spaces, deadlocks frequently emerge that prevent agents from reaching their destinations, particularly when Reinforcement Learning (RL) control policies encounter novel configurations out of learning distribution. Existing RL-based approaches suffer from limited generalization capability in unseen environments. We propose a hybrid framework that seamlessly integrates RL-based reactive navigation with on-demand Multi-Agent Path Finding (MAPF) to explicitly resolve topological deadlocks. Our approach integrates a safety layer that monitors agent progress to detect deadlocks and, when detected, triggers a coordination controller for affected agents. The framework constructs globally feasible trajectories via MAPF and regulates waypoint progression to reduce inter-agent conflicts during navigation.
  Extensive evaluation on dense multi-agent benchmarks shows that our method boosts task completion from marginal to near-universal success, markedly reducing deadlocks and collisions. When integrated with hierarchical task planning, it enables coordinated navigation for heterogeneous robots, demonstrating that coupling reactive RL navigation with selective MAPF intervention yields a robust, zero-shot performance.

</details>


### [16] [Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations](https://arxiv.org/abs/2511.22697)
*Chancharik Mitra,Yusen Luo,Raj Saravanan,Dantong Niu,Anirudh Pai,Jesse Thomason,Trevor Darrell,Abrar Anwar,Deva Ramanan,Roei Herzig*

Main category: cs.RO

TL;DR: 本文提出了一种名为Robotic Steering的微调方法，该方法基于机械可解释性，利用少量样本演示来识别并选择性地微调与机器人任务的物理、视觉和语言要求相匹配的任务特定注意力头。实验表明，这种方法在多种机器人任务上优于LoRA，并且具有更好的鲁棒性、更低的计算成本以及更高的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言动作（VLAs）模型虽然在视觉-语言领域取得了显著成功，但将其应用于机器人时，需要针对不同的物理因素如机器人形态、环境特性和每项任务的空间关系进行微调。然而，现有的微调方法缺乏针对性，对所有任务都调整相同的参数集，而没有考虑到任务特有的视觉、语言及物理特性。受神经科学中功能特异性概念的启发，研究者假设为给定任务微调稀疏模型表示更为有效。

Method: 提出了Robotic Steering微调方法，该方法基于机械可解释性原则，通过利用少量示例演示来识别并与机器人任务的具体物理、视觉和语言需求相匹配的任务特定注意头，从而实现选择性微调。

Result: 通过对Franka Emika机械臂进行全面的实际机器人评估显示，Robotic Steering不仅在性能上超越了LoRA方法，而且在任务变化下表现出更优的鲁棒性、减少了计算开销，并提高了将VLAs适应于多样化机器人任务过程中的可解释性。

Conclusion: 本研究表明，采用Robotic Steering方法可以有效地提高视觉-语言动作模型在不同机器人应用中的适应能力，同时保持较高的执行效率和理解度。

Abstract: Vision-Language Action (VLAs) models promise to extend the remarkable success of vision-language models (VLMs) to robotics. Yet, unlike VLMs in the vision-language domain, VLAs for robotics require finetuning to contend with varying physical factors like robot embodiment, environment characteristics, and spatial relationships of each task. Existing fine-tuning methods lack specificity, adapting the same set of parameters regardless of a task's visual, linguistic, and physical characteristics. Inspired by functional specificity in neuroscience, we hypothesize that it is more effective to finetune sparse model representations specific to a given task. In this work, we introduce Robotic Steering, a finetuning approach grounded in mechanistic interpretability that leverages few-shot demonstrations to identify and selectively finetune task-specific attention heads aligned with the physical, visual, and linguistic requirements of robotic tasks. Through comprehensive on-robot evaluations with a Franka Emika robot arm, we demonstrate that Robotic Steering outperforms LoRA while achieving superior robustness under task variation, reduced computational cost, and enhanced interpretability for adapting VLAs to diverse robotic tasks.

</details>


### [17] [A Two Degrees-of-Freedom Floor-Based Robot for Transfer and Rehabilitation Applications](https://arxiv.org/abs/2511.22705)
*Ian Lalonde,Jeff Denis,Mathieu Lamy,Camille Martin,Karina Lebel,Alexandre Girard*

Main category: cs.RO

TL;DR: Researchers developed a sit-to-stand (STS) training device that can be adjusted to various mobility levels, providing precise weight unloading and assistance during the STS motion. The device was tested on healthy adults of different heights and weights, showing minimal impact on natural STS kinematics while effectively supporting the transition of bodyweight to the feet.


<details>
  <summary>Details</summary>
Motivation: The need for a device that can adjust to different mobility levels to support the sit-to-stand (STS) motion, which is critical for improving functional mobility and reducing rehospitalization risks, motivated the development of this new STS training device.

Method: A novel STS training device was designed with capabilities to configure impedance and apply vertical/forward forces, thus adapting to multiple training needs. The device's effectiveness was evaluated through experiments involving healthy adults of varying heights and weights.

Result: Experiments demonstrated that the STS training device had a minor effect on the natural STS movement, could accurately unload weight at the user's center of mass, and provided an assistive forward force to help shift the bodyweight onto the feet at the beginning of the STS action.

Conclusion: The developed STS training device successfully adapts to different users' mobility levels, offering tailored support and rehabilitation possibilities, while also maintaining the functionality of a commercial raising aid.

Abstract: The ability to accomplish a sit-to-stand (STS) motion is key to increase functional mobility and reduce rehospitalization risks. While raising aid (transfer) devices and partial bodyweight support (rehabilitation) devices exist, both are unable to adjust the STS training to different mobility levels. Therefore, We have developed an STS training device that allows various configurations of impedance and vertical/forward forces to adapt to many training needs while maintaining commercial raising aid transfer capabilities. Experiments with healthy adults (both men and women) of various heights and weights show that the device 1) has a low impact on the natural STS kinematics, 2) can provide precise weight unloading at the patient's center of mass and 3) can add a forward virtual spring to assist the transfer of the bodyweight to the feet for seat-off, at the start of the STS motion.

</details>


### [18] [Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion](https://arxiv.org/abs/2511.22744)
*Rémy Rahem,Wael Suleiman*

Main category: cs.RO

TL;DR: 本文提出了一种基于多视角深度信息的运动框架，通过结合自我中心和外部视角观察来提供更丰富的环境上下文，从而改善了四足机器人在动态移动中的鲁棒性和敏捷性。


<details>
  <summary>Details</summary>
Motivation: 当前腿部运动方法主要依赖于自我中心（第一人称）感知，当机器人的视野被遮挡时，其性能会受到限制。为了提高机器人的环境意识，本研究旨在通过使用互补视角，如多个参与者交换感知信息，来增强机器人的运动能力。

Method: 提出了一个多视角深度为基础的运动框架，该框架结合了自我中心和外部视角的观察；采用了教师-学生蒸馏法，使学生策略能够学习融合本体感受与双深度流，同时对现实世界中的感知不完美保持鲁棒性；引入了广泛的领域随机化技术，包括随机远程摄像机断开和3D位置扰动，以模拟空中-地面协作感知。

Result: 仿真结果显示，多视点策略在跨越间隙、下台阶等动态操作上优于单视点基线，并且在外部视角部分或完全不可用的情况下仍能保持稳定性；额外实验表明，在训练过程中加入适度视角错位是可接受的。

Conclusion: 异构视觉反馈提高了四足运动中的鲁棒性和敏捷性。

Abstract: Recent progress in legged locomotion has allowed highly dynamic and parkour-like behaviors for robots, similar to their biological counterparts. Yet, these methods mostly rely on egocentric (first-person) perception, limiting their performance, especially when the viewpoint of the robot is occluded. A promising solution would be to enhance the robot's environmental awareness by using complementary viewpoints, such as multiple actors exchanging perceptual information. Inspired by this idea, this work proposes a multi-view depth-based locomotion framework that combines egocentric and exocentric observations to provide richer environmental context during agile locomotion. Using a teacher-student distillation approach, the student policy learns to fuse proprioception with dual depth streams while remaining robust to real-world sensing imperfections. To further improve robustness, we introduce extensive domain randomization, including stochastic remote-camera dropouts and 3D positional perturbations that emulate aerial-ground cooperative sensing. Simulation results show that multi-viewpoints policies outperform single-viewpoint baseline in gap crossing, step descent, and other dynamic maneuvers, while maintaining stability when the exocentric camera is partially or completely unavailable. Additional experiments show that moderate viewpoint misalignment is well tolerated when incorporated during training. This study demonstrates that heterogeneous visual feedback improves robustness and agility in quadrupedal locomotion. Furthermore, to support reproducibility, the implementation accompanying this work is publicly available at https://anonymous.4open.science/r/multiview-parkour-6FB8

</details>


### [19] [CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance](https://arxiv.org/abs/2511.22773)
*Rui Heng Yang,Xuan Zhao,Leo Maxime Brunswic,Montgomery Alban,Mateo Clemente,Tongtong Cao,Jun Jin,Amir Rasouli*

Main category: cs.RO

TL;DR: 提出了一种名为CAPE的框架，通过上下文感知先验和引导在推理时扩展轨迹分布模式，以解决机器人学习中因数据集规模大而难以获取的问题。特别是对于避障任务，CAPE能够生成更平滑、碰撞可能性更低的轨迹，并在未见过的环境中表现出更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在机器人模仿学习中，扩散模型能够从演示中捕捉多模态轨迹，但要达到最佳性能需要大规模的数据集，这在诸如避障这样具有挑战性的任务中尤其困难且成本高昂。因为这些任务要求覆盖多种障碍物类型及其空间配置，仅靠收集数据难以实现。

Method: 提出了Context-Aware diffusion policy via Proximal mode Expansion (CAPE)框架，该框架利用上下文感知先验并通过一种新颖的基于先验种子的迭代引导细化程序，在推理时扩展轨迹分布模式。它首先生成初始轨迹计划并执行一段短前缀轨迹，然后将剩余轨迹段扰动至中间噪声水平，形成一个上下文感知的轨迹先验。重复此过程结合上下文感知引导去噪，逐步扩大模式支持，找到更平滑、更少碰撞可能的轨迹。

Result: 在多样化操作任务以及拥挤且之前未见的模拟和真实世界环境中评估了CAPE。结果表明，与最先进方法相比，CAPE分别提高了高达26%和80%的成功率，展示了其对未知环境更好的泛化能力。

Conclusion: CAPE框架通过引入上下文感知的先验知识和指导来扩展轨迹分布模式，为机器人在复杂未知环境中的避障问题提供了一个有效的解决方案，显著提高了任务成功率。

Abstract: In robotics, diffusion models can capture multi-modal trajectories from demonstrations, making them a transformative approach in imitation learning. However, achieving optimal performance following this regiment requires a large-scale dataset, which is costly to obtain, especially for challenging tasks, such as collision avoidance. In those tasks, generalization at test time demands coverage of many obstacles types and their spatial configurations, which are impractical to acquire purely via data. To remedy this problem, we propose Context-Aware diffusion policy via Proximal mode Expansion (CAPE), a framework that expands trajectory distribution modes with context-aware prior and guidance at inference via a novel prior-seeded iterative guided refinement procedure. The framework generates an initial trajectory plan and executes a short prefix trajectory, and then the remaining trajectory segment is perturbed to an intermediate noise level, forming a trajectory prior. Such a prior is context-aware and preserves task intent. Repeating the process with context-aware guided denoising iteratively expands mode support to allow finding smoother, less collision-prone trajectories. For collision avoidance, CAPE expands trajectory distribution modes with collision-aware context, enabling the sampling of collision-free trajectories in previously unseen environments while maintaining goal consistency. We evaluate CAPE on diverse manipulation tasks in cluttered unseen simulated and real-world settings and show up to 26% and 80% higher success rates respectively compared to SOTA methods, demonstrating better generalization to unseen environments.

</details>


### [20] [Improving Robotic Manipulation Robustness via NICE Scene Surgery](https://arxiv.org/abs/2511.22777)
*Sajjad Pakdamansavoji,Mozhgan Pourkeshavarz,Adam Sigal,Zhiyuan Li,Rui Heng Yang,Amir Rasouli*

Main category: cs.RO

TL;DR: 本文提出了一种名为NICE（自然主义修复以增强上下文）的框架，通过利用图像生成框架和大型语言模型来提高视觉多样性，从而最小化模仿学习中的OOD差距。NICE无需额外收集机器人数据、访问模拟器或定制模型训练，并且在高度杂乱的场景中提高了可承受性预测的准确性以及物体操作任务的成功率，同时降低了目标混淆和碰撞率。


<details>
  <summary>Details</summary>
Motivation: 在现实世界环境中，视觉干扰物会显著降低机器人操作性能和安全性。为了克服这一挑战，作者提出了NICE框架，旨在通过增加视觉多样性来减小模仿学习中的分布外(OOD)差距。

Method: NICE框架利用现有的演示构建新经验，采用图像生成框架与大型语言模型执行三种编辑操作：对象替换、风格重设及移除分散注意力的对象。这些变化保持了空间关系的一致性而不会遮挡目标对象，同时也保证了动作-标签一致性。此外，该方法不需要额外的数据收集或特定模型训练，使其能够直接应用于现有机器人数据集上。

Result: 实验结果表明，NICE成功地减少了OOD差距，在高度混乱的场景中将可承受性预测准确度提高了超过20%；对于操作任务，在存在不同数量干扰物的测试环境中平均成功率增加了11%。此外，它还提高了视觉鲁棒性，将目标混淆降低了6%，并通过减少碰撞率7%增强了安全性。

Conclusion: NICE框架提供了一种有效且可扩展的方法来提高模仿学习中视觉策略的鲁棒性，尤其适用于充满视觉干扰的真实世界环境。其不仅提升了处理复杂场景的能力，也增强了系统整体的安全性和可靠性。

Abstract: Learning robust visuomotor policies for robotic manipulation remains a challenge in real-world settings, where visual distractors can significantly degrade performance and safety. In this work, we propose an effective and scalable framework, Naturalistic Inpainting for Context Enhancement (NICE). Our method minimizes out-of-distribution (OOD) gap in imitation learning by increasing visual diversity through construction of new experiences using existing demonstrations. By utilizing image generative frameworks and large language models, NICE performs three editing operations, object replacement, restyling, and removal of distracting (non-target) objects. These changes preserve spatial relationships without obstructing target objects and maintain action-label consistency. Unlike previous approaches, NICE requires no additional robot data collection, simulator access, or custom model training, making it readily applicable to existing robotic datasets.
  Using real-world scenes, we showcase the capability of our framework in producing photo-realistic scene enhancement. For downstream tasks, we use NICE data to finetune a vision-language model (VLM) for spatial affordance prediction and a vision-language-action (VLA) policy for object manipulation. Our evaluations show that NICE successfully minimizes OOD gaps, resulting in over 20% improvement in accuracy for affordance prediction in highly cluttered scenes. For manipulation tasks, success rate increases on average by 11% when testing in environments populated with distractors in different quantities. Furthermore, we show that our method improves visual robustness, lowering target confusion by 6%, and enhances safety by reducing collision rate by 7%.

</details>


### [21] [Distracted Robot: How Visual Clutter Undermine Robotic Manipulation](https://arxiv.org/abs/2511.22780)
*Amir Rasouli,Montgomery Alban,Sajjad Pakdamansavoji,Zhiyuan Li,Zhanguang Zhang,Aaron Wu,Xuan Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种评估协议，用于检测杂乱场景中机器人操作策略的表现。通过从心理物理学的角度出发，使用一种统一的杂乱度量方法来考虑环境因素以及干扰物的数量、特性和排列方式。实验结果表明，场景杂乱程度显著影响策略性能，并且尽管在各项任务中的平均表现相似，不同的视觉-语言-动作（VLA）模型对于成功情形有不同的脆弱性及低一致率。此外，研究还发现所提出的杂乱度量是性能下降的有效指标，并分析了干扰物数量及其遮挡效应的影响。最后指出，虽然增强数据上的微调有效，但并不能完全弥补杂乱对性能的所有负面影响。


<details>
  <summary>Details</summary>
Motivation: 针对现有工作在评估机器人操作策略时未充分考虑环境因素与干扰物特性的问题，本文旨在从心理物理学角度出发，提出一个更全面的评估框架以更好地理解杂乱场景下机器人操作策略的表现。

Method: 提出了一个基于心理物理视角的评估协议，该协议采用了一个统一的杂乱度量标准，综合考量环境因素和干扰物的数量、特征及其布局。在此基础上，作者们构建了一系列高度仿真的模拟场景及真实世界场景来进行广泛的实验测试，特别是针对视觉-语言-行动(VLA)模型的操作策略进行了深入研究。

Result: 实验结果显示，随着场景复杂度增加，机器人操作策略的整体表现会显著下降，最大降幅可达34%；不同VLA模型尽管整体表现相近，但在具体任务上表现出各自独特的弱点且成功案例间的一致性较低；此外，所提杂乱度量被证实能够有效反映性能衰退情况，并揭示了干扰物体数量及其遮挡效果对系统性能的具体影响；值得注意的是，尽管利用增强后的数据进行微调可以改善部分问题，但仍无法完全克服杂乱环境带来的所有负面作用。

Conclusion: 本研究表明，通过引入更加全面的杂乱度量标准，可以更准确地评估并理解杂乱环境中机器人操作策略的实际表现。同时，它也强调了开发能够适应高杂乱度条件下的鲁棒性更强的VLA模型的重要性。

Abstract: In this work, we propose an evaluation protocol for examining the performance of robotic manipulation policies in cluttered scenes. Contrary to prior works, we approach evaluation from a psychophysical perspective, therefore we use a unified measure of clutter that accounts for environmental factors as well as the distractors quantity, characteristics, and arrangement. Using this measure, we systematically construct evaluation scenarios in both hyper-realistic simulation and real-world and conduct extensive experimentation on manipulation policies, in particular vision-language-action (VLA) models. Our experiments highlight the significant impact of scene clutter, lowering the performance of the policies, by as much as 34% and show that despite achieving similar average performance across the tasks, different VLA policies have unique vulnerabilities and a relatively low agreement on success scenarios. We further show that our clutter measure is an effective indicator of performance degradation and analyze the impact of distractors in terms of their quantity and occluding influence. At the end, we show that finetuning on enhanced data, although effective, does not equally remedy all negative impacts of clutter on performance.

</details>


### [22] [Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation](https://arxiv.org/abs/2511.22829)
*Zhen Tian,Zhihao Lin*

Main category: cs.RO

TL;DR: 本文提出了一种新的轨迹规划方法，结合了风险感知规划和避碰保证，通过动态风险场(DRF)捕捉周围车辆的静态和动态碰撞风险，并使用受限迭代线性二次调节器(iLQR)算法解决最优控制问题。仿真结果表明该方法在安全性、效率以及舒适性方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了处理自动驾驶中复杂的驾驶场景，如自动变道，需要一种能够综合考虑风险意识规划与碰撞避免的新路径规划方法。

Method: 首先构建了一个动态风险场（DRF）来捕捉来自周围车辆的静态和动态碰撞风险；然后开发出一种生成随时间变化的凸可行空间策略，以确保运动学可行性和安全要求；最后将轨迹规划问题定义为一个有限时间内的最优控制问题，并采用约束迭代线性二次调节器（iLQR）算法求解，该算法同时优化了轨迹平滑度、控制努力程度及风险暴露情况，同时保持严格的可行性。

Result: 广泛的模拟实验表明，所提出的方法相比传统方法，在安全性和效率方面表现更佳，实现了无碰撞的轨迹，且变道距离（28.59米）和时间（2.84秒）更短，同时保持了平稳舒适的加速度模式。此外，在密集环岛环境中，该规划器还展示了更强的适应性，产生了更大的安全裕度、更低的急动度以及比基于APF、MPC和RRT基线更好的曲率平滑度。

Conclusion: 集成DRF与凸可行空间及受限制的iLQR求解器为动态交互交通场景下的安全、高效且舒适的轨迹生成提供了一个平衡解决方案。

Abstract: This paper presents a novel trajectory planning pipeline for complex driving scenarios like autonomous lane changing, by integrating risk-aware planning with guaranteed collision avoidance into a unified optimization framework. We first construct a dynamic risk fields (DRF) that captures both the static and dynamic collision risks from surrounding vehicles. Then, we develop a rigorous strategy for generating time-varying convex feasible spaces that ensure kinematic feasibility and safety requirements. The trajectory planning problem is formulated as a finite-horizon optimal control problem and solved using a constrained iterative Linear Quadratic Regulator (iLQR) algorithm that jointly optimizes trajectory smoothness, control effort, and risk exposure while maintaining strict feasibility. Extensive simulations demonstrate that our method outperforms traditional approaches in terms of safety and efficiency, achieving collision-free trajectories with shorter lane-changing distances (28.59 m) and times (2.84 s) while maintaining smooth and comfortable acceleration patterns. In dense roundabout environments the planner further demonstrates robust adaptability, producing larger safety margins, lower jerk, and superior curvature smoothness compared with APF, MPC, and RRT based baselines. These results confirm that the integrated DRF with convex feasible space and constrained iLQR solver provides a balanced solution for safe, efficient, and comfortable trajectory generation in dynamic and interactive traffic scenarios.

</details>


### [23] [Threat-Aware UAV Dodging of Human-Thrown Projectiles with an RGB-D Camera](https://arxiv.org/abs/2511.22847)
*Yuying Zhang,Na Fan,Haowen Zheng,Junning Liang,Zongliang Pan,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种基于RGB-D相机的新型实时躲避系统，通过结合人体姿态估计和深度信息来预测攻击者的运动轨迹以及随后的投射物轨迹，并引入了考虑不确定性的躲避策略，以使无人机能够有效躲避来袭的投射物。实验表明该框架在面对突然袭击时具有可靠的躲避能力及在多种场景下的出色鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机在执行如运输和航拍等任务时容易受到人类有意投掷物体的攻击。为了应对这种突然且快速的投射物，需要无人机具备超低延迟反应能力和敏捷的机动性能。

Method: 受棒球中分析投手身体动作以预测球轨迹的启发，研究者提出了一套新的基于RGB-D摄像头的实时躲避系统。该方法整合了人体姿态估计与深度信息用于预测攻击者动作轨迹及随后投射物的路径。此外，还开发了一个能意识到不确定性的躲避策略，使得无人机可以高效地避开飞来的投射物。

Result: 感知系统实现了高精度预测，在有效距离和延迟方面优于基线水平。躲避策略解决了时间与空间上的不确定性问题，确保了无人机的安全。广泛的现实世界实验展示了该框架针对突发攻击具有可靠的躲避能力，并且在不同情境下表现出色的鲁棒性。

Conclusion: 这项工作为无人机提供了一种创新的方法来检测并躲避来自人类的故意投掷攻击，通过使用RGB-D摄像机和人体姿态估计技术提高了无人机的安全性和生存能力。

Abstract: Uncrewed aerial vehicles (UAVs) performing tasks such as transportation and aerial photography are vulnerable to intentional projectile attacks from humans. Dodging such a sudden and fast projectile poses a significant challenge for UAVs, requiring ultra-low latency responses and agile maneuvers. Drawing inspiration from baseball, in which pitchers' body movements are analyzed to predict the ball's trajectory, we propose a novel real-time dodging system that leverages an RGB-D camera. Our approach integrates human pose estimation with depth information to predict the attacker's motion trajectory and the subsequent projectile trajectory. Additionally, we introduce an uncertainty-aware dodging strategy to enable the UAV to dodge incoming projectiles efficiently. Our perception system achieves high prediction accuracy and outperforms the baseline in effective distance and latency. The dodging strategy addresses temporal and spatial uncertainties to ensure UAV safety. Extensive real-world experiments demonstrate the framework's reliable dodging capabilities against sudden attacks and its outstanding robustness across diverse scenarios.

</details>


### [24] [MARVO: Marine-Adaptive Radiance-aware Visual Odometry](https://arxiv.org/abs/2511.22860)
*Sacchin Sundar,Atman Kikani,Aaliya Alam,Sumukh Shrote,A. Nayeemulla Khan,A. Shahina*

Main category: cs.RO

TL;DR: 本文提出了一种名为MARVO的物理感知、学习集成的里程计框架，该框架融合了水下图像形成建模、可微匹配和强化学习优化，以解决水下视觉定位问题。


<details>
  <summary>Details</summary>
Motivation: 水下视觉定位由于波长依赖性衰减、纹理差以及非高斯传感器噪声而极具挑战。为了解决这些问题，提出了MARVO系统。

Method: MARVO通过引入物理感知辐射适配器来补偿颜色通道衰减与对比度损失，从而在浑浊条件下生成几何一致的特征对应关系。这些半密集匹配结合惯性和压力测量数据，在因子图后端进行处理，其中使用GTSAM库制定了基于关键帧的视觉-惯性-气压估计器。每个关键帧都包括预积分IMU运动因素、MARVO衍生的视觉姿态因素以及气压深度先验信息，实现实时全状态最大后验估计。此外，还介绍了一种基于强化学习的姿态图优化器，通过学习SE(2)上的最优回撤动作来改进全局轨迹。

Result: 实验结果表明，MARVO能够在存在波长依赖性衰减、低纹理环境及非高斯噪声的情况下提供准确且鲁棒的水下视觉定位解决方案。

Conclusion: MARVO通过整合物理模型、机器学习技术以及多传感器融合，为水下视觉定位领域提供了新的思路和技术手段，显著提高了定位精度与鲁棒性。

Abstract: Underwater visual localization remains challenging due to wavelength-dependent attenuation, poor texture, and non-Gaussian sensor noise. We introduce MARVO, a physics-aware, learning-integrated odometry framework that fuses underwater image formation modeling, differentiable matching, and reinforcement-learning optimization. At the front-end, we extend transformer-based feature matcher with a Physics Aware Radiance Adapter that compensates for color channel attenuation and contrast loss, yielding geometrically consistent feature correspondences under turbidity. These semi dense matches are combined with inertial and pressure measurements inside a factor-graph backend, where we formulate a keyframe-based visual-inertial-barometric estimator using GTSAM library. Each keyframe introduces (i) Pre-integrated IMU motion factors, (ii) MARVO-derived visual pose factors, and (iii) barometric depth priors, giving a full-state MAP estimate in real time. Lastly, we introduce a Reinforcement-Learningbased Pose-Graph Optimizer that refines global trajectories beyond local minima of classical least-squares solvers by learning optimal retraction actions on SE(2).

</details>


### [25] [SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving](https://arxiv.org/abs/2511.22865)
*Wonjeong Ryu,Seungjun Yu,Seokha Moon,Hojun Choi,Junsung Park,Jinkyu Kim,Hyunjung Shim*

Main category: cs.RO

TL;DR: 提出了一种仅基于摄像头的端到端自动驾驶框架，该框架在鸟瞰图空间中直接估计偶然不确定性，并将其纳入路径规划。通过引入车道跟随正则化来促进安全合规驾驶行为，从而提高了在不确定条件下的轨迹规划鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统无法处理感知输出中的不确定性问题，导致在模糊或观察不足的情况下缺乏明确的不确定性度量。

Method: 设计了一个能够在鸟瞰图空间内直接估算偶然不确定性的系统，并生成一个密集、具有不确定性的可行驶地图。此外，还加入了一个车道跟随正则化方法，以编码车道结构和交通规范。

Result: 在NAVSIM基准测试上表现达到最先进水平，在难度较高的NAVSURE和NAVSAGE子集上取得了显著进步。

Conclusion: 这种基于原则的偶然不确定性建模结合驾驶先验知识大大提高了纯视觉端到端自动驾驶的安全性和可靠性。

Abstract: End-to-End (E2E) planning has become a powerful paradigm for autonomous driving, yet current systems remain fundamentally uncertainty-blind. They assume perception outputs are fully reliable, even in ambiguous or poorly observed scenes, leaving the planner without an explicit measure of uncertainty. To address this limitation, we propose a camera-only E2E framework that estimates aleatoric uncertainty directly in BEV space and incorporates it into planning. Our method produces a dense, uncertainty-aware drivability map that captures both semantic structure and geometric layout at pixel-level resolution. To further promote safe and rule-compliant behavior, we introduce a lane-following regularization that encodes lane structure and traffic norms. This prior stabilizes trajectory planning under normal conditions while preserving the flexibility needed for maneuvers such as overtaking or lane changes. Together, these components enable robust and interpretable trajectory planning, even under challenging uncertainty conditions. Evaluated on the NAVSIM benchmark, our method achieves state-of-the-art performance, delivering substantial gains on both the challenging NAVHARD and NAVSAFE subsets. These results demonstrate that our principled aleatoric uncertainty modeling combined with driving priors significantly advances the safety and reliability of camera-only E2E autonomous driving.

</details>


### [26] [Seeing before Observable: Potential Risk Reasoning in Autonomous Driving via Vision Language Models](https://arxiv.org/abs/2511.22928)
*Jiaxin Liu,Xiangyu Yan,Liang Peng,Lei Yang,Lingjun Zhang,Yuechen Luo,Yueming Tao,Ashton Yu Xuan Tan,Mu Li,Lei Zhang,Ziqi Zhan,Sai Guo,Hong Wang,Jun Li*

Main category: cs.RO

TL;DR: 本文针对自动驾驶车辆在处理潜在风险时面临的挑战，提出了一种新的视觉-语言数据集PotentialRiskQA以及基于此数据集的模型PR-Reasoner，旨在提高系统对尚未显现但可通过细微前兆推断出的风险的理解和推理能力。实验结果表明，相较于基线模型，经过PotentialRiskQA微调后的PR-Reasoner在潜在风险推理任务上表现显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统缺乏对潜在风险（即尚未直接观察到但可以通过某些迹象预测的风险）的有效识别能力，主要原因是现有数据集中这类情况较少且缺乏对事故背后因果链路的标注。为了弥补这一空白并提高自动驾驶汽车的安全性，特别是增强其预见性和主动安全性能，研究提出了一个新的解决方案。

Method: 研究人员构建了一个名为PotentialRiskQA的新数据集，该数据集包含结构化的场景描述、语义前兆信息及推断出的风险结果等注释。基于此数据集，他们还开发了PR-Reasoner框架，这是一种利用视觉-语言模型进行车载潜在风险推理的方法。

Result: 通过在PotentialRiskQA上进行微调，PR-Reasoner在潜在风险推理任务中的表现相比基准视觉-语言模型有了显著改善。

Conclusion: 本研究为开发具有更好预见性和主动安全能力的自动驾驶系统奠定了基础，有助于推动更加智能与韧性的自动驾驶技术发展。

Abstract: Ensuring safety remains a key challenge for autonomous vehicles (AVs), especially in rare and complex scenarios. One critical but understudied aspect is the \textbf{potential risk} situations, where the risk is \textbf{not yet observable} but can be inferred from subtle precursors, such as anomalous behaviors or commonsense violations. Recognizing these precursors requires strong semantic understanding and reasoning capabilities, which are often absent in current AV systems due to the scarcity of such cases in existing driving or risk-centric datasets. Moreover, current autonomous driving accident datasets often lack annotations of the causal reasoning chains behind incidents, which are essential for identifying potential risks before they become observable. To address these gaps, we introduce PotentialRiskQA, a novel vision-language dataset designed for reasoning about potential risks prior to observation. Each sample is annotated with structured scene descriptions, semantic precursors, and inferred risk outcomes. Based on this dataset, we further propose PR-Reasoner, a vision-language-model-based framework tailored for onboard potential risk reasoning. Experimental results show that fine-tuning on PotentialRiskQA enables PR-Reasoner to significantly enhance its performance on the potential risk reasoning task compared to baseline VLMs. Together, our dataset and model provide a foundation for developing autonomous systems with improved foresight and proactive safety capabilities, moving toward more intelligent and resilient AVs.

</details>


### [27] [Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary](https://arxiv.org/abs/2511.22963)
*Zhirui Liu,Kaiyang Ji,Ke Yang,Jingyi Yu,Ye Shi,Jingya Wang*

Main category: cs.RO

TL;DR: 本文介绍了一种新的大型语言动作模型Humanoid-LLA，该模型能够将自由形式的语言命令映射到人形机器人可物理执行的全身动作上。通过整合统一的动作词汇、基于词汇的控制器以及利用强化学习进行物理学信息微调阶段，该方法在模拟和真实世界测试中表现出优秀的语言泛化能力和物理逼真度。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前方法在处理复杂指令时难以兼顾动作多样性与物理可行性的局限性，提出了Humanoid-LLA模型来实现更自然流畅且稳定的人机交互。

Method: 提出的方法包括三个核心部分：统一的动作词汇表用于对齐人类与机器人之间的基本运动单位；从特权策略蒸馏而来的基于词汇指导的控制器确保了物理可行性；并通过引入动态意识奖励机制的强化学习进行物理信息导向的微调以增强鲁棒性和稳定性。

Result: 广泛的仿真评估及在真实Unitree G1人形机器人上的测试表明，Humanoid-LLA不仅提供了强大的语言泛化能力，还保持了高物理逼真度，在动作自然性、稳定性及执行成功率方面优于现有条件语言控制器。

Conclusion: 本研究提出的Humanoid-LLA成功地解决了语言条件下人形机器人的全身控制问题，实现了更加多样化且物理上合理的动作响应，为人机协作任务执行提供了一个有效解决方案。

Abstract: Enabling humanoid robots to follow free-form language commands is critical for seamless human-robot interaction, collaborative task execution, and general-purpose embodied intelligence. While recent advances have improved low-level humanoid locomotion and robot manipulation, language-conditioned whole-body control remains a significant challenge. Existing methods are often limited to simple instructions and sacrifice either motion diversity or physical plausibility. To address this, we introduce Humanoid-LLA, a Large Language Action Model that maps expressive language commands to physically executable whole-body actions for humanoid robots. Our approach integrates three core components: a unified motion vocabulary that aligns human and humanoid motion primitives into a shared discrete space; a vocabulary-directed controller distilled from a privileged policy to ensure physical feasibility; and a physics-informed fine-tuning stage using reinforcement learning with dynamics-aware rewards to enhance robustness and stability. Extensive evaluations in simulation and on a real-world Unitree G1 humanoid show that Humanoid-LLA delivers strong language generalization while maintaining high physical fidelity, outperforming existing language-conditioned controllers in motion naturalness, stability, and execution success rate.

</details>


### [28] [Analytical Inverse Kinematic Solution for "Moz1" NonSRS 7-DOF Robot arm with novel arm angle](https://arxiv.org/abs/2511.22996)
*Ke Chen*

Main category: cs.RO

TL;DR: 本文提出了七自由度Moz1机械臂逆运动学问题的解析解，通过新颖的手臂角度解决了算法奇异性的问题，并提供了每种姿态下的全部16个解。


<details>
  <summary>Details</summary>
Motivation: 为了解决七自由度Moz1机械臂在手腕有偏移情况下的逆运动学问题，特别是处理算法奇异性以及如何在传统SEW角度无法定义的情况下解决冗余问题。

Method: 开发了一种新的手臂角度表示方法，用以提供封闭形式的解，该方法允许完全自运动并处理工作空间内的算法奇点。

Result: 得到了一个简单、快速且准确的解决方案，能够针对每个给定的姿态提供完整的解空间（即所有16个解）。

Conclusion: 提出的逆运动学解法不仅有效避免了算法奇异性问题，还成功地解决了机械臂在特定配置下的冗余度问题，为机器人技术的实际应用提供了理论支持。

Abstract: This paper presents an analytical solution to the inverse kinematic problem(IKP) for the seven degree-of-freedom (7-DOF) Moz1 Robot Arm with offsets on wrist. We provide closed-form solutions with the novel arm angle . it allow fully self-motion and solve the problem of algorithmic singularities within the workspace. It also provides information on how the redundancy is resolved in a new arm angle representation where traditional SEW angle faied to be defined and how singularities are handled. The solution is simple, fast and exact, providing full solution space (i.e. all 16 solutions) per pose.

</details>


### [29] [Adaptive Factor Graph-Based Tightly Coupled GNSS/IMU Fusion for Robust Positionin](https://arxiv.org/abs/2511.23017)
*Elham Ahmadi,Alireza Olama,Petri Välisuo,Heidi Kuusniemi*

Main category: cs.RO

TL;DR: 本文提出了一种鲁棒且自适应的因子图融合框架，该框架直接集成了GNSS伪距测量与IMU预积分因素，并采用了Barron损失函数以统一几种M-估计器。通过自适应地降低不可靠GNSS测量值的权重，提高了在城市峡谷等信号不良环境中的定位鲁棒性。实验表明，与标准FGO相比，该方法可减少高达41%的定位误差，在城市峡谷环境中对比扩展卡尔曼滤波（EKF）基线更是有显著改进。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号不佳的环境中实现可靠的定位仍然是导航系统面临的一个关键挑战。尽管紧密耦合的GNSS/IMU融合提高了系统的鲁棒性，但仍然容易受到非高斯噪声和异常值的影响。

Method: 提出了一个基于因子图的鲁棒及自适应融合框架，该框架直接将GNSS伪距测量与IMU预积分因素相结合，并引入了Barron损失函数，这是一种通用的鲁棒损失函数，能够通过单一可调参数统一多个m-估计器。通过自适应下调不可靠GNSS测量值的重要性来增强定位稳定性。

Result: 所提出的解决方案相较于标准固定滞后优化（FGO）减少了最高达41%的定位错误，并且在城市峡谷这样的复杂环境中，相比于使用扩展卡尔曼滤波(EKF)作为基准的方法，实现了更大的提升。

Conclusion: 研究结果突出了Barron损失函数在提高基于GNSS/IMU导航于城市或信号干扰环境下韧性方面的优势。

Abstract: Reliable positioning in GNSS-challenged environments remains a critical challenge for navigation systems. Tightly coupled GNSS/IMU fusion improves robustness but remains vulnerable to non-Gaussian noise and outliers. We present a robust and adaptive factor graph-based fusion framework that directly integrates GNSS pseudorange measurements with IMU preintegration factors and incorporates the Barron loss, a general robust loss function that unifies several m-estimators through a single tunable parameter. By adaptively down weighting unreliable GNSS measurements, our approach improves resilience positioning. The method is implemented in an extended GTSAM framework and evaluated on the UrbanNav dataset. The proposed solution reduces positioning errors by up to 41% relative to standard FGO, and achieves even larger improvements over extended Kalman filter (EKF) baselines in urban canyon environments. These results highlight the benefits of Barron loss in enhancing the resilience of GNSS/IMU-based navigation in urban and signal-compromised environments.

</details>


### [30] [DiskChunGS: Large-Scale 3D Gaussian SLAM Through Chunk-Based Memory Management](https://arxiv.org/abs/2511.23030)
*Casimir Feldmann,Maximum Wilder-Smith,Vaishakh Patil,Michael Oechsle,Michael Niemeyer,Keisuke Tateno,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种名为DiskChunGS的可扩展3D高斯点阵SLAM系统，通过将场景划分为空间块并仅在GPU内存中保留活跃区域来克服了现有方法因GPU内存容量限制而只能重建小规模环境的问题。该系统能与现有的SLAM框架无缝集成，并在全球一致的大规模重建方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯点阵（3DGS）技术虽然在新颖视图合成上表现优异且具有实时渲染能力，但与SLAM系统的集成遇到了一个根本性的可扩展性问题：受制于GPU内存容量，这些方法只能用于重建小规模环境。

Method: 研究者们开发了DiskChunGS，一种创新的3DGS SLAM系统，它采用了一种外部存储策略，将场景分割成多个空间块，并只让当前活动的部分驻留在GPU内存中，其余部分则存储于磁盘上。此外，该架构设计能够与现有的SLAM框架轻松对接，支持姿态估计和回环闭合等功能。

Result: 实验验证表明，DiskChunGS不仅能够在室内环境(如Replica, TUM-RGBD)、城市驾驶场景(KITTI)以及资源受限的Nvidia Jetson平台上有效运行，而且是唯一能够顺利完成所有11个KITTI序列而不出现内存错误的方法，同时还能保持较高的视觉质量。

Conclusion: 通过算法上的革新，DiskChunGS成功解决了之前3DGS SLAM方法由于内存限制所面临的挑战，实现了大规模环境下的全局一致性重建。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated impressive results for novel view synthesis with real-time rendering capabilities. However, integrating 3DGS with SLAM systems faces a fundamental scalability limitation: methods are constrained by GPU memory capacity, restricting reconstruction to small-scale environments. We present DiskChunGS, a scalable 3DGS SLAM system that overcomes this bottleneck through an out-of-core approach that partitions scenes into spatial chunks and maintains only active regions in GPU memory while storing inactive areas on disk. Our architecture integrates seamlessly with existing SLAM frameworks for pose estimation and loop closure, enabling globally consistent reconstruction at scale. We validate DiskChunGS on indoor scenes (Replica, TUM-RGBD), urban driving scenarios (KITTI), and resource-constrained Nvidia Jetson platforms. Our method uniquely completes all 11 KITTI sequences without memory failures while achieving superior visual quality, demonstrating that algorithmic innovation can overcome the memory constraints that have limited previous 3DGS SLAM methods.

</details>


### [31] [LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models](https://arxiv.org/abs/2511.23034)
*Zuolei Li,Xingyu Gao,Xiaofan Wang,Jianlong Fu*

Main category: cs.RO

TL;DR: 提出了一种通用的潜在动作学习框架，该框架通过优化未来帧重建和动作序列预测来处理任务指令和多帧输入，从而在模拟和真实机器人设置中实现了强大的性能，并展示了在机器人操作中的少样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要依赖于视觉重建目标，而忽略了物理先验信息，导致学习通用表示的效果不佳。为了提高下游机器人任务的泛化能力，本文旨在通过学习大规模物体操作视频中的可转移潜在动作来解决这一问题。

Method: 提出了一种名为Universal Latent Action Learning (ULA) 的框架，它以任务指令和多帧图像作为输入，并同时优化未来帧重建与动作序列预测。此外，还通过将潜在动作分解为可学习的运动和场景标记，区分了机器人的主动移动与环境变化，进而过滤掉无关动态。

Result: 所提方法在最新的VLA模型上提炼出的学习到的潜在动作，在SIMPLER和LIBERO等模拟环境中以及Franka机器人的真实世界设置下都取得了优异的表现。特别地，仅用每个任务10条真实轨迹，就成功完成了全部五个挑战性任务，证明了其在机器人操作领域的强大少样本迁移能力。

Conclusion: 通过结合更丰富的物理先验（如真实世界的距离和方向）并利用潜在动作分解技术，本研究提出的ULA框架显著增强了从视频中学习到的动作表示的迁移性，对于促进机器人学领域的发展具有重要意义。

Abstract: Learning transferable latent actions from large-scale object manipulation videos can significantly enhance generalization in downstream robotics tasks, as such representations are agnostic to different robot embodiments. Existing approaches primarily rely on visual reconstruction objectives while neglecting physical priors, leading to sub-optimal performance in learning universal representations. To address these challenges, we propose a Universal Latent Action Learning framework that takes task instructions and multiple frames as inputs, and optimizes both future frame reconstruction and action sequence prediction. Unlike prior works, incorporating action predictions (e.g., gripper or hand trajectories and orientations) allows the model to capture richer physical priors such as real-world distances and orientations, thereby enabling seamless transferability to downstream tasks. We further decompose the latent actions into learnable motion and scene tokens to distinguish the robot's active movements from environmental changes, thus filtering out irrelevant dynamics. By distilling the learned latent actions into the latest VLA models, we achieve strong performance across both simulated (SIMPLER and LIBERO) and real-world robot settings. Notably, with only 10 real-world trajectories per task collected on a Franka robot, our approach successfully completes all five challenging tasks, demonstrating strong few-shot transferability in robotic manipulation.

</details>


### [32] [Automated Generation of MDPs Using Logic Programming and LLMs for Robotic Applications](https://arxiv.org/abs/2511.23143)
*Enrico Saccon,Davide De Martini,Matteo Saveriano,Edoardo Lamon,Luigi Palopoli,Marco Roveri*

Main category: cs.RO

TL;DR: 该论文提出了一种新的框架，通过将大型语言模型与自动规划和形式验证相结合来简化马尔可夫决策过程（MDP）的创建和使用。利用大型语言模型从自然语言描述中提取结构化知识，并自动生成MDP以及最优策略。在三个真人-机器人交互场景中的应用证明了其有效性，展示了结合语言模型与形式方法促进机器人领域概率规划更易访问性和扩展性的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在通过整合大型语言模型、自动化规划及形式验证技术，简化马尔可夫决策过程（MDP）的构建与应用，减少人工干预的同时提高效率。

Method: 首先运用大型语言模型从自然语言描述中抽取信息形成Prolog知识库；接着基于可达性分析自动生成MDP；然后利用Storm模型检测器合成最优策略；最后将生成的策略导出为状态-动作表以供执行。

Result: 在三种不同的人机交互情境下成功验证了所提框架的有效性，能够以极少的人工劳动量产出可执行策略。

Conclusion: 研究表明，通过将语言模型与形式方法相融合，可以实现更为便捷且具备良好扩展性的机器人领域概率规划解决方案。

Abstract: We present a novel framework that integrates Large Language Models (LLMs) with automated planning and formal verification to streamline the creation and use of Markov Decision Processes (MDP). Our system leverages LLMs to extract structured knowledge in the form of a Prolog knowledge base from natural language (NL) descriptions. It then automatically constructs an MDP through reachability analysis, and synthesises optimal policies using the Storm model checker. The resulting policy is exported as a state-action table for execution. We validate the framework in three human-robot interaction scenarios, demonstrating its ability to produce executable policies with minimal manual effort. This work highlights the potential of combining language models with formal methods to enable more accessible and scalable probabilistic planning in robotics.

</details>


### [33] [Obstruction reasoning for robotic grasping](https://arxiv.org/abs/2511.23186)
*Runyu Jiao,Matteo Bortolon,Francesco Giuliari,Alice Fasoli,Sergio Povoli,Guofeng Mei,Yiming Wang,Fabio Poiesi*

Main category: cs.RO

TL;DR: UNOGrasp, a vision-language model, excels in obstruction reasoning for robotic grasping in cluttered environments. It uses a multi-step reasoning process and is trained on UNOBench, a large dataset with human-annotated obstruction paths. The model outperforms alternatives in both synthetic and real-world settings.


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言具身推理模型在障碍物推理和可达性规划方面存在局限。为了克服这些限制，研究者们开发了UNOGrasp模型，该模型能够进行基于视觉的障碍物推理，并推断出需要执行的动作序列以清除通向目标物体路径上的障碍物。

Method: 提出了名为UNOGrasp的学习型视觉-语言模型，该模型通过一个新颖的多步推理过程来处理由目标对象引发的障碍路径问题。每个推理步骤都结合了对障碍物敏感的视觉线索以增强推理能力。此外，还构建了一个大规模数据集UNOBench用于训练与基准测试，其中包含超过10万个由人类标注的带有障碍比率、接触点及自然语言指令的障碍路径。

Result: 广泛的实验和真实机器人评估表明，在合成环境和现实世界环境中，UNOGrasp显著提高了障碍物推理能力和抓取成功率，表现优于通用和其他专有解决方案。

Conclusion: UNOGrasp为机器人在杂乱环境中的抓取任务提供了有效支持，特别是在需要考虑障碍物的情况下。通过结合监督学习与强化微调，以及利用专门设计的数据集，该方法展示了在复杂场景下提高抓取性能的巨大潜力。

Abstract: Successful robotic grasping in cluttered environments not only requires a model to visually ground a target object but also to reason about obstructions that must be cleared beforehand. While current vision-language embodied reasoning models show emergent spatial understanding, they remain limited in terms of obstruction reasoning and accessibility planning. To bridge this gap, we present UNOGrasp, a learning-based vision-language model capable of performing visually-grounded obstruction reasoning to infer the sequence of actions needed to unobstruct the path and grasp the target object. We devise a novel multi-step reasoning process based on obstruction paths originated by the target object. We anchor each reasoning step with obstruction-aware visual cues to incentivize reasoning capability. UNOGrasp combines supervised and reinforcement finetuning through verifiable reasoning rewards. Moreover, we construct UNOBench, a large-scale dataset for both training and benchmarking, based on MetaGraspNetV2, with over 100k obstruction paths annotated by humans with obstruction ratios, contact points, and natural-language instructions. Extensive experiments and real-robot evaluations show that UNOGrasp significantly improves obstruction reasoning and grasp success across both synthetic and real-world environments, outperforming generalist and proprietary alternatives. Project website: https://tev-fbk.github.io/UnoGrasp/.

</details>


### [34] [Field-programmable dynamics in a soft magnetic actuator enabling true random number generation and reservoir computing](https://arxiv.org/abs/2511.23215)
*Eduardo Sergio Oliveros-Mata,Oleksandr V. Pylypovskyi,Eleonora Raimondo,Rico Illing,Yevhen Zabila,Lin Guo,Guannan Mu,Mónica Navarro López,Xu Wang,Georgios Tzortzinis,Angelos Filippatos,Gilbert Santiago Cañón Bermúdez,Francesca Garescì,Giovanni Finocchio,Denys Makarov*

Main category: cs.RO

TL;DR: 研究人员展示了在软体机器人中利用复杂动力学的优势，通过设计能够长时间运行的磁性软执行器，实现了真正随机数生成、随机计算和时间序列预测等新功能。


<details>
  <summary>Details</summary>
Motivation: 尽管复杂乃至混沌的动力学在许多自然和工程系统中普遍存在，但出于对磨损和可控性的担忧，在机电系统的设计中往往被避免使用。研究者认为，在软体机器人领域，这种复杂动力学可能特别有利，能够提供传统驱动方法难以实现的新功能。

Method: 设计并制造了具有可调动态范围且能在数万次循环中无疲劳工作的韧性磁性软执行器，并通过实验验证了这些执行器在真正随机数生成、随机计算以及作为物理储存器进行Mackey-Glass时间序列预测方面的应用。

Result: 所开发的软执行器不仅能够在复杂的动态环境下稳定工作，还成功地应用于多种场景，包括随机数生成、随机计算及时间序列预测，证明了软体机器人在软计算、人机交互与协作机器人等领域中的潜在价值。

Conclusion: 探索软体机器人中的复杂动力学可以拓展其在软计算、人机互动以及协作机器人等方面的应用场景，这为未来软体机器人的发展提供了新的方向。

Abstract: Complex and even chaotic dynamics, though prevalent in many natural and engineered systems, has been largely avoided in the design of electromechanical systems due to concerns about wear and controlability. Here, we demonstrate that complex dynamics might be particularly advantageous in soft robotics, offering new functionalities beyond motion not easily achievable with traditional actuation methods. We designed and realized resilient magnetic soft actuators capable of operating in a tunable dynamic regime for tens of thousands cycles without fatigue. We experimentally demonstrated the application of these actuators for true random number generation and stochastic computing. {W}e validate soft robots as physical reservoirs capable of performing Mackey--Glass time series prediction. These findings show that exploring the complex dynamics in soft robotics would extend the application scenarios in soft computing, human-robot interaction and collaborative robots as we demonstrate with biomimetic blinking and randomized voice modulation.

</details>


### [35] [Incorporating Ephemeral Traffic Waves in A Data-Driven Framework for Microsimulation in CARLA](https://arxiv.org/abs/2511.23236)
*Alex Richardson,Azhar Hasan,Gabor Karsai,Jonathan Sprinkle*

Main category: cs.RO

TL;DR: 本文介绍了一种在CARLA中基于数据驱动的交通微观模拟框架，该框架通过I-24 MOTION测试平台的高保真时空间数据重构了现实世界中的波动态。与以往侧重于局部跟车行为或抽象几何图形的仿真工作不同，本框架旨在实现全时空图谱的逼真度，并作为验证目标。利用CARLA丰富的传感器套件和可配置的车辆动力学特性，我们模拟了低拥堵和高拥堵场景下的波形成与消散过程，为评估交通控制策略、感知驱动自主性以及未来波缓解解决方案的部署提供了一个新颖的共仿真框架。


<details>
  <summary>Details</summary>
Motivation: 交通微观模拟器中重现如交通波这样的瞬态现象是充满挑战的过程。本文旨在重新考虑交通状态数据的存在形式，将其作为自我车辆穿越之前记录的交通数据时的边界条件，而不是在经过校准的微观模拟中复制这些交通现象。目的是建立一个能够更准确地反映真实交通流动特性的仿真环境。

Method: 方法包括自动生成对应于I-24的一英里高速公路段，并使用I-24的数据来驱动一个协同仿真模块，将交通信息注入到仿真中。围绕从实证数据中采样的自我车辆进行CARLA和协同仿真，同时自动产生自我车辆纵向范围内的“可见”交通。对于超出这些可见范围之外的边界控制，则采用位于自我车辆前后（即上游和下游）的幽灵单元来实现。

Result: 结果表明，所生成的涌现行为非常接近真实的交通情况，这提供了一种新的共仿真框架，用于评价交通控制策略、感知驱动的自主性和未来波缓解解决方案的部署。

Conclusion: 本研究首次实现了感知上逼真的、边界驱动的经验交通波现象仿真，填补了微观建模与物理实验数据之间的空白。

Abstract: This paper introduces a data-driven traffic microsimulation framework in CARLA that reconstructs real-world wave dynamics using high-fidelity time-space data from the I-24 MOTION testbed. Calibration of road networks in microsimulators to reproduce ephemeral phenomena such as traffic waves for large-scale simulation is a process that is fraught with challenges. This work reconsiders the existence of the traffic state data as boundary conditions on an ego vehicle moving through previously recorded traffic data, rather than reproducing those traffic phenomena in a calibrated microsim. Our approach is to autogenerate a 1 mile highway segment corresponding to I-24, and use the I-24 data to power a cosimulation module that injects traffic information into the simulation. The CARLA and cosimulation simulations are centered around an ego vehicle sampled from the empirical data, with autogeneration of "visible" traffic within the longitudinal range of the ego vehicle. Boundary control beyond these visible ranges is achieved using ghost cells behind (upstream) and ahead (downstream) of the ego vehicle. Unlike prior simulation work that focuses on local car-following behavior or abstract geometries, our framework targets full time-space diagram fidelity as the validation objective. Leveraging CARLA's rich sensor suite and configurable vehicle dynamics, we simulate wave formation and dissipation in both low-congestion and high-congestion scenarios for qualitative analysis. The resulting emergent behavior closely mirrors that of real traffic, providing a novel cosimulation framework for evaluating traffic control strategies, perception-driven autonomy, and future deployment of wave mitigation solutions. Our work bridges microscopic modeling with physical experimental data, enabling the first perceptually realistic, boundary-driven simulation of empirical traffic wave phenomena in CARLA.

</details>


### [36] [SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot](https://arxiv.org/abs/2511.23300)
*Yara Mahmoud,Jeffrin Sam,Nguyen Khang,Marcelino Fernando,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Muhammad Haris Khan,Artem Lykov,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文提出了一种名为SafeHumanoid的自我中心视觉处理方法，该方法结合了视觉语言模型和检索增强生成技术来为人形机器人调整阻抗和速度参数。通过一系列实验验证了该系统能够根据场景上下文自适应地改变机器人的刚度、阻尼和速度配置文件，从而在保持任务完成的同时提高了安全性。


<details>
  <summary>Details</summary>
Motivation: 为了实现安全且值得信赖的人机交互（HRI），不仅需要机器人能够完成任务，还需要它们能够依据环境背景及人类距离调整其阻抗与速度。

Method: 开发了SafeHumanoid，一个基于自我视角的视觉处理流程，它将视觉语言模型（VLMs）与检索增强生成（RAG）相结合，用于为类人机器人调度阻抗和速度参数。通过对自我中心帧进行结构化的VLM提示处理，嵌入并与经过验证的情景数据库匹配，并通过逆运动学映射到关节级阻抗命令。

Result: 实验结果表明，该管道能够以情境感知的方式调整刚度、阻尼和速度曲线，在保持任务成功的同时提高了安全性。尽管当前推理延迟（高达1.4秒）限制了在高度动态设置下的响应性，但SafeHumanoid展示了语义基础的阻抗控制是通往更安全、符合标准的人形协作的一条可行路径。

Conclusion: 虽然存在一些关于响应时间上的局限性，SafeHumanoid系统证明了利用语义理解来控制阻抗是一种实现更安全、更加符合标准的人形机器人合作的有效途径。

Abstract: Safe and trustworthy Human Robot Interaction (HRI) requires robots not only to complete tasks but also to regulate impedance and speed according to scene context and human proximity. We present SafeHumanoid, an egocentric vision pipeline that links Vision Language Models (VLMs) with Retrieval-Augmented Generation (RAG) to schedule impedance and velocity parameters for a humanoid robot. Egocentric frames are processed by a structured VLM prompt, embedded and matched against a curated database of validated scenarios, and mapped to joint-level impedance commands via inverse kinematics. We evaluate the system on tabletop manipulation tasks with and without human presence, including wiping, object handovers, and liquid pouring. The results show that the pipeline adapts stiffness, damping, and speed profiles in a context-aware manner, maintaining task success while improving safety. Although current inference latency (up to 1.4 s) limits responsiveness in highly dynamic settings, SafeHumanoid demonstrates that semantic grounding of impedance control is a viable path toward safer, standard-compliant humanoid collaboration.

</details>


### [37] [From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products](https://arxiv.org/abs/2511.23407)
*Jan Baumgärtner,Malte Hansjosten,David Hald,Adrian Hauptmannl,Alexander Puchta,Jürgen Fleischer*

Main category: cs.RO

TL;DR: 本文提出了一种将产品拆卸视为部分可观测马尔可夫决策过程（POMDP）的方法，以处理报废产品因磨损、腐蚀或未记录的维修而与初始设计存在偏差的问题。通过结合CAD数据、机器人能力和检查结果自动生成特定POMDP模型，并采用强化学习方法和贝叶斯滤波器来维护执行过程中对潜在报废条件的信念估计。实验表明该框架在平均拆卸时间和差异性方面优于确定性基线，并能适应不同机器人设置及CAD模型中的偏差。


<details>
  <summary>Details</summary>
Motivation: 支持循环经济不仅需要机器人系统能够组装新产品，还需要它们能够拆卸报废产品以便再利用、回收或安全处置。然而，现有的拆卸序列规划方法通常假设产品模型是确定性和完全可观察的，这与现实中报废产品由于磨损、腐蚀或未经文档化的修理导致的实际状态往往不符。因此，需要一种新的方法来处理这种不确定性。

Method: 本文将拆卸过程建模为一个部分可观测马尔可夫决策过程（POMDP），其中隐藏变量代表不确定的结构或物理属性。基于此模型，提出了一种任务与运动规划框架，能够根据CAD数据、机器人能力及检查结果自动导出具体的POMDP模型。为获得可行策略，采用了强化学习方法处理由先验检查信息告知的随机动作结果，同时使用贝叶斯滤波器在执行期间持续更新关于隐含报废状况的置信度。

Result: 通过在两个机器人系统上对三种产品进行测试，证明了所提出的概率规划框架在平均拆卸时间及方差方面优于确定性基准方案，且能够在不同的机器人配置下良好运作。此外，该框架还成功应对了诸如缺失部件或卡住部件等偏离CAD模型的情况。

Conclusion: 研究表明，将拆卸问题建模为POMDP并结合强化学习与贝叶斯过滤技术，可以有效提高机器人拆卸报废产品的效率和灵活性。这种方法不仅能够更好地处理现实世界中报废产品存在的不确定性，而且展示了良好的泛化能力。

Abstract: To support the circular economy, robotic systems must not only assemble new products but also disassemble end-of-life (EOL) ones for reuse, recycling, or safe disposal. Existing approaches to disassembly sequence planning often assume deterministic and fully observable product models, yet real EOL products frequently deviate from their initial designs due to wear, corrosion, or undocumented repairs. We argue that disassembly should therefore be formulated as a Partially Observable Markov Decision Process (POMDP), which naturally captures uncertainty about the product's internal state. We present a mathematical formulation of disassembly as a POMDP, in which hidden variables represent uncertain structural or physical properties. Building on this formulation, we propose a task and motion planning framework that automatically derives specific POMDP models from CAD data, robot capabilities, and inspection results. To obtain tractable policies, we approximate this formulation with a reinforcement-learning approach that operates on stochastic action outcomes informed by inspection priors, while a Bayesian filter continuously maintains beliefs over latent EOL conditions during execution. Using three products on two robotic systems, we demonstrate that this probabilistic planning framework outperforms deterministic baselines in terms of average disassembly time and variance, generalizes across different robot setups, and successfully adapts to deviations from the CAD model, such as missing or stuck parts.

</details>
