<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 13]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [A Robust Task-Level Control Architecture for Learned Dynamical Systems](https://arxiv.org/abs/2511.09790)
*Eshika Pathak,Ahmed Aboudonia,Sandeep Banik,Naira Hovakimyan*

Main category: cs.RO

TL;DR: 提出了一种新的任务级鲁棒控制架构L1-增强动力系统（L1-DS），该架构通过结合名义稳定控制器和L1自适应控制器来处理基于动力系统学习示教方法生成的运动计划中的任务执行不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决由于未建模的动力学、持续的干扰和系统延迟导致机器人在执行基于动力系统的学习示教方案时，实际任务空间状态与期望运动轨迹之间的偏差问题。

Method: 提出了一个名为L1-增强动力系统的新型控制框架，它将任何基于动力系统的学习示教模型与名义稳定控制器和L1自适应控制器相结合，并引入了一个基于窗口动态时间规整的目标选择器以改善相位一致性跟踪。

Result: 通过LASA和IROS手写数据集验证了所提架构的有效性。

Conclusion: L1-增强动力系统架构提供了一种有效的方法来减少任务执行过程中出现的偏差，从而提高了机器人按照基于动力系统学习示教方法生成的运动计划进行操作时的一致性和准确性。

Abstract: Dynamical system (DS)-based learning from demonstration (LfD) is a powerful tool for generating motion plans in the operation (`task') space of robotic systems. However, the realization of the generated motion plans is often compromised by a ''task-execution mismatch'', where unmodeled dynamics, persistent disturbances, and system latency cause the robot's actual task-space state to diverge from the desired motion trajectory. We propose a novel task-level robust control architecture, L1-augmented Dynamical Systems (L1-DS), that explicitly handles the task-execution mismatch in tracking a nominal motion plan generated by any DS-based LfD scheme. Our framework augments any DS-based LfD model with a nominal stabilizing controller and an L1 adaptive controller. Furthermore, we introduce a windowed Dynamic Time Warping (DTW)-based target selector, which enables the nominal stabilizing controller to handle temporal misalignment for improved phase-consistent tracking. We demonstrate the efficacy of our architecture on the LASA and IROS handwriting datasets.

</details>


### [2] [Provably Safe Stein Variational Clarity-Aware Informative Planning](https://arxiv.org/abs/2511.09836)
*Kaleb Ben Naveed,Utkrisht Sahai,Anouck Girard,Dimitra Panagou*

Main category: cs.RO

TL;DR: 本文提出了一种新的规划框架，用于在信息衰减速率不均匀且存在障碍物的环境中为自主机器人规划既安全又具信息量的轨迹。通过引入清晰度概念来表示环境中的不确定性，并结合Stein变分推理进行贝叶斯学习，该框架能够在确保安全的同时减少信息缺失。


<details>
  <summary>Details</summary>
Motivation: 当前大多数路径规划器要么将信息视为静态或均匀衰减，忽略了空间上衰减速率不同的情况；要么忽视了信息随机器人运动而变化的方式；并且几乎都将安全性视为软约束条件。这导致了在复杂多变的实际环境中难以有效规划出既安全又能最大化信息收集效率的路径。

Method: 1. 采用'清晰度'这一标准化差熵表示方法来捕捉信息随新测量值改善以及未被再次访问区域中信息随时间衰退的情况。
2. 提出了Stein变分清晰度感知信息规划框架，该框架将清晰度动态嵌入到轨迹优化过程中，并通过基于先前门卫框架的安全验证机制来强制执行安全性。
3. 利用Stein变分推断进行贝叶斯学习，不断优化具有信息价值的轨迹分布，并过滤掉每个名义上的Stein信息轨迹以保证其安全性。

Result: 实验结果表明，在不同衰减速率和障碍物存在的环境下，所提出的规划方法能够保持一致的安全性并显著减少了信息缺口。

Conclusion: 本研究开发的新规划框架成功解决了在非均匀信息衰减条件下同时考虑安全性和信息获取效率的问题，为未来更广泛的应用场景下的自主机器人路径规划提供了有价值的解决方案。

Abstract: Autonomous robots are increasingly deployed for information-gathering tasks in environments that vary across space and time. Planning informative and safe trajectories in such settings is challenging because information decays when regions are not revisited. Most existing planners model information as static or uniformly decaying, ignoring environments where the decay rate varies spatially; those that model non-uniform decay often overlook how it evolves along the robot's motion, and almost all treat safety as a soft penalty. In this paper, we address these challenges. We model uncertainty in the environment using clarity, a normalized representation of differential entropy from our earlier work that captures how information improves through new measurements and decays over time when regions are not revisited. Building on this, we present Stein Variational Clarity-Aware Informative Planning, a framework that embeds clarity dynamics within trajectory optimization and enforces safety through a low-level filtering mechanism based on our earlier gatekeeper framework for safety verification. The planner performs Bayesian inference-based learning via Stein variational inference, refining a distribution over informative trajectories while filtering each nominal Stein informative trajectory to ensure safety. Hardware experiments and simulations across environments with varying decay rates and obstacles demonstrate consistent safety and reduced information deficits.

</details>


### [3] [PuffyBot: An Untethered Shape Morphing Robot for Multi-environment Locomotion](https://arxiv.org/abs/2511.09885)
*Shashwat Singh,Zilin Si,Zeynep Temel*

Main category: cs.RO

TL;DR: PuffyBot is a shape-morphing, untethered robot inspired by amphibians that can adapt to both terrestrial and aquatic environments. It uses a scissor-lift mechanism for volume change and buoyancy adjustment, allowing it to crawl, swim, and transition between different modes of locomotion. The robot is waterproof, capable of operating for two hours on a single battery charge, and demonstrates the potential for versatile and energy-efficient robotic platforms.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to develop a robot that can mimic the adaptability of amphibians in moving through diverse environments, specifically to create a versatile and energy-efficient robotic platform that can navigate both land and water effectively. This is achieved through the implementation of a unique shape-morphing design that allows for multi-environment locomotion.

Method: The method involves designing PuffyBot with a scissor-lift mechanism actuated by a linear motor to enable body shape transformation. A bell-crank linkage is used to adjust the limbs' orientation, facilitating the switch between crawling and swimming. The robot's waterproofing is ensured by using TPU fabric, and it is powered by an onboard 1000 mA h battery, enabling it to operate independently for up to two hours.

Result: The results show that PuffyBot can successfully perform multi-environment locomotion, including crawling on land, crawling underwater, swimming on the surface, and adjusting its buoyancy to submerge or resurface. The robot is able to modulate its volume from 255.00 cm³ to 423.75 cm³, which is sufficient to counteract the gravitational force due to its 330 g mass.

Conclusion: In conclusion, PuffyBot exemplifies the potential of shape-morphing technology to produce robots that are adaptable to multiple environments, thereby paving the way for the development of more versatile and energy-efficient robotic systems.

Abstract: Amphibians adapt their morphologies and motions to accommodate movement in both terrestrial and aquatic environments. Inspired by these biological features, we present PuffyBot, an untethered shape morphing robot capable of changing its body morphology to navigate multiple environments. Our robot design leverages a scissor-lift mechanism driven by a linear actuator as its primary structure to achieve shape morphing. The transformation enables a volume change from 255.00 cm3 to 423.75 cm3, modulating the buoyant force to counteract a downward force of 3.237 N due to 330 g mass of the robot. A bell-crank linkage is integrated with the scissor-lift mechanism, which adjusts the servo-actuated limbs by 90 degrees, allowing a seamless transition between crawling and swimming modes. The robot is fully waterproof, using thermoplastic polyurethane (TPU) fabric to ensure functionality in aquatic environments. The robot can operate untethered for two hours with an onboard battery of 1000 mA h. Our experimental results demonstrate multi-environment locomotion, including crawling on the land, crawling on the underwater floor, swimming on the water surface, and bimodal buoyancy adjustment to submerge underwater or resurface. These findings show the potential of shape morphing to create versatile and energy efficient robotic platforms suitable for diverse environments.

</details>


### [4] [A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation](https://arxiv.org/abs/2511.09932)
*Hanwen Wang*

Main category: cs.RO

TL;DR: 研究了通过增加数据生成的自动化和多样化来提高视觉运动策略泛化能力的方法，包括相机姿态、光照条件等随机因素，并在低成本操作器上测试了该方法对零样本模拟到现实迁移的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法虽然可以收集大量的轨迹增强数据以训练更通用的模仿学习策略，但这些数据缺乏多样性，限制了训练出的策略的泛化能力。因此，有必要探索如何通过自动化生成影响泛化的因素的数据来改进政策的表现。

Method: 创建了一个包含更多随机化因素的数据集，如不同类型的机械臂和夹爪、相机姿态、光照条件、桌面纹理及高度等，并研究了这些因素对于策略泛化能力的影响。

Result: 所有研究中的随机化因素都对策略的泛化能力有影响，任何形式的随机化都能增强策略的泛化性，特别是多样的轨迹对于跨越视觉差距特别有效。此外，在低成本操作器上验证了所提场景随机化方法能够提高视觉运动策略从模拟到实际零样本转移的泛化能力。

Conclusion: 通过引入更多样化的数据生成过程，尤其是针对显著影响泛化的因素进行自动化处理，可以有效提升视觉运动策略的泛化性能，使得策略能够在未见过的情境下表现良好。

Abstract: The generalization ability of visuomotor policy is crucial, as a good policy should be deployable across diverse scenarios. Some methods can collect large amounts of trajectory augmentation data to train more generalizable imitation learning policies, aimed at handling the random placement of objects on the scene's horizontal plane. However, the data generated by these methods still lack diversity, which limits the generalization ability of the trained policy. To address this, we investigate the performance of policies trained by existing methods across different scene layout factors via automate the data generation for those factors that significantly impact generalization. We have created a more extensively randomized dataset that can be efficiently and automatically generated with only a small amount of human demonstration. The dataset covers five types of manipulators and two types of grippers, incorporating extensive randomization factors such as camera pose, lighting conditions, tabletop texture, and table height across six manipulation tasks. We found that all of these factors influence the generalization ability of the policy. Applying any form of randomization enhances policy generalization, with diverse trajectories particularly effective in bridging visual gap. Notably, we investigated on low-cost manipulator the effect of the scene randomization proposed in this work on enhancing the generalization capability of visuomotor policies for zero-shot sim-to-real transfer.

</details>


### [5] [Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2511.09958)
*Xiangyi Wei,Haotian Zhang,Xinyi Cao,Siyu Xie,Weifeng Ge,Yang Li,Changbo Wang*

Main category: cs.RO

TL;DR: 本文提出了一种新的多模态操作策略Audio-VLA，它通过结合视觉和声音信息来改善机器人在动态交互过程中的感知能力，并引入了任务完成率（TCR）这一度量标准来系统地评估这些过程。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型(Vision-Language-Action, VLA)在机器人操作方面取得了显著进展，但仅依赖视觉信息限制了它们对互动和操作过程中动态变化的感知。为了解决这一问题，提出了Audio-VLA模型，旨在利用接触音频来增强对接触事件及动态过程反馈的理解。

Method: Audio-VLA采用预训练的DINOv2和SigLIP作为视觉编码器、AudioCLIP作为音频编码器以及Llama2作为大型语言模型基础。通过LoRA微调技术调整这些预训练组件，以实现跨模态理解能力。此外，还设计了一个多模态投影层用于将不同来源的信息特征映射到同一空间中。研究者们也增强了RLBench与LIBERO模拟环境，增加了基于碰撞的声音生成机制，以便于在物体交互期间提供真实的听觉反馈。

Result: 广泛的实验结果表明，在LIBERO、RLBench平台以及两项实际任务上，相较于仅使用视觉信息的方法，Audio-VLA表现出了更好的性能；同时，新提出的TCR指标能够有效地量化机器人在执行任务时对动态过程的感知能力。

Conclusion: 通过引入Audio-VLA模型及TCR评价标准，本研究不仅克服了传统VLA模型存在的局限性，也为机器人操作领域提供了更全面的过程评估手段。

Abstract: The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

</details>


### [6] [Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008)
*Xuancun Lu,Jiaxiang Chen,Shilin Xiao,Zizhi Jin,Zhangrui Chen,Hanwen Yu,Bohan Qian,Ruochen Zhou,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.RO

TL;DR: 本研究首次系统地探讨了针对视觉-语言-动作（VLA）模型的物理传感器攻击，引入了一个新颖的'真实-模拟-真实'框架来模拟基于物理的攻击向量，并开发了一种对抗性训练防御方法以增强VLA模型对物理扰动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 鉴于基于视觉-语言-动作（VLA）的系统严重依赖于感官输入，而VLA模型在面对物理世界中的传感器攻击时的安全性仍处于未充分探索的状态，因此需要填补这一空白。

Method: 提出了一种新的'真实-模拟-真实'框架，该框架能够自动模拟针对相机和麦克风等传感器的基于物理原理的攻击，并在真实的机器人系统上进行了验证。此外，还开发了一种基于对抗性训练的防御机制，旨在提高VLA模型面对超出分布外物理扰动时的鲁棒性，同时保持模型性能。

Result: 通过跨越不同VLA架构与任务的大规模评估显示，在各种攻击参数下，VLA模型存在显著脆弱性，且这些易受攻击模式揭示了对于任务类型及模型设计的重要依赖关系。

Conclusion: 研究表明迫切需要建立标准化的鲁棒性基准测试以及缓解策略，以确保VLA部署在关键安全环境中的安全性。

Abstract: Vision-Language-Action (VLA) models revolutionize robotic systems by enabling end-to-end perception-to-action pipelines that integrate multiple sensory modalities, such as visual signals processed by cameras and auditory signals captured by microphones. This multi-modality integration allows VLA models to interpret complex, real-world environments using diverse sensor data streams. Given the fact that VLA-based systems heavily rely on the sensory input, the security of VLA models against physical-world sensor attacks remains critically underexplored.
  To address this gap, we present the first systematic study of physical sensor attacks against VLAs, quantifying the influence of sensor attacks and investigating the defenses for VLA models. We introduce a novel ``Real-Sim-Real'' framework that automatically simulates physics-based sensor attack vectors, including six attacks targeting cameras and two targeting microphones, and validates them on real robotic systems. Through large-scale evaluations across various VLA architectures and tasks under varying attack parameters, we demonstrate significant vulnerabilities, with susceptibility patterns that reveal critical dependencies on task types and model designs. We further develop an adversarial-training-based defense that enhances VLA robustness against out-of-distribution physical perturbations caused by sensor attacks while preserving model performance. Our findings expose an urgent need for standardized robustness benchmarks and mitigation strategies to secure VLA deployments in safety-critical environments.

</details>


### [7] [DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion](https://arxiv.org/abs/2511.10021)
*Egor Davydenko,Andrei Volchenkov,Vladimir Gerasimov,Roman Gorbachev*

Main category: cs.RO

TL;DR: 本文介绍了一种名为DecARt腿的新型电动机器人腿设计，该设计旨在实现敏捷移动，并引入了新的评估指标FAST。通过广泛的模拟和初步硬件实验对设计进行了评估。


<details>
  <summary>Details</summary>
Motivation: 作者希望设计一种能够执行敏捷运动的机器人腿，为此他们提出了具有解耦驱动、近似拟人外观以及新颖踝关节扭矩传递系统的DecARt腿。

Method: 采用准伸缩式运动学结构结合旋转电机进行解耦驱动；设计了面向前方的膝关节；开发了一种新的多杆系统用于从膝盖上方的电机传递脚踝力矩；提出并使用了`最快可达成摆动时间`（FAST）作为新度量来分析设计的敏捷性；通过大量仿真与初步硬件测试评估了性能。

Result: 结果表明，所提出的DecARt腿设计在FAST度量上优于其他设计，并且基于该设计的机器人在模拟和初步硬件实验中表现良好。

Conclusion: DecARt腿的设计为实现机器人的敏捷移动提供了一个有前景的方法，其独特的机制和良好的性能使其成为未来研究的一个有趣方向。

Abstract: In this paper, we propose a novel design of an electrically actuated robotic leg, called the DecARt (Decoupled Actuation Robot) Leg, aimed at performing agile locomotion. This design incorporates several new features, such as the use of a quasi-telescopic kinematic structure with rotational motors for decoupled actuation, a near-anthropomorphic leg appearance with a forward facing knee, and a novel multi-bar system for ankle torque transmission from motors placed above the knee. To analyze the agile locomotion capabilities of the design numerically, we propose a new descriptive metric, called the `Fastest Achievable Swing Time` (FAST), and perform a quantitative evaluation of the proposed design and compare it with other designs. Then we evaluate the performance of the DecARt Leg-based robot via extensive simulation and preliminary hardware experiments.

</details>


### [8] [Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning](https://arxiv.org/abs/2511.10087)
*Haidong Huang,Haiyue Zhu. Jiayu Song,Xixin Zhao,Yaohua Zhou,Jiayi Zhang,Yuze Zhai,Xiaocong Li*

Main category: cs.RO

TL;DR: 提出了一种名为UEPO的框架，通过多种子动态感知扩散策略、动态差异正则化机制和基于扩散的数据增强模块解决了离线到在线强化学习中的行为覆盖有限和分布偏移问题。在D4RL基准测试中显示了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 针对离线到在线强化学习（O2O-RL）中存在的两大挑战：多模态行为覆盖有限以及在线适应过程中的分布变化。

Method: UEPO框架，包含一个多种子动态感知扩散政策来捕捉多种模式而无需训练多个模型；一个动态差异正规化机制以确保物理上有意义的策略多样性；以及一个基于扩散的数据增强模块来提高动力学模型的一般性。

Result: 在D4RL基准测试中，对于移动任务UEPO相比Uni-O4实现了+5.9%的绝对改进，对于灵巧操作任务则达到了+12.4%的提升。

Conclusion: UEPO展示了强大的泛化能力和可扩展性，在解决离线到在线强化学习的关键挑战方面表现出色。

Abstract: Offline-to-online reinforcement learning (O2O-RL) has emerged as a promising paradigm for safe and efficient robotic policy deployment but suffers from two fundamental challenges: limited coverage of multimodal behaviors and distributional shifts during online adaptation. We propose UEPO, a unified generative framework inspired by large language model pretraining and fine-tuning strategies. Our contributions are threefold: (1) a multi-seed dynamics-aware diffusion policy that efficiently captures diverse modalities without training multiple models; (2) a dynamic divergence regularization mechanism that enforces physically meaningful policy diversity; and (3) a diffusion-based data augmentation module that enhances dynamics model generalization. On the D4RL benchmark, UEPO achieves +5.9\% absolute improvement over Uni-O4 on locomotion tasks and +12.4\% on dexterous manipulation, demonstrating strong generalization and scalability.

</details>


### [9] [Learning a Thousand Tasks in a Day](https://arxiv.org/abs/2511.10110)
*Kamil Dreczkowski,Pietro Vitiello,Vitalis Vosylius,Edward Johns*

Main category: cs.RO

TL;DR: 该研究通过将操作轨迹分解为顺序对齐和交互阶段，以及基于检索的泛化，提高了机器人模仿学习的数据效率。在每个任务少于10次演示的情况下，这种分解方法比单一阶段学习的数据效率提高了数量级。基于这些发现，研究人员开发了多任务轨迹转移（MT3）方法，可以从单个演示中学习日常操作任务，并且能够推广到新的对象实例。使用MT3方法，可以在不到24小时内教会机器人1,000种不同的日常任务。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人操作模仿学习方法往往需要数百或数千次的任务演示，这极大地限制了学习效率。本研究旨在通过探索两个基本先验——即操作轨迹的阶段性分解及基于检索的泛化能力——来提高学习效率。

Method: 研究者进行了3,450次现实世界实验，系统地考察了上述两种策略的有效性。他们比较了不同设计选择对于对齐与交互阶段的影响，并且分析了相较于目前主流的行为克隆单一策略下，这种方法在泛化能力和扩展趋势上的表现。基于这些观察，提出了多任务轨迹迁移(MT3)这一模仿学习方法，它结合了分解和检索技术。

Result: 在每项任务演示次数少于10次的情况下，分解方法相比于单一阶段学习在数据效率上实现了数量级的提升；而且，在对齐和交互两方面，检索方法始终优于行为克隆。此外，利用MT3方法能够在不到一天的人类演示时间内教会机器人完成1,000种不同的日常任务。

Conclusion: 通过引入任务分解和基于检索的学习策略，这项工作显著提升了机器人从少量示例中学习执行多种日常任务的能力。此外，它还展示了如何有效地让机器人适应未见过的新对象，从而为快速教授机器人大量技能提供了可能。

Abstract: Humans are remarkably efficient at learning tasks from demonstrations, but today's imitation learning methods for robot manipulation often require hundreds or thousands of demonstrations per task. We investigate two fundamental priors for improving learning efficiency: decomposing manipulation trajectories into sequential alignment and interaction phases, and retrieval-based generalisation. Through 3,450 real-world rollouts, we systematically study this decomposition. We compare different design choices for the alignment and interaction phases, and examine generalisation and scaling trends relative to today's dominant paradigm of behavioural cloning with a single-phase monolithic policy. In the few-demonstrations-per-task regime (<10 demonstrations), decomposition achieves an order of magnitude improvement in data efficiency over single-phase learning, with retrieval consistently outperforming behavioural cloning for both alignment and interaction. Building on these insights, we develop Multi-Task Trajectory Transfer (MT3), an imitation learning method based on decomposition and retrieval. MT3 learns everyday manipulation tasks from as little as a single demonstration each, whilst also generalising to novel object instances. This efficiency enables us to teach a robot 1,000 distinct everyday tasks in under 24 hours of human demonstrator time. Through 2,200 additional real-world rollouts, we reveal MT3's capabilities and limitations across different task families. Videos of our experiments can be found on at https://www.robot-learning.uk/learning-1000-tasks.

</details>


### [10] [RoboBenchMart: Benchmarking Robots in Retail Environment](https://arxiv.org/abs/2511.10276)
*Konstantin Soshin,Alexander Krapukhin,Andrei Spiridonov,Denis Shepelev,Gregorii Bukhtuev,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.RO

TL;DR: RoboBenchMart, a new benchmark for robotic manipulation in dark store settings, challenges current models and provides tools for research, including a store layout generator, trajectory generation, and evaluation tools.


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作基准主要集中在简化的桌面场景上，而RoboBenchMart旨在解决这一局限性，通过引入一个更具有挑战性和现实性的基准，专为暗店环境设计，在这种环境中，机器人必须处理多样化的杂货物品。

Method: 通过开发RoboBenchMart套件，其中包括程序化商店布局生成器、轨迹生成管道、评估工具以及微调的基线模型来支持进一步的研究。

Result: 当前最先进的通用模型在解决常见的零售任务时也面临困难。

Conclusion: RoboBenchMart为研究者提供了一个新的平台，以测试和改进在复杂且充满挑战的暗店环境下执行精细操作任务的机器人能力。

Abstract: Most existing robotic manipulation benchmarks focus on simplified tabletop scenarios, typically involving a stationary robotic arm interacting with various objects on a flat surface. To address this limitation, we introduce RoboBenchMart, a more challenging and realistic benchmark designed for dark store environments, where robots must perform complex manipulation tasks with diverse grocery items. This setting presents significant challenges, including dense object clutter and varied spatial configurations -- with items positioned at different heights, depths, and in close proximity. By targeting the retail domain, our benchmark addresses a setting with strong potential for near-term automation impact. We demonstrate that current state-of-the-art generalist models struggle to solve even common retail tasks. To support further research, we release the RoboBenchMart suite, which includes a procedural store layout generator, a trajectory generation pipeline, evaluation tools and fine-tuned baseline models.

</details>


### [11] [Improving dependability in robotized bolting operations](https://arxiv.org/abs/2511.10448)
*Lorenzo Pagliara,Violeta Redondo,Enrico Ferrentino,Manuel Ferre,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 本文提出了一种用于可靠机器人化拧紧任务的控制框架，该框架具有准确的驱动扭矩控制和主动顺从性，并通过多模态人机界面增强了操作员的情境感知和故障检测能力。实验验证了系统的有效性，但也指出了仅依赖单个摄像头实现全面情境感知的局限性。


<details>
  <summary>Details</summary>
Motivation: 工业装配及科研设施维护中的拧紧操作需要高精度和对故障的强大鲁棒性。尽管机器人解决方案有潜力提高操作安全性和效率，但现有系统仍缺乏可靠的自主性和故障管理能力。为解决这一差距，提出了一个针对机器人拧紧任务的控制框架。

Method: 开发了一个具备精确驱动扭矩控制与全程主动顺应性的控制系统架构，并设计了一个能够实时显示相关系统信息、支持自动与手动控制之间无缝切换的多模态人机交互界面。此外，还设置了一个高级监督者来协调执行过程并管理控制模式之间的转换，确保符合监管控制范式的同时保留人类操作员的权威。

Result: 在一个代表性的管法兰连接拧紧作业中，在多种故障条件下验证了该系统。结果显示，该系统提高了故障检测能力，增强了操作员的情景意识，并且能够准确而灵活地执行拧紧任务。不过，研究也揭示了单纯依靠单一摄像头难以达到完全的情景意识。

Conclusion: 所提出的控制框架在保证安全互动的同时提升了机器人化拧紧任务的可靠性与准确性。然而，为了进一步改进情景意识，未来的工作可能需要考虑集成更多传感器或采用其他技术手段以克服当前方案中存在的局限性。

Abstract: Bolting operations are critical in industrial assembly and in the maintenance of scientific facilities, requiring high precision and robustness to faults. Although robotic solutions have the potential to improve operational safety and effectiveness, current systems still lack reliable autonomy and fault management capabilities. To address this gap, we propose a control framework for dependable robotized bolting tasks and instantiate it on a specific robotic system. The system features a control architecture ensuring accurate driving torque control and active compliance throughout the entire operation, enabling safe interaction even under fault conditions. By designing a multimodal human-robot interface (HRI) providing real-time visualization of relevant system information and supporting seamless transitions between automatic and manual control, we improve operator situation awareness and fault detection capabilities. A high-level supervisor (SV) coordinates the execution and manages transitions between control modes, ensuring consistency with the supervisory control (SVC) paradigm, while preserving the human operator's authority. The system is validated in a representative bolting operation involving pipe flange joining, under several fault conditions. The results demonstrate improved fault detection capabilities, enhanced operator situational awareness, and accurate and compliant execution of the bolting operation. However, they also reveal the limitations of relying on a single camera to achieve full situational awareness.

</details>


### [12] [From Fold to Function: Dynamic Modeling and Simulation-Driven Design of Origami Mechanisms](https://arxiv.org/abs/2511.10580)
*Tianhui Han,Shashwat Singh,Sarvesh Patil,Zeynep Temel*

Main category: cs.RO

TL;DR: 本文提出了一种使用MuJoCo的可变形体能力来模拟折纸机制的设计框架，通过图形用户界面定义折痕和驱动等约束条件，实现了对折纸几何结构及其与外部物体交互的物理一致模拟。并通过一个折纸投石机的案例研究展示了该方法的有效性，利用CMA-ES算法在模拟中优化设计参数，并通过物理原型实验验证了优化结果，证明了系统能够快速支持基于模拟的折纸设计、优化及分析。


<details>
  <summary>Details</summary>
Motivation: 受到折纸启发的机构可以将平面板材转变为轻量、紧凑且能进行复杂运动的功能性三维动态结构，这些特性使其在机器人技术和可部署系统中越来越有价值。然而，准确地模拟其折叠行为以及与环境的互动仍然是具有挑战性的。

Method: 作者提出了一个利用MuJoCo的可变形体功能来模拟折纸机制的设计框架。在这个框架下，折纸被表示为由相互连接的可变形元素组成的图，并通过直观的图形用户界面（GUI）定义如折痕和致动这样的用户指定约束条件。

Result: 通过折纸投石机的案例研究，展示了该方法的应用价值。其中，设计参数在模拟中采用协方差矩阵适应进化策略（CMA-ES）进行了优化，并在物理原型上得到了实验验证。优化后的结构达成了更好的投掷性能。

Conclusion: 所开发的系统能够促进快速、基于仿真的折纸设计、优化和分析流程，从而改善折纸机械装置的实际表现。

Abstract: Origami-inspired mechanisms can transform flat sheets into functional three-dimensional dynamic structures that are lightweight, compact, and capable of complex motion. These properties make origami increasingly valuable in robotic and deployable systems. However, accurately simulating their folding behavior and interactions with the environment remains challenging. To address this, we present a design framework for origami mechanism simulation that utilizes MuJoCo's deformable-body capabilities. In our approach, origami sheets are represented as graphs of interconnected deformable elements with user-specified constraints such as creases and actuation, defined through an intuitive graphical user interface (GUI). This framework allows users to generate physically consistent simulations that capture both the geometric structure of origami mechanisms and their interactions with external objects and surfaces. We demonstrate our method's utility through a case study on an origami catapult, where design parameters are optimized in simulation using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and validated experimentally on physical prototypes. The optimized structure achieves improved throwing performance, illustrating how our system enables rapid, simulation-driven origami design, optimization, and analysis.

</details>


### [13] [Optimizing the flight path for a scouting Uncrewed Aerial Vehicle](https://arxiv.org/abs/2511.10598)
*Raghav Adhikari,Sachet Khatiwada,Suman Poudel*

Main category: cs.RO

TL;DR: 本研究提出了一种基于优化的方法，用于规划无人机在灾区的飞行路径，使其能够在最佳高度上覆盖尽可能多的区域并收集数据，同时最小化不确定性。


<details>
  <summary>Details</summary>
Motivation: 灾后情况下的导航面临独特挑战，尤其是环境的非结构化特性使得为救援车辆铺设路径变得困难。

Method: 提出使用无人飞行器（UAV）执行环境侦察任务，并采用一种基于优化的方法来规划UAV的飞行路径，确保其能在最优高度飞行以最大化传感器覆盖面积及减少数据收集时的不确定性。

Result: 该方法能够有效地让UAV在复杂环境中找到最佳飞行高度，从而提高对地面状况的监测效率与准确性。

Conclusion: 通过利用UAV和提出的优化策略，可以显著改善灾后环境中的导航问题，促进更有效的搜索与救援行动。

Abstract: Post-disaster situations pose unique navigation challenges. One of those challenges is the unstructured nature of the environment, which makes it hard to layout paths for rescue vehicles. We propose the use of Uncrewed Aerial Vehicle (UAV) in such scenario to perform reconnaissance across the environment. To accomplish this, we propose an optimization-based approach to plan a path for the UAV at optimal height where the sensors of the UAV can cover the most area and collect data with minimum uncertainty.

</details>
