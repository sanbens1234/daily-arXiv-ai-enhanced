<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 13]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping](https://arxiv.org/abs/2511.20841)
*Edmond Tong,Advaith Balaji,Anthony Opipari,Stanley Lewis,Zhen Zeng,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: OVAL-Grasp是一种零样本开放词汇方法，用于任务导向的基于可操作性的抓取，它利用大型语言模型和视觉-语言模型来识别并分割物体的正确部分以完成给定的任务。在实验中，该方法在处理家庭物品、部分遮挡以及依赖视觉特征选择部分的场景时表现优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 机器人需要能够根据给定的任务针对物体的部分进行任务导向的抓取，以便在新的非结构化环境中操纵物体。然而，基于几何的方法通常难以处理视觉定义的部分、遮挡物及未见过的物体。

Method: OVAL-Grasp结合了大型语言模型（LLM）和视觉-语言模型（VLM），通过接收RGB图像与任务指令来确定需抓取或避免的物体部位，并生成一个指示可行区域的二维热图。

Result: 在使用20个家用物品每个执行3种不同任务的实验中，OVAL-Grasp的表现超过了两种任务导向型抓取基线。在真实世界实验中，它成功识别并分割正确的物体部分的比例达到95%，并且在78.3%的情况下能够抓住正确的可操作区域。此外，在杂乱场景下，即使存在部分遮挡，该方法也展现了80%的成功率。

Conclusion: OVAL-Grasp展示了在处理包括部分遮挡在内的复杂场景时的有效性，并且通过消融实验显示了其模块化设计带来的好处。

Abstract: To manipulate objects in novel, unstructured environments, robots need task-oriented grasps that target object parts based on the given task. Geometry-based methods often struggle with visually defined parts, occlusions, and unseen objects. We introduce OVAL-Grasp, a zero-shot open-vocabulary approach to task-oriented, affordance based grasping that uses large-language models and vision-language models to allow a robot to grasp objects at the correct part according to a given task. Given an RGB image and a task, OVAL-Grasp identifies parts to grasp or avoid with an LLM, segments them with a VLM, and generates a 2D heatmap of actionable regions on the object. During our evaluations, we found that our method outperformed two task oriented grasping baselines on experiments with 20 household objects with 3 unique tasks for each. OVAL-Grasp successfully identifies and segments the correct object part 95% of the time and grasps the correct actionable area 78.3% of the time in real-world experiments with the Fetch mobile manipulator. Additionally, OVAL-Grasp finds correct object parts under partial occlusions, demonstrating a part selection success rate of 80% in cluttered scenes. We also demonstrate OVAL-Grasp's efficacy in scenarios that rely on visual features for part selection, and show the benefit of a modular design through our ablation experiments. Our project webpage is available at https://ekjt.github.io/OVAL-Grasp/

</details>


### [2] [NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities](https://arxiv.org/abs/2511.20848)
*Tasha Kim,Yingke Wang,Hanvit Cho,Alex Hodges*

Main category: cs.RO

TL;DR: NOIR 2.0, an improved brain-robot interface, uses advanced EEG and few-shot learning for quicker, more accurate task execution by robots, reducing completion time and the need for human demonstrations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to create a more efficient and user-adaptive brain-robot interface (NOIR 2.0) that can interpret human intentions through brain signals with greater speed and accuracy, thereby making daily tasks easier and less time-consuming for users.

Method: NOIR 2.0 employs enhanced brain decoding algorithms and few-shot robot learning algorithms. The system uses electroencephalography (EEG) to read brain signals, and it incorporates foundation models to improve sample efficiency in learning and adaptation, allowing for better performance with fewer demonstrations.

Result: NOIR 2.0 successfully reduces the task completion time by 46% and overall human time by 65%, requiring only 15 demos instead of a single one, due to its advanced algorithms and learning methods.

Conclusion: NOIR 2.0 represents a significant advancement in brain-robot interfaces, offering faster, more accurate, and adaptive control of robots for daily tasks, which could lead to more practical applications of such technologies.

Abstract: Neural Signal Operated Intelligent Robots (NOIR) system is a versatile brain-robot interface that allows humans to control robots for daily tasks using their brain signals. This interface utilizes electroencephalography (EEG) to translate human intentions regarding specific objects and desired actions directly into commands that robots can execute. We present NOIR 2.0, an enhanced version of NOIR. NOIR 2.0 includes faster and more accurate brain decoding algorithms, which reduce task completion time by 46%. NOIR 2.0 uses few-shot robot learning algorithms to adapt to individual users and predict their intentions. The new learning algorithms leverage foundation models for more sample-efficient learning and adaptation (15 demos vs. a single demo), significantly reducing overall human time by 65%.

</details>


### [3] [ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation](https://arxiv.org/abs/2511.20887)
*Rui Yan,Jiajian Fu,Shiqi Yang,Lars Paulsen,Xuxin Cheng,Xiaolong Wang*

Main category: cs.RO

TL;DR: 本文介绍了一种名为ACE-F的可折叠跨实体远程操作系统，该系统集成了力反馈功能，通过反向运动学和精心设计的人机界面简化了机器人演示数据的收集，并提出了一种通用软控制器流程以确保机器人安全及精确动作控制。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有远程操作平台通常缺乏集成力反馈、跨实体泛化能力以及便携性和用户友好设计的问题，限制了它们的实际部署。

Method: 本研究采用反向运动学（IK）结合精心设计的人机界面（HRI），并提出一个整合PD控制与逆动力学的广义软控制器流程，无需额外传感器即可实现力量反馈的跨实体泛化，通过将末端执行器位置偏差解释为虚拟力信号来增强数据收集。

Result: 广泛的远程操作实验表明，ACE-F显著简化了对各种机器人实体的控制，使灵巧的操作任务变得像操作电脑鼠标一样直观。

Conclusion: ACE-F作为一个创新的远程操作系统，不仅解决了当前远程操作平台存在的问题，还为模仿学习等领域的应用提供了新的可能性。

Abstract: Teleoperation systems are essential for efficiently collecting diverse and high-quality robot demonstration data, especially for complex, contact-rich tasks. However, current teleoperation platforms typically lack integrated force feedback, cross-embodiment generalization, and portable, user-friendly designs, limiting their practical deployment. To address these limitations, we introduce ACE-F, a cross embodiment foldable teleoperation system with integrated force feedback. Our approach leverages inverse kinematics (IK) combined with a carefully designed human-robot interface (HRI), enabling users to capture precise and high-quality demonstrations effortlessly. We further propose a generalized soft-controller pipeline integrating PD control and inverse dynamics to ensure robot safety and precise motion control across diverse robotic embodiments. Critically, to achieve cross-embodiment generalization of force feedback without additional sensors, we innovatively interpret end-effector positional deviations as virtual force signals, which enhance data collection and enable applications in imitation learning. Extensive teleoperation experiments confirm that ACE-F significantly simplifies the control of various robot embodiments, making dexterous manipulation tasks as intuitive as operating a computer mouse. The system is open-sourced at: https://acefoldable.github.io/

</details>


### [4] [Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization](https://arxiv.org/abs/2511.20894)
*Vivek Pandey,Amirhossein Mollaei,Nader Motee*

Main category: cs.RO

TL;DR: 本文提出两种快速且内存高效的特征选择算法，旨在实现实时评估视觉特征对机器人定位的效用，从而减少计算时间和内存消耗，同时保持良好的定位精度。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中的自主导航中，基于摄像头的视觉输入是机器人定位的关键。然而，图像帧中往往包含大量特征点，其中很多对于定位来说是冗余或无信息量的。处理所有这些特征会带来显著的计算延迟和效率低下问题。因此，需要一种智能特征选择方法来识别出对定位最有帮助的一小组特征。

Method: 本文提出了两种新的特征选择算法，专注于降低时间与内存复杂度的同时，在计算效率和定位准确性之间取得良好平衡。这些方法设计用于使机器人能够实时地主动评估视觉特征的价值。

Result: 所提出的方法相比现有方法具有更低的计算需求和内存占用，并能够在保证一定水平的定位准确性前提下提高处理速度。

Conclusion: 通过引入这两种新的特征选择算法，可以有效地解决传统方法中存在的计算资源高消耗问题，为机器人提供了一种更高效、更适合实际应用的视觉定位解决方案。

Abstract: Robot localization is a fundamental component of autonomous navigation in unknown environments. Among various sensing modalities, visual input from cameras plays a central role, enabling robots to estimate their position by tracking point features across image frames. However, image frames often contain a large number of features, many of which are redundant or uninformative for localization. Processing all features can introduce significant computational latency and inefficiency. This motivates the need for intelligent feature selection, identifying a subset of features that are most informative for localization over a prediction horizon. In this work, we propose two fast and memory-efficient feature selection algorithms that enable robots to actively evaluate the utility of visual features in real time. Unlike existing approaches with high computational and memory demands, the proposed methods are explicitly designed to reduce both time and memory complexity while achieving a favorable trade-off between computational efficiency and localization accuracy.

</details>


### [5] [Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy](https://arxiv.org/abs/2511.20906)
*Inkook Chun,Seungjae Lee,Michael S. Albergo,Saining Xie,Eric Vanden-Eijnden*

Main category: cs.RO

TL;DR: 本文提出了一种基于难度感知的随机插值策略（DA-SIP），使机器人控制器能够根据任务难度自适应调整其在实时中的积分范围，从而有效减少计算时间而不影响任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散和流式策略虽然在长周期的机器人操作和模仿学习任务中表现出色，但它们在每个控制步骤都使用固定的推理预算，这导致了对于简单子任务的计算效率低下，并且可能在处理复杂任务时表现不佳。

Method: 通过引入难度感知随机插值策略（DA-SIP），利用一个难度分类器分析观察数据来动态选择步数预算、最佳求解器变体以及每个控制周期内的ODE/SDE集成。DA-SIP建立在随机插值公式之上，提供了一个统一框架，解锁了针对扩散和流式策略的各种训练和推断配置。

Result: 经由不同操控任务上的全面基准测试显示，DA-SIP实现了总计算时间2.6到4.4倍的缩减，同时保持与固定最大计算基线相当的任务成功率。

Conclusion: 通过在这个框架内实现自适应计算，DA-SIP将生成型机器人控制器转变为高效的任务感知系统，智能地将推理资源分配给最需要的地方。

Abstract: Diffusion- and flow-based policies deliver state-of-the-art performance on long-horizon robotic manipulation and imitation learning tasks. However, these controllers employ a fixed inference budget at every control step, regardless of task complexity, leading to computational inefficiency for simple subtasks while potentially underperforming on challenging ones. To address these issues, we introduce Difficulty-Aware Stochastic Interpolant Policy (DA-SIP), a framework that enables robotic controllers to adaptively adjust their integration horizon in real time based on task difficulty. Our approach employs a difficulty classifier that analyzes observations to dynamically select the step budget, the optimal solver variant, and ODE/SDE integration at each control cycle. DA-SIP builds upon the stochastic interpolant formulation to provide a unified framework that unlocks diverse training and inference configurations for diffusion- and flow-based policies. Through comprehensive benchmarks across diverse manipulation tasks, DA-SIP achieves 2.6-4.4x reduction in total computation time while maintaining task success rates comparable to fixed maximum-computation baselines. By implementing adaptive computation within this framework, DA-SIP transforms generative robot controllers into efficient, task-aware systems that intelligently allocate inference resources where they provide the greatest benefit.

</details>


### [6] [SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation](https://arxiv.org/abs/2511.21135)
*Ziyi Chen,Yingnan Guo,Zedong Chu,Minghua Luo,Yanfen Shen,Mingchao Sun,Junjun Hu,Shichao Xie,Kuan Yang,Pei Shi,Zhining Gu,Lu Liu,Honglin Han,Xiaolong Wu,Mu Xu,Yu Zhang*

Main category: cs.RO

TL;DR: 本文提出了SocialNav，一个用于社交感知导航的基础模型，结合了大规模数据集SocNav Dataset和多阶段训练流程，通过模仿学习和社会意识流探索GRPO（SAFE-GRPO）来注入并精炼导航智能。SocialNav在导航表现和社会合规性方面均取得了显著提升，相较于现有最先进方法成功率达到+38%，社会合规率更是提高了+46%。


<details>
  <summary>Details</summary>
Motivation: 针对遵循社会规范的具身导航仍是一个开放的研究挑战这一问题，研究者们旨在开发能够理解高层次社会规范同时生成低层次、符合社交礼仪轨迹的导航系统。

Method: 构建了包含认知激活数据集与专家轨迹金字塔的大规模SocNav数据集，并提出了一种多层次“大脑-行动”架构的SocialNav模型。通过模仿学习将通用导航技能及社会规范理解注入模型，随后借助专为具身导航设计的社会意识流探索GRPO (SAFE-GRPO)框架进一步精炼这些技能。

Result: 实验结果显示，SocialNav不仅在导航成功率上比最先进的方法高出38%，而且在遵守社会规范方面也表现出色，提升了46%的社会合规率。

Conclusion: SocialNav证明了其在提高导航性能的同时增强社会合规性的潜力，为未来社交感知导航研究奠定了基础。

Abstract: Embodied navigation that adheres to social norms remains an open research challenge. Our \textbf{SocialNav} is a foundational model for socially-aware navigation with a hierarchical "brain-action" architecture, capable of understanding high-level social norms and generating low-level, socially compliant trajectories. To enable such dual capabilities, we construct the SocNav Dataset, a large-scale collection of 7 million samples, comprising (1) a Cognitive Activation Dataset providing social reasoning signals such as chain-of-thought explanations and social traversability prediction, and (2) an Expert Trajectories Pyramid aggregating diverse navigation demonstrations from internet videos, simulated environments, and real-world robots. A multi-stage training pipeline is proposed to gradually inject and refine navigation intelligence: we first inject general navigation skills and social norms understanding into the model via imitation learning, and then refine such skills through a deliberately designed Socially-Aware Flow Exploration GRPO (SAFE-GRPO), the first flow-based reinforcement learning framework for embodied navigation that explicitly rewards socially compliant behaviors. SocialNav achieves +38% success rate and +46% social compliance rate compared to the state-of-the-art method, demonstrating strong gains in both navigation performance and social compliance. Our project page: https://amap-eai.github.io/SocialNav/

</details>


### [7] [Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning](https://arxiv.org/abs/2511.21149)
*Guoming Huang,Qingyi Zhou,Dianjing Liu,Shuai Zhang,Ming Zhou,Zongfu Yu*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Maglev-Pentabot的磁悬浮系统，它利用深度强化学习来控制克级物体的非接触式操作，并通过优化电磁铁布局和引入动作重映射方法解决了磁场强度非线性带来的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的非接触式操纵技术大多局限于微观尺度，通常只能控制毫克级别的物体。为了解决这一限制，研究提出了一个能够处理克级物体的磁悬浮系统。

Method: 使用了深度强化学习（DRL）开发复杂的控制策略；通过对电磁铁布置进行数值分析优化以最大化可控空间；引入一种动作重映射方法来解决因磁场强度强非线性导致的样本稀疏问题。

Result: 实验结果表明该系统具有灵活的操作能力，并且可以泛化到未经过明确训练的运输任务上。此外，该方法可以通过使用更大的电磁铁来操控更重的物体，为工业规模机器人应用提供了一个参考框架。

Conclusion: Maglev-Pentabot系统成功地扩展了非接触式操纵技术的应用范围至克级物体，证明了其在更广泛工业应用中的潜力。

Abstract: Non-contact manipulation has emerged as a transformative approach across various industrial fields. However, current flexible 2D and 3D non-contact manipulation techniques are often limited to microscopic scales, typically controlling objects in the milligram range. In this paper, we present a magnetic levitation system, termed Maglev-Pentabot, designed to address this limitation. The Maglev-Pentabot leverages deep reinforcement learning (DRL) to develop complex control strategies for manipulating objects in the gram range. Specifically, we propose an electromagnet arrangement optimized through numerical analysis to maximize controllable space. Additionally, an action remapping method is introduced to address sample sparsity issues caused by the strong nonlinearity in magnetic field intensity, hence allowing the DRL controller to converge. Experimental results demonstrate flexible manipulation capabilities, and notably, our system can generalize to transport tasks it has not been explicitly trained for. Furthermore, our approach can be scaled to manipulate heavier objects using larger electromagnets, offering a reference framework for industrial-scale robotic applications.

</details>


### [8] [Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation](https://arxiv.org/abs/2511.21169)
*Kaiyan Xiao,Zihan Xu,Cheng Zhe,Chengju Liu,Qijun Chen*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的框架，通过分三个阶段训练上身策略、下身策略和增量指令策略，旨在提高类人机器人在高负载工业场景中的灵巧性和主动力交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有的类人机器人的运动-操作方法主要集中在灵巧操作上，在高负载工业场景中对灵巧性和主动力量交互的要求未能得到充分满足。

Method: 采用一种基于强化学习的方法，并设计了一个三阶段解耦训练流程：1. 上半身策略，通过设计启发式奖励函数加速训练；2. 下半身策略，开发了基于力的课程学习策略；3. 增量指令策略。

Result: 该方法使得政策能够更快地收敛并表现出更好的性能，同时让机器人能够主动施加和调节与环境之间的交互力。

Conclusion: 所提出的框架为类人机器人在需要高度灵巧性和有效力交互控制的工业应用中提供了新的解决方案。

Abstract: Humanoid robots, with their human-like morphology, hold great potential for industrial applications. However, existing loco-manipulation methods primarily focus on dexterous manipulation, falling short of the combined requirements for dexterity and proactive force interaction in high-load industrial scenarios. To bridge this gap, we propose a reinforcement learning-based framework with a decoupled three-stage training pipeline, consisting of an upper-body policy, a lower-body policy, and a delta-command policy. To accelerate upper-body training, a heuristic reward function is designed. By implicitly embedding forward kinematics priors, it enables the policy to converge faster and achieve superior performance. For the lower body, a force-based curriculum learning strategy is developed, enabling the robot to actively exert and regulate interaction forces with the environment.

</details>


### [9] [Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation](https://arxiv.org/abs/2511.21264)
*Iryna Hurova,Alinjar Dan,Karl Kruusamäe,Arun Kumar Singh*

Main category: cs.RO

TL;DR: 本文提出了一种基于采样的优化框架，利用GPU加速的物理模拟器作为世界模型，通过定制的模型预测路径积分控制算法解决了复杂的双臂操作任务。该方法在处理存在静态障碍物的任务时表现良好，并且实现了从模拟到现实的转换。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的方法难以泛化到新的场景，特别是在杂乱环境中执行双臂操作任务时。为解决这一问题，作者提出了一个替代方案：使用GPU加速的物理模拟器作为世界模型的基于采样优化框架。

Method: 开发了一种定制化的模型预测路径积分控制（MPPI）算法，该算法由精心设计的任务特定成本函数引导，并使用了GPU加速的MuJoCo来高效评估机器人-物体交互。这种方法被应用于解决PerAct$^{2}$基准测试中更具有挑战性的任务版本，如需要将球通过障碍课程进行点对点转移。

Result: 结果表明，所提出的方法可以在商品级GPU上实现实时性能，并且能够成功地从仿真转移到实际应用。此外，还进行了样本复杂性和鲁棒性的统计分析，以量化方法的表现。

Conclusion: 本研究提出的基于采样的优化框架结合GPU加速的物理模拟器有效解决了复杂环境下的双臂操作问题，并展示了良好的泛化能力与实时性能。

Abstract: In recent years, dual-arm manipulation has become an area of strong interest in robotics, with end-to-end learning emerging as the predominant strategy for solving bimanual tasks. A critical limitation of such learning-based approaches, however, is their difficulty in generalizing to novel scenarios, especially within cluttered environments. This paper presents an alternative paradigm: a sampling-based optimization framework that utilizes a GPU-accelerated physics simulator as its world model. We demonstrate that this approach can solve complex bimanual manipulation tasks in the presence of static obstacles. Our contribution is a customized Model Predictive Path Integral Control (MPPI) algorithm, \textbf{guided by carefully designed task-specific cost functions,} that uses GPU-accelerated MuJoCo for efficiently evaluating robot-object interaction. We apply this method to solve significantly more challenging versions of tasks from the PerAct$^{2}$ benchmark, such as requiring the point-to-point transfer of a ball through an obstacle course. Furthermore, we establish that our method achieves real-time performance on commodity GPUs and facilitates successful sim-to-real transfer by leveraging unique features within MuJoCo. The paper concludes with a statistical analysis of the sample complexity and robustness, quantifying the performance of our approach. The project website is available at: https://sites.google.com/view/bimanualakslabunitartu .

</details>


### [10] [Improvement of Collision Avoidance in Cut-In Maneuvers Using Time-to-Collision Metrics](https://arxiv.org/abs/2511.21280)
*Jamal Raiyn*

Main category: cs.RO

TL;DR: 本论文提出了一种新的碰撞避免策略，通过结合深度学习与碰撞时间（TTC）计算来处理切入场景，特别针对自动驾驶车辆面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的基于TTC的方法在处理自动驾驶汽车遇到的切入场景时存在局限性，需要一种更先进的方法来预测潜在的碰撞并确定适当的规避动作。

Method: 采用深度学习技术与TTC指标相结合的新策略，旨在提高对复杂交通情境下潜在碰撞的预测准确性及反应效率。

Result: 该系统相比传统TTC方法能够更有效地预测碰撞风险，并为自动驾驶车辆提供更加合理有效的避碰方案。

Conclusion: 结合深度学习和TTC的新策略展示了在处理自动驾驶中特别困难的切入情况时的优势，为提高道路安全提供了新的可能性。

Abstract: This paper proposes a new strategy for collision avoidance system leveraging Time-to-Collision (TTC) metrics for handling cut-in scenarios, which are particularly challenging for autonomous vehicles (AVs). By integrating a deep learning with TTC calculations, the system predicts potential collisions and determines appropriate evasive actions compared to traditional TTC -based approaches.

</details>


### [11] [Hybrid Control for Robotic Nut Tightening Task](https://arxiv.org/abs/2511.21366)
*Dmitri Kovalenko*

Main category: cs.RO

TL;DR: 提出了一个用于串行机械手的自主机器人紧固系统，该系统基于分层运动原语规划器和交替使用力和位置控制的控制切换方案。仿真显示了该系统对初始条件变化的鲁棒性，并且比基线快14%，同时减少了40倍接触力。


<details>
  <summary>Details</summary>
Motivation: 为了提高串行机械手执行拧紧螺母任务时的速度和效率，同时减少对操作对象施加的接触力。

Method: 开发了一个基于分层运动原语的规划器以及一种可以在力控制与位置控制之间切换的方案。通过大量仿真验证了系统的性能。

Result: 所提出的控制器能够比基准方法快14%完成螺丝紧固任务，并且在操作过程中施加于物体上的接触力减少了40倍。

Conclusion: 该研究为串行机械手提供了一种新的、更高效安全地执行拧紧螺母任务的方法，并且研究成果已开源共享给研究社区。

Abstract: An autonomous robotic nut tightening system for a serial manipulator equipped with a parallel gripper is proposed. The system features a hierarchical motion-primitive-based planner and a control-switching scheme that alternates between force and position control. Extensive simulations demonstrate the system's robustness to variance in initial conditions. Additionally, the proposed controller tightens threaded screws 14% faster than the baseline while applying 40 times less contact force on manipulands. For the benefit of the research community, the system's implementation is open-sourced.

</details>


### [12] [$\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion](https://arxiv.org/abs/2511.21542)
*Zhihao Zhan,Jiaying Zhou,Likui Zhang,Qinhan Lv,Hao Liu,Jusheng Zhang,Weizheng Li,Ziliang Chen,Tianshui Chen,Keze Wang,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: 本文提出了一种名为E0的连续离散扩散框架，用于改进视觉-语言-动作（VLA）模型在机器人操作中的表现。E0通过迭代去噪量化动作令牌生成动作，相比连续扩散策略具有更好的语义条件和更强的真实世界适应性。此外，E0还引入了一种球形视角扰动增强方法来提高对摄像机位移的鲁棒性。实验表明，E0在多个环境下的表现优于现有基准，并且在真实世界的Franka机械臂上也展示了精确、鲁棒且可转移的操作能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作（VLA）模型在跨任务、场景以及相机视角的一般化方面存在困难，同时产生的动作往往不够精细或稳定。

Method: 提出了E0，一种连续离散扩散框架，将动作生成视为对量化动作标记的迭代去噪过程。该方法利用了预训练VLM/VLA骨干网的符号结构进行更强的语义调节，并且由于其与实际机器人控制硬件约束相匹配而展现出更佳的泛化性能。此外，研究者还开发了一种球形视角扰动增强技术以提高对于相机移动的鲁棒性。

Result: 实验结果表明，在LIBERO、VLABench和ManiSkill等14个不同环境下，E0的表现超越了强大的基线方法，平均提高了10.7%。在Franka机械臂上的实际测试进一步验证了E0能够实现精准、鲁棒及可迁移的操作。

Conclusion: E0作为一种新颖的方法，在视觉-语言-动作模型中展现了出色的表现，特别是在促进政策学习的泛化能力方面。它不仅改善了动作的准确性，同时也增强了对不同环境条件下变化的鲁棒性。

Abstract: Vision-Language-Action (VLA) models offer a unified framework for robotic manipulation by integrating visual perception, language understanding, and control generation. Yet existing VLA models still struggle to generalize across diverse tasks, scenes, and camera viewpoints, and often produce coarse or unstable actions. We introduce E0, a continuized discrete diffusion framework that formulates action generation as iterative denoising over quantized action tokens. Compared with continuous diffusion policies, E0 offers two key advantages: (1) discrete action tokens align naturally with the symbolic structure of pretrained VLM/VLA backbones, enabling stronger semantic conditioning; and 2. discrete diffusion matches the true quantized nature of real-world robot control-whose hardware constraints (e.g., encoder resolution, control frequency, actuation latency) inherently discretize continuous signals-and therefore benefits from a Bayes-optimal denoiser that models the correct discrete action distribution, leading to stronger generalization. Compared with discrete autoregressive and mask-based discrete diffusion models, E0 supports a significantly larger and finer-grained action vocabulary and avoids the distributional mismatch introduced by masking-based corruptions-yielding more accurate fine-grained action control. We further introduce a spherical viewpoint perturbation augmentation method to improve robustness to camera shifts without additional data. Experiments on LIBERO, VLABench, and ManiSkill show that E0 achieves state-of-the-art performance across 14 diverse environments, outperforming strong baselines by 10.7% on average. Real-world evaluation on a Franka arm confirms that E0 delivers precise, robust, and transferable manipulation, establishing discrete diffusion as a promising direction for generalizable VLA policy learning.

</details>


### [13] [VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation](https://arxiv.org/abs/2511.21557)
*Hui Zhou,Siyuan Huang,Minxing Li,Hao Zhang,Lue Fan,Shaoshuai Shi*

Main category: cs.RO

TL;DR: 本文提出了一种低成本的集成硬件设计，结合了双指机械夹爪和真空吸盘单元，实现了单一末端执行器内的双模式操作。该系统支持灵活切换或协同使用两种模式，从而扩展了可行任务范围。实验结果表明，与传统双指夹爪相比，这种混合型末端执行器使机器人能够成功执行更多复杂的任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型（VLA）系统大多采用并行双指夹爪作为默认末端执行器，但这类夹爪在处理某些现实世界任务时存在固有限制，如擦拭玻璃表面或打开无把手抽屉等，因为接触面积不足或缺乏附着力。为了解决这些问题，研究者开发了一种新型混合末端执行器。

Method: 研究团队设计了一种将双指机械夹爪与真空吸附单元相结合的低成本、集成化硬件解决方案。该设计允许在同一末端执行器内灵活切换或同时利用这两种操作模式，从而增强了机器人的多功能性。此外，还通过两个最先进的VLA框架DexVLA和Pi0验证了所提方案的有效性和实用性。

Result: 实验结果显示，在配备了提议中的混合型末端执行器后，机器人能够完成多种原本对于标准双指夹爪来说不可行的复杂任务。这证明了新设计不仅提高了效率，也大大拓宽了可由机器人执行的任务种类。

Conclusion: 本研究表明，通过引入集成了夹持与吸附功能于一体的新型末端执行器，可以有效克服传统双指夹爪面临的限制，使得基于视觉-语言模型指导下的机器人操作更加多样化和高效。所有相关硬件设计及控制系统都将公开发布。

Abstract: Vision Language Action models have significantly advanced general purpose robotic manipulation by harnessing large scale pretrained vision and language representations. Among existing approaches, a majority of current VLA systems employ parallel two finger grippers as their default end effectors. However, such grippers face inherent limitations in handling certain real world tasks such as wiping glass surfaces or opening drawers without handles due to insufficient contact area or lack of adhesion. To overcome these challenges, we present a low cost, integrated hardware design that combines a mechanical two finger gripper with a vacuum suction unit, enabling dual mode manipulation within a single end effector. Our system supports flexible switching or synergistic use of both modalities, expanding the range of feasible tasks. We validate the efficiency and practicality of our design within two state of the art VLA frameworks: DexVLA and Pi0. Experimental results demonstrate that with the proposed hybrid end effector, robots can successfully perform multiple complex tasks that are infeasible for conventional two finger grippers alone. All hardware designs and controlling systems will be released.

</details>
