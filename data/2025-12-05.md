<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding](https://arxiv.org/abs/2512.04231)
*Zhou Chen,Joe Lin,Carson Bulgin,Sathyanarayanan N. Aakur*

Main category: cs.RO

TL;DR: 本文介绍了一个名为CRAFT-E的模块化神经符号框架，该框架结合了动词-属性-对象知识图谱与视觉-语言对齐及基于能量的抓取推理。CRAFT-E在静态场景、ImageNet功能检索以及涉及20个动词和39个对象的真实世界试验中表现出色，并且在感知噪声下保持稳健，为辅助机器人系统提供了可解释性和定制化的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于黑盒模型或固定的适用性标签，这限制了面向人类应用的透明度、可控性和可靠性。为了使辅助机器人不仅能够理解物体是什么，还能理解它们可以用于什么目的，需要一种更加透明、可控并可靠的方案来实现从语言动作查询到实际物体的映射。

Method: 提出了一种称为CRAFT-E的模块化神经符号框架，它将结构化的动词-属性-对象知识图谱与视觉-语言对齐及基于能量的抓取推理相结合。此外，还构建了一个基准数据集，包含统一标注的动词-对象兼容性、分割和抓取候选者信息，并在物理机器人上部署了整个流程。

Result: CRAFT-E在静态场景、基于ImageNet的功能检索以及涉及20个动词和39个对象的真实世界试验中表现出了竞争力。即使在存在感知噪声的情况下，该框架也显示出鲁棒性，并提供了组件级别的诊断信息。

Conclusion: 通过将符号推理与具身感知相结合，CRAFT-E为以适用性为基础的对象选择提供了一个可解释且可定制的选择，支持辅助机器人系统中的可信决策制定。

Abstract: Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.

</details>


### [2] [Sliding Mode Control and Subspace Stabilization Methodology for the Orbital Stabilization of Periodic Trajectories](https://arxiv.org/abs/2512.04249)
*Maksim Surov,Leonid Freidovich*

Main category: cs.RO

TL;DR: 本文提出了一种结合滑模控制和子空间稳定化的方法，用于欠驱动机械系统中周期轨迹的轨道稳定。该方法避免了计算密集型的周期LQR问题，并通过Butterfly机器人的实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高欠驱动机械系统中周期轨迹稳定性的鲁棒性，同时避免使用计算量大的周期LQR问题解决方案。

Method: 采用部分反馈线性化与稳定化开始，接着计算参考轨道上的横向线性化，形成一个具有稳定子空间的周期线性时变系统；利用滑模控制将轨迹导向此子空间。

Result: 所提设计不仅避免了处理复杂的周期LQR问题，而且对匹配干扰表现出更好的鲁棒性。在Butterfly机器人上进行了方法验证。

Conclusion: 结合滑模控制与子空间稳定化的策略为欠驱动机械系统的周期轨迹提供了有效的轨道稳定方案，且具有较高的鲁棒性和较低的计算成本。

Abstract: This paper presents a combined sliding-mode control and subspace stabilization methodology for orbital stabilization of periodic trajectories in underactuated mechanical systems with one degree of underactuation. The approach starts with partial feedback linearization and stabilization. Then, transverse linearization along the reference orbit is computed, resulting in a periodic linear time-varying system with a stable subspace. Sliding-mode control drives trajectories toward this subspace. The proposed design avoids solving computationally intensive periodic LQR problems and improves robustness to matched disturbances. The methodology is validated through experiments on the Butterfly robot.

</details>


### [3] [Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates](https://arxiv.org/abs/2512.04373)
*Hann Woei Ho,Ye Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种非线性控制策略，利用两个不同的局部流散度估计来调节航天器在斜坡地形上垂直着陆时的推力和姿态。该方法通过保持局部流散度估计的平均值恒定来确保平滑下降，并通过利用这两个估计之间的差异使飞行器在接触地面时与倾斜表面对齐。仿真结果表明，这种方法可以实现稳定着陆并有效适应不同倾斜角度的地形。


<details>
  <summary>Details</summary>
Motivation: 小型轻量化航天器如旋翼机和着陆器在斜坡地形上自主着陆面临挑战，因为它们的处理能力和载荷能力有限，不能使用先进的深度学习方法或重传感器。受昆虫（如蜜蜂）依靠光学流以最少的神经和感官资源完成着陆启发，研究者们希望开发一种低资源需求的着陆策略。但是，将这种生物启发策略应用于航天器存在两个关键问题：全局流散度估计掩盖了地形倾斜情况，基于散度的控制的非线性特性可能导致使用传统控制器时出现不稳定现象。

Method: 文章介绍了一种新的非线性控制策略，它依赖于增量非线性动态逆（Incremental Nonlinear Dynamic Inversion, INDI）来管理局部流散度估计中的非线性特征。该策略包括两部分：一是通过维持局部流散度估计值的平均数不变来控制推力，从而保证平稳下降；二是通过利用这些估计值之间的差异来调整飞行器姿态，使其能够在接触斜面时正确对齐。

Result: 通过采用简化二维航天器模型进行数值模拟实验，测试了不同斜率及散度设定点条件下所提方法的表现。结果显示，通过调整平均散度能够产生速度和高度呈指数衰减的稳定着陆过程；同时，利用散度差值能有效实现与倾斜地形的良好匹配。

Conclusion: 总体而言，本论文提供的方法是一种稳健且资源消耗低的着陆策略，为小型航天器执行自主行星任务提供了可行性增强方案。

Abstract: Autonomous landing on sloped terrain poses significant challenges for small, lightweight spacecraft, such as rotorcraft and landers. These vehicles have limited processing capability and payload capacity, which makes advanced deep learning methods and heavy sensors impractical. Flying insects, such as bees, achieve remarkable landings with minimal neural and sensory resources, relying heavily on optical flow. By regulating flow divergence, a measure of vertical velocity divided by height, they perform smooth landings in which velocity and height decay exponentially together. However, adapting this bio-inspired strategy for spacecraft landings on sloped terrain presents two key challenges: global flow-divergence estimates obscure terrain inclination, and the nonlinear nature of divergence-based control can lead to instability when using conventional controllers. This paper proposes a nonlinear control strategy that leverages two distinct local flow divergence estimates to regulate both thrust and attitude during vertical landings. The control law is formulated based on Incremental Nonlinear Dynamic Inversion to handle the nonlinear flow divergence. The thrust control ensures a smooth vertical descent by keeping a constant average of the local flow divergence estimates, while the attitude control aligns the vehicle with the inclined surface at touchdown by exploiting their difference. The approach is evaluated in numerical simulations using a simplified 2D spacecraft model across varying slopes and divergence setpoints. Results show that regulating the average divergence yields stable landings with exponential decay of velocity and height, and using the divergence difference enables effective alignment with inclined terrain. Overall, the method offers a robust, low-resource landing strategy that enhances the feasibility of autonomous planetary missions with small spacecraft.

</details>


### [4] [FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination](https://arxiv.org/abs/2512.04381)
*Chengyang He,Ge Sun,Yue Bai,Junkai Lu,Jiadong Zhao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出了FALCON框架，该框架结合了模块化的扩散策略与视觉-语言基础模型作为协调器，将移动和操作解耦为两个专门的视觉运动策略，并通过视觉-语言基础模型恢复这两个独立策略之间的协调。


<details>
  <summary>Details</summary>
Motivation: 为了克服单一策略在融合来自移动和操作的不同且可能不匹配的观察时导致的性能下降问题，提出了一种新的框架以改善协调性、鲁棒性和泛化能力。

Method: 开发了一个名为FALCON的框架，它利用视觉-语言基础模型来编码全局观察和语言指令，形成一个共享潜在嵌入条件，同时引入阶段进展头和协调感知对比损失来增强子系统间的兼容性。

Result: 实验结果表明，在需要导航、精确末端执行器放置及紧密基座-手臂协调的两个具有挑战性的移动操作任务中，FALCON超越了集中式和分散式的基线方法，并展示了对分布外情况更好的鲁棒性和泛化能力。

Conclusion: FALCON提供了一种有效的方法来解决移动操作中的协调问题，通过明确地将移动和操作解耦并通过视觉-语言基础模型进行协调，从而提高了系统的整体性能。

Abstract: We present FoundAtion-model-guided decoupled LoCO-maNipulation visuomotor policies (FALCON), a framework for loco-manipulation that combines modular diffusion policies with a vision-language foundation model as the coordinator. Our approach explicitly decouples locomotion and manipulation into two specialized visuomotor policies, allowing each subsystem to rely on its own observations. This mitigates the performance degradation that arise when a single policy is forced to fuse heterogeneous, potentially mismatched observations from locomotion and manipulation. Our key innovation lies in restoring coordination between these two independent policies through a vision-language foundation model, which encodes global observations and language instructions into a shared latent embedding conditioning both diffusion policies. On top of this backbone, we introduce a phase-progress head that uses textual descriptions of task stages to infer discrete phase and continuous progress estimates without manual phase labels. To further structure the latent space, we incorporate a coordination-aware contrastive loss that explicitly encodes cross-subsystem compatibility between arm and base actions. We evaluate FALCON on two challenging loco-manipulation tasks requiring navigation, precise end-effector placement, and tight base-arm coordination. Results show that it surpasses centralized and decentralized baselines while exhibiting improved robustness and generalization to out-of-distribution scenarios.

</details>


### [5] [Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation](https://arxiv.org/abs/2512.04399)
*Haoqi Han,Yi Yang,Yifei Yu,Yixuan Zhou,Xiaohan Zhu,Hesheng Wang*

Main category: cs.RO

TL;DR: 本研究提出了一种新型15自由度灵巧仿生机械手，通过创新的肌腱驱动机制减少了所需电机数量，同时增强了运动性能并简化了机械结构。该设计在前臂集成了五个电机以提供强大的抓握力，并在手掌中安装了十个小型电机来支持精细操作任务。整个系统重量仅为1.4千克，结合了轻量化和高性能的特点。实验表明，这种仿生手展示出卓越的灵活性和稳健的抓取能力，在机器人操作任务中具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 在机器人手研究领域，减少致动器的数量同时保持与人手一致的尺寸和自由度是一个基本挑战。

Method: 受人类手部运动配置和肌肉分布策略的生物启发，设计了一种新的肌腱驱动机制，使用五个电机位于前臂以增强抓握力，另外十个小型电机位于手掌部分负责精细操作任务。开发了相应的关节感应和电机驱动电气系统以确保有效控制和反馈。

Result: 所设计的仿生手展示了出色的灵活性和强健的抓取能力，整体重量为1.4kg，实现了轻量化与高性能的结合。

Conclusion: 这项工作介绍了一种新颖的15自由度灵巧机械手设计方案，通过减少传统肌腱驱动系统所需的电机数量而提高了性能。实验结果证明了其在执行复杂操控任务方面的显著潜力。

Abstract: In robotic hand research, minimizing the number of actuators while maintaining human-hand-consistent dimensions and degrees of freedom constitutes a fundamental challenge. Drawing bio-inspiration from human hand kinematic configurations and muscle distribution strategies, this work proposes a novel 15-DoF dexterous robotic hand, with detailed analysis of its mechanical architecture, electrical system, and control system. The bionic hand employs a new tendon-driven mechanism, significantly reducing the number of motors required by traditional tendon-driven systems while enhancing motion performance and simplifying the mechanical structure. This design integrates five motors in the forearm to provide strong gripping force, while ten small motors are installed in the palm to support fine manipulation tasks. Additionally, a corresponding joint sensing and motor driving electrical system was developed to ensure efficient control and feedback. The entire system weighs only 1.4kg, combining lightweight and high-performance features. Through experiments, the bionic hand exhibited exceptional dexterity and robust grasping capabilities, demonstrating significant potential for robotic manipulation tasks.

</details>


### [6] [RoboBPP: Benchmarking Robotic Online Bin Packing with Physics-based Simulation](https://arxiv.org/abs/2512.04415)
*Zhoufeng Wang,Hang Zhao,Juzhan Xu,Shishun Zhang,Zeyu Xiong,Ruizhen Hu,Chenyang Zhu,Kai Xu*

Main category: cs.RO

TL;DR: 本文介绍了一个名为RoboBPP的基准系统，它专为机器人在线三维装箱问题设计。该系统通过集成基于物理的模拟器、引入实际比例的机械臂和箱子来模拟真实的工业包装流程，并且提供了三个来自真实工业工作流的数据集，以及新增了结构稳定性和操作安全性的评估指标。


<details>
  <summary>Details</summary>
Motivation: 随着工业自动化的发展，在线三维装箱问题日益受到关注。然而，问题设定、测试数据集及评估指标的一致性缺乏阻碍了领域进步，同时缺少一个全面的基准系统；直接在真实硬件上测试成本高昂，建立逼真的仿真环境也颇具挑战。此外，以往研究多依赖与实际工业数据分布不一致的合成数据集。

Method: 提出了一种名为RoboBPP的新基准系统，该系统专门针对机器人在线三维装箱问题而设计。它包含了一个基于物理学的模拟器以评估解决方案的实际可行性，并通过引入按照现实世界尺寸设计的机械臂和盒子来模仿真实的工业包装作业流程。为了更贴近实际应用情况，还特别收集了来自装配线生产、物流包装和家具制造等领域的三组数据集。

Result: RoboBPP提供了一个可重复使用且易于扩展的研究基础，支持未来关于机器人在线三维装箱的研究及工业应用开发。此系统不仅包括了精心设计的测试场景设置，而且扩展了现有评价标准，增加了对结构稳定性和运行安全性考量的新度量方式。

Conclusion: RoboBPP作为一个开源平台，配备有可视化工具及在线排行榜功能，能够有效促进机器人在线三维装箱领域的研究进展及其在工业中的实际部署。

Abstract: Physical feasibility in 3D bin packing is a key requirement in modern industrial logistics and robotic automation. With the growing adoption of industrial automation, online bin packing has gained increasing attention. However, inconsistencies in problem settings, test datasets, and evaluation metrics have hindered progress in the field, and there is a lack of a comprehensive benchmarking system. Direct testing on real hardware is costly, and building a realistic simulation environment is also challenging. To address these limitations, we introduce RoboBPP, a benchmarking system designed for robotic online bin packing. RoboBPP integrates a physics-based simulator to assess physical feasibility. In our simulation environment, we introduce a robotic arm and boxes at real-world scales to replicate real industrial packing workflows. By simulating conditions that arise in real industrial applications, we ensure that evaluated algorithms are practically deployable. In addition, prior studies often rely on synthetic datasets whose distributions differ from real-world industrial data. To address this issue, we collect three datasets from real industrial workflows, including assembly-line production, logistics packing, and furniture manufacturing. The benchmark comprises three carefully designed test settings and extends existing evaluation metrics with new metrics for structural stability and operational safety. We design a scoring system and derive a range of insights from the evaluation results. RoboBPP is fully open-source and is equipped with visualization tools and an online leaderboard, providing a reproducible and extensible foundation for future research and industrial applications (https://robot-bin-packing-benchmark.github.io).

</details>


### [7] [Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops](https://arxiv.org/abs/2512.04446)
*Chang Liu,Sibo Tian,Sara Behdad,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本研究通过收集定制的数据集对两种视觉-语言-动作(VLA)模型进行微调，以探索其在复杂拆卸任务中的可行性。实验结果表明，尽管VLA模型能够完成多个早期步骤，但在处理需要灵巧性和精确性的关键子任务时遇到困难。结合基于规则控制器的简单混合策略可以成功执行整个拆卸操作。


<details>
  <summary>Details</summary>
Motivation: 电子产品如RAM模块、CPU及硬盘驱动器等高价值或敏感部件的自动化拆解面临挑战，因为这些产品存在固有的多样性和不确定性，并且拆解过程需要顺序、精确和灵巧的操作。当前机器人拆解过程通常被划分为几个阶段，每个阶段都需要显式建模，这限制了它们对不熟悉场景的泛化能力。最近发展的视觉-语言-动作(VLA)模型为通用机器人操控任务提供了一种端到端的方法，但将此类模型应用于复杂拆解任务的可行性尚未得到充分探索。

Method: 研究人员为机器人拆解RAM和CPU创建了一个定制数据集，并利用该数据集对两种已建立的VLA方法（OpenVLA和OpenVLA-OFT）进行了微调。此外，他们还提出了一种简单的混合策略，即将VLA与基于规则的控制器相结合来尝试解决拆解过程中遇到的问题。

Result: 初步实验结果显示，经过微调的VLA模型能够忠实地完成多个早期步骤，但在某些关键子任务上表现不佳导致任务失败。然而，采用VLA与基于规则控制器相结合的简单混合策略则能够成功地执行整个拆解操作。

Conclusion: 这项研究表明，虽然VLA模型在处理需要高度灵巧性和精确性的电子废弃物拆解任务方面存在局限性，但通过结合基于规则的控制策略，仍有可能实现全自动化的端到端拆解流程。研究结果为未来如何克服现有挑战并推动该领域发展提供了见解。

Abstract: Automating disassembly of critical components from end-of-life (EoL) desktops, such as high-value items like RAM modules and CPUs, as well as sensitive parts like hard disk drives, remains challenging due to the inherent variability and uncertainty of these products. Moreover, their disassembly requires sequential, precise, and dexterous operations, further increasing the complexity of automation. Current robotic disassembly processes are typically divided into several stages: perception, sequence planning, task planning, motion planning, and manipulation. Each stage requires explicit modeling, which limits generalization to unfamiliar scenarios. Recent development of vision-language-action (VLA) models has presented an end-to-end approach for general robotic manipulation tasks. Although VLAs have demonstrated promising performance on simple tasks, the feasibility of applying such models to complex disassembly remains largely unexplored. In this paper, we collected a customized dataset for robotic RAM and CPU disassembly and used it to fine-tune two well-established VLA approaches, OpenVLA and OpenVLA-OFT, as a case study. We divided the whole disassembly task into several small steps, and our preliminary experimental results indicate that the fine-tuned VLA models can faithfully complete multiple early steps but struggle with certain critical subtasks, leading to task failure. However, we observed that a simple hybrid strategy that combines VLA with a rule-based controller can successfully perform the entire disassembly operation. These findings highlight the current limitations of VLA models in handling the dexterity and precision required for robotic EoL product disassembly. By offering a detailed analysis of the observed results, this study provides insights that may inform future research to address current challenges and advance end-to-end robotic automated disassembly.

</details>


### [8] [Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration](https://arxiv.org/abs/2512.04453)
*Debasmita Ghose,Oz Gitelson,Marynel Vazquez,Brian Scassellati*

Main category: cs.RO

TL;DR: 本文提出了一种名为BALI的方法，该方法结合了自然语言偏好和观察到的人类行为来预测目标，并在协作烹饪任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了与人类协作，机器人必须推断出经常模糊、难以表达或不固定的目标。先前的方法将推理限制在预定义的目标集上，仅依赖于观察到的动作，或者完全依赖于明确的指令，这使得它们在现实世界的互动中显得脆弱。

Method: 提出了BALI（双向动作-语言推理），一种用于目标预测的方法，它将自然语言偏好与观察到的人类行为整合在一个递减视野规划树中。BALI结合来自人的语言和行动线索，在预期从回答中获得的信息收益超过打断成本时才会提问澄清问题，并选择符合推断目标的支持性行动。

Result: 在协作烹饪任务中的评估表明，与基线相比，BALI能够产生更稳定的目标预测，并显著减少错误。

Conclusion: 通过结合自然语言偏好与实际观察到的行为，BALI提供了一种有效的方法来改善人机协作过程中目标预测的准确性。

Abstract: To collaborate with humans, robots must infer goals that are often ambiguous, difficult to articulate, or not drawn from a fixed set. Prior approaches restrict inference to a predefined goal set, rely only on observed actions, or depend exclusively on explicit instructions, making them brittle in real-world interactions. We present BALI (Bidirectional Action-Language Inference) for goal prediction, a method that integrates natural language preferences with observed human actions in a receding-horizon planning tree. BALI combines language and action cues from the human, asks clarifying questions only when the expected information gain from the answer outweighs the cost of interruption, and selects supportive actions that align with inferred goals. We evaluate the approach in collaborative cooking tasks, where goals may be novel to the robot and unbounded. Compared to baselines, BALI yields more stable goal predictions and significantly fewer mistakes.

</details>


### [9] [One Ring to Rule Them All: Constrained Distributional Control for Massive-Scale Heterogeneous Robotic Ensemble Systems](https://arxiv.org/abs/2512.04502)
*Andres Arias,Wei Zhang,Haoyu Qian,Jr-Shin Li,Chuangchuang Sun*

Main category: cs.RO

TL;DR: 本文提出了一种受限群体控制框架，用于在状态和环境约束下（如避障）对参数化、异构的机器人系统进行控制。通过矩核变换将群体动态映射到核空间中的矩系统，并将状态空间约束也转换到矩空间中，从而实现安全的大规模群体控制。实验表明了该方法在受限环境中安全高效地控制机器人组的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在状态和环境约束条件下，比如需要避开障碍物的情况下，能够有效地控制一组参数不同、类型各异的机器人系统。

Method: 开发了一种矩核变换技术，将参数化的群体动态转换为核空间中的矩系统，同时把诸如必须访问的多面体航点及需避开的障碍物等状态空间约束也转换到了矩空间内，形成一个统一的安全大规模群体控制公式化表达。此外，还利用表达性强的信号时态逻辑规范来编码复杂的访问-避免任务。

Result: 仿真和硬件实验展示了所提方法能够在有约束的环境中安全且高效地控制机器人组。

Conclusion: 本研究提出的受限群体控制框架能够有效解决在存在状态与环境限制条件下的异构机器人系统的控制问题，特别是在需要执行复杂访问-避免任务时。

Abstract: Ensemble control aims to steer a population of dynamical systems using a shared control input. This paper introduces a constrained ensemble control framework for parameterized, heterogeneous robotic systems operating under state and environmental constraints, such as obstacle avoidance. We develop a moment kernel transform that maps the parameterized ensemble dynamics to the moment system in a kernel space, enabling the characterization of population-level behavior. The state-space constraints, such as polyhedral waypoints to be visited and obstacles to be avoided, are also transformed into the moment space, leading to a unified formulation for safe, large-scale ensemble control. Expressive signal temporal logic specifications are employed to encode complex visit-avoid tasks, which are achieved through a single shared controller synthesized from our constrained ensemble control formulation. Simulation and hardware experiments demonstrate the effectiveness of the proposed approach in safely and efficiently controlling robotic ensembles within constrained environments.

</details>


### [10] [Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting](https://arxiv.org/abs/2512.04731)
*Jian Tang,Pu Pang,Haowen Sun,Chengzhong Ma,Xingyu Chen,Hua Huang,Xuguang Lan*

Main category: cs.RO

TL;DR: 本文提出了一种新的表示方法——语义2D高斯点绘（S2GS），通过提取以物体为中心、领域不变的空间特征来解决机器人操作中模拟与现实环境之间显著的领域差距问题。实验结果表明，S2GS能显著提高从模拟到现实的迁移能力，在实际场景中保持了高水平且稳定的表现。


<details>
  <summary>Details</summary>
Motivation: 由于模拟和真实世界环境之间的巨大领域差异，机器人操作中的跨域迁移仍然是一个长期存在的挑战。现有方法如领域随机化、适应和模拟-现实校准通常需要大量的调整，或者无法泛化到未见的情况。

Method: 提出了语义2D高斯点绘（S2GS），这是一种新颖的表示方法，能够提取以物体为中心、领域不变的空间特征。S2GS通过构建多视角2D语义场，并通过特征级别的高斯点绘将其投影至统一的3D空间内。此外，还采用了一个语义过滤机制去除无关背景内容，确保为策略学习提供干净一致的输入。

Result: 为了评估S2GS的有效性，研究者选择了扩散策略作为下游学习算法，并在ManiSkill模拟环境中进行了实验，随后应用于实际部署。结果显示，S2GS显著提升了从模拟到现实世界的迁移性能，在真实场景下维持了高且稳定的任务表现。

Conclusion: 利用S2GS提取并利用领域不变特征的方法可以有效缩小模拟与真实世界间的差距，从而极大地提高了策略的一般性和在新场景下的适用性。

Abstract: Cross-domain transfer in robotic manipulation remains a longstanding challenge due to the significant domain gap between simulated and real-world environments. Existing methods such as domain randomization, adaptation, and sim-real calibration often require extensive tuning or fail to generalize to unseen scenarios. To address this issue, we observe that if domain-invariant features are utilized during policy training in simulation, and the same features can be extracted and provided as the input to policy during real-world deployment, the domain gap can be effectively bridged, leading to significantly improved policy generalization. Accordingly, we propose Semantic 2D Gaussian Splatting (S2GS), a novel representation method that extracts object-centric, domain-invariant spatial features. S2GS constructs multi-view 2D semantic fields and projects them into a unified 3D space via feature-level Gaussian splatting. A semantic filtering mechanism removes irrelevant background content, ensuring clean and consistent inputs for policy learning. To evaluate the effectiveness of S2GS, we adopt Diffusion Policy as the downstream learning algorithm and conduct experiments in the ManiSkill simulation environment, followed by real-world deployment. Results demonstrate that S2GS significantly improves sim-to-real transferability, maintaining high and stable task performance in real-world scenarios.

</details>


### [11] [TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards](https://arxiv.org/abs/2512.04772)
*Mauro Martini,Marco Ambrosio,Judith Vilella-Cantos,Alessandro Navone,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 介绍了TEMPO-VINE数据集，这是一个专为葡萄园环境设计的大规模多时相数据集，用于评估传感器融合、同时定位与地图构建（SLAM）及地点识别技术。


<details>
  <summary>Details</summary>
Motivation: 精准农业领域中，尤其是针对葡萄园这样动态变化的环境，缺乏一个现实条件下通用的基准来测试和开发鲁棒的自主系统。此外，现有的研究往往依赖于受控模拟或孤立的田间试验，这限制了自动化解决方案在真实复杂农业条件下的应用。

Method: 创建了一个名为TEMPO-VINE的数据集，该数据集包括来自不同价位的异构LiDAR、AHRS、RTK-GPS以及摄像机的数据，并且覆盖了多个季节、植被生长阶段、地形和天气条件下的真实葡萄架和凉棚葡萄园的信息。

Result: 提供了首个公共多模态数据集，特别适合于农业环境中传感器融合、定位、制图和地点识别技术的发展。此数据集还包含了多次运行和重访路径，有助于解决上述提到的技术挑战。

Conclusion: 通过提供TEMPO-VINE数据集及相关处理工具和基准测试结果，填补了农业数据集领域中的一个重要空白，促进了适用于农业场景下自主导航系统解决方案的发展。

Abstract: In recent years, precision agriculture has been introducing groundbreaking innovations in the field, with a strong focus on automation. However, research studies in robotics and autonomous navigation often rely on controlled simulations or isolated field trials. The absence of a realistic common benchmark represents a significant limitation for the diffusion of robust autonomous systems under real complex agricultural conditions. Vineyards pose significant challenges due to their dynamic nature, and they are increasingly drawing attention from both academic and industrial stakeholders interested in automation. In this context, we introduce the TEMPO-VINE dataset, a large-scale multi-temporal dataset specifically designed for evaluating sensor fusion, simultaneous localization and mapping (SLAM), and place recognition techniques within operational vineyard environments. TEMPO-VINE is the first multi-modal public dataset that brings together data from heterogeneous LiDARs of different price levels, AHRS, RTK-GPS, and cameras in real trellis and pergola vineyards, with multiple rows exceeding 100 m in length. In this work, we address a critical gap in the landscape of agricultural datasets by providing researchers with a comprehensive data collection and ground truth trajectories in different seasons, vegetation growth stages, terrain and weather conditions. The sequence paths with multiple runs and revisits will foster the development of sensor fusion, localization, mapping and place recognition solutions for agricultural fields. The dataset, the processing tools and the benchmarking results will be available at the dedicated webpage upon acceptance.

</details>


### [12] [Using Machine Learning to Take Stay-or-Go Decisions in Data-driven Drone Missions](https://arxiv.org/abs/2512.04773)
*Giorgos Polychronis,Foivos Pournaropoulos,Christos D. Antonopoulos,Spyros Lalis*

Main category: cs.RO

TL;DR: 本文提出基于分支预测和强化学习的机器学习方法，以帮助无人机在数据驱动任务中决定是否在当前位置采取进一步行动。实验结果表明，所提方法不仅优于现有文献中的回归方法，而且在最坏情况下可以将任务时间提高至4.1倍，同时中位数任务时间与完全已知事件概率的方法非常接近，最多仅高出2.7%。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在多个应用领域的不可或缺性增加，在数据驱动的任务中，除了感知外，无人机还需要在运行时处理收集到的数据，以决定是否需要立即采取额外行动，还是前往下一个兴趣点。错误的决策会导致无效等待或回飞，浪费时间。为了解决这一问题，文章提出了基于分支预测和强化学习的新方法来优化决策过程。

Method: 该研究采用了几种基于机器学习的方法，特别是结合了分支预测技术和强化学习策略，旨在更好地预测特定位置是否会发生需要无人机采取行动的情况。通过对比不同场景下事件发生概率随时间变化的情况，对这些方法进行了评估。

Result: 实验结果显示，所提出的基于机器学习的方法相较于文献中提到的基于回归的方法表现出色，尤其是在最差情况下的任务完成时间上有了显著提升（最高可达4.1倍）。此外，使用新方法达成的任务中位数时间与假设能够完美预知每个兴趣点当前潜在事件发生概率的理想方法相比，也仅仅高出不超过2.7%。

Conclusion: 本研究表明，通过引入基于分支预测和强化学习的创新方法，可以在有效减少无人机在执行数据驱动任务时由于决策不当导致的时间浪费，从而大幅提升任务效率。

Abstract: Drones are becoming indispensable in many application domains. In data-driven missions, besides sensing, the drone must process the collected data at runtime to decide whether additional action must be taken on the spot, before moving to the next point of interest. If processing does not reveal an event or situation that requires such an action, the drone has waited in vain instead of moving to the next point. If, however, the drone starts moving to the next point and it turns out that a follow-up action is needed at the previous point, it must spend time to fly-back. To take this decision, we propose different machine-learning methods based on branch prediction and reinforcement learning. We evaluate these methods for a wide range of scenarios where the probability of event occurrence changes with time. Our results show that the proposed methods consistently outperform the regression-based method proposed in the literature and can significantly improve the worst-case mission time by up to 4.1x. Also, the achieved median mission time is very close, merely up to 2.7% higher, to that of a method with perfect knowledge of the current underlying event probability at each point of interest.

</details>


### [13] [MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation](https://arxiv.org/abs/2512.04813)
*Huanqian Wang,Chi Bene Chen,Yang Yue,Danhua Tao,Tong Guo,Shaoxuan Xie,Denghang Huang,Shiji Song,Guocai Yao,Gao Huang*

Main category: cs.RO

TL;DR: 本文提出了一种名为MOVE（基于运动的变异性增强）的数据收集方法，通过在演示过程中为可移动物体引入运动来增加空间信息的丰富性和多样性，从而提高了模仿学习中数据效率和空间泛化能力。实验结果表明，在某些任务上，与静态数据收集相比，该方法可以达到2-5倍的数据效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法尽管在机器人操作中显示出巨大潜力，但其实用部署受到数据稀缺性的根本限制。现有工作虽然致力于收集大规模数据集，但在实现稳健的空间泛性方面仍存在显著差距。文章指出一个关键局限在于：个体轨迹通常是从环境的单个静态空间配置下收集而来，包括固定的物体和目标位置以及不变的摄像机视角，这极大地限制了可用于学习的空间信息多样性。

Method: 为了解决数据效率中的这一关键瓶颈问题，作者提出了MOtion-Based Variability Enhancement (MOVE)，这是一种简单而有效的数据收集范式，能够从动态演示中获取更丰富的空间信息。其核心贡献是一种增强策略，即对环境中每个演示里的任何可移动物体注入运动，这一过程隐式地在一个单一轨迹内生成密集且多样的空间配置集合。

Result: 通过在模拟和真实世界环境中进行广泛实验验证了所提方法的有效性。例如，在需要强空间泛化的模拟任务中，MOVE达到了39.1%的平均成功率，相对于静态数据收集范式（22.2%）有76.1%的相对改善，并且在某些特定任务上实现了高达2至5倍的数据效率增益。

Conclusion: 研究结果表明，通过采用MOVE方法可以在不显著增加数据量的情况下提高模仿学习算法的空间泛化性能，证明了这种方法对于提高数据利用效率和模型泛化能力的有效性。

Abstract: Imitation learning method has shown immense promise for robotic manipulation, yet its practical deployment is fundamentally constrained by the data scarcity. Despite prior work on collecting large-scale datasets, there still remains a significant gap to robust spatial generalization. We identify a key limitation: individual trajectories, regardless of their length, are typically collected from a \emph{single, static spatial configuration} of the environment. This includes fixed object and target spatial positions as well as unchanging camera viewpoints, which significantly restricts the diversity of spatial information available for learning. To address this critical bottleneck in data efficiency, we propose \textbf{MOtion-Based Variability Enhancement} (\emph{MOVE}), a simple yet effective data collection paradigm that enables the acquisition of richer spatial information from dynamic demonstrations. Our core contribution is an augmentation strategy that injects motion into any movable objects within the environment for each demonstration. This process implicitly generates a dense and diverse set of spatial configurations within a single trajectory. We conduct extensive experiments in both simulation and real-world environments to validate our approach. For example, in simulation tasks requiring strong spatial generalization, \emph{MOVE} achieves an average success rate of 39.1\%, a 76.1\% relative improvement over the static data collection paradigm (22.2\%), and yields up to 2--5$\times$ gains in data efficiency on certain tasks. Our code is available at https://github.com/lucywang720/MOVE.

</details>


### [14] [Hoi! - A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation](https://arxiv.org/abs/2512.04884)
*Tim Engelbracht,René Zurbrügg,Matteo Wohlrapp,Martin Büchner,Abhinav Valada,Marc Pollefeys,Hermann Blum,Zuria Bauer*

Main category: cs.RO

TL;DR: A new dataset for studying force-grounded, cross-view articulated manipulation, featuring 3048 sequences of 381 objects in 38 environments, operated by four different embodiments, to facilitate research on interaction understanding and method transfer between human and robotic perspectives.


<details>
  <summary>Details</summary>
Motivation: 为了促进对交互理解的研究，并评估方法在人类视角和机器人视角之间的迁移效果，同时探索诸如力感知和预测等研究不足的模态。

Method: 创建了一个包含3048个序列的数据集，这些序列来自38个环境中的381个关节物体，每个物体通过四种不同的实施方式（人手、带腕部摄像机的人手、手持UMI夹具和定制的Hoi!夹具）进行操作，工具实施提供了同步的末端执行器力和触觉感应。

Result: 该数据集为从视频中理解交互提供了一个全面的观点，使研究人员能够评价方法在人类与机器人视角间的转移情况，并且可以研究如力感应和预测等未被充分探索的模式。

Conclusion: 此数据集促进了力基础的、跨视图的关节操作研究，支持了视频互动理解的方法开发，并且推动了人与机器人之间视角转换技术的发展。

Abstract: We present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.

</details>


### [15] [On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator](https://arxiv.org/abs/2512.04917)
*Matteo Masoni,Vincenzo Palermo,Marco Gabiccini,Martino Gulisano,Giorgio Previati,Massimiliano Gobbi,Francesco Comolli,Gianpiero Mastinu,Massimo Guiggiani*

Main category: cs.RO

TL;DR: 本研究探讨了在动态模拟器中，由专业驾驶员执行的扰动感知、嵌入鲁棒性的参考轨迹如何转化为驾驶性能。通过对比三种规划的参考轨迹（NOM：名义上的时间最优轨迹；TLC：通过紧缩到赛道边缘获得的赛道限制鲁棒性轨迹；FLC：通过紧缩至轴和轮胎饱和度获得的摩擦限制鲁棒性轨迹）与自由驾驶基线（NOREF），评估圈速（LT）和转向努力（SE）之间的权衡。结果显示了一种帕累托式的LT-SE权衡关系，其中FLC尤其接近有效前沿，在相对NOM仅有轻微圈速增加的情况下显著降低了SE。该研究表明基于参考点及扰动意识的规划是训练以及实现快速且稳定轨迹的有效工具。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索扰动感知和鲁棒性嵌入的参考轨迹对于提高驾驶性能的实际效果，特别是当这些轨迹被专业驾驶员在模拟环境中遵循时，能否在保持高速的同时减少控制输入的需求。

Method: 采用了比较分析的方法，选取了三个不同的参考轨迹方案(NOM, TLC, FLC)与一个无参考轨迹自由驾驶情形(NOREF)进行对比测试。所有轨迹都旨在最小化圈速，并加入了一个小量的转向平滑正则项。实验是在一个高性能汽车上于虚拟赛道中由两位专业驾驶员完成的。

Result: 结果表明存在一种类似于帕累托最优的圈速-转向努力权衡关系：NOM提供了最短的圈速但需要最高的转向努力；TLC以较长的圈速为代价将转向努力降至最低；而FLC则位于效率前沿附近，相比NOM大幅减少了所需的转向努力同时仅略微增加了圈速。去除轨迹指导(NOREF)会同时增加圈速和转向努力。

Conclusion: 结论指出，基于参考轨迹尤其是考虑了扰动因素设计的FLC轨迹，不仅能改善驾驶节奏还能提高控制效率，是训练及实现既快又稳定的驾驶表现的有效手段。

Abstract: This work investigates how disturbance-aware, robustness-embedded reference trajectories translate into driving performance when executed by professional drivers in a dynamic simulator. Three planned reference trajectories are compared against a free-driving baseline (NOREF) to assess trade-offs between lap time (LT) and steering effort (SE): NOM, the nominal time-optimal trajectory; TLC, a track-limit-robust trajectory obtained by tightening margins to the track edges; and FLC, a friction-limit-robust trajectory obtained by tightening against axle and tire saturation. All trajectories share the same minimum lap-time objective with a small steering-smoothness regularizer and are evaluated by two professional drivers using a high-performance car on a virtual track. The trajectories derive from a disturbance-aware minimum-lap-time framework recently proposed by the authors, where worst-case disturbance growth is propagated over a finite horizon and used to tighten tire-friction and track-limit constraints, preserving performance while providing probabilistic safety margins. LT and SE are used as performance indicators, while RMS lateral deviation, speed error, and drift angle characterize driving style. Results show a Pareto-like LT-SE trade-off: NOM yields the shortest LT but highest SE; TLC minimizes SE at the cost of longer LT; FLC lies near the efficient frontier, substantially reducing SE relative to NOM with only a small LT increase. Removing trajectory guidance (NOREF) increases both LT and SE, confirming that reference trajectories improve pace and control efficiency. Overall, the findings highlight reference-based and disturbance-aware planning, especially FLC, as effective tools for training and for achieving fast yet stable trajectories.

</details>


### [16] [Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies](https://arxiv.org/abs/2512.04960)
*Jonne Van Haastregt,Bastian Orthmann,Michael C. Welle,Yuchong Zhang,Danica Kragic*

Main category: cs.RO

TL;DR: 本研究提出了一种结合开环程序与视觉运动扩散策略的混合扩散模型（Hybrid-Diffusion models），通过引入远程操作增强原语(TAPs)来提高复杂操作任务中的准确性和速度。


<details>
  <summary>Details</summary>
Motivation: 尽管基于模仿学习得到的视觉运动策略在复杂的操作任务中表现出良好的性能，但它们通常难以达到传统控制方法那样的精度和速度。

Method: 研究人员开发了混合扩散模型以及远程操作增强原语（TAPs），允许操作者在演示过程中无缝执行预定义的例程，比如锁定特定轴、移动到悬停航点或触发任务特定的例程。该混合扩散方法学会了在推理过程中触发这些TAPs。

Result: 该方法在现实世界中的挑战性任务上得到了验证，包括试管吸液、开放式容器液体转移及容器拧开等。

Conclusion: 通过结合开环例程与视觉运动扩散策略，并利用TAPs提升操作灵活性，混合扩散模型为解决复杂操作任务提供了一个新的视角。

Abstract: Despite the fact that visuomotor-based policies obtained via imitation learning demonstrate good performances in complex manipulation tasks, they usually struggle to achieve the same accuracy and speed as traditional control based methods. In this work, we introduce Hybrid-Diffusion models that combine open-loop routines with visuomotor diffusion policies. We develop Teleoperation Augmentation Primitives (TAPs) that allow the operator to perform predefined routines, such as locking specific axes, moving to perching waypoints, or triggering task-specific routines seamlessly during demonstrations. Our Hybrid-Diffusion method learns to trigger such TAPs during inference. We validate the method on challenging real-world tasks: Vial Aspiration, Open-Container Liquid Transfer, and container unscrewing. All experimental videos are available on the project's website: https://hybriddiffusion.github.io/

</details>


### [17] [Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist](https://arxiv.org/abs/2512.04973)
*Giuseppe Milazzo,Manuel G. Catalano,Antonio Bicchi,Giorgio Grioli*

Main category: cs.RO

TL;DR: 本文介绍了一种新颖的3自由度并行手腕，通过冗余弹性驱动实现可变刚度。该装置紧凑轻便，适用于假肢或人形机器人领域，并且提出了一种复杂的控制策略来独立调节关节位置和刚度。仿真验证了所提出的控制器能够实现高精度和抗干扰性，同时通过其顺应性行为最小化交互力。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，可变刚度执行器对于促进安全交互和提高任务适应性至关重要。但与传统刚性执行器相比，它们的设计往往导致体积更大、重量更重。本研究旨在开发一种既保持可变刚度优点又具有紧凑轻便特性的新型执行器，以满足假肢或人形机器人应用的需求。

Method: 设计了一种基于平行架构的3自由度并行手腕，利用四个电机实现冗余弹性驱动从而达到可变刚度的效果。此外，文章还深入探讨了该设备的理论模型，并提出了一种用于独立控制关节位置和刚度的高级控制策略。

Result: 仿真结果表明，所提出的控制器能够使设备在刚性配置下实现高精度定位及良好的扰动抑制性能；同时，在柔顺模式下，它还能有效减少与环境的交互力。

Conclusion: 这种新式的3 DoF并行手腕结合了紧凑轻便设计与可变刚度功能，为假肢或人形机器人提供了理想的解决方案。通过仿真验证了其在不同应用场景下的有效性。

Abstract: Variable Stiffness Actuators prove invaluable for robotics applications in unstructured environments, fostering safe interactions and enhancing task adaptability. Nevertheless, their mechanical design inevitably results in larger and heavier structures compared to classical rigid actuators. This paper introduces a novel 3 Degrees of Freedom (DoFs) parallel wrist that achieves variable stiffness through redundant elastic actuation. Leveraging its parallel architecture, the device employs only four motors, rendering it compact and lightweight. This characteristic makes it particularly well-suited for applications in prosthetics or humanoid robotics. The manuscript delves into the theoretical model of the device and proposes a sophisticated control strategy for independent regulation of joint position and stiffness. Furthermore, it validates the proposed controller through simulation, utilizing a comprehensive analysis of the system dynamics. The reported results affirm the ability of the device to achieve high accuracy and disturbance rejection in rigid configurations while minimizing interaction forces with its compliant behavior.

</details>


### [18] [Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness](https://arxiv.org/abs/2512.04998)
*Giuseppe Milazzo,Giorgio Grioli,Antonio Bicchi,Manuel G. Catalano*

Main category: cs.RO

TL;DR: 本研究开发了一种配备可变刚度执行器的经肱骨假肢，旨在模仿生物关节的可控顺应性。该假肢采用模块化设计，可根据不同残肢形状进行定制，并能根据用户的生物信号调整。集成的弹性元件支持更自然的动作，促进与环境的安全互动，并适应各种任务需求。


<details>
  <summary>Details</summary>
Motivation: 现有的上肢假肢尽管具备基本的运动功能，但无法完全复制人类手臂自然流畅的运动和交互能力。人体肢体通过内在的柔顺性和主动调节关节刚度来适应不同的任务、吸收冲击并在动态活动中高效传递能量。受到这种适应性的启发，研究人员致力于开发一种能够模仿生物关节可控顺应性的假肢。

Method: 研究者们设计并实现了一种带有可变刚度执行器(VSAs)的经肱骨假肢。该假肢具有模块化特性，可以根据用户的不同残肢形态进行个性化定制，并且能够响应一系列独立控制信号，这些信号源自用户的生理指示。此外，还整合了弹性组件以促进更加自然的动作表现，同时确保与周围环境安全互动以及对不同任务要求的良好适应。

Result: 介绍了一个全新的经肱骨假肢平台及其功能特点，强调了其在假肢领域潜在的应用价值。

Conclusion: 提出的经肱骨假肢通过引入可变刚度执行器成功模拟了生物关节的可控顺应性，为用户提供了一种更接近自然手臂操作体验的选择。其模块化设计和集成弹性元件有助于提高假肢使用的灵活性与安全性，显示出了在提升用户日常生活独立性方面巨大的潜力。

Abstract: Current upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users' biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.

</details>


### [19] [Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain](https://arxiv.org/abs/2512.05008)
*Haroon Hublikar*

Main category: cs.RO

TL;DR: 本文提出了一种统一的建模和仿真框架，用于分析COBRA蛇形机器人在刚性、柔性和颗粒地形上的侧绕和滚动运动。通过接触隐式公式化来模拟侧绕过程中的分布式摩擦交互，并且结合了Project Chrono的土壤接触模型（SCM）以预测滑移、沉陷和负载重新分布等现象。对于陡坡上的高能滚动运动，则使用Chrono DEM引擎来模拟颗粒级的相互作用。研究结果表明，在软质和高度动态环境中进行可靠的移动性分析时，需要连续介质和基于颗粒的地形建模。


<details>
  <summary>Details</summary>
Motivation: 为了提高蛇形机器人在复杂非结构化环境中的移动能力，特别是在软质和高度动态环境中能够准确预测其运动表现。

Method: 采用接触隐式公式化方法建模侧绕过程中的分布式摩擦交互；整合Project Chrono的SCM与多体动力学模型以考虑地形变形效应；利用Chrono DEM引擎模拟高能量滚动运动时的颗粒级相互作用。

Result: 刚性地面模型可以提供准确的短期运动预测，但在软质和高度动态环境中，需要引入连续介质和基于颗粒的地形建模方法来实现可靠的移动性分析。

Conclusion: 本研究建立了一个分层仿真流程，该流程促进了在具有挑战性的非结构化环境中运行的机器人稳健且适应地形的移动性能。

Abstract: This thesis presents a unified modeling and simulation framework for analyzing sidewinding and tumbling locomotion of the COBRA snake robot across rigid, compliant, and granular terrains. A contact-implicit formulation is used to model distributed frictional interactions during sidewinding, and validated through MATLAB Simscape simulations and physical experiments on rigid ground and loose sand. To capture terrain deformation effects, Project Chrono's Soil Contact Model (SCM) is integrated with the articulated multibody dynamics, enabling prediction of slip, sinkage, and load redistribution that reduce stride efficiency on deformable substrates. For high-energy rolling locomotion on steep slopes, the Chrono DEM Engine is used to simulate particle-resolved granular interactions, revealing soil failure, intermittent lift-off, and energy dissipation mechanisms not captured by rigid models. Together, these methods span real-time control-oriented simulation and high-fidelity granular physics. Results demonstrate that rigid-ground models provide accurate short-horizon motion prediction, while continuum and particle-based terrain modeling becomes necessary for reliable mobility analysis in soft and highly dynamic environments. This work establishes a hierarchical simulation pipeline that advances robust, terrain-aware locomotion for robots operating in challenging unstructured settings.

</details>


### [20] [From Generated Human Videos to Physically Plausible Robot Trajectories](https://arxiv.org/abs/2512.05094)
*James Ni,Zekai Wang,Wei Lin,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik,Roei Herzig*

Main category: cs.RO

TL;DR: 提出了一种两阶段方法GenMimic，使类人机器人能够从生成的视频中零样本模仿人类动作，并通过物理感知强化学习策略实现稳定运动跟踪。


<details>
  <summary>Details</summary>
Motivation: 为了解决由视频生成模型产生的视频通常存在噪声和形态扭曲的问题，使得直接模仿变得困难，研究旨在探索如何让类人机器人以零样本方式执行来自这些生成视频的人类动作。

Method: 采用两阶段流程：首先将视频像素转换为4D人体表示并重新定向到类人机器人形态；其次引入了基于3D关键点条件下的物理感知强化学习策略GenMimic，该策略利用对称性正则化和关键点加权追踪奖励进行训练。

Result: 实验结果表明，与强大的基线相比，在模拟环境中表现出了改进，并且在Unitree G1类人机器人上实现了连贯且物理稳定的运动跟踪，无需微调。

Conclusion: 这项工作展示了视频生成模型作为机器人控制高层次策略潜力的一条有希望的道路。

Abstract: Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.

</details>


### [21] [STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](https://arxiv.org/abs/2512.05107)
*Feng Xu,Guangyao Zhai,Xin Kong,Tingzhong Fu,Daniel F. N. Gordon,Xueli An,Benjamin Busam*

Main category: cs.RO

TL;DR: 提出了一种新的方法STARE，它将长时序动作分解为有意义的阶段，并提供密集、可解释且与阶段对齐的强化信号。结合STARE到TPO和PPO中形成了STA-TPO和STA-PPO，用于离线阶段偏好和在线阶段内交互。此外，提出了一种模仿->偏好->交互（IPI）的串行微调流程来提高VLA模型的动作准确性。实验结果表明该方法在SimplerEnv和ManiSkill3任务上达到了最先进的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常将长时序动作视为语言序列，并采用如TPO或PPO等轨迹级优化方法，这导致了粗略的信用分配和不稳定的训练。鉴于动作轨迹通过因果链结的阶段进行，具有不同的学习难度，不同于语言的灵活句子顺序但保持统一语义特性，研究者受到启发提出了基于阶段的逐步优化方法。

Method: 设计了一个名为Stage-Aware Reinforcement (STARE)的模块，能够将长时间跨度的动作路径分解为具有明确意义的几个阶段，并针对每个阶段提供密集、易懂且相匹配的强化反馈。将STARE整合进TPO与PPO之中，分别得到适用于离线阶段偏好调整及在线阶段内部互动的STA-TPO和STA-PPO。另外，还提出了一套按顺序执行的精细调优流程——模仿->偏好->互动(IPI)，旨在提升VLA模型在执行任务时的精确度。

Result: 在SimplerEnv以及ManiSkill3上的实验显示，所提出的方法取得了显著的效果改进，特别是在成功率方面，分别达到98.0%和96.4%，代表了当前领域内的最高水平。

Conclusion: 本文介绍的STARE模块及其衍生出的STA-TPO和STA-PPO算法，加上IPI调优管道，为解决视觉-语言-动作模型中的长时序动作挑战提供了有效途径。实验证明，这种方法不仅增强了学习过程中的稳定性，也极大地提高了最终表现的成功率。

Abstract: Recent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -> Preference -> Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.

</details>
