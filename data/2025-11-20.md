<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Z-Merge: Multi-Agent Reinforcement Learning for On-Ramp Merging with Zone-Specific V2X Traffic Information](https://arxiv.org/abs/2511.14910)
*Yassine Ibork,Myounggyu Won,Lokesh Das*

Main category: cs.RO

TL;DR: 本文提出了一种基于V2X通信的多智能体强化学习框架，用于解决自动驾驶车辆在混合交通环境中的匝道合并问题。通过利用路侧单元提供的区域特定全局信息，该框架协调了变道和车距调整策略之间的复杂交互，从而提高了合并成功率、交通效率和道路安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的匝道合并方法通常仅依赖于局部或邻近信息来实现变车道或创造车辆间空隙，这导致了在安全性和交通效率方面表现不佳。为了解决这个问题，并且考虑到与人类驾驶车辆共存的复杂情况，研究者们开发了一个能够结合局部观察与全局信息的新框架。

Method: 提出了一个基于V2X通信辅助下的多智能体强化学习（MARL）框架，其中将合并控制问题建模成一个多智能体部分可观测马尔可夫决策过程（MA-POMDP）。通过设计一种混合动作空间和支持参数化的深度Q-学习方法来处理离散和连续控制决策。

Result: 通过整合SUMO交通模拟器和MOSAIC V2X模拟器进行的大规模仿真表明，所提出的框架能够在多种交通场景下显著提高合并成功率、交通效率以及道路安全性。

Conclusion: 本研究表明，通过引入V2X通信技术并采用多智能体强化学习方法，可以有效地解决自动驾驶汽车在面临复杂交通状况时的匝道合并难题，进而提升整体交通系统的性能。

Abstract: Ramp merging is a critical and challenging task for autonomous vehicles (AVs), particularly in mixed traffic environments with human-driven vehicles (HVs). Existing approaches typically rely on either lane-changing or inter-vehicle gap creation strategies based solely on local or neighboring information, often leading to suboptimal performance in terms of safety and traffic efficiency. In this paper, we present a V2X (vehicle-to-everything communication)-assisted Multiagent Reinforcement Learning (MARL) framework for on-ramp merging that effectively coordinates the complex interplay between lane-changing and inter-vehicle gap adaptation strategies by utilizing zone-specific global information available from a roadside unit (RSU). The merging control problem is formulated as a Multiagent Partially Observable Markov Decision Process (MA-POMDP), where agents leverage both local and global observations through V2X communication. To support both discrete and continuous control decisions, we design a hybrid action space and adopt a parameterized deep Q-learning approach. Extensive simulations, integrating the SUMO traffic simulator and the MOSAIC V2X simulator, demonstrate that our framework significantly improves merging success rate, traffic efficiency, and road safety across diverse traffic scenarios.

</details>


### [2] [A visual study of ICP variants for Lidar Odometry](https://arxiv.org/abs/2511.14919)
*Sebastian Dingler,Hannes Burrichter*

Main category: cs.RO

TL;DR: 本研究通过可视化ICP算法的多维目标函数来分析不同ICP变体在激光雷达里程计中的应用，并提出了一种新方法以过滤动态物体和解决自我盲点问题。


<details>
  <summary>Details</summary>
Motivation: 鉴于现实世界中的动态物体、非重叠区域及传感器噪声等因素会降低ICP算法的准确性，该研究旨在改进激光雷达里程计的精度。

Method: 采用一种最近提出的方法将ICP的多维目标函数可视化为二维图形，以此来研究不同的ICP变体，并提出新的方法用于滤除动态对象以及处理自车盲点问题。

Result: 研究展示了不同ICP变体对于激光雷达里程计算法的影响，并且所提出的新方法能够有效提高面对动态场景时的定位精度。

Conclusion: 通过对ICP算法及其变体进行深入分析，并引入针对动态物体过滤和自车盲点处理的新策略，可以显著提升基于激光雷达的车辆自我姿态估计准确度。

Abstract: Odometry with lidar sensors is a state-of-the-art method to estimate the ego pose of a moving vehicle. Many implementations of lidar odometry use variants of the Iterative Closest Point (ICP) algorithm. Real-world effects such as dynamic objects, non-overlapping areas, and sensor noise diminish the accuracy of ICP. We build on a recently proposed method that makes these effects visible by visualizing the multidimensional objective function of ICP in two dimensions. We use this method to study different ICP variants in the context of lidar odometry. In addition, we propose a novel method to filter out dynamic objects and to address the ego blind spot problem.

</details>


### [3] [SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification](https://arxiv.org/abs/2511.14977)
*Xiangyu Li,Zhaomiao Guo*

Main category: cs.RO

TL;DR: 本研究提出了SVBRD-LLM框架，通过零样本提示工程从真实交通视频中自动发现、验证并应用可解释的行为规则来分析自动驾驶车辆与人为驾驶车辆的区别。该框架能够有效识别自动驾驶车辆，并揭示了其在速度控制平滑性、变道保守性和加速度稳定性方面的独特特征。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的自动驾驶汽车上路，理解这些车辆在现实世界中的行为对于分析交通安全、制定政策以及公众接受度至关重要。

Method: 使用YOLOv8和ByteTrack提取车辆轨迹，计算运动学特征，并利用GPT-5进行零样本提示以比较自动驾驶车与人类驾驶车的行为模式，生成35条结构化的行为规则假设。随后，在验证集上测试这些规则，并基于失败案例迭代改进以过滤虚假关联，最终形成高置信度规则库。

Result: 实验表明，该框架在独立测试集上的表现优异，特别是在自动驾驶车辆识别任务中达到了90.0%的准确率和93.3%的F1分数。所发现的规则清晰地展示了自动驾驶车辆在速度控制平稳性、变道谨慎性及加速稳定性等方面的显著特点。

Conclusion: SVBRD-LLM框架提供了一种有效的手段来自动发现并验证关于自动驾驶车辆行为的可解释规则，这对于提高交通安全、促进相关政策制定及增强公众对自动驾驶技术的信任具有重要意义。

Abstract: As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.

</details>


### [4] [An Alignment-Based Approach to Learning Motions from Demonstrations](https://arxiv.org/abs/2511.14988)
*Alex Cuellar,Christopher K Fourie,Julie A Shah*

Main category: cs.RO

TL;DR: 本文提出了一种名为CALM的LfD框架，该框架依赖于与演示动作的代表性'平均'轨迹对齐，而非单纯的时间或状态依赖性。通过这种方法，CALM能够克服时间依赖性和非时间依赖性技术各自的缺点，并在2D数据集上进行了验证，在三个不同领域的7自由度机器人上实现了任务学习。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习示例的方法（如学习的动力系统和运动基元）可分为时间依赖型或时间非依赖型两种，但它们各自存在局限：时间非依赖型方法无法学习重叠轨迹，而时间依赖型方法在受到干扰时可能会导致不希望的行为。为了克服这些局限，作者提出了新的方法。

Method: 提出了一种名为Cluster Alignment for Learned Motions (CALM)的学习从演示方法，它依靠与演示动作代表性的'平均'轨迹进行对齐而不是单纯依据时间或状态。介绍了CALM的收敛特性、一种能够处理在受扰动情况下可能发生的对齐偏移的技术以及利用演示聚类来生成多模式行为的方法。

Result: 研究显示，CALM能够在2D数据集上缓解时间依赖型和技术非依赖型技术的不足，并且在7-DoF机器人上针对三个不同领域实施了该系统以完成学习任务。

Conclusion: 通过引入CALM框架，本研究成功地结合了时间依赖型和非时间依赖型LfD方法的优点，同时减轻了各自的缺点，为机器人提供了更鲁棒且灵活的学习能力。

Abstract: Learning from Demonstration (LfD) has shown to provide robots with fundamental motion skills for a variety of domains. Various branches of LfD research (e.g., learned dynamical systems and movement primitives) can generally be classified into ''time-dependent'' or ''time-independent'' systems. Each provides fundamental benefits and drawbacks -- time-independent methods cannot learn overlapping trajectories, while time-dependence can result in undesirable behavior under perturbation. This paper introduces Cluster Alignment for Learned Motions (CALM), an LfD framework dependent upon an alignment with a representative ''mean" trajectory of demonstrated motions rather than pure time- or state-dependence. We discuss the convergence properties of CALM, introduce an alignment technique able to handle the shifts in alignment possible under perturbation, and utilize demonstration clustering to generate multi-modal behavior. We show how CALM mitigates the drawbacks of time-dependent and time-independent techniques on 2D datasets and implement our system on a 7-DoF robot learning tasks in three domains.

</details>


### [5] [Communication-Aware Asynchronous Distributed Trajectory Optimization for UAV Swarm](https://arxiv.org/abs/2511.14994)
*Yue Yu,Xiaobo Zheng,Shaoming He*

Main category: cs.RO

TL;DR: 提出了一种通信感知的异步分布式轨迹优化框架（CA-ADTO），结合了参数化微分动态规划(PDDP)和异步交替方向乘子法(async-ADMM)，以解决无人机群在通信受限环境下的轨迹规划问题。


<details>
  <summary>Details</summary>
Motivation: 针对无人机群在通信受限环境下面临的不可靠链接和有限数据交换挑战，研究旨在开发一种能够在这些条件下有效运行的两层架构。

Method: 通过整合参数化微分动态规划(PDDP)进行单个无人机局部轨迹优化，并使用异步交替方向乘子法(async-ADMM)进行群体级别协调，构建了一个通信感知的异步分布式轨迹优化(CA-ADTO)框架。

Result: 该架构实现了完全分布式的优化，同时大幅减少了通信开销，尤其适用于处理通信受限条件下的非线性动力学和时空耦合问题。

Conclusion: 所提出的CA-ADTO框架为无人机群在不可靠连接场景中提供了有效的轨迹规划解决方案，证明了其在减少通信需求的同时保持高效性能的能力。

Abstract: Distributed optimization offers a promising paradigm for trajectory planning in Unmanned Aerial Vehicle (UAV) swarms, yet its deployment in communication-constrained environments remains challenging due to unreliable links and limited data exchange. This paper addresses this issue via a two-tier architecture explicitly designed for operation under communication constraints. We develop a Communication-Aware Asynchronous Distributed Trajectory Optimization (CA-ADTO) framework that integrates Parameterized Differential Dynamic Programming (PDDP) for local trajectory optimization of individual UAVs with an asynchronous Alternating Direction Method of Multipliers (async-ADMM) for swarm-level coordination. The proposed architecture enables fully distributed optimization while substantially reducing communication overhead, making it suitable for real-world scenarios in which reliable connectivity cannot be guaranteed. The method is particularly effective in handling nonlinear dynamics and spatio-temporal coupling under communication constraints.

</details>


### [6] [Lie Group Control Architectures for UAVs: a Comparison of SE2(3)-Based Approaches in Simulation and Hardware](https://arxiv.org/abs/2511.15023)
*Dimitria Silveria,Kleber Cabral,Peter Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 该论文介绍了基于李群的四旋翼飞行器先进控制策略的集成与实验验证，提出了一种新的SE2(3)模型预测控制器（MPC），并在仿真和实际平台上展示了其在轨迹跟踪性能和鲁棒性方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过结合最优控制的预测能力和约束处理以及李群公式化的几何特性来提高四旋翼飞行器的控制性能。

Method: 开发了一种基于SE2(3)的新型模型预测控制器，并将其与最新的基于SE2(3)的LQR方法进行了对比评估。此外，在Quanser QDrone平台上面向一系列场景测试了这两种控制器及一种工业标准控制架构的表现。

Result: 结果表明，SE2(3) MPC相比其他测试的控制器能够实现更好的轨迹跟踪表现和更强的鲁棒性。

Conclusion: 本研究证明了基于李群的控制器在实践中的有效性，并提供了关于这些控制器如何影响系统行为和实时性能的比较见解。

Abstract: This paper presents the integration and experimental validation of advanced control strategies for quadcopters based on Lie groups. We build upon recent theoretical developments on SE2(3)-based controllers and introduce a novel SE2(3) model predictive controller (MPC) that combines the predictive capabilities and constraint-handling of optimal control with the geometric properties of Lie group formulations. We evaluated this MPC against a state-of-the-art SE2(3)-based LQR approach and obtained comparable performance in simulation. Both controllers where also deployed on the Quanser QDrone platform and compared to each other and an industry standard control architecture. Results show that the SE_2(3) MPC achieves superior trajectory tracking performance and robustness across a range of scenarios. This work demonstrates the practical effectiveness of Lie group-based controllers and offers comparative insights into their impact on system behaviour and real-time performance

</details>


### [7] [Painted Heart Beats](https://arxiv.org/abs/2511.15105)
*Angshu Adhya,Cindy Yang,Emily Wu,Rishad Hasan,Abhishek Narula,Patrícia Alves-Oliveira*

Main category: cs.RO

TL;DR: AURA框架通过结合艺术家的心跳等生物特征，实现人与机器人之间的协作绘画。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何利用人类艺术家的生理数据（如心跳）来指导机器人在共同创作过程中的行为，从而达到更自然流畅的人机互动效果。

Method: 使用配备有EmotiBit传感器的机械臂，根据检测到的艺术家心跳变化调整其与画布之间的距离；同时，还展示了基于自然语言和物理接触的不同形式的人机交互方式。

Result: 结果显示，该系统能够依据艺术家的情绪状态（由心跳速率反映）有效地调整机器人的行为模式，促进了更为和谐的人机共绘体验。

Conclusion: 这项工作为未来开发更加智能、情感化的艺术创作辅助工具提供了新的思路和技术基础。

Abstract: In this work we present AURA, a framework for synergistic human-artist painting. We developed a robot arm that collaboratively paints with a human artist. The robot has an awareness of the artist's heartbeat through the EmotiBit sensor, which provides the arousal levels of the painter. Given the heartbeat detected, the robot decides to increase proximity to the artist's workspace or retract. If a higher heartbeat is detected, which is associated with increased arousal in human artists, the robot will move away from that area of the canvas. If the artist's heart rate is detected as neutral, indicating the human artist's baseline state, the robot will continue its painting actions across the entire canvas. We also demonstrate and propose alternative robot-artist interactions using natural language and physical touch. This work combines the biometrics of a human artist to inform fluent artistic interactions.

</details>


### [8] [Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization](https://arxiv.org/abs/2511.15194)
*Jian Deng,Yuandong Wang,Yangfu Zhu,Tao Feng,Tianyu Wo,Zhenzhou Shao*

Main category: cs.RO

TL;DR: 本文提出了Eq.Bot，一种基于SE(2)群等变理论的通用规范化框架，旨在为机器人操控学习提供空间等变性而无需修改模型架构。实验表明，无论是在基于CNN还是基于Transformer的架构下，Eq.Bot在多种机器人操控任务上相较于现有方法都有显著优势，最大性能提升可达50%。


<details>
  <summary>Details</summary>
Motivation: 当前多模态学习框架缺乏固有的几何一致性保证，在处理诸如旋转和平移这样的空间变换时表现不佳。虽然最近的一些工作试图通过定制化的架构修改来引入等变性，但这些方法存在实现复杂度高、计算成本大以及可移植性差的问题。

Method: 受到人类空间推理认知过程的启发，研究人员提出了Eq.Bot，这是一个基于SE(2)群等变理论的通用规范化框架。该框架将观察转换到一个规范空间中，应用现有的策略，并将结果动作映射回原始空间。作为一个与模型无关的解决方案，Eq.Bot的目标是在不需对架构进行任何修改的情况下赋予模型空间等变性。

Result: 广泛的实验表明，在基于CNN（例如CLIPort）和基于Transformer（例如OpenVLA-OFT）的架构下，Eq.Bot在各种机器人操控任务上的表现优于现有方法，其中最显著的改进可以达到50.0%。

Conclusion: Eq.Bot作为一种创新的方法，有效地解决了传统多模态学习框架在处理空间变换时遇到的问题，为提高机器人操控系统的性能提供了新的途径。

Abstract: Robotic manipulation systems are increasingly deployed across diverse domains. Yet existing multi-modal learning frameworks lack inherent guarantees of geometric consistency, struggling to handle spatial transformations such as rotations and translations. While recent works attempt to introduce equivariance through bespoke architectural modifications, these methods suffer from high implementation complexity, computational cost, and poor portability. Inspired by human cognitive processes in spatial reasoning, we propose Eq.Bot, a universal canonicalization framework grounded in SE(2) group equivariant theory for robotic manipulation learning. Our framework transforms observations into a canonical space, applies an existing policy, and maps the resulting actions back to the original space. As a model-agnostic solution, Eq.Bot aims to endow models with spatial equivariance without requiring architectural modifications. Extensive experiments demonstrate the superiority of Eq.Bot under both CNN-based (e.g., CLIPort) and Transformer-based (e.g., OpenVLA-OFT) architectures over existing methods on various robotic manipulation tasks, where the most significant improvement can reach 50.0%.

</details>


### [9] [VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation](https://arxiv.org/abs/2511.15200)
*Tairan He,Zi Wang,Haoru Xue,Qingwei Ben,Zhengyi Luo,Wenli Xiao,Ye Yuan,Xingye Da,Fernando Castañeda,Shankar Sastry,Changliu Liu,Guanya Shi,Linxi Fan,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文介绍了一种名为VIRAL的视觉仿真到现实框架，该框架完全在仿真环境中学习人形机器人行走操作技能，并能零样本迁移到真实硬件上。通过教师-学生模型设计、大规模计算资源以及视觉域随机化等技术，使得基于RGB的策略能够在没有实际调优的情况下，实现连续多周期的行走操作，并接近专家级远程操控性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署人形机器人面临的主要障碍之一是缺乏自主的行走操作能力。为了解决这个问题，研究者们开发了VIRAL框架，旨在通过模拟环境来训练这种复杂的技能，并能够直接应用到真实的机器人身上，无需额外的实际环境调整。

Method: VIRAL采用了一种教师-学生模式的方法：首先，一个拥有全部状态信息特权的强化学习教师，在delta动作空间和参考状态初始化下学会长时间范围内的行走操作；接着，通过大规模模拟（使用拼贴渲染）结合在线DAgger与行为克隆训练方法，从教师那里提炼出基于视觉的学生策略。此外，为了减少从模拟到实际应用之间的差距，还实施了广泛的视觉域随机化处理，包括照明、材质、摄像头参数、图像质量和传感器延迟等方面的调整，同时确保灵巧手和摄像头的真实到模拟对齐。

Result: 实验结果表明，当扩展模拟计算至数十个GPU时（最多64个），不仅提高了教师和学生训练过程的可靠性，而且最终得到的基于RGB的策略能够在Unitree G1人形机器人上执行多达54个周期的连续行走操作任务，展现出良好的泛化能力，适应不同空间位置及外观变化，其表现接近甚至达到专家级别的远程控制水平。

Conclusion: 本研究表明，通过适当的设计选择如教师-学生模型架构、足够的计算资源投入以及细致的视觉域随机化措施，可以有效克服仅依赖RGB输入实现人形机器人行走操作所面临的挑战，从而促进此类技术向实际应用场景转化。

Abstract: A key barrier to the real-world deployment of humanoid robots is the lack of autonomous loco-manipulation skills. We introduce VIRAL, a visual sim-to-real framework that learns humanoid loco-manipulation entirely in simulation and deploys it zero-shot to real hardware. VIRAL follows a teacher-student design: a privileged RL teacher, operating on full state, learns long-horizon loco-manipulation using a delta action space and reference state initialization. A vision-based student policy is then distilled from the teacher via large-scale simulation with tiled rendering, trained with a mixture of online DAgger and behavior cloning. We find that compute scale is critical: scaling simulation to tens of GPUs (up to 64) makes both teacher and student training reliable, while low-compute regimes often fail. To bridge the sim-to-real gap, VIRAL combines large-scale visual domain randomization over lighting, materials, camera parameters, image quality, and sensor delays--with real-to-sim alignment of the dexterous hands and cameras. Deployed on a Unitree G1 humanoid, the resulting RGB-based policy performs continuous loco-manipulation for up to 54 cycles, generalizing to diverse spatial and appearance variations without any real-world fine-tuning, and approaching expert-level teleoperation performance. Extensive ablations dissect the key design choices required to make RGB-based humanoid loco-manipulation work in practice.

</details>


### [10] [A Class of Dual-Frame Passively-Tilting Fully-Actuated Hexacopter](https://arxiv.org/abs/2511.15225)
*Jiajun Liu,Yimin Zhu,Xiaorui Liu,Mingye Cao,Mingchao Li,Lixian Zhang*

Main category: cs.RO

TL;DR: 提出了一种新颖的全驱动六旋翼无人机，采用双框架被动倾斜结构，实现了最小致动器下的平移运动和姿态独立控制。基于其动态模型设计了全驱动控制器，并通过仿真验证了该无人机优秀的全驱动运动能力和所提控制策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种相较于现有全驱动无人机具有更高飞行效率和耐力的新型六旋翼无人机，同时减少内部力抵消问题。

Method: 设计了一种带有双框架被动倾斜结构的全驱动六旋翼无人机，并根据其动力学模型开发了一个全驱动控制器。

Result: 通过仿真表明，这种全驱动六旋翼无人机在同等负载条件下展现出优越的全驱动运动能力，并且所提出的控制策略有效。

Conclusion: 本研究介绍了一种新的全驱动六旋翼无人机设计方案，它不仅提高了飞行效率与耐久度，还展示了良好的可控性。

Abstract: This paper proposed a novel fully-actuated hexacopter. It features a dual-frame passive tilting structure and achieves independent control of translational motion and attitude with minimal actuators. Compared to previous fully-actuated UAVs, it liminates internal force cancellation, resulting in higher flight efficiency and endurance under equivalent payload conditions. Based on the dynamic model of fully-actuated hexacopter, a full-actuation controller is designed to achieve efficient and stable control. Finally, simulation is conducted, validating the superior fully-actuated motion capability of fully-actuated hexacopter and the effectiveness of the proposed control strategy.

</details>


### [11] [Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy](https://arxiv.org/abs/2511.15239)
*Tomoki Nakao,Kazumi Kasaura,Tadashi Kozuno*

Main category: cs.RO

TL;DR: 提出了一种新的分层导航方法，通过使用缠绕数这一拓扑不变量量化合作对称性破缺策略，并通过强化学习来学习这些策略，从而解决分布式多智能体导航中的对称性导致的死锁问题。


<details>
  <summary>Details</summary>
Motivation: 在多智能体交互时，自主打破决定如何相互通过的对称性非常困难，这导致了分布式多智能体导航中出现对称性引起的死锁问题。

Method: 采用一种新提出的分层导航法，该方法包括基于学习的规划者（Planner）和基于模型的控制器（Controller）。其中，Planner通过强化学习学会生成两种类型的参数给Controller：一是以缠绕数表示的拓扑合作策略；二是动态权重集合，用于确定在多个智能体同时穿越的密集场景下优先处理哪个智能体间的交互。

Result: 仿真和真实机器人实验表明，所提方法在密集环境中表现优于现有基线，能够高效避免碰撞和死锁，实现更优的导航性能。

Conclusion: 本文介绍的方法结合了基于学习的方法的灵活决策能力和基于模型的方法的可靠性，在密集环境下的多智能体导航中表现出色，有效地解决了由对称性引发的死锁问题。

Abstract: We address the fundamental challenge of resolving symmetry-induced deadlocks in distributed multi-agent navigation by proposing a new hierarchical navigation method. When multiple agents interact, it is inherently difficult for them to autonomously break the symmetry of deciding how to pass each other. To tackle this problem, we introduce an approach that quantifies cooperative symmetry-breaking strategies using a topological invariant called the winding number, and learns the strategies themselves through reinforcement learning. Our method features a hierarchical policy consisting of a learning-based Planner, which plans topological cooperative strategies, and a model-based Controller, which executes them. Through reinforcement learning, the Planner learns to produce two types of parameters for the Controller: one is the topological cooperative strategy represented by winding numbers, and the other is a set of dynamic weights that determine which agent interaction to prioritize in dense scenarios where multiple agents cross simultaneously. The Controller then generates collision-free and efficient motions based on the strategy and weights provided by the Planner. This hierarchical structure combines the flexible decision-making ability of learning-based methods with the reliability of model-based approaches. Simulation and real-world robot experiments demonstrate that our method outperforms existing baselines, particularly in dense environments, by efficiently avoiding collisions and deadlocks while achieving superior navigation performance. The code for the experiments is available at https://github.com/omron-sinicx/WNumMPC.

</details>


### [12] [Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception](https://arxiv.org/abs/2511.15279)
*Jiashu Yang,Yifan Han,Yucheng Xie,Ning Guo,Wenzhao Lian*

Main category: cs.RO

TL;DR: EyeVLA is a robotic eyeball for active visual perception, integrating vision-language models (VLMs) and action tokens to enable detailed and wide-ranging observation. It uses reinforcement learning to improve viewpoint selection and effectively performs instructed tasks in real-world environments, enhancing the capability of acquiring accurate visual information.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to overcome the limitations of existing vision models and fixed RGB-D camera systems, which are unable to reconcile wide-area coverage with the acquisition of fine-grained details. This severely limits their effectiveness in open-world robotic applications. The authors aim to create a system that can actively acquire more informative data within given constraints, thereby improving the performance of robotic systems in real-world settings.

Method: The method involves creating EyeVLA, a robotic eyeball that discretizes actions into action tokens and integrates them with VLMs. These VLMs have strong open-world understanding capabilities. The system uses 2D bounding box coordinates to guide reasoning and applies reinforcement learning to refine its viewpoint selection policy. The objective is to transfer the open-world scene understanding capability of the VLM to a VLA policy using minimal real-world data.

Result: Experiments show that EyeVLA can efficiently perform instructed scenes in real-world environments. It actively acquires more accurate visual information through instruction-driven actions such as rotation and zoom, leading to enhanced environmental perception capabilities. The system demonstrates strong potential for downstream embodied tasks by leveraging large-scale, detailed, and spatially rich embodied data.

Conclusion: In conclusion, EyeVLA introduces a novel approach to robotic vision by enabling active visual perception that combines vision, language, and actions. This system shows significant improvements in acquiring detailed and wide-ranging visual observations, making it a promising solution for enhancing the capabilities of robots in various real-world applications.

Abstract: In embodied AI perception systems, visual perception should be active: the goal is not to passively process static images, but to actively acquire more informative data within pixel and spatial budget constraints. Existing vision models and fixed RGB-D camera systems fundamentally fail to reconcile wide-area coverage with fine-grained detail acquisition, severely limiting their efficacy in open-world robotic applications. To address this issue, we propose EyeVLA, a robotic eyeball for active visual perception that can take proactive actions based on instructions, enabling clear observation of fine-grained target objects and detailed information across a wide spatial extent. EyeVLA discretizes action behaviors into action tokens and integrates them with vision-language models (VLMs) that possess strong open-world understanding capabilities, enabling joint modeling of vision, language, and actions within a single autoregressive sequence. By using the 2D bounding box coordinates to guide the reasoning chain and applying reinforcement learning to refine the viewpoint selection policy, we transfer the open-world scene understanding capability of the VLM to a vision language action (VLA) policy using only minimal real-world data. Experiments show that our system efficiently performs instructed scenes in real-world environments and actively acquires more accurate visual information through instruction-driven actions of rotation and zoom, thereby achieving strong environmental perception capabilities. EyeVLA introduces a novel robotic vision system that leverages detailed and spatially rich, large-scale embodied data, and actively acquires highly informative visual observations for downstream embodied tasks.

</details>


### [13] [Optimizing Robot Positioning Against Placement Inaccuracies: A Study on the Fanuc CRX10iA/L](https://arxiv.org/abs/2511.15290)
*Nicolas Gautier,Yves Guillermit,Mathieu Porez,David Lemoine,Damien Chablat*

Main category: cs.RO

TL;DR: 该研究提出了一种方法，用于确定Fanuc CRX10iA/L协作机器人执行特定工业任务所需轨迹的最佳基座位置。采用粒子群优化算法探索搜索空间，并结合α-形状算法和Voronoi图来界定可行区域并计算最大内切圆。此外，该方法还考虑了逆运动学模型、关节限制、奇点及工作空间限制等约束条件，以确保轨迹执行的可行性与效率。


<details>
  <summary>Details</summary>
Motivation: 为了在面对机器人放置不准确的情况下（例如机器人被放置在一个移动基座上时）提供鲁棒性标准，研究者开发了一种方法来找到能够使Fanuc CRX10iA/L协作机器人顺利完成给定轨迹的最佳基座位置。

Method: 研究采用了粒子群优化算法来搜索最优基座位置，通过逆运动学模型评估所有初始配置，并利用雅可比矩阵沿参考轨迹移动机器人末端执行器，同时为每次尝试打分。接着，使用α-形状算法绘制可行区域边界，并基于Voronoi图计算最大内切圆。整个过程中还需考虑到关节极限、奇异性以及工作空间限制等因素。

Result: 研究表明，所提出的方法能够有效地识别出适合Fanuc CRX10iA/L协作机器人完成特定任务的最佳基座放置区域。此外，该方法还能够处理复杂的逆运动学解（对于Fanuc CRX10iA/L最多可达16个），并充分考虑了实际操作中的各种约束条件。

Conclusion: 本研究提出的方法为解决机器人放置问题提供了新的视角，特别是在存在放置误差的情况下，它能够帮助确定最佳基座位置以保证轨迹执行的有效性和鲁棒性。

Abstract: This study presents a methodology for determining the optimal base placement of a Fanuc CRX10iA/L collaborative robot for a desired trajectory corresponding to an industrial task. The proposed method uses a particle swarm optimization algorithm that explores the search space to find positions for performing the trajectory. An $α$-shape algorithm is then used to draw the borders of the feasibility areas, and the largest circle inscribed is calculated from the Voronoi diagrams. The aim of this approach is to provide a robustness criterion in the context of robot placement inaccuracies that may be encountered, for example, if the robot is placed on a mobile base when the system is deployed by an operator. The approach developed uses an inverse kinematics model to evaluate all initial configurations, then moves the robot end-effector along the reference trajectory using the Jacobian matrix and assigns a score to the attempt. For the Fanuc CRX10iA/L robot, there can be up to 16 solutions to the inverse kinematics model. The calculation of these solutions is not trivial and requires a specific study that planning tools such as MoveIt cannot fully take into account. Additionally, the optimization process must consider constraints such as joint limits, singularities, and workspace limitations to ensure feasible and efficient trajectory execution.

</details>


### [14] [MSA - Technique for Stiffness Modeling of Manipulators with Complex and Hybrid Structures](https://arxiv.org/abs/2511.15294)
*Alexandr Klimchik,Anatol Pashkevich,Damien Chablat*

Main category: cs.RO

TL;DR: 本文提出了一种基于矩阵结构分析的系统方法，用于具有复杂和混合结构的操作器的刚度建模。该方法适用于包含闭环、柔性链接、刚性连接以及带有外部载荷和预载荷的被动和弹性关节的混合架构。通过这种方法可以半解析地生成笛卡尔刚度矩阵，并且允许用户直接聚合刚度模型方程而无需执行传统的扩展刚度矩阵中的列/行合并过程。以NaVaRo操作器的刚度分析为例展示了此方法的优势。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种能够处理包括闭环、柔性链接、刚性连接及带有外部载荷和预载荷的被动与弹性关节在内的混合架构的刚度建模方法。

Method: 采用矩阵结构分析技术，为操作器创建了一个系统化的刚度建模方案。此方法能以半解析形式生成笛卡尔刚度矩阵，并将操作器刚度模型表示为一组描述链接弹性的常规方程，辅以一组描述链接间连接关系的约束条件。

Result: 展示了一种新的刚度建模方式，它允许用户直接聚合刚度模型方程，避免了传统上在扩展刚度矩阵中进行的列或行合并步骤。

Conclusion: 提出的方法对于处理复杂的机器人手臂结构特别有效，如NaVaRo操作器所示，能够在保持计算效率的同时提供精确的刚度分析结果。

Abstract: The paper presents a systematic approach for stiffness modeling of manipulators with complex and hybrid structures using matrix structural analysis. In contrast to previous results, it is suitable for mixed architectures containing closed-loops, flexible links, rigid connections, passive and elastic joints with external loadings and preloadings. The proposed approach produces the Cartesian stiffness matrices in a semi-analytical manner. It presents the manipulator stiffness model as a set of conventional equations describing the link elasticities that are supplemented by a set of constraints describing connections between links. Its allows user straightforward aggregation of stiffness model equations avoiding traditional column/row merging procedures in the extended stiffness matrix. Advantages of this approach are illustrated by stiffness analysis of NaVaRo manipulator.

</details>


### [15] [C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models](https://arxiv.org/abs/2511.15333)
*Nayoung Oh,Dohyun Kim,Junhyeong Bang,Rohan Paul,Daehyung Park*

Main category: cs.RO

TL;DR: 提出了一种新的粗到细的空间定位框架C2F-Space，结合视觉-语言模型(VLMs)的优势进行初步估计，并通过超像素化来细化与局部环境对齐的区域。该方法在新的空间定位基准测试中显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统的空间定位方法难以处理复杂的推理（如距离、几何和物体间关系），而视觉-语言模型虽然具有强大的推理能力，但在生成精细输出区域方面存在困难。为了克服这些限制，提出了C2F-Space框架。

Method: C2F-Space采用两步走策略：首先利用VLM估计一个大致但空间上一致的区域；然后通过超像素化将此区域调整得更贴合周围环境。对于粗略估计部分，设计了基于网格的视觉定位提示及提议验证策略以增强VLM的空间理解力。

Result: 构建了一个新的空间定位基准，并与五种最先进的基线方法进行了比较。结果显示，C2F-Space在成功率和交并比指标上明显优于所有基线。消融研究表明，两步骤过程中的每个模块及其组合框架都有效。此外，还展示了C2F-Space应用于模拟机器人拾取放置任务的能力。

Conclusion: C2F-Space为解决自然语言指令中提到的空间参考定位问题提供了一个有效的解决方案，不仅提高了定位精度，而且增强了对复杂场景的理解。

Abstract: Space grounding refers to localizing a set of spatial references described in natural language instructions. Traditional methods often fail to account for complex reasoning -- such as distance, geometry, and inter-object relationships -- while vision-language models (VLMs), despite strong reasoning abilities, struggle to produce a fine-grained region of outputs. To overcome these limitations, we propose C2F-Space, a novel coarse-to-fine space-grounding framework that (i) estimates an approximated yet spatially consistent region using a VLM, then (ii) refines the region to align with the local environment through superpixelization. For the coarse estimation, we design a grid-based visual-grounding prompt with a propose-validate strategy, maximizing VLM's spatial understanding and yielding physically and semantically valid canonical region (i.e., ellipses). For the refinement, we locally adapt the region to surrounding environment without over-relaxed to free space. We construct a new space-grounding benchmark and compare C2F-Space with five state-of-the-art baselines using success rate and intersection-over-union. Our C2F-Space significantly outperforms all baselines. Our ablation study confirms the effectiveness of each module in the two-step process and their synergistic effect of the combined framework. We finally demonstrate the applicability of C2F-Space to simulated robotic pick-and-place tasks.

</details>


### [16] [Discovering Optimal Natural Gaits of Dissipative Systems via Virtual Energy Injection](https://arxiv.org/abs/2511.15513)
*Korbinian Griesbauer,Davide Calzolari,Maximilian Raff,C. David Remy,Alin Albu-Schäffer*

Main category: cs.RO

TL;DR: 本文提出了一种利用弹性元件来优化腿式机器人能效的方法，通过一个新颖的能量注入技术识别被动运动模式，并基于这些模式使用连续方法推导出能量最优控制输入。该方法在单腿和多腿机器人系统中进行了测试，证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在穿越非结构化环境时具有优势，但它们的效率往往不如轮式机器人。为了提高它们的能源经济性，文章提出了利用弹性元件来优化其自然（未驱动）动力学的方法。

Method: 研究采用了统一的多阶段框架来设计能量最优的控制输入，首先通过一种新的能量注入技术识别系统的自然动力学下的被动运动模式，然后基于这些被动解决方案，采用连续方法为完全受控、耗散的机器人系统推导出能量最优控制输入。

Result: 该方法在模拟模型上进行了测试，展示了它在单腿和多腿机器人系统中的适用性。

Conclusion: 通过对弹性腿式机器人的设计与操作提供有价值的见解，本研究表明了如何通过利用自然系统动力学来提高这类机器人的效率和适应性。

Abstract: Legged robots offer several advantages when navigating unstructured environments, but they often fall short of the efficiency achieved by wheeled robots. One promising strategy to improve their energy economy is to leverage their natural (unactuated) dynamics using elastic elements. This work explores that concept by designing energy-optimal control inputs through a unified, multi-stage framework. It starts with a novel energy injection technique to identify passive motion patterns by harnessing the system's natural dynamics. This enables the discovery of passive solutions even in systems with energy dissipation caused by factors such as friction or plastic collisions. Building on these passive solutions, we then employ a continuation approach to derive energy-optimal control inputs for the fully actuated, dissipative robotic system. The method is tested on simulated models to demonstrate its applicability in both single- and multi-legged robotic systems. This analysis provides valuable insights into the design and operation of elastic legged robots, offering pathways to improve their efficiency and adaptability by exploiting the natural system dynamics.

</details>


### [17] [Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies](https://arxiv.org/abs/2511.15520)
*Gabriel Lauzier,Alexandre Girard,François Ferland*

Main category: cs.RO

TL;DR: 本文研究了在执行动作前仅部分进行去噪过程的可能性，以加速扩散策略在机器人操作任务中的应用，并探讨了当系统动力学与去噪动力学耦合时闭环系统的稳定性理论界限。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散策略在处理随机扰动的机器人操作任务中表现出色，但其依赖于计算成本高昂的反向时间扩散（去噪）过程来进行动作推断，这限制了它在需要快速决策的实时应用中的使用。因此，本研究旨在通过仅部分完成去噪过程来提高效率，同时保持系统的稳定性。

Method: 提出了一种新方法，允许在计算机上继续进行反向时间扩散动力学的同时，根据系统自身的动态演化执行动作。此外，还研究了当系统动力学与去噪过程耦合时，基于演示方差给出控制器稳定性的框架和度量标准。

Result: 开发了一个能够评估控制器稳定性的框架，并给出了一个指标，该指标可以预测基于演示数据的变异性控制器是否将保持稳定。

Conclusion: 本研究表明，在保证系统稳定性的前提下，通过部分去噪加快了扩散策略应用于机器人模仿学习的速度，为实现实时控制提供了可能。

Abstract: Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.

</details>


### [18] [Decentralized Gaussian Process Classification and an Application in Subsea Robotics](https://arxiv.org/abs/2511.15529)
*Yifei Gao,Hans J. He,Daniel J. Stilwell,James McMahon*

Main category: cs.RO

TL;DR: 本研究提出了一种严格推导的数据共享策略，用于在水下环境中实时构建通信成功率地图。通过实验验证了该策略的有效性，使用了从弗吉尼亚理工大学690 AUV团队收集的真实声学通信数据。


<details>
  <summary>Details</summary>
Motivation: 为了解决水下自主航行器（AUV）团队在依赖声学通讯进行协调时遇到的范围限制、多路径效应以及低带宽问题，需要开发一种方法来实时学习通讯环境，并克服由于声学通讯不确定性带来的挑战。

Method: 研究者们提出了一个针对分散式分类问题——即通讯事件是否成功——的解决方案，在这个问题中，AUV之间分享部分通讯测量结果以共同构建一个表示从一个位置到另一个位置通讯成功率的地图。主要贡献在于提出了一种严格推导的数据共享策略，用来选择AUV之间应共享的测量值。

Result: 通过使用来自弗吉尼亚理工大学690 AUVs队伍收集的真实声学通讯数据进行实验验证，证明了所提出的共享策略在水下环境中的有效性。

Conclusion: 本研究表明，通过采用一种精心设计的数据共享策略，可以在不确定条件下提高AUV团队之间声学通讯的成功率，从而改善它们在执行任务时的合作效率。

Abstract: Teams of cooperating autonomous underwater vehicles (AUVs) rely on acoustic communication for coordination, yet this communication medium is constrained by limited range, multi-path effects, and low bandwidth. One way to address the uncertainty associated with acoustic communication is to learn the communication environment in real-time. We address the challenge of a team of robots building a map of the probability of communication success from one location to another in real-time. This is a decentralized classification problem -- communication events are either successful or unsuccessful -- where AUVs share a subset of their communication measurements to build the map. The main contribution of this work is a rigorously derived data sharing policy that selects measurements to be shared among AUVs. We experimentally validate our proposed sharing policy using real acoustic communication data collected from teams of Virginia Tech 690 AUVs, demonstrating its effectiveness in underwater environments.

</details>


### [19] [NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception](https://arxiv.org/abs/2511.15532)
*Chen Cai,Saksham Kohli,Steven Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于非线性模型预测控制（MPC）的运动规划器，通过引入自适应终端（AT）MPC公式，有效解决了快速移动物体捕捉问题中遇到的执行器功率限制违规问题，并在实验中展示了卓越的实时性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决快速移动物体捕捉对机器人灵活性提出的挑战，特别是针对由两个协作臂组成的系统由于固有的闭环约束所带来的协调难题。

Method: 提出了一种新的自适应终端（AT）MPC方法，该方法通过成本调整来优化控制策略，不同于主要依赖于终端惩罚以实现快速收敛的原始终端（PT）方法。

Result: 实验结果表明，所提出的AT-MPC方案能够显著降低控制努力，并且在双臂协作机器人平台上实现了优秀的实时性能，平均规划周期计算时间为约19毫秒，远低于40毫秒的系统采样时间。

Conclusion: 与PT基线相比，AT配方在几乎不增加计算开销的情况下大幅提高了动作质量和鲁棒性，非常适合动态协作拦截任务。

Abstract: Catching fast-moving objects serves as a benchmark for robotic agility, posing significant coordination challenges for cooperative manipulator systems holding a catcher, particularly due to inherent closed-chain constraints. This paper presents a nonlinear model predictive control (MPC)-based motion planner that bridges high-level interception planning with real-time joint space control, enabling dynamic object interception for systems comprising two cooperating arms. We introduce an Adaptive- Terminal (AT) MPC formulation featuring cost shaping, which contrasts with a simpler Primitive-Terminal (PT) approach relying heavily on terminal penalties for rapid convergence. The proposed AT formulation is shown to effectively mitigate issues related to actuator power limit violations frequently encountered with the PT strategy, yielding trajectories and significantly reduced control effort. Experimental results on a robotic platform with two cooperative arms, demonstrating excellent real time performance, with an average planner cycle computation time of approximately 19 ms-less than half the 40 ms system sampling time. These results indicate that the AT formulation achieves significantly improved motion quality and robustness with minimal computational overhead compared to the PT baseline, making it well-suited for dynamic, cooperative interception tasks.

</details>


### [20] [UltraDP: Generalizable Carotid Ultrasound Scanning with Force-Aware Diffusion Policy](https://arxiv.org/abs/2511.15550)
*Ruoqu Chen,Xiangjie Yan,Kangchen Lv,Gao Huang,Zheng Li,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩散策略的方法UltraDP，用于提高自主超声扫描的准确性和安全性。通过接收多感官输入并生成适合多模态动作分布的动作，结合专门设计的引导模块和混合力-阻抗控制器，实现了对未见过受试者的95%横扫成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的超声扫描机器人在泛化能力和数据利用效率上存在局限性。为了克服这些限制，并解决患者解剖结构变化及复杂的人机交互带来的挑战，提出了UltraDP方法。

Method: UltraDP是一个基于扩散策略的方法，它接收多感官输入（包括超声图像、手腕摄像头图像、接触力矩和探头姿态）并产生适应于多模态动作分布的动作。此外，还开发了一个特定的引导模块来帮助策略输出使动脉居中于超声图像的动作。使用了混合力-阻抗控制器以确保机器人与人体之间的稳定接触和安全互动。构建了一个大规模训练数据集，包含来自21名志愿者的210次扫描共46万样本对。

Result: UltraDP在之前未见过的受试者上实现了95%的横扫成功率，证明了其有效性。

Conclusion: 通过引入UltraDP方法及其特有的引导模块，结合强大的泛化能力和高效的混合力-阻抗控制机制，可以显著提升自动超声扫描的成功率和安全性。

Abstract: Ultrasound scanning is a critical imaging technique for real-time, non-invasive diagnostics. However, variations in patient anatomy and complex human-in-the-loop interactions pose significant challenges for autonomous robotic scanning. Existing ultrasound scanning robots are commonly limited to relatively low generalization and inefficient data utilization. To overcome these limitations, we present UltraDP, a Diffusion-Policy-based method that receives multi-sensory inputs (ultrasound images, wrist camera images, contact wrench, and probe pose) and generates actions that are fit for multi-modal action distributions in autonomous ultrasound scanning of carotid artery. We propose a specialized guidance module to enable the policy to output actions that center the artery in ultrasound images. To ensure stable contact and safe interaction between the robot and the human subject, a hybrid force-impedance controller is utilized to drive the robot to track such trajectories. Also, we have built a large-scale training dataset for carotid scanning comprising 210 scans with 460k sample pairs from 21 volunteers of both genders. By exploring our guidance module and DP's strong generalization ability, UltraDP achieves a 95% success rate in transverse scanning on previously unseen subjects, demonstrating its effectiveness.

</details>
