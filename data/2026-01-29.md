<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [E2HiL: Entropy-Guided Sample Selection for Efficient Real-World Human-in-the-Loop Reinforcement Learning](https://arxiv.org/abs/2601.19969)
*Haoyuan Deng,Yuanjiang Xue,Haoyang Du,Boyang Zhou,Zhenyu Wu,Ziwei Wang*

Main category: cs.RO

TL;DR: 提出了一种名为\method的高效现实世界人类在环强化学习框架，通过主动选择信息样本减少所需的人类干预次数。该方法通过稳定降低策略熵来改善探索与利用之间的权衡，从而提高样本效率。实验结果表明，与最先进的HiL-RL方法相比，\method在四个实际操作任务中实现了42.1%的成功率提升，并且所需的人类干预减少了10.1%。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类在环的强化学习（HiL-RL）框架往往样本效率低下，需要大量的人工干预才能达到收敛，导致劳动成本高。为了解决这个问题，研究提出了一个样本高效的现实世界人类在环强化学习框架。

Method: 构建了不同样本对策略熵的影响函数，并通过行动概率和策略软优势的协方差有效估计这些影响函数。接着选取影响函数值适中的样本，同时剔除引起熵急剧下降的捷径样本以及几乎没有影响的噪声样本。

Result: 在四个真实世界的操作任务上进行了广泛的实验，结果显示\method比当前最先进的HiL-RL方法提高了42.1%的成功率，并且所需的人类干预减少了10.1%。

Conclusion: 本研究提出的\method框架能够显著提高样本效率并减少人类干预需求，在实际操作任务中表现出色。

Abstract: Human-in-the-loop guidance has emerged as an effective approach for enabling faster convergence in online reinforcement learning (RL) of complex real-world manipulation tasks. However, existing human-in-the-loop RL (HiL-RL) frameworks often suffer from low sample efficiency, requiring substantial human interventions to achieve convergence and thereby leading to high labor costs. To address this, we propose a sample-efficient real-world human-in-the-loop RL framework named \method, which requires fewer human intervention by actively selecting informative samples. Specifically, stable reduction of policy entropy enables improved trade-off between exploration and exploitation with higher sample efficiency. We first build influence functions of different samples on the policy entropy, which is efficiently estimated by the covariance of action probabilities and soft advantages of policies. Then we select samples with moderate values of influence functions, where shortcut samples that induce sharp entropy drops and noisy samples with negligible effect are pruned. Extensive experiments on four real-world manipulation tasks demonstrate that \method achieves a 42.1\% higher success rate while requiring 10.1\% fewer human interventions compared to the state-of-the-art HiL-RL method, validating its effectiveness. The project page providing code, videos, and mathematical formulations can be found at https://e2hil.github.io/.

</details>


### [2] [Just in time Informed Trees: Manipulability-Aware Asymptotically Optimized Motion Planning](https://arxiv.org/abs/2601.19972)
*Kuanqi Cai,Liding Zhang,Xinwen Su,Kejia Chen,Chaoqun Wang,Sami Haddadin,Alois Knoll,Arash Ajoudani,Luis Figueredo*

Main category: cs.RO

TL;DR: 本文提出了一种名为JIT*的算法，用于改进高维机器人路径规划。该算法通过Just-in-Time模块和运动性能模块来提高路径搜索效率并优化控制，同时减少奇异点的风险。实验表明，JIT*在不同维度上均优于传统的基于采样的规划器，并且在单臂与双臂操作任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对高维机器人路径规划中传统基于采样方法难以有效识别可行及最优路径的问题，特别是在存在多障碍物环境下的机械臂路径规划，面临运动效率低下、安全性差以及奇异点和自碰撞风险等问题，提出了新的解决方案。

Method: 提出了Just-in-Time Informed Trees (JIT*) 算法，该算法包含两个核心组件：Just-in-Time 模块和Motion Performance模块。前者通过动态调整边连接性和瓶颈区域的采样密度加快初始路径发现；后者则通过动态切换以平衡可操作性和轨迹成本，从而优化运动控制并降低奇异点风险。

Result: 实验分析表明，在从四维到十六维的不同维度下，JIT*算法的表现始终优于传统基于采样的规划器。此外，它还在单臂与双臂操控任务中展示了其有效性。

Conclusion: JIT*算法为解决高维空间内复杂环境下的机器人路径规划问题提供了有效的手段，不仅提高了路径搜索的速度和质量，还增强了机械臂操作的安全性和灵活性。

Abstract: In high-dimensional robotic path planning, traditional sampling-based methods often struggle to efficiently identify both feasible and optimal paths in complex, multi-obstacle environments. This challenge is intensified in robotic manipulators, where the risk of kinematic singularities and self-collisions further complicates motion efficiency and safety. To address these issues, we introduce the Just-in-Time Informed Trees (JIT*) algorithm, an enhancement over Effort Informed Trees (EIT*), designed to improve path planning through two core modules: the Just-in-Time module and the Motion Performance module. The Just-in-Time module includes "Just-in-Time Edge," which dynamically refines edge connectivity, and "Just-in-Time Sample," which adjusts sampling density in bottleneck areas to enable faster initial path discovery. The Motion Performance module balances manipulability and trajectory cost through dynamic switching, optimizing motion control while reducing the risk of singularities. Comparative analysis shows that JIT* consistently outperforms traditional sampling-based planners across $\mathbb{R}^4$ to $\mathbb{R}^{16}$ dimensions. Its effectiveness is further demonstrated in single-arm and dual-arm manipulation tasks, with experimental results available in a video at https://youtu.be/nL1BMHpMR7c.

</details>


### [3] [Real-Time Robot Execution with Masked Action Chunking](https://arxiv.org/abs/2601.20130)
*Haoxuan Wang,Gengyu Zhang,Yan Yan,Yuzhang Shang,Ramana Rao Kompella,Gaowen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种名为REMAC的方法，通过遮罩动作分块学习校正调整，解决了异步推理中由于块内不一致导致的执行失败问题，同时引入前缀保留采样过程以增强块间连续性，从而在不增加延迟的情况下提供更可靠的策略。实验表明该方法能够实现更快的任务执行速度、保持对不同延迟的鲁棒性，并且始终达到更高的完成率。


<details>
  <summary>Details</summary>
Motivation: 现有的异步推理虽然实现了实时响应，但简单的集成经常会导致执行失败。以往的方法主要关注于解决块间不连续性的问题，而本文则发现了另一个关键但被忽视的因素：块内不一致性，即机器人执行的动作部分与其当前感知不匹配。为了解决这个问题并提高系统的可靠性，提出了新的方法。

Method: 提出了REMAC（Resilient Execution with Masked Action Chunking），通过遮罩动作分块来学习对预训练策略进行校正调整，使策略能够在意图行动与实际执行之间存在偏差时仍能保持韧性。此外，还引入了一个前缀保留的采样过程来加强块间的连续性。

Result: 广泛实验显示，在模拟和真实世界环境中，所提出的方法能够实现更快的任务执行速度、维持跨各种延迟的鲁宝性，并且持续获得更高的任务完成率。

Conclusion: 通过解决异步推理中的块内不一致性和块间不连续性问题，REMAC方法为实时机器人操作提供了更加可靠且高效的解决方案。

Abstract: Real-time execution is essential for cyber-physical systems such as robots. These systems operate in dynamic real-world environments where even small delays can undermine responsiveness and compromise performance. Asynchronous inference has recently emerged as a system-level paradigm for real-time robot manipulation, enabling the next action chunk to be predicted while the current one is being executed. While this approach achieves real-time responsiveness, naive integration often results in execution failure. Previous methods attributed this failure to inter-chunk discontinuity and developed test-time algorithms to smooth chunk boundaries. In contrast, we identify another critical yet overlooked factor: intra-chunk inconsistency, where the robot's executed action chunk partially misaligns with its current perception. To address this, we propose REMAC, which learns corrective adjustments on the pretrained policy through masked action chunking, enabling the policy to remain resilient under mismatches between intended actions and actual execution during asynchronous inference. In addition, we introduce a prefix-preserved sampling procedure to reinforce inter-chunk continuity. Overall, our method delivers more reliable policies without incurring additional latency. Extensive experiments in both simulation and real-world settings demonstrate that our method enables faster task execution, maintains robustness across varying delays, and consistently achieves higher completion rates.

</details>


### [4] [A Taylor Series Approach to Correct Localization Errors in Robotic Field Mapping using Gaussian Processes](https://arxiv.org/abs/2601.20149)
*Muzaffar Qureshi,Tochukwu Elijah Ogri,Kyle Volle,Rushikesh Kamalapurkar*

Main category: cs.RO

TL;DR: 本文提出了一种利用高斯过程模型处理由不精确定位导致的测量位置差异的方法，通过预计算雅可比和海森矩阵实现实时修正，从而提高了预测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，使用装备传感器的移动机器人收集数据时，由于定位不准确会导致状态不确定性，这会降低高斯过程模型的估计质量。为了解决这一问题，文章旨在开发一种方法来更新高斯过程模型，当更准确的位置估计可用时能够实时修正这些模型。

Method: 该方法基于核函数的可微性设计了一个二阶校正算法。通过预先计算GP均值和协方差函数的雅可比（Jacobian）和海森（Hessian）矩阵，根据测量点之间的真实与估计位置差异来进行实时调整。

Result: 仿真结果显示，相比于完全重新训练模型的方式，所提出的方法不仅提高了预测准确性，而且在计算效率上也有所提升。

Conclusion: 本文提出的利用改进后的估计值更新高斯过程模型的方法，在存在状态不确定性的场景下展现出了更好的性能。

Abstract: Gaussian Processes (GPs) are powerful non-parametric Bayesian models for regression of scalar fields, formulated under the assumption that measurement locations are perfectly known and the corresponding field measurements have Gaussian noise. However, many real-world scalar field mapping applications rely on sensor-equipped mobile robots to collect field measurements, where imperfect localization introduces state uncertainty. Such discrepancies between the estimated and true measurement locations degrade GP mean and covariance estimates. To address this challenge, we propose a method for updating the GP models when improved estimates become available. Leveraging the differentiability of the kernel function, a second-order correction algorithm is developed using the precomputed Jacobians and Hessians of the GP mean and covariance functions for real-time refinement based on measurement location discrepancy data. Simulation results demonstrate improved prediction accuracy and computational efficiency compared to full model retraining.

</details>


### [5] [TRACER: Texture-Robust Affordance Chain-of-Thought for Deformable-Object Refinement](https://arxiv.org/abs/2601.20208)
*Wanjun Jia,Kang Li,Fan Yang,Mengfei Duan,Wenrui Chen,Yiming Jiang,Hui Zhang,Kailun Yang,Zhiyong Li,Yaonan Wang*

Main category: cs.RO

TL;DR: 提出了一种名为TRACER的框架，用于提高机器人在处理可变形物体时的视觉适应性预测精度，通过分解任务意图、优化边界细化和增强功能区域的空间连续性和物理合理性来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉的适应性预测方法在处理可变形物体时存在边界溢出和功能性区域碎片化的问题。

Method: 开发了TRACER框架，包括树状结构的适应性思考链（TA-CoT）来分解高层任务意图；空间约束边界细化（SCBR）机制抑制预测溢出；以及交互式收敛细化流（ICRF）聚合受外观噪声影响的离散像素，从而提升识别功能区的空间连续性和物理合理性。

Result: 实验表明，TRACER在Fine-AGDDO15数据集及真实机器人平台上显著提高了不同纹理和图案下的适应性定位精度，并增强了长时间任务的成功率。

Conclusion: TRACER成功地缩小了高层语义推理与低层物理执行之间的差距，为机器人操纵可变形物体提供了一个有效的解决方案。

Abstract: The central challenge in robotic manipulation of deformable objects lies in aligning high-level semantic instructions with physical interaction points under complex appearance and texture variations. Due to near-infinite degrees of freedom, complex dynamics, and heterogeneous patterns, existing vision-based affordance prediction methods often suffer from boundary overflow and fragmented functional regions. To address these issues, we propose TRACER, a Texture-Robust Affordance Chain-of-thought with dEformable-object Refinement framework, which establishes a cross-hierarchical mapping from hierarchical semantic reasoning to appearance-robust and physically consistent functional region refinement. Specifically, a Tree-structured Affordance Chain-of-Thought (TA-CoT) is formulated to decompose high-level task intentions into hierarchical sub-task semantics, providing consistent guidance across various execution stages. To ensure spatial integrity, a Spatial-Constrained Boundary Refinement (SCBR) mechanism is introduced to suppress prediction spillover, guiding the perceptual response to converge toward authentic interaction manifolds. Furthermore, an Interactive Convergence Refinement Flow (ICRF) is developed to aggregate discrete pixels corrupted by appearance noise, significantly enhancing the spatial continuity and physical plausibility of the identified functional regions. Extensive experiments conducted on the Fine-AGDDO15 dataset and a real-world robotic platform demonstrate that TRACER significantly improves affordance grounding precision across diverse textures and patterns inherent to deformable objects. More importantly, it enhances the success rate of long-horizon tasks, effectively bridging the gap between high-level semantic reasoning and low-level physical execution. The source code and dataset will be made publicly available at https://github.com/Dikay1/TRACER.

</details>


### [6] [TouchGuide: Inference-Time Steering of Visuomotor Policies via Touch Guidance](https://arxiv.org/abs/2601.20239)
*Zhemeng Zhang,Jiahua Ma,Xincheng Yang,Xin Wen,Yuzhi Zhang,Boyan Li,Yiran Qin,Jin Liu,Can Zhao,Li Kang,Haoqin Hong,Zhenfei Yin,Philip Torr,Hao Su,Ruimao Zhang,Daolin Ma*

Main category: cs.RO

TL;DR: 本文提出了TouchGuide，一种新的跨策略视觉-触觉融合范式，通过在低维动作空间中融合模态来改进机器人对精细和接触丰富操作的处理。此外还介绍了TacUMI数据收集系统以促进高质量且成本效益高的数据收集。实验表明，在如鞋带系紧和芯片交接等五项挑战性任务中，TouchGuide显著优于当前最先进的视觉-触觉策略。


<details>
  <summary>Details</summary>
Motivation: 由于触觉反馈未充分利用，机器人在进行精细和接触丰富的操作时仍面临很大挑战。为了解决这一问题，作者们开发了TouchGuide，旨在通过结合视觉与触觉信息来改善机器人的操控能力。

Method: TouchGuide采用两阶段工作流程：首先基于纯视觉输入生成粗略的动作；随后利用特定于任务的接触物理模型（CPM）提供触觉指导，调整并优化该动作，确保其符合实际物理接触条件。CPM通过对比学习训练而成，并能给出一个基于触觉的可行性分数来引导采样过程朝向更符合物理接触约束的动作。同时，为了支持TouchGuide的有效训练，研究人员还设计了名为TacUMI的数据采集系统，它能够在保证精度的同时降低成本。

Result: 实验结果表明，在包括鞋带系紧和芯片交接在内的五种具有挑战性的接触密集型任务上，TouchGuide始终显著优于现有的最佳视觉-触觉策略。

Conclusion: 本研究提出了一种新的方法——TouchGuide，它通过将视觉和触觉信息融合在一个低维度动作空间内，有效提升了机器人执行复杂接触任务的能力。此外，通过引入经济高效的TacUMI数据收集系统，进一步促进了高质量触觉数据的获取。

Abstract: Fine-grained and contact-rich manipulation remain challenging for robots, largely due to the underutilization of tactile feedback. To address this, we introduce TouchGuide, a novel cross-policy visuo-tactile fusion paradigm that fuses modalities within a low-dimensional action space. Specifically, TouchGuide operates in two stages to guide a pre-trained diffusion or flow-matching visuomotor policy at inference time. First, the policy produces a coarse, visually-plausible action using only visual inputs during early sampling. Second, a task-specific Contact Physical Model (CPM) provides tactile guidance to steer and refine the action, ensuring it aligns with realistic physical contact conditions. Trained through contrastive learning on limited expert demonstrations, the CPM provides a tactile-informed feasibility score to steer the sampling process toward refined actions that satisfy physical contact constraints. Furthermore, to facilitate TouchGuide training with high-quality and cost-effective data, we introduce TacUMI, a data collection system. TacUMI achieves a favorable trade-off between precision and affordability; by leveraging rigid fingertips, it obtains direct tactile feedback, thereby enabling the collection of reliable tactile data. Extensive experiments on five challenging contact-rich tasks, such as shoe lacing and chip handover, show that TouchGuide consistently and significantly outperforms state-of-the-art visuo-tactile policies.

</details>


### [7] [Shallow-π: Knowledge Distillation for Flow-based VLAs](https://arxiv.org/abs/2601.20262)
*Boseong Jeon,Yunho Choi,Taehan Kim*

Main category: cs.RO

TL;DR: 本文提出了Shallow-pi，一个知识蒸馏框架，通过显著减少视觉-语言-动作模型中transformer的层数来实现更快的推理速度，同时在标准操作基准测试上的成功率下降不到1%，并在多种机器人平台上进行了实际验证。


<details>
  <summary>Details</summary>
Motivation: 随着对实时机器人部署需求的增长，需要快速且在设备上进行视觉-语言-动作（VLA）模型的推理。尽管已有研究集中在token级别的效率提升，但对于系统性地减少transformer层数以提高flow-based VLA模型效率的研究较少。

Method: 提出了一种名为Shallow-pli的知识蒸馏框架，该框架能够大幅度削减VLM骨干网和基于流的动作头部的transformer深度，将模型从18层压缩至6层。

Result: Shallow-pi使得推理速度超过原来的两倍，并且在标准操控基准测试中的成功率绝对下降不到1%，在简化后的VLA模型中达到了最先进的性能表现。

Conclusion: Shallow-pi证明了即使大幅降低模型复杂度也能保持高水平的表现，为未来开发更高效、适用于实时应用的VLA模型铺平道路。

Abstract: The growing demand for real-time robotic deployment necessitates fast and on-device inference for vision-language-action (VLA) models. Within the VLA literature, efficiency has been extensively studied at the token level, such as visual token pruning. In contrast, systematic transformer layer reduction has received limited attention and, to the best of our knowledge, has not been explored for flow-based VLA models under knowledge distillation. In this work, we propose Shallow-pi, a principled knowledge distillation framework that aggressively reduces the transformer depth of both the VLM backbone and the flow-based action head, compressing the model from 18 to 6 layers. Shallow-pi achieves over two times faster inference with less than one percent absolute drop in success rate on standard manipulation benchmarks, establishing state-of-the-art performance among reduced VLA models. Crucially, we validate our approach through industrial-scale real-world experiments on Jetson Orin and Jetson Thor across multiple robot platforms, including humanoid systems, in complex and dynamic manipulation scenarios.

</details>


### [8] [Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation](https://arxiv.org/abs/2601.20321)
*Yuzhe Huang,Pei Lin,Wanlin Li,Daohan Li,Jiajun Li,Jiaming Jiang,Chenxi Xiao,Ziyuan Jiao*

Main category: cs.RO

TL;DR: 本文提出了一种新的框架TaF-VLA，通过将触觉观测与物理交互力对齐来提高机器人操作中对于接触丰富任务的处理能力。实验表明，该方法在需要精确力控制的任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作（VLA）模型主要依赖于视觉模态，在执行需要精确实体力调节和物理推理的接触丰富任务时缺乏必要的物理直觉。现有的尝试通常只是简单地将基于视觉的触觉传感作为辅助视觉纹理处理，忽略了表面变形与交互动力学之间的内在联系。

Method: 提出了从触觉-视觉对齐到触觉-力量对齐的范式转变，并引入了TaF-VLA框架。该框架通过开发自动化的触觉-力量数据采集设备及构建包含超过千万次同步触觉观察、六轴力/扭矩和矩阵力图的大规模TaF-Dataset来实现高维触觉观测与物理交互力的显式关联。核心组件Tactile-Force Adapter (TaF-Adapter)用于从触觉传感器中提取离散化潜在信息以编码触觉观测，确保学习到的表现形式能够捕捉到历史依赖性、抗噪声的物理动态而非静态视觉纹理。

Result: 大量现实世界中的实验显示，相比最先进的触觉-视觉对齐以及仅使用视觉的方法而言，TaF-VLA策略在接触密集型任务上的性能显著更优，验证了其通过跨模态物理推理实现稳健且力感知操控的能力。

Conclusion: 通过采用触觉-力量对齐的新方法，TaF-VLA为机器人提供了更好的理解并执行涉及复杂物理交互任务的能力，从而在实际应用中展现出更强的鲁棒性和适应性。

Abstract: Vision-Language-Action (VLA) models have recently emerged as powerful generalists for robotic manipulation. However, due to their predominant reliance on visual modalities, they fundamentally lack the physical intuition required for contact-rich tasks that require precise force regulation and physical reasoning. Existing attempts to incorporate vision-based tactile sensing into VLA models typically treat tactile inputs as auxiliary visual textures, thereby overlooking the underlying correlation between surface deformation and interaction dynamics. To bridge this gap, we propose a paradigm shift from tactile-vision alignment to tactile-force alignment. Here, we introduce TaF-VLA, a framework that explicitly grounds high-dimensional tactile observations in physical interaction forces. To facilitate this, we develop an automated tactile-force data acquisition device and curate the TaF-Dataset, comprising over 10 million synchronized tactile observations, 6-axis force/torque, and matrix force map. To align sequential tactile observations with interaction forces, the central component of our approach is the Tactile-Force Adapter (TaF-Adapter), a tactile sensor encoder that extracts discretized latent information for encoding tactile observations. This mechanism ensures that the learned representations capture history-dependent, noise-insensitive physical dynamics rather than static visual textures. Finally, we integrate this force-aligned encoder into a VLA backbone. Extensive real-world experiments demonstrate that TaF-VLA policy significantly outperforms state-of-the-art tactile-vision-aligned and vision-only baselines on contact-rich tasks, verifying its ability to achieve robust, force-aware manipulation through cross-modal physical reasoning.

</details>


### [9] [RF-MatID: Dataset and Benchmark for Radio Frequency Material Identification](https://arxiv.org/abs/2601.20377)
*Xinyan Chen,Qinchun Li,Ruiqin Ma,Jiaqi Bai,Li Yi,Jianfei Yang*

Main category: cs.RO

TL;DR: 本研究提出了RF-MatID，这是首个开源的、大规模的、宽带且几何多样性的射频数据集，用于精细材料识别。该数据集旨在促进可重复的研究、加速算法进步、增强跨领域鲁棒性，并支持基于射频的材料识别在实际应用中的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉的材料识别方法受到光学传感器固有限制的影响，而基于射频的方法由于能够揭示材料的内在特性而受到越来越多的关注。然而，缺乏大规模公开的数据集和基于学习方法的基准测试限制了基于射频的材料识别的发展。

Method: 创建了一个名为RF-MatID的数据集，它包括16个细分类别，覆盖4至43.5GHz的频率范围，包含142,000个样本，同时考虑了入射角和距离的变化。此外，还通过评估最先进的深度学习模型来建立一个多设置、多协议的基准，以衡量分布内性能及跨角度和跨距离变化下的分布外鲁棒性。

Result: RF-MatID为基于射频的材料识别提供了丰富的资源，包括宽泛的频率范围、大量样本以及对不同几何条件的支持。它允许系统地进行频率和地区级别的分析，从而有利于现实世界的部署。

Conclusion: RF-MatID旨在推动可再现性研究、加快算法开发、促进跨域鲁棒性并支持基于射频的材料识别技术的实际应用开发。

Abstract: Accurate material identification plays a crucial role in embodied AI systems, enabling a wide range of applications. However, current vision-based solutions are limited by the inherent constraints of optical sensors, while radio-frequency (RF) approaches, which can reveal intrinsic material properties, have received growing attention. Despite this progress, RF-based material identification remains hindered by the lack of large-scale public datasets and the limited benchmarking of learning-based approaches. In this work, we present RF-MatID, the first open-source, large-scale, wide-band, and geometry-diverse RF dataset for fine-grained material identification. RF-MatID includes 16 fine-grained categories grouped into 5 superclasses, spanning a broad frequency range from 4 to 43.5 GHz, and comprises 142k samples in both frequency- and time-domain representations. The dataset systematically incorporates controlled geometry perturbations, including variations in incidence angle and stand-off distance. We further establish a multi-setting, multi-protocol benchmark by evaluating state-of-the-art deep learning models, assessing both in-distribution performance and out-of-distribution robustness under cross-angle and cross-distance shifts. The 5 frequency-allocation protocols enable systematic frequency- and region-level analysis, thereby facilitating real-world deployment. RF-MatID aims to enable reproducible research, accelerate algorithmic advancement, foster cross-domain robustness, and support the development of real-world application in RF-based material identification.

</details>


### [10] [STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation](https://arxiv.org/abs/2601.20381)
*Alexandre Chapin,Emmanuel Dellandréa,Liming Chen*

Main category: cs.RO

TL;DR: 提出了一种名为STORM的轻量级面向对象适应模块，用于增强视觉基础模型在机器人操作任务中的表现。通过多阶段训练策略，该方法提高了对视觉干扰器的泛化能力和控制性能。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型为机器人提供了强大的感知特征，但其密集表示缺乏明确的对象级结构，限制了操作任务中的鲁棒性和可扩展性。

Method: STORM（面向任务的对象中心表示法，用于机器人操作）是一种轻量级的对象中心适应模块，它通过添加一小部分语义感知槽来增强冻结的视觉基础模型。采用多阶段训练策略：首先通过使用语言嵌入进行视觉-语义预训练来稳定对象中心槽，然后与下游操作策略一起调整。

Result: 实验表明，与直接使用冻结的基础模型特征或端到端训练面向对象的表示相比，STORM在对象发现基准和模拟操作任务中提高了对视觉干扰器的泛化能力以及控制性能。

Conclusion: 结果强调了多阶段适应作为将通用基础模型特征转换为面向任务的对象中心表示的有效机制，以实现机器人控制。

Abstract: Visual foundation models provide strong perceptual features for robotics, but their dense representations lack explicit object-level structure, limiting robustness and contractility in manipulation tasks. We propose STORM (Slot-based Task-aware Object-centric Representation for robotic Manipulation), a lightweight object-centric adaptation module that augments frozen visual foundation models with a small set of semantic-aware slots for robotic manipulation. Rather than retraining large backbones, STORM employs a multi-phase training strategy: object-centric slots are first stabilized through visual--semantic pretraining using language embeddings, then jointly adapted with a downstream manipulation policy. This staged learning prevents degenerate slot formation and preserves semantic consistency while aligning perception with task objectives. Experiments on object discovery benchmarks and simulated manipulation tasks show that STORM improves generalization to visual distractors, and control performance compared to directly using frozen foundation model features or training object-centric representations end-to-end. Our results highlight multi-phase adaptation as an efficient mechanism for transforming generic foundation model features into task-aware object-centric representations for robotic control.

</details>


### [11] [A Practical Framework of Key Performance Indicators for Multi-Robot Lunar and Planetary Field Tests](https://arxiv.org/abs/2601.20529)
*Julia Richter,David Oberacker,Gabriela Ligeza,Valentin T. Bickel,Philip Arm,William Talbot,Marvin Grosse Besselmann,Florian Kehl,Tristan Schnell,Hendrik Kolvenbach,Rüdiger Dillmann,Arne Roennau,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种关键绩效指标(KPI)框架，用于评估多机器人月球探测任务的效率、鲁棒性和精度。该框架旨在为实地部署提供实用的指导，并通过一次多机器人现场测试进行了验证。尽管在户外模拟环境中获取精确KPI所需的真实数据并不总是可行，但该框架仍被提议作为支持未来行星探索中系统化开发机器人系统的通用评估标准。


<details>
  <summary>Details</summary>
Motivation: 月球上关键资源如钛铁矿、稀土元素和水冰的勘探需要强大的探索方法以应对多样化的地形和恶劣环境条件。现有的模拟试验因机器人平台和实验设置的不同难以比较结果，且通常采用特定场景下的工程指标来评估性能，缺乏与科学目标之间的明确联系。

Method: 作者基于三个反映科学目标和操作约束的现实多机器人月球场景，推导出一个结构化的KPI框架。此框架强调了不同场景下效率、鲁棒性及准确性的重要性，并特别设计以适用于实地部署。

Result: 通过一次多机器人实地测试验证了该框架的有效性和实用性，特别是在效率和鲁棒性相关的KPI方面表现良好；然而，对于准确度相关的KPI来说，由于户外模拟环境中难以获得可靠的基础真实数据，因此这部分的应用存在挑战。

Conclusion: 研究者建议将此KPI框架作为通用评估标准，以促进多机器人实地试验之间的一致性、目标导向性的对比，并支持面向未来的行星探索机器人系统的系统化发展。

Abstract: Robotic prospecting for critical resources on the Moon, such as ilmenite, rare earth elements, and water ice, requires robust exploration methods given the diverse terrain and harsh environmental conditions. Although numerous analog field trials address these goals, comparing their results remains challenging because of differences in robot platforms and experimental setups. These missions typically assess performance using selected, scenario-specific engineering metrics that fail to establish a clear link between field performance and science-driven objectives. In this paper, we address this gap by deriving a structured framework of KPI from three realistic multi-robot lunar scenarios reflecting scientific objectives and operational constraints. Our framework emphasizes scenario-dependent priorities in efficiency, robustness, and precision, and is explicitly designed for practical applicability in field deployments. We validated the framework in a multi-robot field test and found it practical and easy to apply for efficiency- and robustness-related KPI, whereas precision-oriented KPI require reliable ground-truth data that is not always feasible to obtain in outdoor analog environments. Overall, we propose this framework as a common evaluation standard enabling consistent, goal-oriented comparison of multi-robot field trials and supporting systematic development of robotic systems for future planetary exploration.

</details>


### [12] [Vibro-Sense: Robust Vibration-based Impulse Response Localization and Trajectory Tracking for Robotic Hands](https://arxiv.org/abs/2601.20555)
*Wadhah Zai El Amri,Nicolás Navarro-Guerrero*

Main category: cs.RO

TL;DR: 本文提出了一种基于振动声学感知的高精度全身触觉定位方法，使用低成本的压电麦克风和音频频谱转换器解码物理交互过程中产生的振动信号。实验表明该系统在静态条件下定位误差小于5毫米，并且对不同材料特性的响应有所差异，同时在机器人自身运动时也能保持有效跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统的触觉皮肤对于机器人操作来说成本高昂且难以集成，因此需要一种可扩展且经济有效的替代方案来实现丰富的接触感知。

Method: 通过在机器人手上安装七个低成本压电麦克风，并利用音频频谱变换器（Audio Spectrogram Transformer）来解码物理互动过程中产生的振动特征。

Result: 研究结果表明，在静态条件下定位误差小于5毫米；硬质材料如金属由于其尖锐、带宽高的响应特性，在脉冲响应定位上表现优异；而有纹理的材料如木材则为轨迹跟踪提供了更好的摩擦基特征；系统还展示了即使在主动操作期间也能抵抗机器人自身动作影响的能力。

Conclusion: 复杂的物理接触动态可以通过简单的振动信号有效地解码，为机器人领域内广泛且负担得起的接触感知提供了一个可行的路径。

Abstract: Rich contact perception is crucial for robotic manipulation, yet traditional tactile skins remain expensive and complex to integrate. This paper presents a scalable alternative: high-accuracy whole-body touch localization via vibro-acoustic sensing. By equipping a robotic hand with seven low-cost piezoelectric microphones and leveraging an Audio Spectrogram Transformer, we decode the vibrational signatures generated during physical interaction. Extensive evaluation across stationary and dynamic tasks reveals a localization error of under 5 mm in static conditions. Furthermore, our analysis highlights the distinct influence of material properties: stiff materials (e.g., metal) excel in impulse response localization due to sharp, high-bandwidth responses, whereas textured materials (e.g., wood) provide superior friction-based features for trajectory tracking. The system demonstrates robustness to the robot's own motion, maintaining effective tracking even during active operation. Our primary contribution is demonstrating that complex physical contact dynamics can be effectively decoded from simple vibrational signals, offering a viable pathway to widespread, affordable contact perception in robotics. To accelerate research, we provide our full datasets, models, and experimental setups as open-source resources.

</details>


### [13] [MeCo: Enhancing LLM-Empowered Multi-Robot Collaboration via Similar Task Memoization](https://arxiv.org/abs/2601.20577)
*Baiqing Wang,Helei Cui,Bo Zhang,Xiaolong Zheng,Bin Guo,Zhiwen Yu*

Main category: cs.RO

TL;DR: 本文提出了一种名为MeCo的多机器人协作框架，该框架利用任务相似性来减少冗余计算，通过缓存和重用以前解决的任务方案，避免了大型语言模型（LLM）对相同或类似任务重新规划的需求。此外，还提出了一个评估基准MeCoBench，实验结果表明MeCo在降低规划成本和提高成功率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多机器人协作方式依赖于特定任务的大量训练，这限制了它们适应新场景的能力；而最近的研究虽然利用了大型语言模型（LLM）的语言理解和推理能力提高了灵活性，但这些方法在面对相同或相似任务时仍需从头开始规划，忽略了任务间的相似性，导致效率低下。

Method: MeCo框架采用“缓存与重用”原则识别并复用之前已解决过的相关度高的任务解决方案，以减少不必要的计算。为此，开发了一种新的相似性测试方法，能够在不重新调用LLM的情况下有效实现计划重用。

Result: 实验结果显示，与当前最先进的方法相比，MeCo显著降低了规划成本，并且提高了任务完成的成功率。

Conclusion: 通过引入MeCo框架及其配套的评估基准MeCoBench，研究为多机器人系统提供了一种更高效、更具适应性的协作机制，特别是在处理相似任务时表现尤为突出。

Abstract: Multi-robot systems have been widely deployed in real-world applications, providing significant improvements in efficiency and reductions in labor costs. However, most existing multi-robot collaboration methods rely on extensive task-specific training, which limits their adaptability to new or diverse scenarios. Recent research leverages the language understanding and reasoning capabilities of large language models (LLMs) to enable more flexible collaboration without specialized training. Yet, current LLM-empowered approaches remain inefficient: when confronted with identical or similar tasks, they must replan from scratch because they omit task-level similarities. To address this limitation, we propose MeCo, a similarity-aware multi-robot collaboration framework that applies the principle of ``cache and reuse'' (a.k.a., memoization) to reduce redundant computation. Unlike simple task repetition, identifying and reusing solutions for similar but not identical tasks is far more challenging, particularly in multi-robot settings. To this end, MeCo introduces a new similarity testing method that retrieves previously solved tasks with high relevance, enabling effective plan reuse without re-invoking LLMs. Furthermore, we present MeCoBench, the first benchmark designed to evaluate performance on similar-task collaboration scenarios. Experimental results show that MeCo substantially reduces planning costs and improves success rates compared with state-of-the-art approaches.

</details>


### [14] [GPO: Growing Policy Optimization for Legged Robot Locomotion and Whole-Body Control](https://arxiv.org/abs/2601.20668)
*Shuhao Liao,Peizhuo Li,Xinrong Yang,Linnan Chang,Zhaoxin Fan,Qing Wang,Lei Shi,Yuhong Cao,Wenjun Wu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 本文提出了一种名为GPO的训练框架，通过在早期阶段限制有效动作空间来促进更有效的数据收集和策略学习，然后逐步扩展以增强探索并实现更高的预期回报。实验结果表明GPO训练的策略能够持续获得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 针对腿式机器人强化学习策略训练中存在的高维连续动作、硬件约束及有限探索等挑战，现有方法在基于位置控制上表现较好，但在基于扭矩控制上效果不佳的问题。

Method: 提出了一个名为Growing Policy Optimization (GPO)的训练框架，该框架应用了时变动作变换，在训练初期限制有效动作空间，从而鼓励更有效的数据收集与策略学习，并逐渐扩大之以增加探索性和达到更高的预期回报。

Result: GPO不仅在四足和六足机器人上得到了验证，还展示了从模拟直接转移到真实硬件上的零样本部署能力。GPO训练出的策略始终表现出色。

Conclusion: GPO提供了一个通用且与环境无关的优化框架，适用于学习腿式机器人的运动技能。

Abstract: Training reinforcement learning (RL) policies for legged robots remains challenging due to high-dimensional continuous actions, hardware constraints, and limited exploration. Existing methods for locomotion and whole-body control work well for position-based control with environment-specific heuristics (e.g., reward shaping, curriculum design, and manual initialization), but are less effective for torque-based control, where sufficiently exploring the action space and obtaining informative gradient signals for training is significantly more difficult. We introduce Growing Policy Optimization (GPO), a training framework that applies a time-varying action transformation to restrict the effective action space in the early stage, thereby encouraging more effective data collection and policy learning, and then progressively expands it to enhance exploration and achieve higher expected return. We prove that this transformation preserves the PPO update rule and introduces only bounded, vanishing gradient distortion, thereby ensuring stable training. We evaluate GPO on both quadruped and hexapod robots, including zero-shot deployment of simulation-trained policies on hardware. Policies trained with GPO consistently achieve better performance. These results suggest that GPO provides a general, environment-agnostic optimization framework for learning legged locomotion.

</details>


### [15] [Tendon-based modelling, estimation and control for a simulated high-DoF anthropomorphic hand model](https://arxiv.org/abs/2601.20682)
*Péter Polcz,Katalin Schäffer,Miklós Koller*

Main category: cs.RO

TL;DR: 本文提出了一种基于肌腱位移和张力估计关节位置的计算方法，结合雅可比比例积分控制器用于无直接关节传感器的人形机器人手的姿态跟踪。通过MuJoCo模拟环境验证了该方法的有效性和局限性。


<details>
  <summary>Details</summary>
Motivation: 由于在肌腱驱动的人形机器人手中加入关节编码器会损害机械紧凑性和灵巧性，因此缺乏直接的关节角度感知。为了解决这个问题，本文提出了一种从测量得到的肌腱位移和张力来估计关节位置的方法。

Method: 首先基于Denavit-Hartenberg约定介绍了一种针对人形手的有效运动学建模框架。使用简化的肌腱模型，推导出将肌腱状态与关节位置关联起来的一组非线性方程，并通过非线性优化方法求解。然后，利用估计出的关节角度，通过一个增强有前馈项的基于雅可比的比例积分（PI）控制器实现闭环控制，从而能够在没有直接关节传感器的情况下进行手势跟踪。

Result: 提出的估计与控制框架的有效性和局限性在MuJoCo仿真环境中得到了展示，该环境使用了具有每根长指五个自由度、拇指六个自由度的解剖学上正确的生物机电手。

Conclusion: 本研究提出的方法能够有效地估计关节位置并支持无直接关节传感的手势跟踪，在保持机械紧凑性和灵巧性的同时，为肌腱驱动的人形机器人手提供了新的控制方案。

Abstract: Tendon-driven anthropomorphic robotic hands often lack direct joint angle sensing, as the integration of joint encoders can compromise mechanical compactness and dexterity. This paper presents a computational method for estimating joint positions from measured tendon displacements and tensions. An efficient kinematic modeling framework for anthropomorphic hands is first introduced based on the Denavit-Hartenberg convention. Using a simplified tendon model, a system of nonlinear equations relating tendon states to joint positions is derived and solved via a nonlinear optimization approach. The estimated joint angles are then employed for closed-loop control through a Jacobian-based proportional-integral (PI) controller augmented with a feedforward term, enabling gesture tracking without direct joint sensing. The effectiveness and limitations of the proposed estimation and control framework are demonstrated in the MuJoCo simulation environment using the Anatomically Correct Biomechatronic Hand, featuring five degrees of freedom for each long finger and six degrees of freedom for the thumb.

</details>


### [16] [One Step Is Enough: Dispersive MeanFlow Policy Optimization](https://arxiv.org/abs/2601.20701)
*Guowei Zou,Haitao Wang,Hejun Wu,Yukun Qian,Yuhang Wang,Weibing Li*

Main category: cs.RO

TL;DR: 提出了一种名为DMPO的新框架，实现了单步生成动作，适用于实时机器人控制。通过MeanFlow、分散正则化和强化学习微调三个关键组件协同工作，DMPO在保持或超越多步基线性能的同时，显著提高了推理速度，满足了实时控制的需求，并在实际机器人上得到了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散和流匹配的生成策略需要多步骤采样，这限制了它们在时间紧迫场景中的应用。因此，开发一种能够实现单步生成动作的方法对于满足实时机器人控制的需求至关重要。

Method: 研究者们提出了一个统一框架——Dispersive MeanFlow Policy Optimization (DMPO)，它包含三个核心组成部分：用于数学推导单一步骤推理的MeanFlow（无需知识蒸馏）、防止表示崩溃的分散正则化技术以及通过强化学习微调来超越专家演示的表现。

Result: 实验结果表明，在RoboMimic操作和OpenAI Gym移动基准测试中，与多步基线相比，DMPO表现出竞争性甚至更优的性能。此外，该方法还实现了5到20倍的推理加速，能够在高性能GPU上达到数百赫兹的运行频率。

Conclusion: DMPO不仅能满足而且超越了实时控制的要求，其轻量级模型架构加上三个关键算法组件的协同作用，使得该方法非常适合应用于对响应时间有严格要求的机器人控制系统之中。

Abstract: Real-time robotic control demands fast action generation. However, existing generative policies based on diffusion and flow matching require multi-step
  sampling, fundamentally limiting deployment in time-critical scenarios. We propose Dispersive MeanFlow Policy Optimization (DMPO), a unified framework that
  enables true one-step generation through three key components: MeanFlow for mathematically-derived single-step inference without knowledge distillation,
  dispersive regularization to prevent representation collapse, and reinforcement learning (RL) fine-tuning to surpass expert demonstrations. Experiments
  across RoboMimic manipulation and OpenAI Gym locomotion benchmarks demonstrate competitive or superior performance compared to multi-step baselines. With
  our lightweight model architecture and the three key algorithmic components working in synergy, DMPO exceeds real-time control requirements (>120Hz) with
  5-20x inference speedup, reaching hundreds of Hertz on high-performance GPUs. Physical deployment on a Franka-Emika-Panda robot validates real-world
  applicability.

</details>


### [17] [A Methodology for Designing Knowledge-Driven Missions for Robots](https://arxiv.org/abs/2601.20797)
*Guillermo GP-Lenza,Carmen DR. Pita-Romero,Miguel Fernandez-Cortizas,Pascual Campoy*

Main category: cs.RO

TL;DR: 本文提出了一种在ROS 2系统中实现知识图谱的综合方法论，通过在Aerostack2框架下的模拟搜索和救援任务展示了该方法的有效性，从而提高自主机器人任务的决策能力和任务表现。


<details>
  <summary>Details</summary>
Motivation: 旨在通过将知识图谱应用于ROS 2系统来提升自主机器人任务的效率与智能水平。

Method: 本研究的方法包括定义初始条件与目标状态、结构化任务及子任务、规划执行顺序、以知识图谱形式表示任务相关数据，并利用高级语言设计任务。此外，还通过Aerostack2框架内的一次Gazebo环境下的搜救模拟任务进行了实际演示。

Result: 结果显示，所提方法能够有效增强机器人的决策过程和任务执行效果。

Conclusion: 使用知识图谱可以显著改善基于ROS 2系统的自主机器人任务的表现。

Abstract: This paper presents a comprehensive methodology for implementing knowledge graphs in ROS 2 systems, aiming to enhance the efficiency and intelligence of autonomous robotic missions. The methodology encompasses several key steps: defining initial and target conditions, structuring tasks and subtasks, planning their sequence, representing task-related data in a knowledge graph, and designing the mission using a high-level language. Each step builds on the previous one to ensure a cohesive process from initial setup to final execution. A practical implementation within the Aerostack2 framework is demonstrated through a simulated search and rescue mission in a Gazebo environment, where drones autonomously locate a target. This implementation highlights the effectiveness of the methodology in improving decision-making and mission performance by leveraging knowledge graphs.

</details>


### [18] [End-to-end example-based sim-to-real RL policy transfer based on neural stylisation with application to robotic cutting](https://arxiv.org/abs/2601.20846)
*Jamie Hathaway,Alireza Rastegarpanah,Rustam Stolkin*

Main category: cs.RO

TL;DR: 提出了一种基于神经风格迁移的新方法来解决强化学习从模拟到现实的迁移问题，通过变分自编码器联合学习自我监督特征表示，并生成弱配对的源-目标轨迹以提高合成轨迹的物理真实性。在机器人切割未知材料的案例研究中，该方法相比基线方法实现了更好的任务完成时间和行为稳定性，且仅需少量真实世界数据。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习虽然在处理复杂不确定环境下的机器人控制问题上取得了一定成功，但其依赖于大量通常来自模拟环境的数据，这限制了它在实际中的应用，因为模拟与物理系统之间存在领域差异以及真实世界样本量有限的问题。

Method: 提出了一种新的从模拟到真实的强化学习策略转移方法，借鉴图像处理中的神经风格迁移概念来合成新的训练数据。使用变分自编码器共同学习用于风格迁移的自我监督特征表示，并创建弱配对的源-目标轨迹以增强所合成轨迹的物理真实性。

Result: 通过机器人切割未知材料的应用案例表明，相较于包括之前工作在内的几种基准方法（如CycleGAN和基于条件变分自编码器的时间序列转换），所提出的方法在任务完成时间及行为稳定性方面表现更优，同时只需要很少的真实世界数据。

Conclusion: 本研究提出的框架展示了对于几何和材料变化的鲁棒性，在缺乏真实世界奖励信息的情况下也能够适应具有挑战性的接触密集型任务，证明了政策调整的可能性。

Abstract: Whereas reinforcement learning has been applied with success to a range of robotic control problems in complex, uncertain environments, reliance on extensive data - typically sourced from simulation environments - limits real-world deployment due to the domain gap between simulated and physical systems, coupled with limited real-world sample availability. We propose a novel method for sim-to-real transfer of reinforcement learning policies, based on a reinterpretation of neural style transfer from image processing to synthesise novel training data from unpaired unlabelled real world datasets. We employ a variational autoencoder to jointly learn self-supervised feature representations for style transfer and generate weakly paired source-target trajectories to improve physical realism of synthesised trajectories. We demonstrate the application of our approach based on the case study of robot cutting of unknown materials. Compared to baseline methods, including our previous work, CycleGAN, and conditional variational autoencoder-based time series translation, our approach achieves improved task completion time and behavioural stability with minimal real-world data. Our framework demonstrates robustness to geometric and material variation, and highlights the feasibility of policy adaptation in challenging contact-rich tasks where real-world reward information is unavailable.

</details>
