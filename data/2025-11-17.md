<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues](https://arxiv.org/abs/2511.10762)
*Nikolaos Tsagkas,Andreas Sochopoulos,Duolikun Danier,Sethu Vijayakumar,Alexandros Kouris,Oisin Mac Aodha,Chris Xiaoxuan Lu*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级可训练的池化机制——注意力特征聚合(AFA)，它能够自然地关注与任务相关的视觉线索，忽略场景中的干扰因素。实验表明，在存在视觉扰动的情况下，使用AFA训练的策略显著优于标准池化方法，且无需昂贵的数据集扩充或预训练视觉表示(PVR)的微调。


<details>
  <summary>Details</summary>
Motivation: 当前利用大规模视觉模型特征进行视觉-运动策略训练时，所采用的预训练视觉表示可能会编码大量与任务无关的场景信息，导致训练出的策略对超出领域范围的视觉变化及干扰物敏感度高、鲁棒性差。

Method: 引入了名为注意力特征聚合（AFA）的新颖池化机制。AFA是一种轻量化、可训练的方法，旨在通过学习来识别并聚焦于与任务相关的关键视觉提示上，同时忽略掉即使是富含语义信息的场景干扰元素。

Result: 在模拟环境和真实世界中进行了广泛的测试后发现，基于AFA训练而成的策略面对视觉干扰时的表现远超常规池化技术；并且在整个过程中不需要依赖成本高昂的数据集扩增或是对PVR进行细致调整。

Conclusion: 研究结果强调了排除无关紧要视觉信息的重要性，这是朝向开发更加稳健且具有广泛适用性的视觉-运动策略迈出的关键一步。

Abstract: The adoption of pre-trained visual representations (PVRs), leveraging features from large-scale vision models, has become a popular paradigm for training visuomotor policies. However, these powerful representations can encode a broad range of task-irrelevant scene information, making the resulting trained policies vulnerable to out-of-domain visual changes and distractors. In this work we address visuomotor policy feature pooling as a solution to the observed lack of robustness in perturbed scenes. We achieve this via Attentive Feature Aggregation (AFA), a lightweight, trainable pooling mechanism that learns to naturally attend to task-relevant visual cues, ignoring even semantically rich scene distractors. Through extensive experiments in both simulation and the real world, we demonstrate that policies trained with AFA significantly outperform standard pooling approaches in the presence of visual perturbations, without requiring expensive dataset augmentation or fine-tuning of the PVR. Our findings show that ignoring extraneous visual information is a crucial step towards deploying robust and generalisable visuomotor policies. Project Page: tsagkas.github.io/afa

</details>


### [2] [From Framework to Reliable Practice: End-User Perspectives on Social Robots in Public Spaces](https://arxiv.org/abs/2511.10770)
*Samson Oruma,Ricardo Colomo-Palacios,Vasileios Gkioulos*

Main category: cs.RO

TL;DR: 本研究通过在大学接待场景中部署ARI社交机器人，并收集了35名学生和员工的反馈，评估了机器人的安全性、隐私性、可用性、可访问性和透明度。结果表明，尽管参与者对物理安全、数据保护和伦理行为持积极态度，但在可访问性、包容性和动态互动方面仍存在挑战。此外，该研究还提供了一个公共GitHub仓库，内含可复用的ARI机器人应用程序模板以支持再现性和降低新研究者的入门门槛。


<details>
  <summary>Details</summary>
Motivation: 随着社交机器人越来越多地进入公共场所，它们的接受度不仅取决于技术可靠性，还取决于伦理完整性、可访问性和用户信任。为了探索如何在实际环境中实施安全和伦理的社会机器人部署，本研究采用SecuRoPS框架设计并试点部署了一款作为大学接待员的ARI社交机器人。

Method: 本研究通过让35名学生和工作人员与作为大学接待员的ARI社交机器人互动，并就安全性、隐私性、可用性、可达性和透明度等方面提供结构化的反馈来进行。

Result: 研究结果显示，参与者普遍对物理安全、数据保护以及伦理行为有正面看法，但同时也指出了在可达性、包容性及动态交互方面存在的挑战。

Conclusion: 除了实证发现外，该研究表明了如何通过最终用户评价在现实世界情境中实施安全和道德设计的理论框架。它还为ARI机器人应用提供了可重用模板的公共GitHub存储库，以支持可重复性和降低新研究人员的准入门槛。这项工作结合了用户视角与实用的技术资源，促进了AI与社会持续对话，并支持开发值得信赖、包容且具有伦理责任感的公共服务型社交机器人。

Abstract: As social robots increasingly enter public environments, their acceptance depends not only on technical reliability but also on ethical integrity, accessibility, and user trust. This paper reports on a pilot deployment of an ARI social robot functioning as a university receptionist, designed in alignment with the SecuRoPS framework for secure and ethical social robot deployment. Thirty-five students and staff interacted with the robot and provided structured feedback on safety, privacy, usability, accessibility, and transparency. The results show generally positive perceptions of physical safety, data protection, and ethical behavior, while also highlighting challenges related to accessibility, inclusiveness, and dynamic interaction. Beyond the empirical findings, the study demonstrates how theoretical frameworks for ethical and secure design can be implemented in real-world contexts through end-user evaluation. It also provides a public GitHub repository containing reusable templates for ARI robot applications to support reproducibility and lower the entry barrier for new researchers. By combining user perspectives with practical technical resources, this work contributes to ongoing discussions in AI and society and supports the development of trustworthy, inclusive, and ethically responsible social robots for public spaces.

</details>


### [3] [$\rm{A}^{\rm{SAR}}$: $\varepsilon$-Optimal Graph Search for Minimum Expected-Detection-Time Paths with Path Budget Constraints for Search and Rescue](https://arxiv.org/abs/2511.10792)
*Eric Mugford,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 本文提出了一种名为A^SAR的ε-最优搜索算法，用于搜索和救援（SAR）规划。该算法通过计算启发式来限定搜索空间，并使用图搜索方法找到形式上保证在用户指定因子ε范围内的最优解。相比于现有的优化方法，它在操作模拟中更快地找到了更好的解决方案，并在加拿大安大略湖的真实场景试验中成功定位了一个漂浮的人体模型，仅用时150秒。


<details>
  <summary>Details</summary>
Motivation: 在搜救行动中，由于信息不确定、观察者不完美以及搜索区域广阔，寻找失踪人员或物品面临着巨大挑战。特别是在海上搜救等情境下，预期生存时间短，优化搜索可以提高成功的可能性。然而，由于问题具有概率性质，对于非平凡的问题来说，这种优化问题是复杂的。随机优化方法通过非确定性采样减少问题的有效规模来解决大规模问题，但其随机性无法对有限时间内找到的解决方案质量提供正式保证。因此，需要一种能够提供正式质量保证的高效搜索算法。

Method: 提出了A^SAR算法，这是一种针对SAR规划的ε-最优搜索算法。该算法首先计算一个启发式以限制搜索空间，然后运用图搜索技术来找出被证明位于最优解一定范围（由用户定义的ε值决定）内的解答。此法旨在克服现有随机优化方法缺乏正式性能保证的问题。

Result: A^SAR算法在运作仿真测试中比当前的优化手段更快地识别出更优策略。此外，在加拿大的安大略湖进行的一次实际外场实验里，该算法成功地在短短150秒内锁定了一具漂移中的假人。

Conclusion: A^SAR算法为搜索与救援规划提供了一种新的方法，能够在较短时间内找到接近最优解的方案，并且在真实世界的应用中展现了其实效性。相比传统随机优化方法，A^SAR提供了关于解的质量的形式化保障。

Abstract: Searches are conducted to find missing persons and/or objects given uncertain information, imperfect observers and large search areas in Search and Rescue (SAR). In many scenarios, such as Maritime SAR, expected survival times are short and optimal search could increase the likelihood of success. This optimization problem is complex for nontrivial problems given its probabilistic nature.
  Stochastic optimization methods search large problems by nondeterministically sampling the space to reduce the effective size of the problem. This has been used in SAR planning to search otherwise intractably large problems but the stochastic nature provides no formal guarantees on the quality of solutions found in finite time.
  This paper instead presents $\rm{A}^{\rm{SAR}}$, an $\varepsilon$-optimal search algorithm for SAR planning. It calculates a heuristic to bound the search space and uses graph-search methods to find solutions that are formally guaranteed to be within a user-specified factor, $\varepsilon$, of the optimal solution. It finds better solutions faster than existing optimization approaches in operational simulations. It is also demonstrated with a real-world field trial on Lake Ontario, Canada, where it was used to locate a drifting manikin in only 150s.

</details>


### [4] [An Investigation into Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios](https://arxiv.org/abs/2511.10816)
*William Harris,Lucas Yager,Syler Sylvester,Elizabeth Peiros,Micheal C. Yip*

Main category: cs.RO

TL;DR: 本文介绍了一种新型的可动态伸缩的机器人腿设计，旨在提高搜索救援机器人的地形适应性和高力度输出能力。通过五杆连杆设计实现了高度优势和力优势配置之间的机械切换，并通过实验台评估了不同连杆几何形状和操作模式下的腿部性能，结果表明这种变形腿为开发既能快速穿越地形又能有效执行救援任务的SAR机器人提供了一个有希望的方向。


<details>
  <summary>Details</summary>
Motivation: 现有搜索救援（SAR）机器人在应对不平地形与执行需要高力度输出的任务之间存在局限性，即很少有平台能够同时满足这两方面的需求。虽然腿式机器人在穿越不平地面方面表现出色，但它们通常难以集成提供可变高力度输出的机制。因此，研究提出一种新概念来解决这一问题。

Method: 提出并实现了一种基于五杆连杆机构、能够动态伸缩的机器人腿设计方案。该方案允许通过几何变换，在有利于高度和力量输出的不同配置之间进行机械切换。此外，还构建了一个测试平台用于评估不同连杆几何结构及工作模式下腿部的表现，包括步长、力量输出以及稳定性等方面。

Result: 实验分析表明，所设计的变形腿能够在不同连杆几何形状和操作模式下展现出良好的性能，在步长、力量输出及稳定性上均达到了预期效果。这证明了该设计确实为创造既能高效移动又能完成高强度救援工作的SAR机器人开辟了一条可行的道路。

Conclusion: 本研究展示了一种创新性的可变形机器人腿的概念，它能够增强SAR机器人跨越复杂地形的能力，并且在执行需要大作用力的任务时也能表现良好。未来的研究可以进一步优化该设计，以更好地满足实际应用中的多样化需求。

Abstract: Search and rescue (SAR) robots are required to quickly traverse terrain and perform high-force rescue tasks, necessitating both terrain adaptability and controlled high-force output. Few platforms exist today for SAR, and fewer still have the ability to cover both tasks of terrain adaptability and high-force output when performing extraction. While legged robots offer significant ability to traverse uneven terrain, they typically are unable to incorporate mechanisms that provide variable high-force outputs, unlike traditional wheel-based drive trains. This work introduces a novel concept for a dynamically extensible and retractable robot leg. Leveraging a dynamically extensible and retractable five-bar linkage design, it allows for mechanically switching between height-advantaged and force-advantaged configurations via a geometric transformation. A testbed evaluated leg performance across linkage geometries and operating modes, with empirical and analytical analyses conducted on stride length, force output, and stability. The results demonstrate that the morphing leg offers a promising path toward SAR robots that can both navigate terrain quickly and perform rescue tasks effectively.

</details>


### [5] [MIGHTY: Hermite Spline-based Efficient Trajectory Planning](https://arxiv.org/abs/2511.10822)
*Kota Kondo,Yuwei Wu,Vijay Kumar,Jonathan P. How*

Main category: cs.RO

TL;DR: 本文提出了一种基于Hermite样条的规划器MIGHTY，它在保持连续搜索空间的同时进行时空优化。仿真结果显示，与现有技术相比，MIGHTY减少了9.3%的计算时间和13.1%的行进时间，并且成功率达到100%。硬件测试中，MIGHTY能够在充满静态障碍物的环境中以高达6.7米/秒的速度飞行，并处理动态添加的障碍物。


<details>
  <summary>Details</summary>
Motivation: 当前硬约束轨迹规划器通常依赖商业求解器并需要大量的计算资源；而现有的软约束方法虽然能实现更快的计算速度，但要么将空间和时间优化分离，要么限制了搜索空间。为了克服这些限制，作者们提出了新的解决方案。

Method: 提出了一种名为MIGHTY的基于Hermite样条的规划器，该规划器能够在充分利用样条提供的连续搜索空间的同时执行时空联合优化。

Result: 通过仿真实验验证了MIGHTY相较于最先进基线算法，在减少9.3%的计算时间和13.1%的行进时间方面表现优异，并达到了100%的成功率。实际飞行测试也表明，MIGHTY能够支持高速度（最高达6.7m/s）下的导航以及应对动态变化环境的能力。

Conclusion: MIGHTY作为一种新型的基于Hermite样条的轨迹规划方法，不仅有效解决了现有软约束方法中存在的问题，而且在计算效率、飞行性能等方面展示了显著优势。

Abstract: Hard-constraint trajectory planners often rely on commercial solvers and demand substantial computational resources. Existing soft-constraint methods achieve faster computation, but either (1) decouple spatial and temporal optimization or (2) restrict the search space. To overcome these limitations, we introduce MIGHTY, a Hermite spline-based planner that performs spatiotemporal optimization while fully leveraging the continuous search space of a spline. In simulation, MIGHTY achieves a 9.3% reduction in computation time and a 13.1% reduction in travel time over state-of-the-art baselines, with a 100% success rate. In hardware, MIGHTY completes multiple high-speed flights up to 6.7 m/s in a cluttered static environment and long-duration flights with dynamically added obstacles.

</details>


### [6] [Decentralized Swarm Control via SO(3) Embeddings for 3D Trajectories](https://arxiv.org/abs/2511.10858)
*Dimitria Silveria,Kleber Cabral,Peter Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 本文提出了一种新的去中心化方法，用于在多智能体系统中以最少的信息共享实现涌现行为。该方法基于李群的几何嵌入稳定系统，生成了比现有四元数方法更广泛的周期曲线，并且利用SO(3)属性消除了对速度输入的需求，只让智能体接收位置输入。此外，还引入了一种新颖的相位控制器确保智能体均匀分布，并提供了正式的稳定性证明。通过模拟和实验验证了该方法能够适应复杂的低级动态和干扰。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一种能够在多智能体系统中实现涌现行为的新方法，同时减少信息共享的需求。通过采用基于李群的方法而非传统的四元数方法，研究者希望能够生成更加多样化的稳定周期轨迹，并简化智能体间的通信要求。

Method: 本研究采用了一种基于SO(3)李群的新型几何嵌入技术来稳定系统，使得可以仅使用位置输入而无需速度信息就能控制智能体。此外，还设计了一个新的相位控制器来保持智能体之间的均匀间隔，并对该系统的稳定性给出了数学上的证明。

Result: 结果显示，所提出的方法能够产生比现有技术更为丰富的周期性运动模式，并且即便是在面对复杂底层动力学及外界扰动时也表现出良好的鲁棒性和适应性。

Conclusion: 研究表明，通过结合SO(3)李群特性的新方法可以在多智能体系统中有效地创建出多样化且稳定的周期性路径，同时减少了对于信息交换的需求。这为未来设计高效、鲁棒性强的多智能体系统提供了一条有前景的道路。

Abstract: This paper presents a novel decentralized approach for achieving emergent behavior in multi-agent systems with minimal information sharing. Based on prior work in simple orbits, our method produces a broad class of stable, periodic trajectories by stabilizing the system around a Lie group-based geometric embedding. Employing the Lie group SO(3), we generate a wider range of periodic curves than existing quaternion-based methods. Furthermore, we exploit SO(3) properties to eliminate the need for velocity inputs, allowing agents to receive only position inputs. We also propose a novel phase controller that ensures uniform agent separation, along with a formal stability proof. Validation through simulations and experiments showcases the method's adaptability to complex low-level dynamics and disturbances.

</details>


### [7] [WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot](https://arxiv.org/abs/2511.10864)
*Jose Vasquez,Xuping Zhang*

Main category: cs.RO

TL;DR: 本研究介绍了一种名为WetExplorer的自主履带机器人，该机器人能够自动化完成湿地温室气体采样的全部流程。通过集成低地压移动、厘米级精确定位提升放置、双RTK传感器融合、避障规划以及深度学习感知技术，WetExplorer展示了在无人员干预情况下实现高精度定位与有效障碍物规避的能力。这为密集且长时间的湿地温室气体监测开辟了新的途径。


<details>
  <summary>Details</summary>
Motivation: 量化湿地中的温室气体对于气候模型构建和恢复效果评估至关重要，但传统的手动采样方法耗时费力。因此，开发一种能够自动化这一过程的解决方案显得尤为必要。

Method: 研究人员设计并测试了一个名为WetExplorer的自主履带式机器人系统，它结合了低地压行走机制、厘米级精准抬放能力、双RTK传感器数据融合技术、基于视觉的障碍物识别与绕行策略以及深度学习增强的环境感知能力，所有这些都封装在一个ROS2容器化软件栈中。

Result: 户外实验表明，该系统的传感器融合组件可保持平均1.71厘米的位置误差；视觉模块能以7毫米平移误差及3度旋转误差估计物体姿态；室内测试则显示，完整的运动规划流水线能够在避开障碍的同时将采样舱定位到全球容差70毫米范围内，整个过程无需人工介入。

Conclusion: WetExplorer消除了传统手工操作带来的瓶颈，使得高频次、多站点温室气体测量成为可能，并为进一步收集饱和湿地地形下密集且长期的数据集奠定了基础。

Abstract: Quantifying greenhouse-gases (GHG) in wetlands is critical for climate modeling and restoration assessment, yet manual sampling is labor-intensive, and time demanding. We present WetExplorer, an autonomous tracked robot that automates the full GHG-sampling workflow. The robot system integrates low-ground-pressure locomotion, centimeter-accurate lift placement, dual-RTK sensor fusion, obstacle avoidance planning, and deep-learning perception in a containerized ROS2 stack. Outdoor trials verified that the sensor-fusion stack maintains a mean localization error of 1.71 cm, the vision module estimates object pose with 7 mm translational and 3° rotational accuracy, while indoor trials demonstrated that the full motion-planning pipeline positions the sampling chamber within a global tolerance of 70 mm while avoiding obstacles, all without human intervention. By eliminating the manual bottleneck, WetExplorer enables high-frequency, multi-site GHG measurements and opens the door for dense, long-duration datasets in saturated wetland terrain.

</details>


### [8] [Terradynamics and design of tip-extending robotic anchors](https://arxiv.org/abs/2511.10901)
*Deniz Kerimoglu,Nicholas D. Naclerio,Sean Chu,Andrew Krohn,Vineet Kupunaram,Alexander Schepelmann,Daniel I. Goldman,Elliot W. Hawkes*

Main category: cs.RO

TL;DR: 研究了根尖延伸锚与传统桩状侵入物在颗粒力学上的差异，提出了设计轻量级、软体机器人锚的四个关键原则，并开发出一种能够在火星松散土壤模拟物中深入45厘米并以自身重量的40倍力固定温度传感器的装置。


<details>
  <summary>Details</summary>
Motivation: 现有的工程桩需要较大的力量才能打入地面，而拔出时却相对容易得多，这导致在难以到达的地方（包括外星地点）使用重型设备进行打桩非常困难。相比之下，树根通过尖端生长的方式进入土壤，所需插入力远小于拔出力。受此启发，研究旨在利用根尖生长机制来设计更有效的机器人锚固装置。

Method: 通过比较根尖延伸型锚与传统桩状侵入者在颗粒介质中的行为，研究了其背后的物理机制；基于这些发现，制定了四条设计原则：达到临界深度后继续延伸、带有毛发状突起、近乎垂直地延伸以及采用多个小锚而非单一大锚；最后，根据上述原则开发了一种轻质、仿生的软体机器人锚固装置。

Result: 所开发的300克重的装置能够将一系列温度传感器部署到45厘米深的火星松散土壤模拟物中，并以平均120牛顿的力量固定，实现了锚固力与自重比为40:1的效果。

Conclusion: 通过模仿自然界的根系生长机制，可以设计出既轻便又高效的新型锚固系统，适用于地球上难以接近地区乃至未来太空探索任务中的固定需求。

Abstract: Most engineered pilings require substantially more force to be driven into the ground than they can resist during extraction. This requires relatively heavy equipment for insertion, which is problematic for anchoring in hard-to-access sites, including in extraterrestrial locations. In contrast, for tree roots, the external reaction force required to extract is much greater than required to insert--little more than the weight of the seed initiates insertion. This is partly due to the mechanism by which roots insert into the ground: tip extension. Proof-of-concept robotic prototypes have shown the benefits of using this mechanism, but a rigorous understanding of the underlying granular mechanics and how they inform the design of a robotic anchor is lacking. Here, we study the terradynamics of tip-extending anchors compared to traditional piling-like intruders, develop a set of design insights, and apply these to create a deployable robotic anchor. Specifically, we identify that to increase an anchor's ratio of extraction force to insertion force, it should: (i) extend beyond a critical depth; (ii) include hair-like protrusions; (iii) extend near-vertically, and (iv) incorporate multiple smaller anchors rather than a single large anchor. Synthesizing these insights, we developed a lightweight, soft robotic, root-inspired anchoring device that inserts into the ground with a reaction force less than its weight. We demonstrate that the 300 g device can deploy a series of temperature sensors 45 cm deep into loose Martian regolith simulant while anchoring with an average of 120 N, resulting in an anchoring-to-weight ratio of 40:1.

</details>


### [9] [Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment](https://arxiv.org/abs/2511.10987)
*Wenbin Bai,Qiyu Chen,Xiangbo Lin,Jianwen Li,Quancheng Li,Hejiang Pan,Yi Sun*

Main category: cs.RO

TL;DR: 本研究提出了一种手无关的操作转移系统，通过将人类手部操作序列从演示视频转换为高质量的灵巧操作轨迹，来解决多指机器人手硬件平台收集操作数据的困难和局限性。该系统仅使用人类手部操作视频就能自动配置不同任务的系统参数，在不同灵巧手、物体类别及任务间平衡运动匹配与动态优化，实验结果表明该框架能够高效且通用地生成平滑且语义正确的灵巧手操作，平均转移成功率达到了73%。


<details>
  <summary>Details</summary>
Motivation: 由于使用多指机器人手硬件平台收集操作数据存在固有的难度和有限的可扩展性，导致了严重的数据稀缺问题，阻碍了基于数据驱动的灵巧操作策略学习的研究发展。

Method: 设计了一个渐进式转移框架：首先基于运动学匹配建立灵巧手的基本控制信号；接着通过动作空间重缩放和拇指引导初始化训练残差策略以在统一奖励下动态优化接触交互；最后计算手腕控制轨迹以保持操作语义。整个系统仅需人类手部操作视频作为输入，即可根据不同任务自动调整系统参数。

Result: 广泛的实验结果显示，所提出的框架能够自动生成流畅且语义正确的灵巧手操作，忠实地再现人类意图，并且具有较高的效率和强大的泛化能力，平均转移成功率为73%。

Conclusion: 这项工作提供了一种易于实现且可扩展的方法来收集机器人的灵巧操作数据，有效地解决了现有方法中数据稀缺的问题，为灵巧手操作的学习开辟了新的途径。

Abstract: The inherent difficulty and limited scalability of collecting manipulation data using multi-fingered robot hand hardware platforms have resulted in severe data scarcity, impeding research on data-driven dexterous manipulation policy learning. To address this challenge, we present a hand-agnostic manipulation transfer system. It efficiently converts human hand manipulation sequences from demonstration videos into high-quality dexterous manipulation trajectories without requirements of massive training data. To tackle the multi-dimensional disparities between human hands and dexterous hands, as well as the challenges posed by high-degree-of-freedom coordinated control of dexterous hands, we design a progressive transfer framework: first, we establish primary control signals for dexterous hands based on kinematic matching; subsequently, we train residual policies with action space rescaling and thumb-guided initialization to dynamically optimize contact interactions under unified rewards; finally, we compute wrist control trajectories with the objective of preserving operational semantics. Using only human hand manipulation videos, our system automatically configures system parameters for different tasks, balancing kinematic matching and dynamic optimization across dexterous hands, object categories, and tasks. Extensive experimental results demonstrate that our framework can automatically generate smooth and semantically correct dexterous hand manipulation that faithfully reproduces human intentions, achieving high efficiency and strong generalizability with an average transfer success rate of 73%, providing an easily implementable and scalable method for collecting robot dexterous manipulation data.

</details>


### [10] [Dynamic Reconfiguration of Robotic Swarms: Coordination and Control for Precise Shape Formation](https://arxiv.org/abs/2511.10989)
*Prab Prasertying,Paulo Garcia,Warisa Sritriratanarak*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人集群从一个配置到另一个配置无缝转换的算法，通过适当的控制、定位和映射技术将几何公式映射到物理领域，从而为实现更复杂的分布式行为铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 在机器人集群中协调运动和配置是一个具有挑战性的任务，因为确定每个单独的机器人何时何地移动是一个计算复杂的问题，并且由于物理系统固有的测量误差和控制动态等困难而变得更加复杂。因此，如何最好地确定每个机器人的最优路径以及如何最好地执行这种确定并产生相应的运动仍然是一个开放的问题。

Method: 本文介绍了一种用于机器人集群协调的新算法，该算法利用了几何公式并通过适当的控制、定位和映射技术将其映射到物理领域。

Result: 所提出的方法允许机器人集群从一种配置无缝过渡到另一种配置，这为实现更加复杂的分布式行为提供了可能。

Conclusion: 本文提出的算法为解决机器人集群的协调问题提供了一个新的视角，它通过结合几何公式与物理领域的技术来实现机器人之间更有效的协作，进而开启了机器人集群应用的新可能性。

Abstract: Coordination of movement and configuration in robotic swarms is a challenging endeavor. Deciding when and where each individual robot must move is a computationally complex problem. The challenge is further exacerbated by difficulties inherent to physical systems, such as measurement error and control dynamics. Thus, how to best determine the optimal path for each robot, when moving from one configuration to another, and how to best perform such determination and effect corresponding motion remains an open problem. In this paper, we show an algorithm for such coordination of robotic swarms. Our methods allow seamless transition from one configuration to another, leveraging geometric formulations that are mapped to the physical domain through appropriate control, localization, and mapping techniques. This paves the way for novel applications of robotic swarms by enabling more sophisticated distributed behaviors.

</details>


### [11] [Latent-Space Autoregressive World Model for Efficient and Robust Image-Goal Navigation](https://arxiv.org/abs/2511.11011)
*Zhiwei Zhang,Hui Zhang,Xieyuanli Chen,Kaihong Huang,Chenghao Shi,Huimin Lu*

Main category: cs.RO

TL;DR: 提出了一种轻量级的潜空间导航世界模型LS-NWM，通过在潜空间中训练和操作，大幅减少了训练时间和规划时间，并提高了导航性能。


<details>
  <summary>Details</summary>
Motivation: 传统的导航方法严重依赖于精确的位置定位和地图绘制，而基于潜空间的世界模型虽然为导航任务提供了新的视角，但其在训练和推理过程中面临高计算成本的问题。

Method: 开发了LS-NWM（轻量级潜空间导航世界模型），该模型完全在潜空间中进行训练和运作。它预测未来状态而非像素级别的环境细节，采用自回归多帧预测策略来捕捉长期时空依赖性。

Result: 与最先进的基线相比，所提方法将训练时间减少了约3.2倍，规划时间减少约447倍，同时提高了导航表现，成功率(SR)提升了35%，单路径长度(SPL)提高了11%。

Conclusion: 实验结果表明，此方法不仅实现了顶级的导航性能，还在效率上显著优于现有方法。

Abstract: Traditional navigation methods rely heavily on accurate localization and mapping. In contrast, world models that capture environmental dynamics in latent space have opened up new perspectives for navigation tasks, enabling systems to move beyond traditional multi-module pipelines. However, world model often suffers from high computational costs in both training and inference. To address this, we propose LS-NWM - a lightweight latent space navigation world model that is trained and operates entirely in latent space, compared to the state-of-the-art baseline, our method reduces training time by approximately 3.2x and planning time by about 447x,while further improving navigation performance with a 35% higher SR and an 11% higher SPL. The key idea is that accurate pixel-wise environmental prediction is unnecessary for navigation. Instead, the model predicts future latent states based on current observational features and action inputs, then performs path planning and decision-making within this compact representation, significantly improving computational efficiency. By incorporating an autoregressive multi-frame prediction strategy during training, the model effectively captures long-term spatiotemporal dependencies, thereby enhancing navigation performance in complex scenarios. Experimental results demonstrate that our method achieves state-of-the-art navigation performance while maintaining a substantial efficiency advantage over existing approaches.

</details>


### [12] [Miniature Testbed for Validating Multi-Agent Cooperative Autonomous Driving](https://arxiv.org/abs/2511.11022)
*Hyunchul Bae,Eunjae Lee,Jehyeop Han,Minhee Kang,Jaehyeon Kim,Junggeun Seo,Minkyun Noh,Heejin Ahn*

Main category: cs.RO

TL;DR: Researchers developed CIVAT, a 1:15-scale testbed for cooperative autonomous driving, integrating V2V and V2I communication to enable real-time collaboration between vehicles and smart infrastructure, validated through perception and intersection management experiments.


<details>
  <summary>Details</summary>
Motivation: 鉴于现有测试平台缺乏具备感知、边缘计算和通信能力的智能基础设施，为解决这一空白并推动合作自动驾驶的发展，研究者设计并实现了一个名为CIVAT的缩小比例测试平台。

Method: 研究者设计并实现了CIVAT，一个1:15比例的小型测试平台，包括缩小的城市地图、配备车载传感器的自动驾驶车辆以及智能基础设施。该测试平台通过共享Wi-Fi和ROS2框架集成了V2V（车对车）和V2I（车对基础设施）通信，采用发布-订阅模式来实现实时信息交换。

Result: 作为案例研究，系统通过基于基础设施的感知实验和交叉口管理实验得到了验证。这些实验表明了CIVAT在支持合作驾驶功能方面的有效性。

Conclusion: CIVAT作为一个创新的小规模测试平台，成功展示了其在合作自动驾驶中的潜力，特别是在利用智能基础设施增强车辆自主性方面。

Abstract: Cooperative autonomous driving, which extends vehicle autonomy by enabling real-time collaboration between vehicles and smart roadside infrastructure, remains a challenging yet essential problem. However, none of the existing testbeds employ smart infrastructure equipped with sensing, edge computing, and communication capabilities. To address this gap, we design and implement a 1:15-scale miniature testbed, CIVAT, for validating cooperative autonomous driving, consisting of a scaled urban map, autonomous vehicles with onboard sensors, and smart infrastructure. The proposed testbed integrates V2V and V2I communication with the publish-subscribe pattern through a shared Wi-Fi and ROS2 framework, enabling information exchange between vehicles and infrastructure to realize cooperative driving functionality. As a case study, we validate the system through infrastructure-based perception and intersection management experiments.

</details>


### [13] [AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation](https://arxiv.org/abs/2511.11052)
*Jinxuan Zhu,Chenrui Tie,Xinyi Cao,Yuran Wang,Jingxiang Guo,Zixuan Chen,Haonan Chen,Junting Chen,Yangyu Xiao,Ruihai Wu,Lin Shao*

Main category: cs.RO

TL;DR: 本文介绍了一种名为ApaptPNP的框架，该框架利用视觉-语言模型来规划和执行非抓取式（NP）与抓取式（P）机器人操作的结合，以完成多样化的操控任务。通过数字孪生技术预测物体姿态，并结合连续反馈机制实现在线任务计划调整。


<details>
  <summary>Details</summary>
Motivation: 非抓取式（NP）操控能够扩展机器人的操作能力，特别是在传统抓握方法不可行或不足的情况下。然而，将非抓取式与抓取式动作整合到一个通用框架中，以适应不同任务、对象及环境仍然面临挑战。因此，需要开发一种能够智能选择并组合这两种技能的方法，以提高机器人处理复杂任务的能力。

Method: 提出ApaptPNP框架，该框架首先使用视觉-语言模型理解视觉场景观察和文本任务描述，生成包含P和NP动作序列的高层次计划骨架；其次，通过基于数字孪生的对象中心中间层预测所需物体姿态，支持对操作序列的事先心理演练；最后，控制模块负责合成低级机器人指令，同时借助持续执行反馈促进在线任务计划细化以及通过视觉-语言模型进行自适应重规划。

Result: ApaptPNP在模拟和现实环境中针对代表性的P&NP混合操作任务进行了评估，结果表明了这种混合P&NP操作方法对于实现通用、人类水平的机器人操作能力具有重要潜力。

Conclusion: 通过引入ApaptPNP框架，研究展示了如何有效地将非抓取式与抓取式机器人操作相结合，以解决多样化操控任务。这为向更加灵活多变的自动化系统迈进奠定了基础。

Abstract: Non-prehensile (NP) manipulation, in which robots alter object states without forming stable grasps (for example, pushing, poking, or sliding), significantly broadens robotic manipulation capabilities when grasping is infeasible or insufficient. However, enabling a unified framework that generalizes across different tasks, objects, and environments while seamlessly integrating non-prehensile and prehensile (P) actions remains challenging: robots must determine when to invoke NP skills, select the appropriate primitive for each context, and compose P and NP strategies into robust, multi-step plans. We introduce ApaptPNP, a vision-language model (VLM)-empowered task and motion planning framework that systematically selects and combines P and NP skills to accomplish diverse manipulation objectives. Our approach leverages a VLM to interpret visual scene observations and textual task descriptions, generating a high-level plan skeleton that prescribes the sequence and coordination of P and NP actions. A digital-twin based object-centric intermediate layer predicts desired object poses, enabling proactive mental rehearsal of manipulation sequences. Finally, a control module synthesizes low-level robot commands, with continuous execution feedback enabling online task plan refinement and adaptive replanning through the VLM. We evaluate ApaptPNP across representative P&NP hybrid manipulation tasks in both simulation and real-world environments. These results underscore the potential of hybrid P&NP manipulation as a crucial step toward general-purpose, human-level robotic manipulation capabilities. Project Website: https://sites.google.com/view/adaptpnp/home

</details>


### [14] [Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning](https://arxiv.org/abs/2511.11218)
*Chenhao Liu,Leyun Jiang,Yibo Wang,Kairan Yao,Jinchen Fu,Xiaoyu Ren*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的训练流程，用于开发一个统一的全身控制器，使类人机器人能够进行羽毛球运动。该方法通过三个阶段的课程学习来实现腿脚和手臂的协调动作，并采用扩展卡尔曼滤波器（EKF）来估计和预测羽毛球轨迹。实验结果表明，在模拟环境和现实世界中，该系统都能让机器人完成连续击球任务，并且无预测变体也表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管类人机器人在处理确定性场景方面表现出色，但面对动态环境时，仅依靠静态互动是不够的。为了解决这一问题并朝着更动态交互场景迈进，研究者们开发了这样一个系统，旨在赋予类人机器人执行如羽毛球这样需要高度动态反应能力的任务。

Method: 本研究采用了一种基于强化学习的方法来训练类人机器人打羽毛球，整个训练过程分为三个阶段：首先是脚步移动的学习，接着是精确控制球拍挥动的动作生成，最后是对任务目标的进一步优化。此外，为了提高打击精度，还引入了扩展卡尔曼滤波器以估算和预测羽毛球飞行轨迹。同时，研究团队也探索了一个不依赖于轨迹预测的替代方案。

Result: 实验部分包括了五个系列的测试，既包含了仿真环境也涉及到了真实世界的验证。结果显示，在仿真环境中两个机器人能够维持连续21次的成功击球；而在没有使用EKF的情况下，机器人依旧能够达到与已知目标政策相当的表现水平。实地测试证明，无论是带有预测功能还是去除预测功能的版本，都能够准确地命中目标，实现出球速度高达10m/s，平均回球落点距离为3.5米。

Conclusion: 这项研究表明，所提出的框架能够使类人机器人在羽毛球这类需要高度动态性和精准性的活动中表现出色，并且该技术还有望应用于其他对动态响应要求较高的领域。

Abstract: Humanoid robots have demonstrated strong capability for interacting with deterministic scenes across locomotion, manipulation, and more challenging loco-manipulation tasks. Yet the real world is dynamic, quasi-static interactions are insufficient to cope with the various environmental conditions. As a step toward more dynamic interaction scenario, we present a reinforcement-learning-based training pipeline that produces a unified whole-body controller for humanoid badminton, enabling coordinated lower-body footwork and upper-body striking without any motion priors or expert demonstrations. Training follows a three-stage curriculum: first footwork acquisition, then precision-guided racket swing generation, and finally task-focused refinement, yielding motions in which both legs and arms serve the hitting objective. For deployment, we incorporate an Extended Kalman Filter (EKF) to estimate and predict shuttlecock trajectories for target striking. We also introduce a prediction-free variant that dispenses with EKF and explicit trajectory prediction. To validate the framework, we conduct five sets of experiment in both simulation and the real world. In simulation, two robots sustain a rally of 21 consecutive hits. Moreover, the prediction-free variant achieves successful hits with comparable performance relative to the target-known policy. In real-world tests, both the prediction and controller module exhibit high accuracy, and on-court hitting achieves an outgoing shuttle speed up to 10 m/s with a mean return landing distance of 3.5 m. These experiment results show that our humanoid robot can deliver highly dynamic while precise goal striking in badminton, and can be adapted to more dynamism critical domains.

</details>


### [15] [Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects](https://arxiv.org/abs/2511.11223)
*Sverre Herland,Amit Parag,Elling Ruud Øye,Fangyi Zhang,Fouad Makiyeh,Aleksander Lillienskiold,Abhaya Pal Singh,Edward H. Adelson,Francois Chaumette,Alexandre Krupa,Peter Corke,Ekrem Misimi*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Sashimi-Bot的自主多机器人系统，专门用于处理像鲑鱼柳这样的可变形、体积物体的高级操作和切割。通过深度强化学习与手内工具形状操控、切割及视觉和触觉反馈相结合，该系统在面对任务中固有的变化时表现出强大的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于可变形、体积物体的柔软性、脆弱性、变异性和交互过程中的不确定性，对它们进行高级机器人操作仍然是一个巨大的挑战。受到这些挑战的激励，本研究旨在开发一种能够高效处理如鲑鱼柳等自然来源且尺寸形状不一、易变形且难以固定物品的自动化系统。

Method: 提出了一种名为Sashimi-Bot的自主多机器人系统，它结合了深度强化学习技术以及手内工具的操作技巧（包括形状调整与切割），同时利用视觉与触觉信息反馈来应对任务过程中遇到的各种变数。

Result: Sashimi-Bot成功展示了对于处理具有高度不确定性的可变形物体的能力，能够完成从拉直鱼肉、握持刀具到切片以及拾取薄片等一系列复杂动作。

Conclusion: 这项工作标志着在处理可变形、体积物体方面的一个重要里程碑，并可能激发并促成其他许多现实世界应用的发展。

Abstract: Advanced robotic manipulation of deformable, volumetric objects remains one of the greatest challenges due to their pliancy, frailness, variability, and uncertainties during interaction. Motivated by these challenges, this article introduces Sashimi-Bot, an autonomous multi-robotic system for advanced manipulation and cutting, specifically the preparation of sashimi. The objects that we manipulate, salmon loins, are natural in origin and vary in size and shape, they are limp and deformable with poorly characterized elastoplastic parameters, while also being slippery and hard to hold. The three robots straighten the loin; grasp and hold the knife; cut with the knife in a slicing motion while cooperatively stabilizing the loin during cutting; and pick up the thin slices from the cutting board or knife blade. Our system combines deep reinforcement learning with in-hand tool shape manipulation, in-hand tool cutting, and feedback of visual and tactile information to achieve robustness to the variabilities inherent in this task. This work represents a milestone in robotic manipulation of deformable, volumetric objects that may inspire and enable a wide range of other real-world applications.

</details>


### [16] [Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2511.11298)
*Yihao Zhang,Yuankai Qi,Xi Zheng*

Main category: cs.RO

TL;DR: 本文对四种代表性的视觉-语言-动作（VLA）模型在真实世界中的表现进行了基准测试，涵盖四个操作任务，并提出了一个标准化评估框架来衡量性能。研究发现，不同模型在分布内稳定性、适应性以及指令跟随准确性上各有优势和局限，为实际应用提供了有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 尽管基于基础模型的机器人技术，特别是视觉-语言-动作(VLA)模型，在实现通用操作方面展现出巨大潜力，但系统化的现实世界评估与跨模型比较仍然不足。

Method: 通过在模拟环境及ALOHA Mobile平台上对四个代表性VLA模型（ACT, OpenVLA-OFT, RDT-1B, π₀）进行四项操作任务的测试，建立了一个从准确性和效率、适应性、以及语言指令跟随准确性三个关键维度衡量性能的标准评估框架。

Result: 观察到π₀模型在外部分布场景中表现出色；而ACT模型则在分布内提供了最高的稳定性。进一步分析揭示了各模型之间计算需求、数据扩展行为以及常见失败模式如接近错失抓取、过早释放和长时状态漂移等方面的差异。

Conclusion: 这些发现揭示了VLA模型架构在平衡精度、泛化能力和部署成本方面的实际权衡，为选择和部署适用于真实世界机器人操作任务的VLA提供了可操作的见解。

Abstract: Foundation models applied in robotics, particularly \textbf{Vision--Language--Action (VLA)} models, hold great promise for achieving general-purpose manipulation. Yet, systematic real-world evaluations and cross-model comparisons remain scarce. This paper reports our \textbf{empirical experiences} from benchmarking four representative VLAs -- \textbf{ACT}, \textbf{OpenVLA--OFT}, \textbf{RDT-1B}, and \boldmath{$π_0$} -- across four manipulation tasks conducted in both simulation and on the \textbf{ALOHA Mobile} platform. We establish a \textbf{standardized evaluation framework} that measures performance along three key dimensions: (1) \textit{accuracy and efficiency} (success rate and time-to-success), (2) \textit{adaptability} across in-distribution, spatial out-of-distribution, and instance-plus-spatial out-of-distribution settings, and (3) \textit{language instruction-following accuracy}. Through this process, we observe that \boldmath{$π_0$} demonstrates superior adaptability in out-of-distribution scenarios, while \textbf{ACT} provides the highest stability in-distribution. Further analysis highlights differences in computational demands, data-scaling behavior, and recurring failure modes such as near-miss grasps, premature releases, and long-horizon state drift. These findings reveal practical trade-offs among VLA model architectures in balancing precision, generalization, and deployment cost, offering actionable insights for selecting and deploying VLAs in real-world robotic manipulation tasks.

</details>


### [17] [Simulating an Autonomous System in CARLA using ROS 2](https://arxiv.org/abs/2511.11310)
*Joseph Abdo,Aditya Shibu,Moaiz Saeed,Abdul Maajid Aga,Apsara Sivaprazad,Mohamed Al-Musleh*

Main category: cs.RO

TL;DR: 本文提出了一种在CARLA模拟器中设计和评估自动驾驶赛车软件堆栈的方法，通过使用360°激光雷达、立体相机、全球导航卫星系统和惯性测量单元传感器，实现了对赛道边界的可靠检测，并计算了优化轨迹。该系统最终在实际硬件上进行了实现与验证。


<details>
  <summary>Details</summary>
Motivation: 为了在高速度和不确定性条件下严格测试感知、规划和控制能力，同时为Formula Student UK Driverless (FS-AI) 2025比赛准备具有竞争力的自动驾驶赛车。

Method: 采用360° LiDAR、立体相机、GNSS及IMU传感器并通过ROS 2集成，以检测距离达35米的赛道边界锥体；基于车辆动力学及环境因素如能见度和光照条件来计算最优路径。

Result: 开发出的全自主驾驶堆栈不仅在CARLA内的专用车辆(ADS-DV)上得到了广泛验证，还成功移植到了包括Jetson AGX Orin 64GB、ZED2i立体摄像机等在内的真实硬件平台上。

Conclusion: 本研究展示了如何有效地结合多种传感器技术与先进的软件算法，在模拟环境中创建并测试高性能的自动驾驶赛车解决方案，为参与现实世界中的无人驾驶赛车比赛奠定了基础。

Abstract: Autonomous racing offers a rigorous setting to stress test perception, planning, and control under high speed and uncertainty. This paper proposes an approach to design and evaluate a software stack for an autonomous race car in CARLA: Car Learning to Act simulator, targeting competitive driving performance in the Formula Student UK Driverless (FS-AI) 2025 competition. By utilizing a 360° light detection and ranging (LiDAR), stereo camera, global navigation satellite system (GNSS), and inertial measurement unit (IMU) sensor via ROS 2 (Robot Operating System), the system reliably detects the cones marking the track boundaries at distances of up to 35 m. Optimized trajectories are computed considering vehicle dynamics and simulated environmental factors such as visibility and lighting to navigate the track efficiently. The complete autonomous stack is implemented in ROS 2 and validated extensively in CARLA on a dedicated vehicle (ADS-DV) before being ported to the actual hardware, which includes the Jetson AGX Orin 64GB, ZED2i Stereo Camera, Robosense Helios 16P LiDAR, and CHCNAV Inertial Navigation System (INS).

</details>


### [18] [A Comparative Evaluation of Prominent Methods in Autonomous Vehicle Certification](https://arxiv.org/abs/2511.11484)
*Mustafa Erdem Kırmızıgül,Hasan Feyzi Doğruyol,Haluk Bayram*

Main category: cs.RO

TL;DR: 本文比较评估了计划用于自动驾驶车辆认证过程中的主要方法，探讨了这些方法在认证流程中的应用阶段、参与者及领域，并为此类车辆的认证流程开发了一个框架。


<details>
  <summary>Details</summary>
Motivation: 鉴于'零愿景'政策旨在消除交通事故导致的死亡和重伤，而自动驾驶车辆被视为实现这一目标的一种方式，但目前尚不清楚如何验证和认证自动驾驶车辆必须满足的基本安全要求以及将使用哪些方法。

Method: 本文采用的方法包括：1. 对拟用于自动驾驶车辆认证过程的主要方法进行比较评价；2. 开发一套针对自动驾驶车辆认证的流程；3. 确定上述方法可应用于认证过程的具体阶段、参与者及相关领域。

Result: 研究结果明确了自动驾驶汽车认证过程中可以应用的各种关键方法，并为该认证过程提供了一个结构化的管道，指出了不同阶段适合采用的方法及其相关参与者。

Conclusion: 通过比较评估潜在的认证方法并构建认证流程，本研究为确保自动驾驶车辆符合'零愿景'政策下所需的安全标准提供了指导方向。

Abstract: The "Vision Zero" policy, introduced by the Swedish Parliament in 1997, aims to eliminate fatalities and serious injuries resulting from traffic accidents. To achieve this goal, the use of self-driving vehicles in traffic is envisioned and a roadmap for the certification of self-driving vehicles is aimed to be determined. However, it is still unclear how the basic safety requirements that autonomous vehicles must meet will be verified and certified, and which methods will be used. This paper focuses on the comparative evaluation of the prominent methods planned to be used in the certification process of autonomous vehicles. It examines the prominent methods used in the certification process, develops a pipeline for the certification process of autonomous vehicles, and determines the stages, actors, and areas where the addressed methods can be applied.

</details>


### [19] [Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities](https://arxiv.org/abs/2511.11512)
*Yiyun Zhou,Mingjing Xu,Jingwei Shi,Quanjiang Li,Jingyuan Chen*

Main category: cs.RO

TL;DR: 提出了一种基于CLIP的触觉-语言-视觉协作表示学习方法TLV-CoRe，通过Sensor-Aware Modulator统一不同传感器的触觉特征，并使用Unified Bridging Adapter增强三模态间的交互。此外，还提出了RSS评估框架来公平地评价触觉模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前触觉传感器缺乏标准化，导致了冗余特性阻碍了跨传感器的泛化能力。同时，现有方法未能充分利用触觉、语言和视觉模态之间的中间交流。

Method: 开发了TLV-CoRe，一种结合触觉-语言-视觉协同表示学习的方法。该方法包括Sensor-Aware Modulator用于统合来自不同传感器的数据，以及Unified Bridging Adapter促进共享表示空间内三种模态之间的互动。

Result: 实验结果表明，TLV-CoRe在传感器无关的表示学习和跨模态对齐方面取得了显著改进，为多模态触觉表示开辟了新方向。

Conclusion: TLV-CoRe有效解决了触觉信息与其它感官信息融合的问题，提升了机器人对于细粒度物体属性感知的能力。

Abstract: Tactile sensing offers rich and complementary information to vision and language, enabling robots to perceive fine-grained object properties. However, existing tactile sensors lack standardization, leading to redundant features that hinder cross-sensor generalization. Moreover, existing methods fail to fully integrate the intermediate communication among tactile, language, and vision modalities. To address this, we propose TLV-CoRe, a CLIP-based Tactile-Language-Vision Collaborative Representation learning method. TLV-CoRe introduces a Sensor-Aware Modulator to unify tactile features across different sensors and employs tactile-irrelevant decoupled learning to disentangle irrelevant tactile features. Additionally, a Unified Bridging Adapter is introduced to enhance tri-modal interaction within the shared representation space. To fairly evaluate the effectiveness of tactile models, we further propose the RSS evaluation framework, focusing on Robustness, Synergy, and Stability across different methods. Experimental results demonstrate that TLV-CoRe significantly improves sensor-agnostic representation learning and cross-modal alignment, offering a new direction for multimodal tactile representation.

</details>


### [20] [Scalable Coverage Trajectory Synthesis on GPUs as Statistical Inference](https://arxiv.org/abs/2511.11514)
*Max M. Sun,Jueun Kwon,Todd Murphey*

Main category: cs.RO

TL;DR: 本文提出了一种新的覆盖运动规划问题的表述方法，通过流匹配这一生成建模技术将其视为统计推断问题。该方法统一了常用的统计差异度量与线性二次调节器问题，并且能够解耦轨迹梯度生成与非线性系统动力学下的控制合成，从而在现代计算架构尤其是GPU上实现显著加速和平行化处理。


<details>
  <summary>Details</summary>
Motivation: 传统的运动规划问题主要关注状态的时间序列，而覆盖运动规划需要考虑整个轨迹的空间分布，这使得标准的运动规划方法在计算效率方面受限，并且难以适应现代化并行化框架。因此，研究者们旨在找到一种更高效、更适合并行化的解决方案来处理覆盖运动规划问题。

Method: 采用流匹配（flow matching）的方法将覆盖运动规划问题转化为统计推断问题，并结合Kullback-Leibler散度和Sinkhorn散度等统计差异度量手段以及线性二次调节器模型进行求解。此方法能够分离出轨迹梯度的生成过程与非线性系统动态下控制策略的制定，特别适合于利用图形处理器(GPU)等现代计算架构进行并行加速。

Result: 所提方法能够在保持或提高规划质量的同时，显著提升了计算效率，特别是在使用GPU等现代计算架构时，能够有效利用其并行处理能力以加快解决覆盖运动规划问题的速度。

Conclusion: 本研究提供了一种新颖的覆盖运动规划问题解决途径，它不仅统一了不同类型的统计度量方式，还解决了传统方法难以克服的并行化挑战，为未来相关领域的发展奠定了基础。

Abstract: Coverage motion planning is essential to a wide range of robotic tasks. Unlike conventional motion planning problems, which reason over temporal sequences of states, coverage motion planning requires reasoning over the spatial distribution of entire trajectories, making standard motion planning methods limited in computational efficiency and less amenable to modern parallelization frameworks. In this work, we formulate the coverage motion planning problem as a statistical inference problem from the perspective of flow matching, a generative modeling technique that has gained significant attention in recent years. The proposed formulation unifies commonly used statistical discrepancy measures, such as Kullback-Leibler divergence and Sinkhorn divergence, with a standard linear quadratic regulator problem. More importantly, it decouples the generation of trajectory gradients for coverage from the synthesis of control under nonlinear system dynamics, enabling significant acceleration through parallelization on modern computational architectures, particularly Graphics Processing Units (GPUs). This paper focuses on the advantages of this formulation in terms of scalability through parallelization, highlighting its computational benefits compared to conventional methods based on waypoint tracking.

</details>


### [21] [Terrain Costmap Generation via Scaled Preference Conditioning](https://arxiv.org/abs/2511.11529)
*Luisa Mao,Garret Warnell,Peter Stone,Joydeep Biswas*

Main category: cs.RO

TL;DR: 提出了一种新的全地形成本图生成方法SPACER，该方法利用合成数据进行训练以适应新地形，并通过用户指定的比例偏好上下文快速调整测试时的成本。实验表明，SPACER在生成用于地形导航的成本图方面优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 当前的地形成本图生成方法要么能够快速适应测试时的成本变化（例如基于语义分割的方法），要么能够泛化到新的地形类型（例如基于表示学习的方法），但无法同时做到两者。为了解决这一问题，研究提出了SPACER方法，旨在同时实现对不同地形的良好泛化和快速适应特定任务需求的能力。

Method: SPACER方法结合了合成数据训练与用户指定比例偏好上下文条件，在训练过程中使用合成数据来提高模型对于未见过地形类型的泛化能力；同时，通过在测试阶段根据具体任务要求调整偏好设置，使得成本图能够迅速适应不同的实际需求。

Result: 实验结果显示，在五个不同环境下的全球路径规划中，SPACER相较于其他方法表现出了更低的遗憾度量值，证明了其在生成适用于多种偏好的地形导航成本图方面的优越性能。

Conclusion: 本研究表明，通过采用SPACER方法，可以在保证对新地形良好泛化的同时，实现针对特定任务需求的成本图快速调整，从而为自主机器人越野导航提供了更优解决方案。

Abstract: Successful autonomous robot navigation in off-road domains requires the ability to generate high-quality terrain costmaps that are able to both generalize well over a wide variety of terrains and rapidly adapt relative costs at test time to meet mission-specific needs. Existing approaches for costmap generation allow for either rapid test-time adaptation of relative costs (e.g., semantic segmentation methods) or generalization to new terrain types (e.g., representation learning methods), but not both. In this work, we present scaled preference conditioned all-terrain costmap generation (SPACER), a novel approach for generating terrain costmaps that leverages synthetic data during training in order to generalize well to new terrains, and allows for rapid test-time adaptation of relative costs by conditioning on a user-specified scaled preference context. Using large-scale aerial maps, we provide empirical evidence that SPACER outperforms other approaches at generating costmaps for terrain navigation, with the lowest measured regret across varied preferences in five of seven environments for global path planning.

</details>
