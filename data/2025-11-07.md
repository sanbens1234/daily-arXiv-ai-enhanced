<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 本文对比研究了三种数据驱动的模型降阶技术，用于生成适用于软体机器人动态形状控制的线性模型。实验结果表明，基于Lagrangian算子推断（LOpInf）方法的策略在所有测试中产生的跟踪误差都低于其他模型基础上的策略。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏通用工具来为控制目的建模软体机器人，导致难以实现有效的动态形状控制。为了克服这一挑战，本研究旨在探索适合于软体机器人动态形状控制的数据驱动模型简化技术。

Method: 采用了三种方法进行比较研究：特征系统实现算法、含控制的动态模式分解以及Lagrangian算子推断(LOpInf)方法。通过每种类型的模型，研究人员探讨了它们在模拟鳗鱼启发式软体机器人的动态形状控制中的效能，特别是应用于模型预测控制策略时的表现。

Result: 在所有实验中，基于LOpInf的方法所生成的控制策略相较于其他两种方法而言，能够产生更低的跟踪误差。这些实验包括跟踪已知可行的模拟参考轨迹、由鳗鱼运动学生物模型生成的参考轨迹，以及由缩小比例物理模型生成的参考轨迹。

Conclusion: 研究表明，在软体机器人的动态形状控制方面，基于LOpInf的方法比其他测试过的数据驱动模型降阶技术更有效。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [2] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 本研究提出了一种基于统一强化学习的控制器，使类人机器人能够通过视觉感知和运动控制的直接集成来获得反应式的足球技能。


<details>
  <summary>Details</summary>
Motivation: 现有的系统通常依赖于解耦模块，在动态环境中导致响应延迟和行为不一致，而现实世界的感知限制进一步加剧了这些问题。

Method: 该方法扩展了对抗性动作先验到现实世界动态环境中的感知设置，引入了编码器-解码器架构与虚拟感知系统结合，允许策略从不完美的观察中恢复特权状态，并建立感知与行动之间的主动协调。

Result: 所得到的控制器展现了强大的反应能力，在各种场景下包括真实的RoboCup比赛中，能够持续执行连贯且稳健的足球行为。

Conclusion: 这项工作展示了一种有效的方法，用于在类人机器人上实现视觉感知驱动的即时反应足球技能，代表了向更自然、高效的机器人足球运动员迈进的重要一步。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [3] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 本文介绍了一种上肢姿态优化方法，旨在提高双手机器人-人协作搬运任务中的物理人体工程学和力可操作性。通过最小化成本函数来优化简化的人体骨骼模型的关节角度，以优先考虑安全性和操纵能力，并通过一个转换模块生成机器人的参考末端执行器姿态。提出了一种双手机器人预测阻抗控制器（MPIC）用于通过规划轨迹重新校准末端执行器的姿态。该方法在人类-人类协作（HHC）和人类-机器人协作（HRC）中得到了验证，实验结果表明目标肌肉激活情况有显著改善。


<details>
  <summary>Details</summary>
Motivation: 现有的研究通常强调人类安全或操纵效率，而本论文提出的方法独特地将这两个方面结合起来，以加强在不同条件下的协作（例如，人类的不同抓握姿势，以及物体的不同形状）。

Method: 该方法通过对简化的人体骨骼模型的关节角度进行优化，同时最小化成本函数，以优先保证安全性和操作能力。为了引导人类达到优化后的姿势，通过一个变换模块生成了机器人的参考末端执行器姿态。此外，还为类人机器人CURI设计了一种双手模型预测阻抗控制器(MPIC)，用以通过计划好的轨迹重新调整末端执行器的位置。

Result: 所提出的方法已经在人类-人类协作(HHC)和人类-机器人协作(HRC)过程中进行了验证。实验结果显示，在采用该优化方法后，目标肌肉的状态有了明显的改进。

Conclusion: 此论文提出了一种新的上肢姿态优化方法，能够有效提升双手机器人-人协作搬运任务中的安全性与操控性能。这种方法不仅考虑到了人类的安全因素，同时也提高了操作效率，并且在实际应用中证明了其有效性。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [4] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种新的LLM-CRF系统，利用大型语言模型来增强人-无人机群协作的认知处理能力，通过自然和多模态交互方式捕捉操作员意图，并进行意图理解、任务分解和任务规划。实验结果表明，与传统命令接口相比，该方法显著减少了任务完成时间（约64.2%）、提高了任务成功率（7%）并大幅降低了主观认知负荷（NASA-TLX评分下降了42.9%）。


<details>
  <summary>Details</summary>
Motivation: 大规模灾难搜救行动面临复杂地形和通讯中断的挑战。虽然无人飞行器(UAV)集群为广域搜索和物资配送等任务提供了有前景的解决方案，但其有效协调给人类操作者带来了巨大的认知负担。人机协作的核心瓶颈在于“意图到行动”的转换过程，在高压环境下容易出错。

Method: 提出了一种新型的LLM-CRF系统，首先通过语音或图形注释等方式与设备进行自然且多模态的互动以捕捉操作者的意图；然后使用大型语言模型作为认知引擎执行意图理解、层次化任务分解以及UAV集群的任务规划。

Result: 在模拟的SAR场景中评估了所提框架。结果显示，与传统的基于指令和控制的界面相比，提出的LLM驱动的方法将任务完成时间减少了大约64.2%，并将任务成功率提高了7%。此外，它还导致主观认知工作量显著减少，NASA-TLX分数下降了42.9%。

Conclusion: 这项工作展示了大型语言模型在高风险情境下创造更直观有效的人-群协作方面的潜力。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [5] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 本文评估了下一代多核处理器上GNC和LVS算法的部署，展示了与传统航天硬件相比在图像处理和轨迹优化上的显著加速。此外，提出了一种名为ARBITER的多核投票机制来保证计算可靠性，并通过故障注入研究确定了最敏感于位级错误的阶段，为未来任务提供了可扩展且节能的架构。


<details>
  <summary>Details</summary>
Motivation: 未来的行星探测任务需要高性能、容错性强的计算能力，以支持进入、下降和着陆期间的自主制导、导航、控制（GNC）以及着陆视觉系统（LVS）操作。

Method: 本文采用了HPSC、Snapdragon VOXL2 和 AMD Xilinx Versal 等下一代多核处理器来部署GNC和LVS算法，并引入了名为ARBITER（异步冗余行为检测以实现可信执行与恢复）的多核投票机制来进行实时故障检测与纠正。同时，通过对GFOLD进行故障注入研究来识别对位级错误最为敏感的阶段。

Result: 实验结果显示，在使用上述多核处理器后，LVS图像处理速度提高了15倍以上，GFOLD轨迹优化的速度更是提升了超过250倍。同时，ARBITER机制在静态优化任务（如GFOLD）和动态闭环控制（如姿态控制系统）中均得到了验证。

Conclusion: 本研究为包括火星样本返回、恩克拉多斯轨道着陆器及谷神星样本返回等未来任务提供了一个可扩展且能效高的架构方案，在这些任务中，机载自主性、低延迟以及抗故障能力至关重要。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [6] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero is a novel framework for humanoid robots that learns a shared latent representation, allowing a single policy to handle multiple tasks without retraining. It integrates unsupervised RL and FB models, supporting versatile real-world applications such as zero-shot motion tracking and goal reaching.


<details>
  <summary>Details</summary>
Motivation: The motivation is to create a unified, promptable generalist policy (Behavioral Foundation Models, BFMs) for humanoid robots capable of performing diverse control tasks, overcoming the limitations of existing approaches which are either confined to simulation or specialized to specific tasks.

Method: BFM-Zero utilizes an innovative approach by integrating recent advancements in unsupervised reinforcement learning (RL) and Forward-Backward (FB) models. This integration enables the creation of a well-structured, smooth, and explainable latent space for whole-body motions. The model also incorporates critical reward shaping, domain randomization, and history-dependent asymmetric learning to facilitate its application in real-world scenarios.

Result: BFM-Zero demonstrates versatile and robust whole-body skills on a Unitree G1 humanoid robot in the real world, through various inference methods including zero-shot motion tracking, goal reaching, and reward optimization. Its design choices were quantitatively evaluated in simulations, proving its effectiveness in bridging the sim-to-real gap.

Conclusion: BFM-Zero represents a significant advancement towards scalable, promptable Behavioral Foundation Models for whole-body humanoid control, capable of unifying diverse control tasks under a single, adaptable policy with minimal need for retraining.

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [7] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出了一种结合路径-不确定性协同优化深度强化学习框架和轻量级停滞检测机制的混合框架，以解决现有主动SLAM方法探索速度慢及路径欠佳的问题。实验结果显示，与前沿法和RRT法相比，该方法可将探索时间缩短最多65%，路径距离减少最多42%。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有主动SLAM方法中存在的探索速度慢以及生成次优路径的问题。

Method: 提出了一种混合框架，该框架结合了路径-不确定性协同优化深度强化学习（通过双目标奖励函数共同优化行进距离和地图不确定性）和轻量级停滞检测机制（通过激光雷达静态异常检测和地图更新停滞检测减少冗余探索）。

Result: 与基于前沿的方法和RRT方法相比，所提出的方法在复杂环境中可以将探索时间缩短多达65％，同时使路径距离减少多达42％，显著提高了探索效率，并保持了可靠的地图完整性。消融研究表明协作机制加速了训练收敛。在物理机器人平台上的实证验证表明，该算法具有实际应用性，并成功地从模拟环境转移到现实世界环境。

Conclusion: 提出的混合框架有效改善了主动SLAM中探索速度慢和路径质量不佳的问题，不仅提高了探索效率，还保证了地图构建的质量，在实际场景中展现了良好的适用性和转换能力。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [8] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB图像的机器人抓取系统，通过全局感知场景重建、主动感知策略以及在线度量对齐模块，实现了在杂乱环境中对透明或反光物体的准确抓取，性能优于基于RGB-D和单视图RGB的基线方法。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境下，由于遮挡、感知质量差及3D重建不一致等问题，机器人抓取仍然面临很大挑战。传统的解决方案依赖于RGB-D相机提供几何信息，但对于透明或反光物体表现不佳，并且近距离时性能下降。

Method: GraspView结合了三个关键组件：(i) 全局感知场景重建，从单一RGB视角提供局部一致、比例正确的几何形状，并将多视角投影融合为连贯的全局3D场景；(ii) 渲染并评分的主动感知策略，动态选择下一个最佳视角以揭示被遮挡区域；(iii) 在线度量对准模块，校准VGGT预测与机器人运动学之间的关系，确保物理尺度一致性。

Result: 实验表明，在多种桌面物品上，特别是在严重遮挡、近场感应和处理透明物体的情况下，GraspView显著优于基于RGB-D和单视图RGB的方法。

Conclusion: GraspView作为RGB-D管道的一种实用而多功能的替代方案，能够在非结构化的真实世界环境中实现可靠的抓取。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [9] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 研究通过在基于域随机化的强化学习框架中加入上下文估计模块，来改善从模拟到现实世界的策略迁移问题。实验结果表明，在不同任务设置下，上下文感知策略比无上下文基线表现得更好。


<details>
  <summary>Details</summary>
Motivation: 由于环境动态差异导致的仿真训练策略在现实世界中的泛化失败问题，是机器人强化学习领域的一个主要挑战。虽然域随机化（DR）方法能够缓解这个问题，但它同时也会降低性能。因此，该研究探索了通过条件化策略于动力学参数估计（即上下文）之上，是否可以提高从模拟到现实的转移效果。

Method: 研究者将一个上下文估计模块集成到了基于域随机化的RL框架内，并系统地比较了几种最先进的监督策略。他们使用了一个标准控制基准和一个利用Franka Emika Panda机器人进行的真实世界推动物体任务来评估所得到的上下文感知型策略的效果。

Result: 结果显示，无论在哪种设定下，上下文感知型策略都优于没有考虑上下文信息的基础版本。不过，最佳的监督策略选择取决于具体任务类型。

Conclusion: 本研究表明，通过引入对环境动力学参数敏感的上下文信息，可以有效提升从模拟环境到真实环境中策略迁移的成功率，但需要根据特定任务选取最合适的监督方式以获得最优效果。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [10] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文介绍了一种具有可重构机翼设计的垂直起降无人机，该设计允许在多旋翼模式下收起机翼，在固定翼模式下展开。同时采用了异构双旋翼配置以提高能效，并通过无倾斜盘机制来简化结构和减轻重量，最终进行了全面的过渡飞行测试以验证整个飞行包线内的稳定飞行性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决尾座式垂直起降无人机在多旋翼模式下容易受到风干扰的问题，以及为了降低能耗和简化结构复杂性。

Method: 提出了一种可以改变机翼布局的设计（在多旋翼模式时收起机翼，在固定翼模式时展开），采用了同轴异构双旋翼配置以减少总功耗，并使用了改进后的无倾斜盘机构来控制俯仰与滚转。此外，还通过添加摆动铰链优化了无倾斜盘机构的结构，从而减少了循环加速减速过程中的振动。

Result: 通过综合性的过渡飞行测试验证了所提出的无人机设计方案能够在全飞行包线内实现稳定的飞行表现。

Conclusion: 本研究中提出的创新设计有效提升了尾座式垂直起降无人机的抗风能力和能源效率，同时简化了其机械结构，为这类无人机的实际应用提供了新的可能性。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [11] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav, a learning-based navigation framework, uses a lightweight context encoder and a reinforcement learning policy for efficient and effective autonomous navigation in unknown environments, outperforming state-of-the-art methods in success rate and path length while keeping computational costs low.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to address the challenge faced by existing autonomous navigation approaches in balancing rich contextual representation with navigation efficiency, especially in unknown and partially observable environments. The goal is to develop a more compact and expressive method that can support high-level decision making effectively.

Method: The method introduced in the paper is MacroNav, which consists of two main components: 1) A lightweight context encoder that is trained through multi-task self-supervised learning to generate multi-scale, navigation-focused spatial representations; 2) A reinforcement learning (RL) policy that combines these spatial representations with graph-based reasoning to make efficient action selections during navigation.

Result: The experiments conducted show that the context encoder within MacroNav provides an efficient and robust understanding of the environment. In real-world deployments, MacroNav has demonstrated significant improvements over leading navigation methods, particularly in terms of Success Rate (SR) and Success weighted by Path Length (SPL), all while maintaining a low computational cost.

Conclusion: In conclusion, MacroNav offers a novel approach to autonomous navigation that enhances both the efficiency and effectiveness of navigating unknown environments, as evidenced by its superior performance in SR and SPL metrics compared to current state-of-the-art methods, alongside its practicality due to low computational requirements.

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [12] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: 本文提出了一种新的神经符号方法GraSP-VLA，它利用连续场景图表示来生成人类演示的符号表示，用于自动生成规划领域，并作为低级VLA策略的协调器，从而在一系列动作中扩展可再现的动作数量。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端模仿学习与视觉-语言动作(VLA)模型或带有动作模型学习(AML)的符号方法在处理长期任务时存在局限性。VLA模型缺乏高级别符号规划能力，而AML中的符号方法缺乏泛化和可扩展性视角。

Method: 本文介绍了一种名为GraSP-VLA的新神经符号方法，该框架采用连续场景图表示来从人类演示中产生符号表示。此表示法被用来在推理过程中生成新的规划域，并作为低级别VLA策略的编排者，增加能够连续执行的动作数量。

Result: 结果表明，GraSP-VLA在根据观察自动规划域生成的任务上对建模符号表示是有效的。此外，在实际实验中的结果显示了连续场景图表示在长周期任务中协调低层次VLA政策方面的潜力。

Conclusion: GraSP-VLA为自主机器人通过演示学习新技能提供了一个有前景的方法，特别是对于需要长期规划的任务而言。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [13] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo is a generative robotic agent that uses a propose-generate-learn-actuate cycle to autonomously acquire manipulation skills through generative simulations. It integrates generative paradigms with classical control, showing superior interpretability and execution efficiency compared to end-to-end policy learning methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to efficiently leverage simulation for robots to learn advanced manipulation skills, aiming to improve upon direct low-level policy learning by integrating generative paradigms with classical control approaches.

Method: ForeRobo utilizes a self-guided propose-generate-learn-actuate cycle where it proposes skills, generates corresponding simulation environments, configures objects for skill-consistent goal states, trains the ForeFormer model to predict 3D goal positions, and then applies classical control algorithms to execute actions in real-world settings based on the envisioned goals.

Result: ForeFormer demonstrates an average improvement of 56.32% over state-of-the-art state generation models across various manipulation tasks. In real-world tests, ForeRobo achieves zero-shot sim-to-real transfer and has a 79.28% success rate across more than 20 robotic tasks.

Conclusion: By combining generative simulations with classical control, ForeRobo offers a promising approach for robots to autonomously develop manipulation skills, exhibiting strong generalization and high success rates in real-world applications.

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [14] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: 提出了Evo-1，一种轻量级的视觉-语言-动作(VLA)模型，通过创新架构和两阶段训练方法，在减少计算量、提高部署效率的同时保持了强大的性能表现，无需预先在机器人数据上进行训练。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型通常参数庞大，依赖大规模机器人数据预训练，导致训练期间计算成本高，并且实时推理部署能力有限。此外，大多数训练范式经常降低视觉-语言主干的感知表示能力，导致对下游任务过拟合和泛化能力差。

Method: 基于原生多模态视觉-语言模型(VLM)，结合了一种新颖的跨模态扩散变压器以及一个优化后的集成模块，形成了有效的架构。引入了两阶段训练范式，逐步将动作与感知对齐，同时保留了VLM的表示。

Result: Evo-1仅以0.77亿个参数达到了Meta-World和RoboTwin套件上的最先进结果，分别超过了之前的最佳模型12.4%和6.9%，并且在LIBERO上也获得了94.8%的竞争性成绩。实际评估中，Evo-1实现了78%的成功率，具有高频推理能力和低内存占用。

Conclusion: Evo-1作为一种轻量级VLA模型，在减少计算量和提高部署效率方面展示了显著优势，同时在多个基准测试中表现出色，为未来研究提供了新的方向。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [15] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 本文提出了一种统一的共享自主框架，该框架通过视觉语言模型从多模态线索中推断驾驶员意图，并在人类和自主控制之间合成连贯策略。实验表明，该方法在模拟人设置中表现出色，在Bench2Drive基准测试中显著降低了碰撞率并提高了整体性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统在罕见、模糊及超出分布的情境下表现脆弱，而人类驾驶员可以通过上下文推理成功应对。共享自主性作为一种有前景的方法，通过在自动驾驶不确定时引入人类输入来缓解这些失败。然而，大多数现有方法仅限于低级轨迹层面进行仲裁，这仅代表了几何路径，因此未能保留底层驾驶意图。

Method: 提出了一种统一的共享自主框架，该框架利用视觉语言模型（VLMs）从包括驾驶员动作和环境背景在内的多模态提示中推断出驾驶员意图，并综合出协调人类与自动控制之间的连贯策略。

Result: 在模拟人类环境中研究了该框架，实现了完美召回以及高准确性和精确度。一项针对人类受试者的调查显示高度一致，参与者在92%的情况下同意仲裁结果。此外，在Bench2Drive基准上的评估显示，与纯自主相比，碰撞率大幅降低且整体性能得到改善。

Conclusion: 基于语义的语言表示层面上的仲裁成为共享自主的设计原则，使系统能够运用常识推理并保持与人类意图的一致性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [16] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种基于真实到模拟的策略评估框架，通过从真实世界视频中构建软体数字孪生，并使用3D高斯点绘技术以照片级真实感渲染机器人、物体和环境，为软体交互任务提供可扩展、系统化且准确的评估方法。


<details>
  <summary>Details</summary>
Motivation: 针对直接在现实世界中评估机器人操作策略成本高、耗时长且难以复现的问题，尤其是涉及可变形物体的任务，提出了一个结合物理信息重建与高质量渲染的解决方案，以实现可重复性、可扩展性和准确性更高的评估。

Method: 开发了一个从真实到模拟的策略评估框架，该框架能够从现实世界的视频中创建软体对象的数字孪生，并利用3D高斯点绘技术达到照片级别的逼真度来呈现机器人、物品及环境。

Result: 在包括毛绒玩具包装、绳索布线以及T型块推动等代表性可变形物体操作任务上验证了所提方法的有效性，表明模拟执行结果与实际执行性能高度相关，并能揭示学习到策略的关键行为模式。

Conclusion: 结合物理信息重建与高质量渲染的方法，可以支持机器人操作策略的可再现、规模化及精确评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [17] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion框架通过在人类动作数据中添加噪声来模糊执行差异，同时保留任务指导信息，从而训练出更适应机器人执行的动作策略。


<details>
  <summary>Details</summary>
Motivation: 人类视频可以作为机器人学习的大规模训练数据源，但人与机器人的身体构造不同，直接将人类手部动作转换给机器人可能会产生无法执行的动作。尽管存在这些差异，人类演示提供了关于如何操作和与物体互动的宝贵线索。

Method: X-Diffusion首先训练一个分类器来预测带有噪声的动作是由人类还是机器人执行的。只有当对人类动作添加足够多的噪声以至于分类器无法区分其执行者时，该动作才会被纳入策略训练中。与机器人执行相一致的动作在低噪声水平下监督精细去噪过程，而高噪声水平下不匹配的人类动作用于提供粗略指导。

Result: 实验表明，在执行差异下的简单共同训练会降低策略性能，而X-Diffusion则始终能够提高它。在五个操作任务上，X-Diffusion比最佳基线方法平均成功率高出16%。

Conclusion: X-Diffusion为利用人类数据训练扩散策略提供了一个原则性框架，能够在不学习对机器人来说动态不可行动作的前提下最大化地利用人类数据。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [18] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: 提出了GentleHumanoid框架，将阻抗控制集成到全身运动跟踪策略中，以实现上身的顺应性，通过模拟和实际机器人测试表明该方法可以在保持任务成功率的同时减少峰值接触力，从而实现更安全、自然的人机交互。


<details>
  <summary>Details</summary>
Motivation: 目前大多数强化学习策略侧重于刚性追踪并抑制外部力量，而现有的增强阻抗方法通常局限于基座或末端执行器控制，并且主要关注抵抗极端力量而不是实现顺应性。为了使人形机器人在以人为中心的环境中能够进行安全自然的身体互动，需要一种新的方法来改善这一点。

Method: GentleHumanoid是一个将阻抗控制与全身动作跟踪策略相结合的框架，旨在实现上半身的顺应性。它采用统一的弹簧模型来模拟阻力接触（当压向表面时产生的恢复力）和引导接触（从人类动作数据采样的推拉）。该方法确保了肩部、肘部和腕部之间的一致动力学效应，同时让策略能够应对多样的互动情景。此外，通过可调的任务相关力阈值进一步支持安全性。

Result: 研究者们在仿真环境以及Unitree G1人形机器人上对所提出的方法进行了评估，针对不同层次顺应性需求的任务如温柔拥抱、坐立辅助及安全物体操作等。相较于基准方法，他们的策略在保持任务完成度的同时显著降低了峰值接触力，实现了更加平滑自然的人机互动。

Conclusion: 这些结果标志着向着能够在现实世界环境中安全有效地与人类合作并处理物品的人形机器人迈出了一步。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>
