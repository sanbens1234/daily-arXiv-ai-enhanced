<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 19]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Advanced techniques and applications of LiDAR Place Recognition in Agricultural Environments: A Comprehensive Survey](https://arxiv.org/abs/2601.22198)
*Judith Vilella-Cantos,Mónica Ballesta,David Valiente,María Flores,Luis Payá*

Main category: cs.RO

TL;DR: 本文综述了农业环境中基于LiDAR的定位技术，特别是深度学习应用的最新进展，分析了现有方法、数据集以及评估指标，并探讨了该领域的挑战、局限性及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 在自主机器人系统的发展中，定位问题的最佳解决方案至关重要。除了自动驾驶汽车外，精准农业是能够从这些系统中受益最多的领域之一。尽管近年来LiDAR地点识别技术被广泛用于实现精确定位，但主要是在城市环境中使用。然而，在农业环境中，由于缺乏独特的特征和环境结构化程度低，使得地点识别变得非常具有挑战性。

Method: 本研究通过文献回顾的方式，对目前最前沿的深度学习应用于农业环境下的LiDAR地点识别（LPR）技术进行了全面的考察。

Result: 文章分析了农业环境中存在的挑战，包括现有方法、所用的数据集以及用来评估LPR系统性能的度量标准，并讨论了这一领域内的局限性和未来的研究方向。

Conclusion: 这是首个专注于农业环境下基于LiDAR定位的调研报告，旨在为该专门领域提供深入的理解并促进进一步的研究。

Abstract: An optimal solution to the localization problem is essential for developing autonomous robotic systems. Apart from autonomous vehicles, precision agriculture is one of the elds that can bene t most from these systems. Although LiDAR place recognition is a widely used technique in recent years to achieve accurate localization, it is mostly used in urban settings. However, the lack of distinctive features and the unstructured nature of agricultural environments make place recognition challenging. This work presents a comprehensive review of state-of-the-art the latest deep learning applications for agricultural environments and LPR techniques. We focus on the challenges that arise in these environments. We analyze the existing approaches, datasets, and metrics used to evaluate LPR system performance and discuss the limitations and future directions of research in this eld. This is the rst survey that focuses on LiDAR based localization in agricultural settings, with the aim of providing a thorough understanding and fostering further research in this specialized domain.

</details>


### [2] [Lantern: A Minimalist Robotic Object Platform](https://arxiv.org/abs/2601.22381)
*Victor Nikhil Antony,Zhili Gong,Guanchen Li,Clara Jeon,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 本文设计并引入了一个名为Lantern的极简机器人对象平台，旨在以低成本（约40美元）构建简单的机器人制品。通过一系列探索活动，包括共同设计工作坊、感官室案例研究等，Lantern被证明能够有效促进人机交互，并支持从情绪调节到专注工作的多种应用。


<details>
  <summary>Details</summary>
Motivation: 开发一个成本低廉且功能多样的机器人平台，利用人类倾向于将社会意义赋予简单形式的特点，探索和扩展人机交互（HRI）的应用场景。

Method: 设计并迭代了Lantern的机电架构，确保其实现特定的设计目标同时保持低建造成本；通过共设计工作坊、感官房间案例分析、向外部HRI实验室分发设备、整合进研究生级别HRI课程以及面向老年人与儿童的公共展览等多种方式来评估Lantern在HRI中的潜力。

Result: Lantern成功地激发了参与者的兴趣，适用于从情感管理到集中注意力工作的广泛用途，并作为降低进入HRI领域门槛的有效工具。

Conclusion: Lantern作为一个可扩展、开源的平台，在促进人机互动方面表现出巨大潜力，能够支持多样化的人机交互场景，并有助于减少进入该领域的障碍。

Abstract: Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.

</details>


### [3] [Plant-Inspired Robot Design Metaphors for Ambient HRI](https://arxiv.org/abs/2601.22387)
*Victor Nikhil Antony,Adithya R N,Sarah Derrick,Zhili Gong,Peter M. Donley,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 本文通过研究设计的方法，探索了植物作为人机交互的隐喻灵感，开发了一系列受植物启发的机器人原型，并通过工作坊探讨人们对这些机器人的感知和想象，为使用植物隐喻重塑人机交互提供了设计考虑。


<details>
  <summary>Details</summary>
Motivation: 当前的人机交互（HRI）主要基于类人或类动物的范式，而植物以一种低需求但又能影响环境氛围、日常生活及人际关系的独特方式存在。作者旨在通过植物的隐喻来探索新的HRI模式，这种模式可以是更含蓄且不那么直接要求互动的形式。

Method: 采用“通过设计进行研究”（RtD）的方法论，包括迭代的想法生成、原型制作与反思过程，来探索从植物隐喻中产生的设计元素以及如何将这些元素组合成具有表现力的机器人形态。同时，通过围绕原型的工作坊进一步深化对人们如何看待植物启发式机器人的理解。

Result: 本研究贡献了一套受植物启发的机器人制品；关于人们如何感知这类机器人的设计洞察；以及利用植物隐喻重新构想HRI的设计考量建议。

Conclusion: 这项研究表明，采用植物作为隐喻来源能够为HRI领域带来新颖的设计思路与形式，有助于创造更加自然和谐的人机共存体验。

Abstract: Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.

</details>


### [4] [Accurate Pedestrian Tracking in Urban Canyons: A Multi-Modal Fusion Approach](https://arxiv.org/abs/2601.22406)
*Shahar Dubiner,Peng Ren,Roberto Manduchi*

Main category: cs.RO

TL;DR: 该论文提出了一种基于粒子滤波器融合GNSS和惯性数据的行人导航方法，利用地图空间先验提高城市环境中定位精度。实验结果表明，所提出的融合方法在大多数指标上优于仅使用GNSS的定位效果。


<details>
  <summary>Details</summary>
Motivation: 在GNSS性能下降的城市环境中，特别是对于依赖精确引导（如识别街道正确边）的盲人或低视力用户，需要一种更准确的行人导航方案。

Method: 通过结合GNSS、惯性数据以及地图中的空间先验（例如不可通行的建筑物和不太可能行走的区域），采用粒子滤波器进行数据融合。其中，惯性定位由RoNIN机器学习方法提供，与GNSS的融合则根据粒子与GNSS估计值及其不确定性的一致性来加权实现。

Result: 在旧金山市中心六个具有挑战性的步行路线上的测试显示，融合方法（GNSS+RoNIN+PF）在多数度量标准下明显优于单独使用GNSS的定位表现；而仅使用惯性加上粒子滤波的方法也超过了单用GNSS，在关键度量如人行道分配和跨街误差方面表现更好。

Conclusion: 提出的方法能够有效提升城市环境下行人导航系统的定位准确性，特别是在GNSS信号不佳的情况下为视觉障碍者提供了更可靠的导航解决方案。

Abstract: The contribution describes a pedestrian navigation approach designed to improve localization accuracy in urban environments where GNSS performance is degraded, a problem that is especially critical for blind or low-vision users who depend on precise guidance such as identifying the correct side of a street. To address GNSS limitations and the impracticality of camera-based visual positioning, the work proposes a particle filter based fusion of GNSS and inertial data that incorporates spatial priors from maps, such as impassable buildings and unlikely walking areas, functioning as a probabilistic form of map matching. Inertial localization is provided by the RoNIN machine learning method, and fusion with GNSS is achieved by weighting particles based on their consistency with GNSS estimates and uncertainty. The system was evaluated on six challenging walking routes in downtown San Francisco using three metrics related to sidewalk correctness and localization error. Results show that the fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS only localization on most metrics, while inertial-only localization with particle filtering also surpasses GNSS alone for critical measures such as sidewalk assignment and across street error.

</details>


### [5] [High-Definition 5MP Stereo Vision Sensing for Robotics](https://arxiv.org/abs/2601.22445)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.RO

TL;DR: 该研究通过引入一种新的帧到帧校准和立体匹配方法，解决了高分辨率立体视觉系统中高精度校准和快速处理的需求，并证明了只有通过实现高精度校准，高像素计数相机才能产生高质量的点云。


<details>
  <summary>Details</summary>
Motivation: 为了充分发挥高角分辨率传感器的潜力，需要相应提高校准精度并加快处理速度，而传统方法往往无法满足这些要求。

Method: 研究采用了500万像素摄像机图像，并使用了一种新颖的高级帧到帧校准及立体匹配方法来同时达到高准确度与速度。此外，还提出了一种新方法来评估实时性能，即通过将实时视差图与基于更耗计算资源的立体匹配算法得到的真实视差图进行对比。

Result: 研究表明，仅当实现了高精度校准时，高像素计数相机才能够生成高质量的点云。

Conclusion: 本研究为高分辨率立体视觉系统提供了有效的方法论，强调了高精度校准对于提升机器人能力的重要性。

Abstract: High-resolution (5MP+) stereo vision systems are essential for advancing robotic capabilities, enabling operation over longer ranges and generating significantly denser and accurate 3D point clouds. However, realizing the full potential of high-angular-resolution sensors requires a commensurately higher level of calibration accuracy and faster processing -- requirements often unmet by conventional methods. This study addresses that critical gap by processing 5MP camera imagery using a novel, advanced frame-to-frame calibration and stereo matching methodology designed to achieve both high accuracy and speed. Furthermore, we introduce a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth disparity maps derived from more computationally intensive stereo matching algorithms. Crucially, the research demonstrates that high-pixel-count cameras yield high-quality point clouds only through the implementation of high-accuracy calibration.

</details>


### [6] [CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control](https://arxiv.org/abs/2601.22467)
*Jiaqi Shi,Xulong Zhang,Xiaoyang Qu,Jianzong Wang*

Main category: cs.RO

TL;DR: 提出了一种新的框架CARE，它通过仅使用视频-文本对来训练视觉-语言-动作模型以执行机器人任务，无需明确的动作标签，从而提高了模型的可扩展性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在机器人控制上的应用受限于对动作监督的需求，这限制了它们的可扩展性和泛化能力。为解决这一问题，研究者开发了CARE框架，旨在减少对明确动作标注的依赖。

Method: CARE框架利用视频-文本对作为数据源，在预训练阶段通过一种新设计的多任务预训练目标学习连续潜在的动作表示。在微调阶段，则使用少量标记数据训练动作头部以实现控制。

Result: 实验结果显示，CARE在各种模拟任务中展示了更高的成功率、更好的语义可解释性以及避免捷径学习的能力。

Conclusion: CARE框架证明了其在弱监督条件下对于提高机器人控制任务的可扩展性、可解释性和有效性方面的潜力。

Abstract: Recent advances in Vision-Language-Action (VLA) models have shown promise for robot control, but their dependence on action supervision limits scalability and generalization. To address this challenge, we introduce CARE, a novel framework designed to train VLA models for robotic task execution. Unlike existing methods that depend on action annotations during pretraining, CARE eliminates the need for explicit action labels by leveraging only video-text pairs. These weakly aligned data sources enable the model to learn continuous latent action representations through a newly designed multi-task pretraining objective. During fine-tuning, a small set of labeled data is used to train the action head for control. Experimental results across various simulation tasks demonstrate CARE's superior success rate, semantic interpretability, and ability to avoid shortcut learning. These results underscore CARE's scalability, interpretability, and effectiveness in robotic control with weak supervision.

</details>


### [7] [RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing](https://arxiv.org/abs/2601.22517)
*Kangning Yin,Zhe Cao,Wentao Dong,Weishuai Zeng,Tianyi Zhang,Qiang Zhang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Weinan Zhang*

Main category: cs.RO

TL;DR: RoboStriker, a three-stage framework, uses motion capture data and latent space interactions to enable humanoid robots to box, showing improved performance in simulation and real-world transfer.


<details>
  <summary>Details</summary>
Motivation: The challenge of achieving human-like intelligence and physical agility in humanoid robots, especially in dynamic tasks like boxing, is addressed. The motivation is to overcome the limitations of directly applying Multi-Agent Reinforcement Learning (MARL) to robot control due to complex contact dynamics and the lack of strong physical motion priors.

Method: A hierarchical three-stage approach called RoboStriker is proposed. It begins with learning a range of boxing skills through single-agent motion tracking on human data. These skills are then represented in a structured latent space, constrained topologically to ensure physically plausible motions. Finally, Latent-Space Neural Fictitious Self-Play (LS-NFSP) is employed for agents to learn competitive tactics within this latent space, improving training stability.

Result: Experiments show that RoboStriker outperforms in simulated competitive scenarios and demonstrates successful simulation-to-reality (sim-to-real) transfer.

Conclusion: The RoboStriker framework effectively bridges the gap between high-level strategy and low-level execution in humanoid boxing, providing a promising direction for enhancing robotic capabilities in dynamic, contact-rich environments.

Abstract: Achieving human-level competitive intelligence and physical agility in humanoid robots remains a major challenge, particularly in contact-rich and highly dynamic tasks such as boxing. While Multi-Agent Reinforcement Learning (MARL) offers a principled framework for strategic interaction, its direct application to humanoid control is hindered by high-dimensional contact dynamics and the absence of strong physical motion priors. We propose RoboStriker, a hierarchical three-stage framework that enables fully autonomous humanoid boxing by decoupling high-level strategic reasoning from low-level physical execution. The framework first learns a comprehensive repertoire of boxing skills by training a single-agent motion tracker on human motion capture data. These skills are subsequently distilled into a structured latent manifold, regularized by projecting the Gaussian-parameterized distribution onto a unit hypersphere. This topological constraint effectively confines exploration to the subspace of physically plausible motions. In the final stage, we introduce Latent-Space Neural Fictitious Self-Play (LS-NFSP), where competing agents learn competitive tactics by interacting within the latent action space rather than the raw motor space, significantly stabilizing multi-agent training. Experimental results demonstrate that RoboStriker achieves superior competitive performance in simulation and exhibits sim-to-real transfer. Our website is available at RoboStriker.

</details>


### [8] [Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios](https://arxiv.org/abs/2601.22545)
*Feng Tao,Luca Paparusso,Chenyi Gu,Robin Koehler,Chenxu Wu,Xinyu Huang,Christian Juette,David Paz,Ren Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习的实时路径规划框架，用于解决停车场景中的路径规划问题。该方法不需要理想的感知条件，且在测试时只需一次前向传递即可生成动作，具有较高的实用性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划方法在完美感知假设下有效，但对实际感知限制敏感，并且在线搜索过程计算成本高，在复杂环境中难以实现实时部署。为了解决这些问题，本文提出了一个针对停车场景的深度强化学习（DRL）框架，特别关注需要多次倒车调整的紧凑空间。

Method: 任务被定义为基于自行车模型动力学的序列决策问题，使智能体能够直接学习到符合车辆运动学和环境约束的导航策略。同时开发了一个新的基准来支持训练与评估，涵盖了多样化的挑战性场景。

Result: 所提方法达到了最先进的成功率和效率，相比经典规划器基线，成功率提高了96%，效率提高了52%。此外，还发布了开源基准及配套工具以促进未来研究。

Conclusion: 通过引入深度强化学习框架解决了受限环境下实时路径规划的基本挑战，特别是对于停车场景而言，该方案比传统规划方法更简单、更实用。

Abstract: Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems. The benchmark and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.

</details>


### [9] [Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation](https://arxiv.org/abs/2601.22550)
*Geonho Leem,Jaedong Lee,Jehee Lee,Seungmoon Song,Jungdam Won*

Main category: cs.RO

TL;DR: 介绍了Exo-plore，一个结合神经机械模拟与深度强化学习的仿真框架，用于优化髋关节外骨骼辅助而无需真实人类实验。该框架能够生成逼真的步态数据、提供可靠的优化结果，并且可以泛化到病理性步态。


<details>
  <summary>Details</summary>
Motivation: 外骨骼在增强移动性方面显示出巨大潜力，但由于人类对外力适应的复杂性，提供恰当的辅助仍具有挑战性。当前最先进的优化外骨骼控制器的方法需要进行大量的人体实验，这对那些最能从外骨骼辅助中受益但行动不便的人来说尤其困难。

Method: 开发了Exo-plore仿真框架，它将神经机械模拟与深度强化学习相结合，以优化髋关节外骨骼辅助。通过此方法，可以在不依赖于实际人体实验的情况下，生成反映人类对辅助力量适应性的步态数据，同时克服步态随机性带来的挑战。

Result: Exo-plore能够产生接近真实的步态数据，可靠地完成优化任务，并且适用于病理性步态，展示了病理严重程度与最佳辅助之间存在强线性关系。

Conclusion: Exo-plore为优化髋关节外骨骼辅助提供了新的途径，使得即使是对行动不便者也能更加高效和安全地找到最适合他们的辅助方案，从而推动了外骨骼技术的发展。

Abstract: Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current state-of-the-art approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation framework that combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable optimization results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.

</details>


### [10] [Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies](https://arxiv.org/abs/2601.22672)
*Theodora Kastritsi,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 本文提出了一种新的控制框架，通过向使用超数机器人身体（SRBs）的用户提供动觉反馈来阻止非人体工程学姿势，并促进长期学习良好的人体工程学习惯。


<details>
  <summary>Details</summary>
Motivation: 尽管联合协作机器人作为超数机器人身体可以增强人类负载能力，但在涉及与人类物理交互的任务中，用户仍可能采取不舒适、不符合人体工程学的姿势，导致不适或伤害。因此，需要一种方法来促进正确的姿势并鼓励长期学习良好的人体工程学习惯。

Method: 开发了一个虚拟夹具方法，结合了连续在线的人体工程学姿势评估框架。此外，还调整了浮动基座的位置以改善操作员和SRB之间的协调性。

Result: 实验结果证明了该人体工程学驱动控制框架的功能性和有效性，包括两个用户研究，涉及14名受试者执行实际的位移操作任务，并将所提出的框架与一个不考虑人体工程学的基准控制框架进行了比较。

Conclusion: 所提出的人体工程学驱动控制框架能够有效减少用户的不良姿势，促进健康的工作方式。

Abstract: Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.

</details>


### [11] [FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation](https://arxiv.org/abs/2601.22686)
*Biyu Ye,Na Fan,Zhengping Fan,Weiliang Deng,Hongming Chen,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种新的机载框架，用于增强空中操纵器在处理未知物体时的鲁棒性。该系统结合了基于视觉的抓取前惯量估计模块和抓取后适应机制，并开发了一种基于增益调度的惯量感知自适应控制策略，实验证明了其有效性和可行性。


<details>
  <summary>Details</summary>
Motivation: 由于传统多旋翼无人机在灵活性方面的不足，空中操纵器（AMs）在自动化运输和紧急服务中越来越受到关注。然而，它们实际部署面临的一个挑战是时间变化的惯性参数复杂性问题，这与负载变化及操纵器配置高度敏感相关。受人类与未知物体交互策略启发，研究者提出了一个新颖的机载框架来解决这一难题。

Method: 所提出的系统整合了一个基于视觉的预抓取惯量估计模块与一个抓取后的适应机制，实现了惯性动态的实时估计和调整。此外，还开发了一种基于增益调度的惯量感知自适应控制策略，并通过频域系统识别评估了其鲁棒性。

Result: 研究表明，该方法为AMs提供了关于抓取后控制的新见解，并且真实世界的实验验证了所提框架的有效性和可行性。

Conclusion: 本文介绍了一种创新的方法，能够提高空中操纵器在面对未知物体时的操作性能。通过结合视觉技术、实时适应机制以及先进的控制策略，解决了因负载变化导致的惯性参数变动问题，为未来空中机器人技术的发展奠定了基础。

Abstract: Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.

</details>


### [12] [Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives](https://arxiv.org/abs/2601.22849)
*Christian Dietz,Sebastian Albrecht,Gianluca Frison,Moritz Diehl,Armin Nurkanović*

Main category: cs.RO

TL;DR: 本文提出了一种基于可微物理模拟的样本高效鲁棒最优控制方法来规划装配动作，该方法通过有效利用导数信息显著减少了规划过程中所需的物理模拟步骤。实验结果表明，在实际应用中成功执行率超过99%。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，高效地规划装配动作一直是一个长期存在的挑战，主要依赖于强化学习和基于采样的方法进行大量物理仿真。本文旨在提出一种更样本高效的鲁棒最优控制方法以减少规划时所需的物理仿真步数。

Method: 构建了一个可微分的物理仿真环境，它能够为数值求解器提供二阶解析导数，并允许从信息丰富的导数无缝过渡到精确的接触仿真。通过对碰撞检测及接触解决过程采用内部点法启发式的平滑处理，使物理仿真问题的解决方案变得可微分。此外，还提出了一种优化后的线性程序形式的碰撞检测公式及其一阶和二阶导数的有效实现方式。为了确保对模拟与现实之间差异的鲁棒性，设计了一个多情景下的轨迹优化问题。

Result: 所提方法在真实世界实验中的成功率超过了99%，并且通过仔细研究接触动力学和平滑近似以及鲁棒建模对成功率的影响进行了验证。此外，在不同销孔问题上的模拟测试进一步展示了使用精确海森矩阵相比常用海森近似的优势。

Conclusion: 提出的样本高效鲁棒最优控制方法能够显著降低规划装配动作时所需物理仿真步骤的数量，同时保证了高成功率和对模拟到现实转换误差的良好鲁棒性。

Abstract: Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.

</details>


### [13] [Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs](https://arxiv.org/abs/2601.22927)
*Lars Ullrich,Michael Buchholz,Klaus Dietmayer,Knut Graichen*

Main category: cs.RO

TL;DR: 本文探讨了人工智能在自动驾驶领域带来的挑战与机遇，分析了当前自动驾驶的状态、局限性以及可预见的技术可能性，并重新考虑了随着AI技术进步的全自动驾驶的需求和研究问题。


<details>
  <summary>Details</summary>
Motivation: 鉴于向完全自动驾驶过渡面临现实世界不断变化所带来的挑战，本文旨在识别AI在实现自动驾驶功能时所引发的挑战和机会。

Method: 通过分析自动驾驶现状、描绘局限性并识别出可预见的技术可能性来研究AI对自动驾驶的影响。

Result: 发现了使用AI能够超越传统方法处理更高复杂度的情况，但同时也提出了安全性和可转移性的问题。此外，还探讨了未来发展中可能遇到的各种其他挑战。

Conclusion: 文章基于AI领域的进展重新审视了全自动驾驶的概念，并指出了相应的需要解决的问题及由此产生的研究课题。

Abstract: Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of artificial intelligence (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.

</details>


### [14] [MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2601.22930)
*Xidong Li,Mingyu Guo,Chenchao Xu,Bailin Li,Wenjing Zhu,Yangang Zou,Rui Chen,Zehuan Wang*

Main category: cs.RO

TL;DR: 提出了一种名为MTDrive的多轮次框架，该框架通过环境反馈迭代优化自动驾驶中的轨迹规划。它使用了多轮次组相对策略优化（mtGRPO）来减少奖励稀疏性，并通过闭环仿真构建了一个交互式轨迹理解数据集以支持训练。实验表明其在复杂任务处理上优于现有方法，同时系统级优化减少了高分辨率图像和多轮序列引起的数据传输开销，实现了2.5倍的训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的将多模态大语言模型与强化学习相结合的方法在解决“长尾”场景时显示出潜力，但局限于单轮推理，难以应对需要迭代优化的复杂任务。为了解决这一限制并提高处理复杂驾驶情景的能力。

Method: 提出了MTDrive，一个基于多轮次迭代改进轨迹规划的框架。该框架采用了多轮次组相对策略优化算法（mtGRPO），旨在通过跨轮次计算相对优势来缓解奖励稀疏的问题。此外，还从闭环模拟中构建了一个互动式的轨迹理解数据集，用于支撑多轮次训练过程。

Result: 在NAVSIM基准测试上的实验结果表明，所提方法相比现有技术表现更优，验证了多轮次推理范式的有效性。另外，通过对系统层面进行优化，特别是针对由高分辨率图片及多轮序列导致的数据传输负担问题，成功地达到了2.5倍的训练效率提升。

Conclusion: 本研究介绍了一种新的多轮次框架MTDrive，能够利用环境反馈迭代改善轨迹规划，特别适用于复杂任务。通过引入mtGRPO算法和专门的数据集，不仅提高了对‘长尾’情形的处理能力，也显著增强了训练效率。

Abstract: Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with Reinforcement Learning (RL) has shown promise in addressing "long-tail" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn framework that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy Optimization (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.

</details>


### [15] [Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation](https://arxiv.org/abs/2601.22965)
*Runhua Zhang,Junyi Hou,Changxu Cheng,Qiyi Chen,Tao Wang,Wuyue Zhao*

Main category: cs.RO

TL;DR: 提出了一种自模仿扩散策略（SIDP）框架，通过奖励引导的自我模仿机制来提高视觉导航中的路径规划质量，并减少了对大量采样和后过滤的依赖。实验表明，SIDP在仿真基准测试中显著优于先前的方法，并且在实际机器人平台上也证实了其有效性，特别是在Jetson Orin Nano上的推理速度比基线方法NavDP快2.5倍。


<details>
  <summary>Details</summary>
Motivation: 标准模仿学习经常从专家演示中继承次优性和冗余性，导致需要一个计算密集型的“生成-然后过滤”流程，这在推理时非常依赖辅助选择器。为了解决这些问题，提出了Self-Imitated Diffusion Policy (SIDP)框架。

Method: SIDP引入了一种奖励导向的自我模仿机制，鼓励策略高效地持续产生高质量轨迹。训练过程中采用了基于奖励的学习课程设计以克服数据利用效率低下的问题，以及目标无关探索来增强轨迹多样性从而提高规划鲁棒性。

Result: 综合模拟基准测试显示SIDP明显优于之前的方法；真实世界实验进一步验证了它在多种机器人平台上的有效性；特别地，在Jetson Orin Nano上，SIDP相比基准方法NavDP实现了2.5倍更快的推理速度，即110毫秒对比273毫秒。

Conclusion: SIDP提供了一种新的途径来改进视觉导航任务中的路径规划，通过减少对广泛采样和后期过滤的需求而提高了效率。该方法不仅在仿真环境中表现出色，而且也在实际应用中展示了其实用价值。

Abstract: Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive "generate-then-filter" pipeline that relies on auxiliary selectors during inference. To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a novel framework that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a comprehensive simulation benchmark show that SIDP significantly outperforms previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5$\times$ faster inference than the baseline NavDP, i.e., 110ms VS 273ms, enabling efficient real-time deployment.

</details>


### [16] [Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.22988)
*Di Zhang,Weicheng Duan,Dasen Gu,Hongye Lu,Hai Zhang,Hang Yu,Junqiao Zhao,Guang Chen*

Main category: cs.RO

TL;DR: 提出了一种名为MethodName的统一表示-策略学习框架，用于视角泛化的机器人操作。该方法通过单视图3D预训练范式和多步蒸馏来提高几何理解，并在RLBench任务上表现出色，尤其是在零样本视角泛化方面超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人操作需要视觉运动策略能够进行鲁棒的空间场景理解和跨不同摄像机视角的强大泛化能力。尽管3D感知视觉表示的最新进展显示出了希望，但它们仍然存在一些关键限制，包括推理期间依赖多视图观察、场景建模不完整以及缺乏有效的策略训练策略等问题。

Method: MethodName是一种统一的表示-策略学习框架，用于实现视角泛化下的机器人操作。它引入了一种单视图3D预训练范例，在多视图监督下利用点云重建和前馈高斯散射来学习整体几何表示。在策略学习阶段，MethodName执行多步蒸馏以保留预训练的几何理解并将之有效地转移到操作技能中。

Result: 在12个RLBench任务上的实验表明，与之前的最先进方法相比，所提出的方法平均成功率提高了12.7%。进一步对六个代表性任务的评估显示了强大的零样本视角泛化性能，其中在适度和大视角变化下成功率分别仅下降了22.0%和29.7%，而最先进方法则分别下降了41.6%和51.5%。

Conclusion: MethodName通过创新性的单视图3D预训练和策略学习方法有效解决了当前3D感知视觉表示存在的问题，显著提升了机器人操作的表现特别是其视角泛化能力。

Abstract: Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning framework for view-generalizable robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous state-of-the-art method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the state-of-the-art method suffers larger decreases of 41.6% and 51.5%.

</details>


### [17] [Robust and Generalized Humanoid Motion Tracking](https://arxiv.org/abs/2601.23080)
*Yubiao Ma,Han Yu,Jiayin Xie,Changtai Lv,Qiang Luo,Chi Zhang,Yunpeng Yin,Boyang Xing,Xuemei Ren,Dongdong Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于动力学条件的命令聚合框架，通过因果时间编码器和多头交叉注意力命令编码器来提升人形机器人全身控制器的学习效果。该方法在多样化参考输入和挑战性运动模式下进行了评估，展示了对未见动作的零样本迁移以及从模拟到实际物理人形机器人的稳健迁移。


<details>
  <summary>Details</summary>
Motivation: 学习一个通用的人形机器人全身控制器具有挑战性，因为实际参考动作在转移到机器人领域后可能会表现出噪声和不一致性，局部缺陷可能因闭环执行而被放大，导致在高度动态和接触丰富的行为中出现漂移或失败。

Method: 提出了一种基于动力学条件的命令聚合框架，该框架使用因果时间编码器来总结最近的本体感受，并利用多头交叉注意力命令编码器根据当前动力学选择性地聚集上下文窗口。此外，还结合了一个摔倒恢复课程，采用随机不稳定初始化和退火向上的辅助力以提高鲁棒性和抗干扰能力。

Result: 所得到的策略只需要大约3.5小时的动作数据支持单阶段端到端训练而无需蒸馏过程。该方法在多种参考输入和挑战性的运动模式下进行了评估，证明了对于未知动作的零样本迁移能力以及从模拟到真实物理人形机器人的强大迁移能力。

Conclusion: 本文介绍的方法能够有效改善人形机器人全身控制中的噪声与不一致问题，同时提高了系统面对扰动时的鲁棒性。通过引入动力学条件下的命令聚合机制，实现了更高效、更准确的动作执行。

Abstract: Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot.

</details>


### [18] [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](https://arxiv.org/abs/2601.23087)
*Wu Songwei,Jiang Zhiduo,Xie Guanghu,Liu Yang,Liu Hong*

Main category: cs.RO

TL;DR: 本文提出了一种名为LG-Flow Policy的模仿学习框架，该框架通过在连续潜在动作空间中执行流匹配来实现长时间范围内的机器人操作。实验结果表明，LG-Flow Policy接近单步推理，在轨迹平滑度和任务成功率方面显著优于基于原始动作空间的方法，并且比基于扩散的方法更有效率。


<details>
  <summary>Details</summary>
Motivation: 现有生成策略难以同时满足表达行为建模、实时推理与稳定执行的需求。尽管基于扩散的方法提供了强大的建模能力，但通常会带来较高的推理延迟；而流匹配虽然可以快速一步生成，但直接应用于原始动作空间时往往会导致不稳定执行。

Method: 提出了LG-Flow Policy，一种在连续潜在动作空间内执行流匹配的轨迹级模仿学习框架。通过对动作序列编码为时间正则化的潜在轨迹并学习明确的潜在空间流，此方法将全局运动结构与低级控制噪声解耦，从而实现了平滑可靠的长时间范围执行。此外，LG-Flow Policy还结合了几何感知点云条件设置和执行时多模式调节，其中视觉线索作为现实世界环境中的代表性模式进行了评估。

Result: 实验结果（包括模拟测试及物理机器人平台上的应用）显示，LG-Flow Policy几乎达到了单步推理的效果，相比于在原始动作空间工作的基于流的方法，它极大地提高了轨迹平滑性和任务完成率，并且相比基于扩散的方法效率更高。

Conclusion: LG-Flow Policy提供了一种有效的解决方案，用于解决长时域机器人操控中的关键挑战，包括提高模型表现力、加快推理速度以及确保执行稳定性。

Abstract: Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space.
  We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution.
  LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies.

</details>


### [19] [End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms](https://arxiv.org/abs/2601.23285)
*MH Farhadi,Ali Rabiee,Sima Ghafoori,Anna Cetera,Andrew Fisher,Reza Abiri*

Main category: cs.RO

TL;DR: 本文提出了一种新的框架BRACE，通过端到端的梯度流在意图推断和辅助仲裁之间进行微调，以实现贝叶斯意图推断和上下文自适应辅助。与现有方法相比，在处理目标模糊性和环境约束的情况下，BRACE能够提高成功率和路径效率。


<details>
  <summary>Details</summary>
Motivation: 共享自主系统需要一种原则性方法来推断用户意图并确定适当的辅助水平，这在人机交互中是一个核心挑战。先前的方法依赖于静态混合比率或将目标推理与辅助仲裁分开，导致在非结构化环境中表现不佳。

Method: 引入了BRACE（具有上下文编码的贝叶斯强化辅助）框架，该框架允许在意图推断和辅助仲裁之间传递端到端梯度流，从而微调贝叶斯意图推断和上下文自适应辅助。此管道根据环境背景及完整的目标概率分布条件协作控制策略。

Result: 研究结果表明：(1) 随着目标不确定性增加，最佳辅助水平应降低；随着环境约束严重性增加，最佳辅助水平应升高。(2) 将信念信息整合进策略学习相较于顺序方法具有二次预期遗憾优势。实验验证显示，与SOTA方法（IDA, DQN）相比，BRACE在不同任务中分别提高了6.3%的成功率、41%的路径效率以及36.3%的成功率和87%的路径效率。

Conclusion: BRACE框架在复杂且目标模糊的情境下最为有益，并且可泛化至需要目标导向辅助的各种机器人领域，推进了自适应共享自主技术的发展状态。

Abstract: Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated optimization is most beneficial in complex, goal-ambiguous scenarios, and is generalizable across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.

</details>
