{"id": "2512.21375", "categories": ["cs.RO", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.21375", "abs": "https://arxiv.org/abs/2512.21375", "authors": ["Yuanshuang Fu", "Qianyao Wang", "Qihao Wang", "Bonan Zhang", "Jiaxin Zhao", "Yiming Cao", "Zhijun Li"], "title": "Safe Path Planning and Observation Quality Enhancement Strategy for Unmanned Aerial Vehicles in Water Quality Monitoring Tasks", "comment": null, "summary": "Unmanned Aerial Vehicle (UAV) spectral remote sensing technology is widely used in water quality monitoring. However, in dynamic environments, varying illumination conditions, such as shadows and specular reflection (sun glint), can cause severe spectral distortion, thereby reducing data availability. To maximize the acquisition of high-quality data while ensuring flight safety, this paper proposes an active path planning method for dynamic light and shadow disturbance avoidance. First, a dynamic prediction model is constructed to transform the time-varying light and shadow disturbance areas into three-dimensional virtual obstacles. Second, an improved Interfered Fluid Dynamical System (IFDS) algorithm is introduced, which generates a smooth initial obstacle avoidance path by building a repulsive force field. Subsequently, a Model Predictive Control (MPC) framework is employed for rolling-horizon path optimization to handle flight dynamics constraints and achieve real-time trajectory tracking. Furthermore, a Dynamic Flight Altitude Adjustment (DFAA) mechanism is designed to actively reduce the flight altitude when the observable area is narrow, thereby enhancing spatial resolution. Simulation results show that, compared with traditional PID and single obstacle avoidance algorithms, the proposed method achieves an obstacle avoidance success rate of 98% in densely disturbed scenarios, significantly improves path smoothness, and increases the volume of effective observation data by approximately 27%. This research provides an effective engineering solution for precise UAV water quality monitoring in complex illumination environments."}
{"id": "2512.21398", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21398", "abs": "https://arxiv.org/abs/2512.21398", "authors": ["Rahul Moorthy Mahesh", "Oguzhan Goktug Poyrazoglu", "Yukang Cao", "Volkan Isler"], "title": "Fast Navigation Through Occluded Spaces via Language-Conditioned Map Prediction", "comment": null, "summary": "In cluttered environments, motion planners often face a trade-off between safety and speed due to uncertainty caused by occlusions and limited sensor range. In this work, we investigate whether co-pilot instructions can help robots plan more decisively while remaining safe. We introduce PaceForecaster, as an approach that incorporates such co-pilot instructions into local planners. PaceForecaster takes the robot's local sensor footprint (Level-1) and the provided co-pilot instructions as input and predicts (i) a forecasted map with all regions visible from Level-1 (Level-2) and (ii) an instruction-conditioned subgoal within Level-2. The subgoal provides the planner with explicit guidance to exploit the forecasted environment in a goal-directed manner. We integrate PaceForecaster with a Log-MPPI controller and demonstrate that using language-conditioned forecasts and goals improves navigation performance by 36% over a local-map-only baseline while in polygonal environments."}
{"id": "2512.21425", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.21425", "abs": "https://arxiv.org/abs/2512.21425", "authors": ["Hang Zhou", "Yuhui Zhai", "Shiyu Shen", "Yanfeng Ouyang", "Xiaowei Shi", "Xiaopeng"], "title": "Developing a Fundamental Diagram for Urban Air Mobility Based on Physical Experiments", "comment": null, "summary": "Urban Air Mobility (UAM) is an emerging application of unmanned aerial vehicles (UAVs) that promises to reduce travel time and alleviate congestion in urban transportation systems. As drone density increases, UAM operations are expected to experience congestion similar to that in ground traffic. However, the fundamental characteristics of UAM traffic flow, particularly under real-world operating conditions, remain poorly understood. This study proposes a general framework for constructing the fundamental diagram (FD) of UAM traffic by integrating theoretical analysis with physical experiments. To the best of our knowledge, this is the first study to derive a UAM FD using real-world physical test data. On the theoretical side, we design two drone control laws for collision avoidance and develop simulation-based traffic generation methods to produce diverse UAM traffic scenarios. Based on Edie's definition, traffic flow theory is then applied to construct the FD and characterize the macroscopic properties of UAM traffic. To account for real-world disturbances and modeling uncertainties, we further conduct physical experiments on a reduced-scale testbed using Bitcraze Crazyflie drones. Both simulation and physical test trajectory data are collected and organized into the UAMTra2Flow dataset, which is analyzed using the proposed framework. Preliminary results indicate that classical FD structures for ground transportation are also applicable to UAM systems. Notably, FD curves obtained from physical experiments exhibit deviations from simulation-based results, highlighting the importance of experimental validation. Finally, results from the reduced-scale testbed are scaled to realistic operating conditions to provide practical insights for future UAM traffic systems. The dataset and code for this paper are publicly available at https://github.com/CATS-Lab/UAM-FD."}
{"id": "2512.21430", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21430", "abs": "https://arxiv.org/abs/2512.21430", "authors": ["Yusuf Ali", "Gryphon Patlin", "Karthik Kothuri", "Muhammad Zubair Irshad", "Wuwei Liang", "Zsolt Kira"], "title": "EVE: A Generator-Verifier System for Generative Policies", "comment": null, "summary": "Visuomotor policies based on generative architectures such as diffusion and flow-based matching have shown strong performance but degrade under distribution shifts, demonstrating limited recovery capabilities without costly finetuning. In the language modeling domain, test-time compute scaling has revolutionized reasoning capabilities of modern LLMs by leveraging additional inference-time compute for candidate solution refinement. These methods typically leverage foundation models as verification modules in a zero-shot manner to synthesize improved candidate solutions. In this work, we hypothesize that generative policies can similarly benefit from additional inference-time compute that employs zero-shot VLM-based verifiers. A systematic analysis of improving policy performance through the generation-verification framework remains relatively underexplored in the current literature. To this end, we introduce EVE - a modular, generator-verifier interaction framework - that boosts the performance of pretrained generative policies at test time, with no additional training. EVE wraps a frozen base policy with multiple zero-shot, VLM-based verifier agents. Each verifier proposes action refinements to the base policy candidate actions, while an action incorporator fuses the aggregated verifier output into the base policy action prediction to produce the final executed action. We study design choices for generator-verifier information interfacing across a system of verifiers with distinct capabilities. Across a diverse suite of manipulation tasks, EVE consistently improves task success rates without any additional policy training. Through extensive ablations, we isolate the contribution of verifier capabilities and action incorporator strategies, offering practical guidelines to build scalable, modular generator-verifier systems for embodied control."}
{"id": "2512.21438", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21438", "abs": "https://arxiv.org/abs/2512.21438", "authors": ["Marvin Chancán", "Avijit Banerjee", "George Nikolakopoulos"], "title": "Planetary Terrain Datasets and Benchmarks for Rover Path Planning", "comment": null, "summary": "Planetary rover exploration is attracting renewed interest with several upcoming space missions to the Moon and Mars. However, a substantial amount of data from prior missions remain underutilized for path planning and autonomous navigation research. As a result, there is a lack of space mission-based planetary datasets, standardized benchmarks, and evaluation protocols. In this paper, we take a step towards coordinating these three research directions in the context of planetary rover path planning. We propose the first two large planar benchmark datasets, MarsPlanBench and MoonPlanBench, derived from high-resolution digital terrain images of Mars and the Moon. In addition, we set up classical and learned path planning algorithms, in a unified framework, and evaluate them on our proposed datasets and on a popular planning benchmark. Through comprehensive experiments, we report new insights on the performance of representative path planning algorithms on planetary terrains, for the first time to the best of our knowledge. Our results show that classical algorithms can achieve up to 100% global path planning success rates on average across challenging terrains such as Moon's north and south poles. This suggests, for instance, why these algorithms are used in practice by NASA. Conversely, learning-based models, although showing promising results in less complex environments, still struggle to generalize to planetary domains. To serve as a starting point for fundamental path planning research, our code and datasets will be released at: https://github.com/mchancan/PlanetaryPathBench."}
{"id": "2512.21497", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.21497", "abs": "https://arxiv.org/abs/2512.21497", "authors": ["Siddhartha Upadhyay", "Ratnangshu Das", "Pushpak Jagtap"], "title": "Spatiotemporal Tubes for Probabilistic Temporal Reach-Avoid-Stay Task in Uncertain Dynamic Environment", "comment": null, "summary": "In this work, we extend the Spatiotemporal Tube (STT) framework to address Probabilistic Temporal Reach-Avoid-Stay (PrT-RAS) tasks in dynamic environments with uncertain obstacles. We develop a real-time tube synthesis procedure that explicitly accounts for time-varying uncertain obstacles and provides formal probabilistic safety guarantees. The STT is formulated as a time-varying ball in the state space whose center and radius evolve online based on uncertain sensory information. We derive a closed-form, approximation-free control law that confines the system trajectory within the tube, ensuring both probabilistic safety and task satisfaction. Our method offers a formal guarantee for probabilistic avoidance and finite-time task completion. The resulting controller is model-free, approximation-free, and optimization-free, enabling efficient real-time execution while guaranteeing convergence to the target. The effectiveness and scalability of the framework are demonstrated through simulation studies and hardware experiments on mobile robots, a UAV, and a 7-DOF manipulator navigating in cluttered and uncertain environments."}
{"id": "2512.21534", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21534", "abs": "https://arxiv.org/abs/2512.21534", "authors": ["Congrui Bai", "Zhenting Du", "Weibang Bai"], "title": "A Novel Robotic Variable Stiffness Mechanism Based on Helically Wound Structured Electrostatic Layer Jamming", "comment": null, "summary": "This paper introduces a novel variable stiffness mechanism termed Helically Wound Structured Electrostatic Layer Jamming (HWS-ELJ) and systematically investigates its potential applications in variable stiffness robotic finger design. The proposed method utilizes electrostatic attraction to enhance interlayer friction, thereby suppressing relative sliding and enabling tunable stiffness. Compared with conventional planar ELJ, the helical configuration of HWS-ELJ provides exponentially increasing stiffness adjustment with winding angle, achieving significantly greater stiffness enhancement for the same electrode contact area while reducing the required footprint under equivalent stiffness conditions. Considering the practical advantage of voltage-based control, a series of experimental tests under different initial force conditions were conducted to evaluate the stiffness modulation characteristics of HWS-ELJ. The results demonstrated its rational design and efficacy, with outcomes following the deduced theoretical trends. Furthermore, a robotic finger prototype integrating HWS-ELJ was developed, demonstrating voltage-driven stiffness modulation and confirming the feasibility of the proposed robotic variable stiffness mechanism."}
{"id": "2512.21573", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21573", "abs": "https://arxiv.org/abs/2512.21573", "authors": ["Zhangzheng Tum", "Kailun Su", "Shaolong Zhu", "Yukun Zheng"], "title": "World-Coordinate Human Motion Retargeting via SAM 3D Body", "comment": null, "summary": "Recovering world-coordinate human motion from monocular videos with humanoid robot retargeting is significant for embodied intelligence and robotics. To avoid complex SLAM pipelines or heavy temporal models, we propose a lightweight, engineering-oriented framework that leverages SAM 3D Body (3DB) as a frozen perception backbone and uses the Momentum HumanRig (MHR) representation as a robot-friendly intermediate. Our method (i) locks the identity and skeleton-scale parameters of per tracked subject to enforce temporally consistent bone lengths, (ii) smooths per-frame predictions via efficient sliding-window optimization in the low-dimensional MHR latent space, and (iii) recovers physically plausible global root trajectories with a differentiable soft foot-ground contact model and contact-aware global optimization. Finally, we retarget the reconstructed motion to the Unitree G1 humanoid using a kinematics-aware two-stage inverse kinematics pipeline. Results on real monocular videos show that our method has stable world trajectories and reliable robot retargeting, indicating that structured human representations with lightweight physical constraints can yield robot-ready motion from monocular input."}
{"id": "2512.21627", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21627", "abs": "https://arxiv.org/abs/2512.21627", "authors": ["Botao Ren", "Junjun Hu", "Xinda Xue", "Minghua Luo", "Jintao Chen", "Haochen Bai", "Liangliang You", "Mu Xu"], "title": "AstraNav-Memory: Contexts Compression for Long Memory", "comment": null, "summary": "Lifelong embodied navigation requires agents to accumulate, retain, and exploit spatial-semantic experience across tasks, enabling efficient exploration in novel environments and rapid goal reaching in familiar ones. While object-centric memory is interpretable, it depends on detection and reconstruction pipelines that limit robustness and scalability. We propose an image-centric memory framework that achieves long-term implicit memory via an efficient visual context compression module end-to-end coupled with a Qwen2.5-VL-based navigation policy. Built atop a ViT backbone with frozen DINOv3 features and lightweight PixelUnshuffle+Conv blocks, our visual tokenizer supports configurable compression rates; for example, under a representative 16$\\times$ compression setting, each image is encoded with about 30 tokens, expanding the effective context capacity from tens to hundreds of images. Experimental results on GOAT-Bench and HM3D-OVON show that our method achieves state-of-the-art navigation performance, improving exploration in unfamiliar environments and shortening paths in familiar ones. Ablation studies further reveal that moderate compression provides the best balance between efficiency and accuracy. These findings position compressed image-centric memory as a practical and scalable interface for lifelong embodied agents, enabling them to reason over long visual histories and navigate with human-like efficiency."}
{"id": "2512.21654", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21654", "abs": "https://arxiv.org/abs/2512.21654", "authors": ["Zikun Guo", "Adeyinka P. Adedigba", "Rammohan Mallipeddi", "Heoncheol Lee"], "title": "Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning", "comment": "20pages, 6Figues", "summary": "Multi-robot path planning is a fundamental yet challenging problem due to its combinatorial complexity and the need to balance global efficiency with fair task allocation among robots. Traditional swarm intelligence methods, although effective on small instances, often converge prematurely and struggle to scale to complex environments. In this work, we present a structure-induced exploration framework that integrates structural priors into the search process of the ant colony optimization (ACO). The approach leverages the spatial distribution of the task to induce a structural prior at initialization, thereby constraining the search space. The pheromone update rule is then designed to emphasize structurally meaningful connections and incorporates a load-aware objective to reconcile the total travel distance with individual robot workload. An explicit overlap suppression strategy further ensures that tasks remain distinct and balanced across the team. The proposed framework was validated on diverse benchmark scenarios covering a wide range of instance sizes and robot team configurations. The results demonstrate consistent improvements in route compactness, stability, and workload distribution compared to representative metaheuristic baselines. Beyond performance gains, the method also provides a scalable and interpretable framework that can be readily applied to logistics, surveillance, and search-and-rescue applications where reliable large-scale coordination is essential."}
{"id": "2512.21722", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21722", "abs": "https://arxiv.org/abs/2512.21722", "authors": ["Zishuo Wang", "Xinyu Zhang", "Zhuonan Liu", "Tomohito Kawabata", "Daeun Song", "Xuesu Xiao", "Ling Xiao"], "title": "MAction-SocialNav: Multi-Action Socially Compliant Navigation via Reasoning-enhanced Prompt Tuning", "comment": null, "summary": "Socially compliant navigation requires robots to move safely and appropriately in human-centered environments by respecting social norms. However, social norms are often ambiguous, and in a single scenario, multiple actions may be equally acceptable. Most existing methods simplify this problem by assuming a single correct action, which limits their ability to handle real-world social uncertainty. In this work, we propose MAction-SocialNav, an efficient vision language model for socially compliant navigation that explicitly addresses action ambiguity, enabling generating multiple plausible actions within one scenario. To enhance the model's reasoning capability, we introduce a novel meta-cognitive prompt (MCP) method. Furthermore, to evaluate the proposed method, we curate a multi-action socially compliant navigation dataset that accounts for diverse conditions, including crowd density, indoor and outdoor environments, and dual human annotations. The dataset contains 789 samples, each with three-turn conversation, split into 710 training samples and 79 test samples through random selection. We also design five evaluation metrics to assess high-level decision precision, safety, and diversity. Extensive experiments demonstrate that the proposed MAction-SocialNav achieves strong social reasoning performance while maintaining high efficiency, highlighting its potential for real-world human robot navigation. Compared with zero-shot GPT-4o and Claude, our model achieves substantially higher decision quality (APG: 0.595 vs. 0.000/0.025) and safety alignment (ER: 0.264 vs. 0.642/0.668), while maintaining real-time efficiency (1.524 FPS, over 3x faster)."}
{"id": "2512.21723", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21723", "abs": "https://arxiv.org/abs/2512.21723", "authors": ["Alexandr V. Korchemnyi", "Anatoly O. Onishchenko", "Eva A. Bakaeva", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "HELP: Hierarchical Embodied Language Planner for Household Tasks", "comment": null, "summary": "Embodied agents tasked with complex scenarios, whether in real or simulated environments, rely heavily on robust planning capabilities. When instructions are formulated in natural language, large language models (LLMs) equipped with extensive linguistic knowledge can play this role. However, to effectively exploit the ability of such models to handle linguistic ambiguity, to retrieve information from the environment, and to be based on the available skills of an agent, an appropriate architecture must be designed. We propose a Hierarchical Embodied Language Planner, called HELP, consisting of a set of LLM-based agents, each dedicated to solving a different subtask. We evaluate the proposed approach on a household task and perform real-world experiments with an embodied agent. We also focus on the use of open source LLMs with a relatively small number of parameters, to enable autonomous deployment."}
{"id": "2512.21853", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21853", "abs": "https://arxiv.org/abs/2512.21853", "authors": ["Kentaro Uno", "Elian Neppel", "Gustavo H. Diaz", "Ashutosh Mishra", "Shamistan Karimov", "A. Sejal Jain", "Ayesha Habib", "Pascal Pama", "Hazal Gozbasi", "Shreya Santra", "Kazuya Yoshida"], "title": "MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction", "comment": "This is the authors' version of a paper accepted for publication in IEEE Transactions on Field Robotics, (c) IEEE. The final published version is available at https://doi.org/10.1109/TFR.2025.3624346", "summary": "The allure of lunar surface exploration and development has recently captured widespread global attention. Robots have proved to be indispensable for exploring uncharted terrains, uncovering and leveraging local resources, and facilitating the construction of future human habitats. In this article, we introduce the modular and on-demand reconfigurable robot (MoonBot), a modular and reconfigurable robotic system engineered to maximize functionality while operating within the stringent mass constraints of lunar payloads and adapting to varying environmental conditions and task requirements. This article details the design and development of MoonBot and presents a preliminary field demonstration that validates the proof of concept through the execution of milestone tasks simulating the establishment of lunar infrastructure. These tasks include essential civil engineering operations, infrastructural component transportation and deployment, and assistive operations with inflatable modules. Furthermore, we systematically summarize the lessons learned during testing, focusing on the connector design and providing valuable insights for the advancement of modular robotic systems in future lunar missions."}
{"id": "2512.21882", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.21882", "abs": "https://arxiv.org/abs/2512.21882", "authors": ["Kenta Iizuka", "Akiyoshi Uchida", "Kentaro Uno", "Kazuya Yoshida"], "title": "Optimal Trajectory Planning for Orbital Robot Rendezvous and Docking", "comment": "Author's version of a manuscript accepted at the International Conference on Space Robotics 2025 (iSpaRo 2025). (c) IEEE", "summary": "Approaching a tumbling target safely is a critical challenge in space debris removal missions utilizing robotic manipulators onboard servicing satellites. In this work, we propose a trajectory planning method based on nonlinear optimization for a close-range rendezvous to bring a free-floating, rotating debris object in a two-dimensional plane into the manipulator's workspace, as a preliminary step for its capture. The proposed method introduces a dynamic keep-out sphere that adapts depending on the approach conditions, allowing for closer and safer access to the target. Furthermore, a control strategy is developed to reproduce the optimized trajectory using discrete ON/OFF thrusters, considering practical implementation constraints."}
{"id": "2512.21886", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21886", "abs": "https://arxiv.org/abs/2512.21886", "authors": ["Akiyoshi Uchida", "Antonine Richard", "Kentaro Uno", "Miguel Olivares-Mendez", "Kazuya Yoshida"], "title": "Online Inertia Parameter Estimation for Unknown Objects Grasped by a Manipulator Towards Space Applications", "comment": "Author's version of a manuscript accepted at the International Conference on Space Robotics 2025 (iSpaRo 2025). (c) IEEE", "summary": "Knowing the inertia parameters of a grasped object is crucial for dynamics-aware manipulation, especially in space robotics with free-floating bases. This work addresses the problem of estimating the inertia parameters of an unknown target object during manipulation. We apply and extend an existing online identification method by incorporating momentum conservation, enabling its use for the floating-base robots. The proposed method is validated through numerical simulations, and the estimated parameters are compared with ground-truth values. Results demonstrate accurate identification in the scenarios, highlighting the method's applicability to on-orbit servicing and other space missions."}
{"id": "2512.21887", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21887", "abs": "https://arxiv.org/abs/2512.21887", "authors": ["Weichen Zhang", "Peizhi Tang", "Xin Zeng", "Fanhang Man", "Shiquan Yu", "Zichao Dai", "Baining Zhao", "Hongjin Chen", "Yu Shang", "Wei Wu", "Chen Gao", "Xinlei Chen", "Xin Wang", "Yong Li", "Wenwu Zhu"], "title": "Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space", "comment": null, "summary": "Unmanned aerial vehicles (UAVs) have emerged as powerful embodied agents. One of the core abilities is autonomous navigation in large-scale three-dimensional environments. Existing navigation policies, however, are typically optimized for low-level objectives such as obstacle avoidance and trajectory smoothness, lacking the ability to incorporate high-level semantics into planning. To bridge this gap, we propose ANWM, an aerial navigation world model that predicts future visual observations conditioned on past frames and actions, thereby enabling agents to rank candidate trajectories by their semantic plausibility and navigational utility. ANWM is trained on 4-DoF UAV trajectories and introduces a physics-inspired module: Future Frame Projection (FFP), which projects past frames into future viewpoints to provide coarse geometric priors. This module mitigates representational uncertainty in long-distance visual generation and captures the mapping between 3D trajectories and egocentric observations. Empirical results demonstrate that ANWM significantly outperforms existing world models in long-distance visual forecasting and improves UAV navigation success rates in large-scale environments."}
{"id": "2512.21898", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21898", "abs": "https://arxiv.org/abs/2512.21898", "authors": ["Chaoqi Liu", "Haonan Chen", "Sigmund H. Høeg", "Shaoxiong Yao", "Yunzhu Li", "Kris Hauser", "Yilun Du"], "title": "Flexible Multitask Learning with Factorized Diffusion Policy", "comment": null, "summary": "Multitask learning poses significant challenges due to the highly multimodal and diverse nature of robot action distributions. However, effectively fitting policies to these complex task distributions is often difficult, and existing monolithic models often underfit the action distribution and lack the flexibility required for efficient adaptation. We introduce a novel modular diffusion policy framework that factorizes complex action distributions into a composition of specialized diffusion models, each capturing a distinct sub-mode of the behavior space for a more effective overall policy. In addition, this modular structure enables flexible policy adaptation to new tasks by adding or fine-tuning components, which inherently mitigates catastrophic forgetting. Empirically, across both simulation and real-world robotic manipulation settings, we illustrate how our method consistently outperforms strong modular and monolithic baselines."}
{"id": "2512.21970", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21970", "abs": "https://arxiv.org/abs/2512.21970", "authors": ["Shengliang Deng", "Mi Yan", "Yixin Zheng", "Jiayi Su", "Wenhao Zhang", "Xiaoguang Zhao", "Heming Cui", "Zhizheng Zhang", "He Wang"], "title": "StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision", "comment": null, "summary": "Stereo cameras closely mimic human binocular vision, providing rich spatial cues critical for precise robotic manipulation. Despite their advantage, the adoption of stereo vision in vision-language-action models (VLAs) remains underexplored. In this work, we present StereoVLA, a VLA model that leverages rich geometric cues from stereo vision. We propose a novel Geometric-Semantic Feature Extraction module that utilizes vision foundation models to extract and fuse two key features: 1) geometric features from subtle stereo-view differences for spatial perception; 2) semantic-rich features from the monocular view for instruction following. Additionally, we propose an auxiliary Interaction-Region Depth Estimation task to further enhance spatial perception and accelerate model convergence. Extensive experiments show that our approach outperforms baselines by a large margin in diverse tasks under the stereo setting and demonstrates strong robustness to camera pose variations."}
{"id": "2512.21983", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21983", "abs": "https://arxiv.org/abs/2512.21983", "authors": ["Saksham Gupta", "Sarthak Mishra", "Arshad Ayub", "Kamran Farooque", "Spandan Roy", "Babita Gupta"], "title": "Bab_Sak Robotic Intubation System (BRIS): A Learning-Enabled Control Framework for Safe Fiberoptic Endotracheal Intubation", "comment": null, "summary": "Endotracheal intubation is a critical yet technically demanding procedure, with failure or improper tube placement leading to severe complications. Existing robotic and teleoperated intubation systems primarily focus on airway navigation and do not provide integrated control of endotracheal tube advancement or objective verification of tube depth relative to the carina. This paper presents the Robotic Intubation System (BRIS), a compact, human-in-the-loop platform designed to assist fiberoptic-guided intubation while enabling real-time, objective depth awareness. BRIS integrates a four-way steerable fiberoptic bronchoscope, an independent endotracheal tube advancement mechanism, and a camera-augmented mouthpiece compatible with standard clinical workflows. A learning-enabled closed-loop control framework leverages real-time shape sensing to map joystick inputs to distal bronchoscope tip motion in Cartesian space, providing stable and intuitive teleoperation under tendon nonlinearities and airway contact. Monocular endoscopic depth estimation is used to classify airway regions and provide interpretable, anatomy-aware guidance for safe tube positioning relative to the carina. The system is validated on high-fidelity airway mannequins under standard and difficult airway configurations, demonstrating reliable navigation and controlled tube placement. These results highlight BRIS as a step toward safer, more consistent, and clinically compatible robotic airway management."}
