<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 14]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning](https://arxiv.org/abs/2510.20884)
*Pranamya Kulkarni,Puranjay Datta,Burak Varıcı,Emre Acartürk,Karthikeyan Shanmugam,Ali Tajer*

Main category: cs.RO

TL;DR: 该论文提出了一种基于评分的因果表示学习(ROPES)方法，用于机器人姿态估计。通过无监督方式，成功地从原始图像中解耦并恢复了可控的潜在变量，如关节角度等，而无需使用任何标记数据。此外，还与一个半监督框架进行了比较，并认为机器人姿态估计可以作为因果表示学习的一个接近实用的测试平台。


<details>
  <summary>Details</summary>
Motivation: 尽管因果表示学习(CRL)在理论上取得了进展，但在实际应用中仍存在差距。本文旨在通过将CRL应用于机器人领域来缩小这一差距，特别是解决机器人姿态估计问题——即从原始图像中恢复位置和方向信息。

Method: 提出了名为ROPES（Robotic Pose Estimation via Score-Based CRL）的方法，它是一个无监督框架，能够识别那些被驱动的生成因素。这些因素包括内在和外在的潜在因素（例如，关节角度、肢体几何形状、照明、背景及相机配置）。目标是解耦并恢复可以通过执行器直接控制的潜在变量。

Result: 半合成操作器实验中的实证评估表明，ROPES能够以高保真度相对于真实值解耦潜在生成因素。重要的是，这仅通过利用分布变化实现，而没有使用任何标签数据。

Conclusion: 研究结论认为，机器人姿态估计可作为因果表示学习的一个几乎实际的应用场景，同时展示了ROPES方法的有效性。

Abstract: Causal representation learning (CRL) has emerged as a powerful unsupervised
framework that (i) disentangles the latent generative factors underlying
high-dimensional data, and (ii) learns the cause-and-effect interactions among
the disentangled variables. Despite extensive recent advances in
identifiability and some practical progress, a substantial gap remains between
theory and real-world practice. This paper takes a step toward closing that gap
by bringing CRL to robotics, a domain that has motivated CRL. Specifically,
this paper addresses the well-defined robot pose estimation -- the recovery of
position and orientation from raw images -- by introducing Robotic Pose
Estimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES
embodies the essence of interventional CRL by identifying those generative
factors that are actuated: images are generated by intrinsic and extrinsic
latent factors (e.g., joint angles, arm/limb geometry, lighting, background,
and camera configuration) and the objective is to disentangle and recover the
controllable latent variables, i.e., those that can be directly manipulated
(intervened upon) through actuation. Interventional CRL theory shows that
variables that undergo variations via interventions can be identified. In
robotics, such interventions arise naturally by commanding actuators of various
joints and recording images under varied controls. Empirical evaluations in
semi-synthetic manipulator experiments demonstrate that ROPES successfully
disentangles latent generative factors with high fidelity with respect to the
ground truth. Crucially, this is achieved by leveraging only distributional
changes, without using any labeled data. The paper also includes a comparison
with a baseline based on a recently proposed semi-supervised framework. This
paper concludes by positioning robot pose estimation as a near-practical
testbed for CRL.

</details>


### [2] [Aircraft Collision Avoidance Systems: Technological Challenges and Solutions on the Path to Regulatory Acceptance](https://arxiv.org/abs/2510.20916)
*Sydney M. Katz,Robert J. Moss,Dylan M. Asmar,Wesley A. Olson,James K. Kuchar,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 本文概述了航空器防撞系统面临的技术挑战及其解决方案，特别强调了那些经过严格验证过程并被监管机构接受的方案。


<details>
  <summary>Details</summary>
Motivation: 航空器防撞系统对于现代航空至关重要，但其开发面临着与监视、决策制定及验证相关的多种技术难题。这些挑战不仅限于航空领域，也为其他安全关键系统提供了宝贵见解。

Method: 通过回顾过去数十年间在航空器防撞系统方面开展的研究与发展工作，总结出一系列已被提出并测试过的解决方案。

Result: 文章详细介绍了几种经过充分验证且获得监管机构认可的有效防撞系统解决方案。

Conclusion: 航空器防撞系统的发展为解决该领域及其他类似安全关键系统中遇到的问题提供了重要参考案例。

Abstract: Aircraft collision avoidance systems is critical to modern aviation. These
systems are designed to predict potential collisions between aircraft and
recommend appropriate avoidance actions. Creating effective collision avoidance
systems requires solutions to a variety of technical challenges related to
surveillance, decision making, and validation. These challenges have sparked
significant research and development efforts over the past several decades that
have resulted in a variety of proposed solutions. This article provides an
overview of these challenges and solutions with an emphasis on those that have
been put through a rigorous validation process and accepted by regulatory
bodies. The challenges posed by the collision avoidance problem are often
present in other domains, and aircraft collision avoidance systems can serve as
case studies that provide valuable insights for a wide range of safety-critical
systems.

</details>


### [3] [SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing](https://arxiv.org/abs/2510.20965)
*Jesse Haworth,Juo-Tung Chen,Nigel Nelson,Ji Woong Kim,Masoud Moghani,Chelsea Finn,Axel Krieger*

Main category: cs.RO

TL;DR: 介绍了SutureBot，一个在da Vinci研究套件上实现的自主缝合基准系统，包括针拾取、组织插入和打结，并发布了一个高保真数据集以提高目标准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管有许多努力致力于端到端自动化，但在物理硬件上尚未展示出完全自动化的缝合流程。为了促进这一领域的发展，研究者们希望建立一个可重复使用的基准任务，支持精确度高的长期灵巧操作策略的研发。

Method: 提出了一个目标条件框架，该框架明确优化了插入点精度；评估了最先进的视觉-语言-动作模型，每种模型都增加了高级任务预测策略。此外，还发布了包含1890个缝合演示的高保真度数据集。

Result: 提出的框架相较于仅基于任务的基线，在目标准确性方面提高了59%-74%。

Conclusion: SutureBot为精密导向的长期灵巧操控政策提供了可复制的评估和发展基础，是朝向手术中机器人自主性迈进的关键里程碑。

Abstract: Robotic suturing is a prototypical long-horizon dexterous manipulation task,
requiring coordinated needle grasping, precise tissue penetration, and secure
knot tying. Despite numerous efforts toward end-to-end autonomy, a fully
autonomous suturing pipeline has yet to be demonstrated on physical hardware.
We introduce SutureBot: an autonomous suturing benchmark on the da Vinci
Research Kit (dVRK), spanning needle pickup, tissue insertion, and knot tying.
To ensure repeatability, we release a high-fidelity dataset comprising 1,890
suturing demonstrations. Furthermore, we propose a goal-conditioned framework
that explicitly optimizes insertion-point precision, improving targeting
accuracy by 59\%-74\% over a task-only baseline. To establish this task as a
benchmark for dexterous imitation learning, we evaluate state-of-the-art
vision-language-action (VLA) models, including $\pi_0$, GR00T N1, OpenVLA-OFT,
and multitask ACT, each augmented with a high-level task-prediction policy.
Autonomous suturing is a key milestone toward achieving robotic autonomy in
surgery. These contributions support reproducible evaluation and development of
precision-focused, long-horizon dexterous manipulation policies necessary for
end-to-end suturing. Dataset is available at:
https://huggingface.co/datasets/jchen396/suturebot

</details>


### [4] [Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization](https://arxiv.org/abs/2510.20974)
*Michael Bezick,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 该论文提出了一种名为PCA点云(PPC)的规范化框架，用于将点云映射到一个独特的标准姿态下，从而减少视角变化导致的不一致性，提高了机器人任务中对未见过的相机姿态的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 强化学习从原始视觉输入已经取得了显著的成功，但是它对于分布外的变化（如光照、颜色和视角的变化）仍然很脆弱。虽然点云强化学习提供了一个有希望的替代方案，但其对相机姿态不匹配的敏感性继续削弱了在现实设置中的可靠性。

Method: 提出了PCA点云(PPC)，这是一种专门为下游机器人控制设计的规范化框架。通过PPC，可以在任意刚体变换下将点云映射至唯一确定的标准姿态，使观察结果对齐到一致的坐标系中，从而大幅减少了因视角不同而引起的不一致性问题。

Result: 实验表明，PPC能够提高对具有挑战性的机器人任务中未见相机姿态的鲁棒性，为领域随机化提供了一种原则性的替代方法。

Conclusion: PCA点云(PPC)框架为解决由于相机姿态差异导致的点云强化学习稳定性问题提供了有效手段，并且在多种机器人应用场景下展示出了良好的适应性和鲁棒性。

Abstract: Reinforcement Learning (RL) from raw visual input has achieved impressive
successes in recent years, yet it remains fragile to out-of-distribution
variations such as changes in lighting, color, and viewpoint. Point Cloud
Reinforcement Learning (PC-RL) offers a promising alternative by mitigating
appearance-based brittleness, but its sensitivity to camera pose mismatches
continues to undermine reliability in realistic settings. To address this
challenge, we propose PCA Point Cloud (PPC), a canonicalization framework
specifically tailored for downstream robotic control. PPC maps point clouds
under arbitrary rigid-body transformations to a unique canonical pose, aligning
observations to a consistent frame, thereby substantially decreasing
viewpoint-induced inconsistencies. In our experiments, we show that PPC
improves robustness to unseen camera poses across challenging robotic tasks,
providing a principled alternative to domain randomization.

</details>


### [5] [HRT1: One-Shot Human-to-Robot Trajectory Transfer for Mobile Manipulation](https://arxiv.org/abs/2510.21026)
*Sai Haneesh Allu,Jishnu Jaykumar P,Ninad Khargonkar,Tyler Summers,Jian Yao,Yu Xiang*

Main category: cs.RO

TL;DR: 本文提出了一种新的系统，通过学习人类演示视频使机器人能够操作物体。该系统包括四个模块：数据收集、视频理解、轨迹转移以及轨迹优化。实验证明了该系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人能够通过观看人类的演示视频来学会如何操作物体，并能够在不同的环境中重复执行相同的任务。

Method: 开发了一个由四个模块组成的系统：1. 采用AR头显从机器人视角收集人类演示视频；2. 从视频中检测物体并提取三维人手轨迹；3. 将人手轨迹转换为机器人末端执行器的参考轨迹；4. 利用轨迹优化算法在机器人配置空间中生成可跟随转换后轨迹的新路径。

Result: 实验结果表明，本系统能够让机器人仅需观看一次人类演示视频就能在不同环境下完成相同的操作任务，即使物体摆放位置与演示中有所不同也能成功完成。

Conclusion: 所提出的基于人类到机器人轨迹转移的系统对于增强机器人的自主操作能力具有显著效果，特别是在需要适应新环境的情况下。

Abstract: We introduce a novel system for human-to-robot trajectory transfer that
enables robots to manipulate objects by learning from human demonstration
videos. The system consists of four modules. The first module is a data
collection module that is designed to collect human demonstration videos from
the point of view of a robot using an AR headset. The second module is a video
understanding module that detects objects and extracts 3D human-hand
trajectories from demonstration videos. The third module transfers a human-hand
trajectory into a reference trajectory of a robot end-effector in 3D space. The
last module utilizes a trajectory optimization algorithm to solve a trajectory
in the robot configuration space that can follow the end-effector trajectory
transferred from the human demonstration. Consequently, these modules enable a
robot to watch a human demonstration video once and then repeat the same mobile
manipulation task in different environments, even when objects are placed
differently from the demonstrations. Experiments of different manipulation
tasks are conducted on a mobile manipulator to verify the effectiveness of our
system

</details>


### [6] [Sequentially Teaching Sequential Tasks $(ST)^2$: Teaching Robots Long-horizon Manipulation Skills](https://arxiv.org/abs/2510.21046)
*Zlatan Ajanović,Ravi Prakash,Leandro de Souza Rosa,Jens Kober*

Main category: cs.RO

TL;DR: 本文研究了用户对两种教学框架的反应：整体方法和逐步方法，并提出了一种新的序列化方法(ST)²来学习长周期操作任务，允许用户通过定义关键点控制教学流程。实验结果表明两种方法在轨迹质量和成功率上相似，但用户根据个人偏好有所选择。


<details>
  <summary>Details</summary>
Motivation: 解决长时间多技能任务教学中遇到的问题，如偏差累积、分布偏移增加及人类教师疲劳等，从而提高教学效率与成功率。

Method: 提出一种名为(ST)²的序列化方法用于学习长周期操作任务，该方法让用户能够通过定义关键点来控制教学流程。此外，还进行了一项涉及16名参与者的真实零售环境下的用户研究，以评估用户偏好和方法的有效性。

Result: 客观和主观的结果显示，两种方法在轨迹质量和成功率方面表现相近。部分参与者更喜欢逐步方法提供的迭代控制，而另一些人则倾向于整体方法的简单性。

Conclusion: 虽然两种教学方法在性能上相当，但(ST)²提供了一种结构化且可增量式演示的方法，为用户提供更多灵活性。不同用户基于个人喜好对两种方法有不同的偏好。

Abstract: Learning from demonstration is effective for teaching robots complex skills
with high sample efficiency. However, teaching long-horizon tasks with multiple
skills is difficult, as deviations accumulate, distributional shift increases,
and human teachers become fatigued, raising the chance of failure. In this
work, we study user responses to two teaching frameworks: (i) a traditional
monolithic approach, where users demonstrate the entire trajectory of a
long-horizon task; and (ii) a sequential approach, where the task is segmented
by the user and demonstrations are provided step by step. To support this
study, we introduce $(ST)^2$, a sequential method for learning long-horizon
manipulation tasks that allows users to control the teaching flow by defining
key points, enabling incremental and structured demonstrations. We conducted a
user study on a restocking task with 16 participants in a realistic retail
environment to evaluate both user preference and method effectiveness. Our
objective and subjective results show that both methods achieve similar
trajectory quality and success rates. Some participants preferred the
sequential approach for its iterative control, while others favored the
monolithic approach for its simplicity.

</details>


### [7] [Revisiting Replanning from Scratch: Real-Time Incremental Planning with Fast Almost-Surely Asymptotically Optimal Planners](https://arxiv.org/abs/2510.21074)
*Mitchell E. C. Sabbadini,Andrew H. Liu,Joseph Ruan,Tyler S. Wilson,Zachary Kingston,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 本文提出了一种新的方法，通过使用快速几乎肯定渐近最优(ASAO)规划算法来解决增量规划问题，而不是更新现有的计划。这种方法在存在变化障碍的情况下也能找到一致的全局规划，而不需要显式的计划重用。


<details>
  <summary>Details</summary>
Motivation: 传统的反应式重规划方法需要更新密集的规划图，这在计算上可能是禁止的，并且检测某些应用中的变化也需要大量的努力。因此，研究者重新审视了反应式重规划需要更新现有计划这一长期持有的假设。

Method: 采用快速几乎肯定渐近最优(ASAO)规划算法，如Effort Informed Trees (EIT*) 和 Asymptotically Optimal RRT-Connect (AORRTC)，将增量规划问题作为一系列独立的问题来更有效地解决。这些算法能够快速找到初始解决方案并趋向于最优解。

Result: 模拟实验表明，Effort Informed Trees (EIT*) 找到的中位数解路径比测试中的反应式规划算法更短。此外，Asymptotically Optimal RRT-Connect (AORRTC) 在一个实际机器人手臂上的规划问题中也得到了验证。

Conclusion: 该研究表明，通过使用ASAO算法，无需显式的计划重用也可以高效地进行反应式重规划，在面对环境变化时能够生成高质量的路径。

Abstract: Robots operating in changing environments either predict obstacle changes
and/or plan quickly enough to react to them. Predictive approaches require a
strong prior about the position and motion of obstacles. Reactive approaches
require no assumptions about their environment but must replan quickly and find
high-quality paths to navigate effectively.
  Reactive approaches often reuse information between queries to reduce
planning cost. These techniques are conceptually sound but updating dense
planning graphs when information changes can be computationally prohibitive. It
can also require significant effort to detect the changes in some applications.
  This paper revisits the long-held assumption that reactive replanning
requires updating existing plans. It shows that the incremental planning
problem can alternatively be solved more efficiently as a series of independent
problems using fast almost-surely asymptotically optimal (ASAO) planning
algorithms. These ASAO algorithms quickly find an initial solution and converge
towards an optimal solution which allows them to find consistent global plans
in the presence of changing obstacles without requiring explicit plan reuse.
This is demonstrated with simulated experiments where Effort Informed Trees
(EIT*) finds shorter median solution paths than the tested reactive planning
algorithms and is further validated using Asymptotically Optimal RRT-Connect
(AORRTC) on a real-world planning problem on a robot arm.

</details>


### [8] [An Agnostic End-Effector Alignment Controller for Robust Assembly of Modular Space Robots](https://arxiv.org/abs/2510.21164)
*Shamistan Karimov,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文介绍了一种新的控制器，该控制器通过动态超球体夹紧来实施自适应速度边界，以确保模块化机器人在月球任务中能够平稳、稳定地对齐而不会出现突然的动作。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够适应真实世界干扰的控制器，对于需要可重构性和容错性的月球任务中的模块化机器人来说至关重要。

Method: 基于先前硬件无关的执行器同步技术，研究人员开发了这种新的控制器，它利用实时末端执行器和目标姿态测量值调整其平移和旋转速度限制。此外，还实现了两种变体：一种是离散的、基于步骤的版本；另一种是连续的、基于速度的版本，并在日本宇宙航空研究开发机构（JAXA）的月球环境模拟器上使用两个MoonBot肢体进行了测试。

Result: 实地试验证明，基于步骤的版本产生了高度可预测且低摆动的动作，而连续版本则更快收敛并保持毫米级的位置精度。两者都对具有不同机械缺陷和感知噪声的肢体表现出鲁棒性。

Conclusion: 这些结果突出了我们机器人无关框架在恶劣条件下进行自主自组装和重新配置时的灵活性与鲁棒性。

Abstract: Modular robots offer reconfigurability and fault tolerance essential for
lunar missions, but require controllers that adapt safely to real-world
disturbances. We build on our previous hardware-agnostic actuator
synchronization in Motion Stack to develop a new controller enforcing adaptive
velocity bounds via a dynamic hypersphere clamp. Using only real-time
end-effector and target pose measurements, the controller adjusts its
translational and rotational speed limits to ensure smooth, stable alignment
without abrupt motions. We implemented two variants, a discrete, step-based
version and a continuous, velocity-based version, and tested them on two
MoonBot limbs in JAXA's lunar environment simulator. Field trials demonstrate
that the step-based variant produces highly predictable, low-wobble motions,
while the continuous variant converges more quickly and maintains
millimeter-level positional accuracy, and both remain robust across limbs with
differing mechanical imperfections and sensing noise (e.g., backlash and flex).
These results highlight the flexibility and robustness of our robot-agnostic
framework for autonomous self-assembly and reconfiguration under harsh
conditions.

</details>


### [9] [Underwater Visual-Inertial-Acoustic-Depth SLAM with DVL Preintegration for Degraded Environments](https://arxiv.org/abs/2510.21215)
*Shuoshuo Ding,Tiedong Zhang,Dapeng Jiang,Ming Lei*

Main category: cs.RO

TL;DR: 本文提出了一种基于图的视觉-惯性-声学-深度SLAM系统，集成了立体相机、IMU、多普勒速度记录仪（DVL）和压力传感器，以解决水下环境中由于能见度低、光照不足及特征稀少导致的视觉退化问题。通过引入新的DVL预积分策略以及前端混合跟踪策略和声学-惯性-深度联合优化，该系统在模拟和真实水下场景中表现出优于现有系统的稳定性和定位准确性。


<details>
  <summary>Details</summary>
Motivation: 水下环境中的视觉退化问题对视觉-惯性同时定位与建图（SLAM）系统构成了重大挑战。为了解决这些问题，需要开发一种能够在视觉条件不佳的情况下也能可靠工作的新型SLAM系统。

Method: 设计并实现了一个整合了立体相机、IMU、DVL及压力传感器的基于图模型的视觉-惯性-声学-深度SLAM系统。特别地，提出了一个基于速度偏差的DVL预积分方法来减少DVL漂移，并采用了混合追踪策略加上声学-惯性-深度联合优化来提高前端处理能力。整个系统还利用了多源混合残差进行图优化。

Result: 通过在模拟和实际水下场景中进行广泛的定量与定性分析，结果表明所提出的系统在稳定性与定位精度方面均优于当前最先进的立体视觉-惯性SLAM系统，尤其是在视觉条件极具挑战性的环境下表现尤为出色。

Conclusion: 本研究成功开发出一种能够有效应对水下复杂视觉条件的新型视觉-惯性-声学-深度SLAM系统，为未来水下导航技术的发展提供了有力支持。

Abstract: Visual degradation caused by limited visibility, insufficient lighting, and
feature scarcity in underwater environments presents significant challenges to
visual-inertial simultaneous localization and mapping (SLAM) systems. To
address these challenges, this paper proposes a graph-based
visual-inertial-acoustic-depth SLAM system that integrates a stereo camera, an
inertial measurement unit (IMU), the Doppler velocity log (DVL), and a pressure
sensor. The key innovation lies in the tight integration of four distinct
sensor modalities to ensure reliable operation, even under degraded visual
conditions. To mitigate DVL drift and improve measurement efficiency, we
propose a novel velocity-bias-based DVL preintegration strategy. At the
frontend, hybrid tracking strategies and acoustic-inertial-depth joint
optimization enhance system stability. Additionally, multi-source hybrid
residuals are incorporated into a graph optimization framework. Extensive
quantitative and qualitative analyses of the proposed system are conducted in
both simulated and real-world underwater scenarios. The results demonstrate
that our approach outperforms current state-of-the-art stereo visual-inertial
SLAM systems in both stability and localization accuracy, exhibiting
exceptional robustness, particularly in visually challenging environments.

</details>


### [10] [Remote Autonomy for Multiple Small Lowcost UAVs in GNSS-denied Search and Rescue Operations](https://arxiv.org/abs/2510.21357)
*Daniel Schleich,Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 提出了一种使用轻量级消费级DJI无人机的自主飞行系统，通过在遥控器上运行的Android应用程序实现状态估计和避障，并结合地面控制站对多架异构无人机进行配置、监督以及环境信息整合。


<details>
  <summary>Details</summary>
Motivation: 为了减少操作员的压力并促进无人机的应用，尤其是在未知的无GNSS环境下及结构附近，同时避免了对特殊编程接口、定制传感器设置和强大机载计算机的需求，从而扩大无人机的部署范围。

Method: 开发了一款Android应用直接在无人机遥控器上运行，用于状态估计与障碍物规避；设计了一个地面控制站，支持单个操作员同时配置和监控多架不同类型的无人机，并将所有无人机的观测数据合并成一个联合3D环境模型以提高态势感知能力。

Result: 该系统能够在不依赖额外硬件的情况下实现消费级无人机的自主飞行，并且能够通过单一平台管理多架无人机，构建共享的三维环境模型。

Conclusion: 本研究为第一响应者提供了更加便捷易用的自主飞行解决方案，降低了操作难度和技术门槛，使得普通消费者级别的无人机也能执行复杂的任务。

Abstract: In recent years, consumer-grade UAVs have been widely adopted by first
responders. In general, they are operated manually, which requires trained
pilots, especially in unknown GNSS-denied environments and in the vicinity of
structures. Autonomous flight can facilitate the application of UAVs and reduce
operator strain. However, autonomous systems usually require special
programming interfaces, custom sensor setups, and strong onboard computers,
which limits a broader deployment.
  We present a system for autonomous flight using lightweight consumer-grade
DJI drones. They are controlled by an Android app for state estimation and
obstacle avoidance directly running on the UAV's remote control. Our ground
control station enables a single operator to configure and supervise multiple
heterogeneous UAVs at once. Furthermore, it combines the observations of all
UAVs into a joint 3D environment model for improved situational awareness.

</details>


### [11] [Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain](https://arxiv.org/abs/2510.21369)
*Vivian S. Medeiros,Giovanni B. Dessy,Thiago Boaventura,Marcelo Becker,Claudio Semini,Victor Barasuol*

Main category: cs.RO

TL;DR: 本文提出了一种鲁棒的运动框架，通过整合地形探测、承重分析、运动规划和控制策略，使四足机器人能够在不稳定表面上安全导航。实验结果表明该框架能够穿越塌陷地形，同时保持稳定性和优先考虑安全性。


<details>
  <summary>Details</summary>
Motivation: 在搜救任务或行星探索中遇到的塌陷地形给四足机器人的移动带来了很大的挑战。为了解决这个问题，研究者们开发了一种新的方法来提高四足机器人在这些复杂环境中的导航能力。

Method: 本研究采用了一个结合了地形探测、承载力分析、运动规划以及控制策略的综合框架。特别地，这种方法利用关节测量来评估地形稳定性，而不需要额外的硬件修改。此外，引入了模型预测控制（MPC）系统以优化机器人的动作，在保持稳定性和进行探测之间找到平衡点；并且使用状态机协调地形探测行为，允许机器人检测可塌陷区域并动态调整其立足点。

Result: 通过对定制的可塌陷平台及岩石地形上的实验测试，证明了该框架能够让四足机器人成功穿越塌陷地形，并且在整个过程中保持良好的稳定性和安全性。

Conclusion: 提出的鲁棒运动框架为四足机器人提供了一种有效的方法来应对塌陷地形所带来的挑战，提高了它们在执行搜索救援任务或行星探索时的安全性与效率。

Abstract: Collapsing terrains, often present in search and rescue missions or planetary
exploration, pose significant challenges for quadruped robots. This paper
introduces a robust locomotion framework for safe navigation over unstable
surfaces by integrating terrain probing, load-bearing analysis, motion
planning, and control strategies. Unlike traditional methods that rely on
specialized sensors or external terrain mapping alone, our approach leverages
joint measurements to assess terrain stability without hardware modifications.
A Model Predictive Control (MPC) system optimizes robot motion, balancing
stability and probing constraints, while a state machine coordinates terrain
probing actions, enabling the robot to detect collapsible regions and
dynamically adjust its footholds. Experimental results on custom-made
collapsing platforms and rocky terrains demonstrate the framework's ability to
traverse collapsing terrain while maintaining stability and prioritizing
safety.

</details>


### [12] [Enhancing Social Robots through Resilient AI](https://arxiv.org/abs/2510.21469)
*Domenico Palmisano,Giuseppe Palestra,Berardina Nadja De Carolis*

Main category: cs.RO

TL;DR: 本文强调了社会机器人在医疗保健、教育和日常生活等敏感领域中的韧性重要性，特别是在与老年人互动时，这种韧性有助于建立对机器人的信任。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的进步及其在医疗保健、教育等敏感领域的深入应用，确保这些系统具备韧性和鲁棒性变得至关重要。尤其是在与老年人互动时，他们往往对这类系统缺乏信任。

Method: 本文通过定义韧性——即在不利或压力条件下仍能保持基本操作能力的特性——来展示其对于社会机器人的重要性。

Result: 研究表明，韧性是社会机器人的一种基本特征，它能够保证机器人即使在性能下降的情况下也能维持关键功能，这对于赢得用户特别是老年用户的信任非常重要。

Conclusion: 综上所述，为了提高社会机器人在各种环境下的可靠性和被接受度，增强其韧性是一个关键因素。

Abstract: As artificial intelligence continues to advance and becomes more integrated
into sensitive areas like healthcare, education, and everyday life, it's
crucial for these systems to be both resilient and robust. This paper shows how
resilience is a fundamental characteristic of social robots, which, through it,
ensure trust in the robot itself-an essential element especially when operating
in contexts with elderly people, who often have low trust in these systems.
Resilience is therefore the ability to operate under adverse or stressful
conditions, even when degraded or weakened, while maintaining essential
operational capabilities.

</details>


### [13] [Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos](https://arxiv.org/abs/2510.21571)
*Qixiu Li,Yu Deng,Yaobo Liang,Lin Luo,Lei Zhou,Chengtang Yao,Lingqi Zeng,Zhiyuan Feng,Huizhi Liang,Sicheng Xu,Yizhong Zhang,Xi Chen,Hao Chen,Lily Sun,Dong Chen,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: A novel method for pretraining robotic VLA models using unscripted human hand activity videos, resulting in a large dataset and a dexterous hand VLA model with strong zero-shot and fine-tuning performance.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to leverage unannotated, real-life human hand activity videos to create a large-scale training dataset for robotic manipulation Vision-Language-Action (VLA) models, in order to improve the generalization and dexterity of robots in real-world scenarios.

Method: The authors developed a fully-automated holistic human activity analysis approach that can process unscripted real-life video recordings of human hand activities, generating atomic-level hand activity segments with language descriptions and 3D motion data. They created a large-scale training dataset from these videos and used it to pretrain a dexterous hand VLA model.

Result: The pretrained model demonstrated robust zero-shot performance on unseen real-world observations and, when fine-tuned with a small amount of real robot action data, achieved higher task success rates and better generalization to new objects. The model also showed an appealing increase in task performance as the scale of pretraining data grew.

Conclusion: This work establishes a strong foundation for scalable Vision-Language-Action (VLA) pretraining, which is key to advancing robots towards more generalizable embodied intelligence. The model shows zero-shot capabilities and improved task success rates with fine-tuning on real robot data, along with good scaling behavior as the amount of pretraining data increases.

Abstract: This paper presents a novel approach for pretraining robotic manipulation
Vision-Language-Action (VLA) models using a large corpus of unscripted
real-life video recordings of human hand activities. Treating human hand as
dexterous robot end-effector, we show that "in-the-wild" egocentric human
videos without any annotations can be transformed into data formats fully
aligned with existing robotic V-L-A training data in terms of task granularity
and labels. This is achieved by the development of a fully-automated holistic
human activity analysis approach for arbitrary human hand videos. This approach
can generate atomic-level hand activity segments and their language
descriptions, each accompanied with framewise 3D hand motion and camera motion.
We process a large volume of egocentric videos and create a hand-VLA training
dataset containing 1M episodes and 26M frames. This training data covers a wide
range of objects and concepts, dexterous manipulation tasks, and environment
variations in real life, vastly exceeding the coverage of existing robot data.
We design a dexterous hand VLA model architecture and pretrain the model on
this dataset. The model exhibits strong zero-shot capabilities on completely
unseen real-world observations. Additionally, fine-tuning it on a small amount
of real robot action data significantly improves task success rates and
generalization to novel objects in real robotic experiments. We also
demonstrate the appealing scaling behavior of the model's task performance with
respect to pretraining data scale. We believe this work lays a solid foundation
for scalable VLA pretraining, advancing robots toward truly generalizable
embodied intelligence.

</details>


### [14] [Design and Structural Validation of a Micro-UAV with On-Board Dynamic Route Planning](https://arxiv.org/abs/2510.21648)
*Inbazhagan Ravikumar,Ram Sundhar,Narendhiran Vijayakumar*

Main category: cs.RO

TL;DR: 本文介绍了一种完全定制的低成本无人机，它使用常见的组件和材料从零开始构建，强调模块化、低成本和易于组装。该无人机结构框架采用轻便但耐用的材料加固，能够承受冲击；其机载控制系统完全由免费开源软件解决方案驱动，展示了实时感知和自适应导航能力，为现实世界的搜救任务提供了一个经济实惠且实用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 微型飞行器在搜索和救援行动中变得越来越重要，因为它们具有敏捷性、速度以及进入狭小空间或危险区域的能力。然而，设计轻量级空中系统存在显著的结构、空气动力学和计算挑战。特别是对于许多两公斤以下的低成本空中系统来说，它们在穿越崎岖地形时缺乏结构耐久性，并且无法在检测到新受害者或障碍物时动态重新规划路径。

Method: 研究团队提出了一种完全定制的无人机，从头开始使用仅常见的组件和材料建造，注重模块化、低成本与易装配性。结构框架通过轻质却坚固的材料得到加强以抵抗冲击，而机载控制系统则完全依赖于自由开放源代码软件解决方案来运作。

Result: 所提出的系统展示出无需依靠昂贵硬件加速器即可实现的实时感知与适应性导航功能，为实际中的搜索及救援任务提供了既负担得起又切实可行的选择。

Conclusion: 通过本研究开发的这款全定制化无人机，不仅解决了现有低成本无人机在结构耐久性和动态路径重规划方面的局限，还证明了利用通用部件结合开源软件可以创造出适合真实世界应用的强大工具，特别是在搜索和救援领域。

Abstract: Micro aerial vehicles are becoming increasingly important in search and
rescue operations due to their agility, speed, and ability to access confined
spaces or hazardous areas. However, designing lightweight aerial systems
presents significant structural, aerodynamic, and computational challenges.
This work addresses two key limitations in many low-cost aerial systems under
two kilograms: their lack of structural durability during flight through rough
terrains and inability to replan paths dynamically when new victims or
obstacles are detected. We present a fully customised drone built from scratch
using only commonly available components and materials, emphasising modularity,
low cost, and ease of assembly. The structural frame is reinforced with
lightweight yet durable materials to withstand impact, while the onboard
control system is powered entirely by free, open-source software solutions. The
proposed system demonstrates real-time perception and adaptive navigation
capabilities without relying on expensive hardware accelerators, offering an
affordable and practical solution for real-world search and rescue missions.

</details>
