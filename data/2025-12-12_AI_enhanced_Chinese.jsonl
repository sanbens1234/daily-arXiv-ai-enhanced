{"id": "2512.10116", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10116", "abs": "https://arxiv.org/abs/2512.10116", "authors": ["Andrew Razjigaev", "Hans Lohr", "Alejandro Vargas-Uscategui", "Peter King", "Tirthankar Bandyopadhyay"], "title": "Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks", "comment": "Published at the Australasian Conference on Robotics and Automation (ACRA 2025) https://ssl.linklings.net/conferences/acra/acra2025_proceedings/views/includes/files/pap149s2.pdf", "summary": "Industrial automation with six-axis robotic arms is critical for many manufacturing tasks, including welding and additive manufacturing applications; however, many of these operations are functionally redundant due to the symmetrical tool axis, which effectively makes the operation a five-axis task. Exploiting this redundancy is crucial for achieving the desired workspace and dexterity required for the feasibility and optimisation of toolpath planning. Inverse kinematics algorithms can solve this in a fast, reactive framework, but these techniques are underutilised over the more computationally expensive offline planning methods. We propose a novel algorithm to solve functionally redundant inverse kinematics for robotic manipulation utilising a task space decomposition approach, the damped least-squares method and Halley's method to achieve fast and robust solutions with reduced joint motion. We evaluate our methodology in the case of toolpath optimisation in a cold spray coating application on a non-planar surface. The functionally redundant inverse kinematics algorithm can quickly solve motion plans that minimise joint motion, expanding the feasible operating space of the complex toolpath. We validate our approach on an industrial ABB manipulator and cold-spray gun executing the computed toolpath.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u4efb\u52a1\u7a7a\u95f4\u5206\u89e3\u65b9\u6cd5\u3001\u963b\u5c3c\u6700\u5c0f\u4e8c\u4e58\u6cd5\u548cHalley\u65b9\u6cd5\u6765\u89e3\u51b3\u516d\u8f74\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u529f\u80fd\u5197\u4f59\u9006\u8fd0\u52a8\u5b66\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u5feb\u901f\u7a33\u5065\u7684\u89e3\uff0c\u5e76\u51cf\u5c11\u5173\u8282\u8fd0\u52a8\u3002\u8be5\u65b9\u6cd5\u5728\u51b7\u55b7\u6d82\u6d82\u5c42\u5e94\u7528\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u80fd\u6709\u6548\u6269\u5927\u590d\u6742\u8def\u5f84\u7684\u53ef\u884c\u5de5\u4f5c\u7a7a\u95f4\u3002", "motivation": "\u8bb8\u591a\u5236\u9020\u4efb\u52a1\u4f9d\u8d56\u4e8e\u516d\u8f74\u673a\u68b0\u81c2\u7684\u5de5\u4e1a\u81ea\u52a8\u5316\uff0c\u4f46\u7531\u4e8e\u5de5\u5177\u8f74\u5bf9\u79f0\u6027\u5bfc\u81f4\u5b9e\u9645\u64cd\u4f5c\u53ea\u9700\u4e94\u8f74\u5373\u53ef\u5b8c\u6210\u3002\u5229\u7528\u8fd9\u79cd\u5197\u4f59\u5bf9\u4e8e\u63d0\u9ad8\u5de5\u4f5c\u7a7a\u95f4\u548c\u7075\u6d3b\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4ece\u800c\u4f18\u5316\u8def\u5f84\u89c4\u5212\u3002", "method": "\u63d0\u51fa\u7684\u65b0\u7b97\u6cd5\u7ed3\u5408\u4e86\u4efb\u52a1\u7a7a\u95f4\u5206\u89e3\u3001\u963b\u5c3c\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4ee5\u53caHalley\u65b9\u6cd5\uff0c\u65e8\u5728\u4e3a\u5177\u6709\u529f\u80fd\u6027\u5197\u4f59\u7684\u673a\u68b0\u81c2\u63d0\u4f9b\u5feb\u901f\u4e14\u9c81\u68d2\u6027\u5f3a\u7684\u9006\u8fd0\u52a8\u5b66\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u51cf\u5c11\u5173\u8282\u79fb\u52a8\u3002", "result": "\u6240\u63d0\u7b97\u6cd5\u80fd\u591f\u5728\u975e\u5e73\u9762\u8868\u9762\u4e0a\u6267\u884c\u51b7\u55b7\u6d82\u6d82\u5c42\u5e94\u7528\u65f6\u5feb\u901f\u627e\u5230\u6700\u5c0f\u5316\u5173\u8282\u52a8\u4f5c\u7684\u8fd0\u52a8\u8ba1\u5212\uff0c\u6709\u6548\u6269\u5c55\u4e86\u590d\u6742\u5de5\u5177\u8def\u5f84\u7684\u53ef\u64cd\u4f5c\u8303\u56f4\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u9488\u5bf9\u529f\u80fd\u5197\u4f59\u9006\u8fd0\u52a8\u5b66\u6c42\u89e3\u7684\u65b9\u6cd5\uff0c\u5728ABB\u5de5\u4e1a\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u51cf\u5c11\u5173\u8282\u8fd0\u52a8\u53ca\u589e\u52a0\u64cd\u4f5c\u7a7a\u95f4\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2512.10128", "categories": ["cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10128", "abs": "https://arxiv.org/abs/2512.10128", "authors": ["Chuan Huang", "Gustaf Hendeby", "Isaac Skog"], "title": "Inertial Magnetic SLAM Systems Using Low-Cost Sensors", "comment": null, "summary": "Spatially inhomogeneous magnetic fields offer a valuable, non-visual information source for positioning. Among systems leveraging this, magnetic field-based simultaneous localization and mapping (SLAM) systems are particularly attractive because they can provide positioning information and build a magnetic field map on the fly. Moreover, they have bounded error within mapped regions. However, state-of-the-art methods typically require low-drift odometry data provided by visual odometry or a wheel encoder, etc. This is because these systems need to minimize/reduce positioning errors while exploring, which happens when they are in unmapped regions. To address these limitations, this work proposes a loosely coupled and a tightly coupled inertial magnetic SLAM (IM-SLAM) system. The proposed systems use commonly available low-cost sensors: an inertial measurement unit (IMU), a magnetometer array, and a barometer. The use of non-visual data provides a significant advantage over visual-based systems, making it robust to low-visibility conditions. Both systems employ state-space representations, and magnetic field models on different scales. The difference lies in how they use a local and global magnetic field model. The loosely coupled system uses these models separately in two state-space models, while the tightly coupled system integrates them into one state-space model. Experiment results show that the tightly coupled IM-SLAM system achieves lower positioning errors than the loosely coupled system in most scenarios, with typical errors on the order of meters per 100 meters traveled. These results demonstrate the feasiblity of developing a full 3D IM-SLAM systems using low-cost sensors and the potential of applying these systems in emergency response scenarios such as mine/fire rescue.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f4e\u6210\u672c\u4f20\u611f\u5668\u7684\u677e\u6563\u8026\u5408\u548c\u7d27\u5bc6\u8026\u5408\u60ef\u6027\u78c1SLAM\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4f4e\u6f02\u79fb\u91cc\u7a0b\u8ba1\u6570\u636e\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7d27\u5bc6\u8026\u5408IM-SLAM\u7cfb\u7edf\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u5b9a\u4f4d\u8bef\u5dee\u66f4\u4f4e\uff0c\u5177\u6709\u5e94\u7528\u4e8e\u7d27\u6025\u6551\u63f4\u573a\u666f\u5982\u77ff\u4e95/\u706b\u707e\u6551\u63f4\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u78c1\u573a\u7684\u540c\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\uff08SLAM\uff09\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u4f9d\u9760\u89c6\u89c9\u91cc\u7a0b\u8ba1\u6216\u8f6e\u5f0f\u7f16\u7801\u5668\u7b49\u63d0\u4f9b\u7684\u4f4e\u6f02\u79fb\u91cc\u7a0b\u8ba1\u6570\u636e\u4ee5\u51cf\u5c11\u672a\u6620\u5c04\u533a\u57df\u4e2d\u7684\u5b9a\u4f4d\u8bef\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4f7f\u7528\u4f4e\u6210\u672c\u4f20\u611f\u5668\uff08IMU\u3001\u78c1\u529b\u8ba1\u9635\u5217\u548c\u6c14\u538b\u8ba1\uff09\u7684\u677e\u6563\u8026\u5408\u53ca\u7d27\u5bc6\u8026\u5408\u60ef\u6027\u78c1SLAM\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u4f4e\u53ef\u89c1\u5ea6\u6761\u4ef6\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u964d\u4f4e\u5b9a\u4f4d\u8bef\u5dee\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cd\u57fa\u4e8e\u975e\u89c6\u89c9\u6570\u636e\u7684IM-SLAM\u7cfb\u7edf\uff1a\u4e00\u79cd\u662f\u677e\u6563\u8026\u5408\u7cfb\u7edf\uff0c\u53e6\u4e00\u79cd\u662f\u7d27\u5bc6\u8026\u5408\u7cfb\u7edf\u3002\u4e24\u8005\u90fd\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u6cd5\u4ee5\u53ca\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u7684\u78c1\u573a\u6a21\u578b\uff1b\u533a\u522b\u5728\u4e8e\u677e\u6563\u8026\u5408\u7cfb\u7edf\u5c06\u5c40\u90e8\u548c\u5168\u5c40\u78c1\u573a\u6a21\u578b\u5206\u522b\u7528\u4e8e\u4e24\u4e2a\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\uff0c\u800c\u7d27\u5bc6\u8026\u5408\u7cfb\u7edf\u5219\u5c06\u5b83\u4eec\u96c6\u6210\u5230\u4e00\u4e2a\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5185\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u7d27\u5bc6\u8026\u5408IM-SLAM\u7cfb\u7edf\u7684\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u677e\u6563\u8026\u5408\u7cfb\u7edf\u66f4\u4f4e\uff0c\u5178\u578b\u8bef\u5dee\u5927\u7ea6\u4e3a\u6bcf\u884c\u9a76100\u7c73\u65f6\u8bef\u5dee\u51e0\u7c73\u3002\u8fd9\u8bc1\u660e\u4e86\u4f7f\u7528\u4f4e\u6210\u672c\u4f20\u611f\u5668\u5f00\u53d1\u51683D IM-SLAM\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u53ca\u5176\u5728\u7d27\u6025\u54cd\u5e94\u60c5\u666f\u5982\u77ff\u5c71\u6216\u706b\u707e\u6551\u63f4\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u677e\u6563\u8026\u5408\u548c\u7d27\u5bc6\u8026\u5408\u4e24\u79cd\u5f62\u5f0f\u7684IM-SLAM\u7cfb\u7edf\uff0c\u672c\u7814\u7a76\u8868\u660e\u5373\u4f7f\u5728\u4e0d\u4f9d\u8d56\u6602\u8d35\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u3002\u7279\u522b\u662f\u7d27\u5bc6\u8026\u5408\u7cfb\u7edf\u5c55\u793a\u4e86\u66f4\u4f18\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u5bfc\u822a\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.10235", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10235", "abs": "https://arxiv.org/abs/2512.10235", "authors": ["Hui Li", "Akhlak Uz Zaman", "Fujian Yan", "Hongsheng He"], "title": "Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine", "comment": null, "summary": "This paper presents a reinforcement learning framework that incorporates a Contextual Reward Machine for task-oriented grasping. The Contextual Reward Machine reduces task complexity by decomposing grasping tasks into manageable sub-tasks. Each sub-task is associated with a stage-specific context, including a reward function, an action space, and a state abstraction function. This contextual information enables efficient intra-stage guidance and improves learning efficiency by reducing the state-action space and guiding exploration within clearly defined boundaries. In addition, transition rewards are introduced to encourage or penalize transitions between stages which guides the model toward desirable stage sequences and further accelerates convergence. When integrated with the Proximal Policy Optimization algorithm, the proposed method achieved a 95% success rate across 1,000 simulated grasping tasks encompassing diverse objects, affordances, and grasp topologies. It outperformed the state-of-the-art methods in both learning speed and success rate. The approach was transferred to a real robot, where it achieved a success rate of 83.3% in 60 grasping tasks over six affordances. These experimental results demonstrate superior accuracy, data efficiency, and learning efficiency. They underscore the model's potential to advance task-oriented grasping in both simulated and real-world settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u60c5\u5883\u5956\u52b1\u673a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4efb\u52a1\u5bfc\u5411\u7684\u6293\u53d6\u3002\u901a\u8fc7\u5c06\u6293\u53d6\u4efb\u52a1\u5206\u89e3\u4e3a\u66f4\u6613\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u8f6c\u6362\u5956\u52b1\u6765\u5f15\u5bfc\u6a21\u578b\u671d\u5411\u7406\u60f3\u7684\u9636\u6bb5\u5e8f\u5217\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u6210\u529f\u7387\u548c\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u4efb\u52a1\u5bfc\u5411\u6293\u53d6\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u5e76\u5f15\u5bfc\u63a2\u7d22\u5728\u660e\u786e\u754c\u5b9a\u7684\u8fb9\u754c\u5185\u8fdb\u884c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u60c5\u5883\u5956\u52b1\u673a\uff08Contextual Reward Machine\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5b50\u4efb\u52a1\u90fd\u4e0e\u7279\u5b9a\u9636\u6bb5\u7684\u60c5\u5883\u76f8\u5173\u8054\uff0c\u5305\u62ec\u5956\u52b1\u51fd\u6570\u3001\u52a8\u4f5c\u7a7a\u95f4\u53ca\u72b6\u6001\u62bd\u8c61\u51fd\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u8f6c\u6362\u5956\u52b1\u4ee5\u9f13\u52b1\u6216\u60e9\u7f5a\u9636\u6bb5\u95f4\u7684\u8f6c\u6362\uff0c\u4ece\u800c\u6307\u5bfc\u6a21\u578b\u8d8b\u5411\u4e8e\u6709\u5229\u7684\u9636\u6bb5\u5e8f\u5217\u3002", "result": "\u5728\u4e0e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u96c6\u6210\u540e\uff0c\u6240\u63d0\u65b9\u6cd5\u57281,000\u6b21\u5305\u542b\u4e0d\u540c\u5bf9\u8c61\u3001\u53ef\u627f\u53d7\u6027\u548c\u6293\u53d6\u62d3\u6251\u7ed3\u6784\u7684\u6a21\u62df\u6293\u53d6\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e8695%\u7684\u6210\u529f\u7387\uff0c\u5e76\u4e14\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5728\u5b66\u4e60\u901f\u5ea6\u548c\u6210\u529f\u7387\u4e0a\u8868\u73b0\u66f4\u597d\u3002\u5f53\u5e94\u7528\u4e8e\u771f\u5b9e\u673a\u5668\u4eba\u65f6\uff0c\u5728\u8986\u76d6\u516d\u79cd\u53ef\u627f\u53d7\u6027\u768460\u6b21\u6293\u53d6\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8683.3%\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u3001\u6570\u636e\u5229\u7528\u6548\u7387\u548c\u5b66\u4e60\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63a8\u8fdb\u6a21\u62df\u73af\u5883\u548c\u5b9e\u9645\u573a\u666f\u4e0b\u4efb\u52a1\u5bfc\u5411\u6293\u53d6\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.10294", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10294", "abs": "https://arxiv.org/abs/2512.10294", "authors": ["Lu\u00eds Marques", "Maani Ghaffari", "Dmitry Berenson"], "title": "Lies We Can Trust: Quantifying Action Uncertainty with Inaccurate Stochastic Dynamics through Conformalized Nonholonomic Lie Groups", "comment": "13 pages, 7 figures. Under review", "summary": "We propose Conformal Lie-group Action Prediction Sets (CLAPS), a symmetry-aware conformal prediction-based algorithm that constructs, for a given action, a set guaranteed to contain the resulting system configuration at a user-defined probability. Our assurance holds under both aleatoric and epistemic uncertainty, non-asymptotically, and does not require strong assumptions about the true system dynamics, the uncertainty sources, or the quality of the approximate dynamics model. Typically, uncertainty quantification is tackled by making strong assumptions about the error distribution or magnitude, or by relying on uncalibrated uncertainty estimates - i.e., with no link to frequentist probabilities - which are insufficient for safe control. Recently, conformal prediction has emerged as a statistical framework capable of providing distribution-free probabilistic guarantees on test-time prediction accuracy. While current conformal methods treat robots as Euclidean points, many systems have non-Euclidean configurations, e.g., some mobile robots have SE(2). In this work, we rigorously analyze configuration errors using Lie groups, extending previous Euclidean Space theoretical guarantees to SE(2). Our experiments on a simulated JetBot, and on a real MBot, suggest that by considering the configuration space's structure, our symmetry-informed nonconformity score leads to more volume-efficient prediction regions which represent the underlying uncertainty better than existing approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u79f0\u6027\u611f\u77e5\u7684\u4fdd\u5f62\u9884\u6d4b\u7b97\u6cd5CLAPS\uff0c\u5b83\u80fd\u4e3a\u7ed9\u5b9a\u52a8\u4f5c\u751f\u6210\u4e00\u4e2a\u96c6\u5408\uff0c\u8be5\u96c6\u5408\u4ee5\u7528\u6237\u5b9a\u4e49\u7684\u6982\u7387\u5305\u542b\u7cfb\u7edf\u6267\u884c\u52a8\u4f5c\u540e\u7684\u914d\u7f6e\u3002\u6b64\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u91cf\u5316\u65f6\u4e0d\u9700\u8981\u5bf9\u7cfb\u7edf\u52a8\u529b\u5b66\u3001\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u6216\u8fd1\u4f3c\u52a8\u529b\u5b66\u6a21\u578b\u7684\u8d28\u91cf\u505a\u51fa\u5f3a\u5047\u8bbe\uff0c\u5e76\u4e14\u901a\u8fc7\u674e\u7fa4\u5206\u6790\u6269\u5c55\u4e86\u5148\u524d\u7684\u7406\u8bba\u4fdd\u8bc1\u81f3SE(2)\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u8868\u793a\u57fa\u7840\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5bf9\u8bef\u5dee\u5206\u5e03\u6216\u5927\u5c0f\u7684\u5f3a\u5047\u8bbe\uff0c\u6216\u8005\u4f9d\u8d56\u4e8e\u672a\u7ecf\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u8fd9\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u5b89\u5168\u63a7\u5236\u3002\u800c\u4fdd\u5f62\u9884\u6d4b\u4f5c\u4e3a\u4e00\u79cd\u7edf\u8ba1\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u4e0e\u5206\u5e03\u65e0\u5173\u7684\u6982\u7387\u4fdd\u8bc1\uff0c\u4f46\u73b0\u6709\u7684\u4fdd\u5f62\u65b9\u6cd5\u5c06\u673a\u5668\u4eba\u89c6\u4e3a\u6b27\u51e0\u91cc\u5f97\u70b9\uff0c\u672a\u8003\u8651\u8bb8\u591a\u7cfb\u7edf\u5177\u6709\u975e\u6b27\u51e0\u91cc\u5f97\u914d\u7f6e\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86Conformal Lie-group Action Prediction Sets (CLAPS)\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u674e\u7fa4\u6765\u4e25\u683c\u5206\u6790\u6784\u578b\u9519\u8bef\uff0c\u5c06\u4e4b\u524d\u7684\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u5230\u4e86SE(2)\u3002CLAPS\u7b97\u6cd5\u80fd\u591f\u5728\u4e0d\u5bf9\u771f\u5b9e\u7cfb\u7edf\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u6216\u8fd1\u4f3c\u52a8\u6001\u6a21\u578b\u8d28\u91cf\u505a\u5f3a\u70c8\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u5de5\u4f5c\u3002", "result": "\u901a\u8fc7\u6a21\u62dfJetBot\u548c\u5b9e\u9645MBot\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8003\u8651\u5230\u914d\u7f6e\u7a7a\u95f4\u7ed3\u6784\u540e\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u5bf9\u79f0\u4fe1\u606f\u975e\u4e00\u81f4\u6027\u8bc4\u5206\u5bfc\u81f4\u4e86\u4f53\u79ef\u6548\u7387\u66f4\u9ad8\u7684\u9884\u6d4b\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u5730\u4ee3\u8868\u4e86\u6f5c\u5728\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "CLAPS\u7b97\u6cd5\u80fd\u591f\u4e3a\u7ed9\u5b9a\u52a8\u4f5c\u4ea7\u751f\u7684\u7ed3\u679c\u6784\u9020\u51fa\u4e00\u4e2a\u96c6\u5408\uff0c\u5e76\u4e14\u8fd9\u4e2a\u96c6\u5408\u4ee5\u7528\u6237\u5b9a\u4e49\u7684\u6982\u7387\u5305\u542b\u4e86\u7cfb\u7edf\u7684\u65b0\u914d\u7f6e\u3002\u6b64\u5916\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u968f\u673a\u6027\u548c\u77e5\u8bc6\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u4e14\u4e0d\u9700\u8981\u5173\u4e8e\u771f\u5b9e\u7cfb\u7edf\u52a8\u6001\u7b49\u6761\u4ef6\u7684\u5f3a\u5047\u8bbe\uff0c\u663e\u793a\u51fa\u5bf9\u4e8e\u5b89\u5168\u63a7\u5236\u9886\u57df\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.10319", "categories": ["cs.RO", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10319", "abs": "https://arxiv.org/abs/2512.10319", "authors": ["Muhammad Usama", "Muhammad Ibrahim Khan", "Ahmad Hasan", "Muhammad Shaaf Nadeem", "Khawaja Fahad Iqbal", "Jawad Aslam", "Mian Ashfaq Ali", "Asad Nisar Awan"], "title": "Design of a six wheel suspension and a three-axis linear actuation mechanism for a laser weeding robot", "comment": "15 Pages, 10 figures", "summary": "Mobile robots are increasingly utilized in agriculture to automate labor-intensive tasks such as weeding, sowing, harvesting and soil analysis. Recently, agricultural robots have been developed to detect and remove weeds using mechanical tools or precise herbicide sprays. Mechanical weeding is inefficient over large fields, and herbicides harm the soil ecosystem. Laser weeding with mobile robots has emerged as a sustainable alternative in precision farming. In this paper, we present an autonomous weeding robot that uses controlled exposure to a low energy laser beam for weed removal. The proposed robot is six-wheeled with a novel double four-bar suspension for higher stability. The laser is guided towards the detected weeds by a three-dimensional linear actuation mechanism. Field tests have demonstrated the robot's capability to navigate agricultural terrains effectively by overcoming obstacles up to 15 cm in height. At an optimal speed of 42.5 cm/s, the robot achieves a weed detection rate of 86.2\\% and operating time of 87 seconds per meter. The laser actuation mechanism maintains a minimal mean positional error of 1.54 mm, combined with a high hit rate of 97\\%, ensuring effective and accurate weed removal. This combination of speed, accuracy, and efficiency highlights the robot's potential for significantly enhancing precision farming practices.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4f7f\u7528\u4f4e\u80fd\u91cf\u6fc0\u5149\u675f\u8fdb\u884c\u9664\u8349\u7684\u81ea\u4e3b\u519c\u4e1a\u673a\u5668\u4eba\uff0c\u8be5\u673a\u5668\u4eba\u5177\u6709\u516d\u8f6e\u8bbe\u8ba1\u548c\u65b0\u578b\u53cc\u56db\u8fde\u6746\u60ac\u67b6\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002\u5728\u5b9e\u5730\u6d4b\u8bd5\u4e2d\uff0c\u673a\u5668\u4eba\u80fd\u591f\u6709\u6548\u5bfc\u822a\u5e76\u514b\u670d\u9ad8\u8fbe15\u5398\u7c73\u7684\u969c\u788d\u7269\uff0c\u572842.5\u5398\u7c73/\u79d2\u7684\u6700\u4f73\u901f\u5ea6\u4e0b\u8fbe\u523086.2%\u7684\u6742\u8349\u68c0\u6d4b\u7387\uff0c\u5e76\u4e14\u6bcf\u7c73\u64cd\u4f5c\u65f6\u95f4\u4e3a87\u79d2\u3002\u6fc0\u5149\u6267\u884c\u673a\u6784\u4fdd\u6301\u4e861.54\u6beb\u7c73\u7684\u6700\u5c0f\u5e73\u5747\u4f4d\u7f6e\u8bef\u5dee\u4ee5\u53ca97%\u7684\u547d\u4e2d\u7387\uff0c\u786e\u4fdd\u4e86\u6709\u6548\u7684\u6742\u8349\u53bb\u9664\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u673a\u5668\u4eba\u5728\u519c\u4e1a\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4e3a\u4e86\u81ea\u52a8\u5316\u52b3\u52a8\u5bc6\u96c6\u578b\u4efb\u52a1\u5982\u9664\u8349\u3001\u64ad\u79cd\u3001\u6536\u83b7\u548c\u571f\u58e4\u5206\u6790\u7b49\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u51fa\u4e86\u53ef\u4ee5\u5229\u7528\u673a\u68b0\u5de5\u5177\u6216\u7cbe\u786e\u55b7\u6d12\u9664\u8349\u5242\u6765\u68c0\u6d4b\u548c\u79fb\u9664\u6742\u8349\u7684\u519c\u4e1a\u673a\u5668\u4eba\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u673a\u68b0\u9664\u8349\u65b9\u6cd5\u5bf9\u4e8e\u5927\u9762\u79ef\u7530\u5730\u6765\u8bf4\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u5316\u5b66\u9664\u8349\u5242\u5bf9\u571f\u58e4\u751f\u6001\u7cfb\u7edf\u6709\u5bb3\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6301\u7eed\u7684\u9009\u62e9\u2014\u2014\u5229\u7528\u79fb\u52a8\u673a\u5668\u4eba\u914d\u5408\u6fc0\u5149\u6280\u672f\u8fdb\u884c\u7cbe\u51c6\u519c\u4e1a\u4e2d\u7684\u9664\u8349\u5de5\u4f5c\u3002", "method": "\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u516d\u8f6e\u81ea\u4e3b\u9664\u8349\u673a\u5668\u4eba\uff0c\u91c7\u7528\u521b\u65b0\u7684\u53cc\u56db\u8fde\u6746\u60ac\u6302\u7cfb\u7edf\u4ee5\u589e\u5f3a\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u4e09\u7ef4\u7ebf\u6027\u81f4\u52a8\u673a\u5236\u5f15\u5bfc\u6fc0\u5149\u6307\u5411\u68c0\u6d4b\u5230\u7684\u6742\u8349\u3002", "result": "\u73b0\u573a\u6d4b\u8bd5\u8868\u660e\uff0c\u8fd9\u6b3e\u673a\u5668\u4eba\u80fd\u591f\u6709\u6548\u7a7f\u8d8a\u519c\u4e1a\u5730\u5f62\uff0c\u514b\u670d\u9ad8\u8fbe15\u5398\u7c73\u9ad8\u7684\u969c\u788d\u7269\uff1b\u5f53\u4ee542.5\u5398\u7c73/\u79d2\u7684\u901f\u5ea6\u8fd0\u884c\u65f6\uff0c\u5176\u6742\u8349\u8bc6\u522b\u7387\u8fbe\u523086.2%\uff0c\u6bcf\u884c\u8fdb\u4e00\u7c73\u9700\u898187\u79d2\u5904\u7406\u65f6\u95f4\u3002\u6fc0\u5149\u5b9a\u4f4d\u7cbe\u5ea6\u6781\u9ad8\uff0c\u5e73\u5747\u4f4d\u7f6e\u8bef\u5dee\u4ec5\u4e3a1.54\u6beb\u7c73\uff0c\u540c\u65f6\u62e5\u670997%\u7684\u547d\u4e2d\u7387\uff0c\u4fdd\u8bc1\u4e86\u9664\u8349\u8fc7\u7a0b\u65e2\u9ad8\u6548\u53c8\u51c6\u786e\u3002", "conclusion": "\u7ed3\u5408\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u7279\u70b9\uff0c\u8fd9\u6b3e\u57fa\u4e8e\u6fc0\u5149\u6280\u672f\u7684\u81ea\u4e3b\u9664\u8349\u673a\u5668\u4eba\u5c55\u73b0\u4e86\u663e\u8457\u6539\u5584\u7cbe\u51c6\u519c\u4e1a\u5b9e\u8df5\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.10349", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10349", "abs": "https://arxiv.org/abs/2512.10349", "authors": ["Quan Yuan", "Zhenting Du", "Daqian Cao", "Weibang Bai"], "title": "Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing", "comment": "7 pages and 11 figures", "summary": "Tendon-driven under-actuated robotic fingers provide advantages for dexterous manipulation through reduced actuator requirements and simplified mechanical design. However, achieving both high load capacity and adaptive compliance in a compact form remains challenging. This paper presents an under-actuated tendon-driven robotic finger (UTRF) featuring a synchronous tendon routing that mechanically couples all joints with fixed angular velocity ratios, enabling the entire finger to be actuated by a single actuator. This approach significantly reduces the number of actuators required in multi-finger hands, resulting in a lighter and more compact structure without sacrificing stiffness or compliance. The kinematic and static models of the finger are derived, incorporating tendon elasticity to predict structural stiffness. A single-finger prototype was fabricated and tested under static loading, showing an average deflection prediction error of 1.0 mm (0.322% of total finger length) and a measured stiffness of 1.2x10^3 N/m under a 3 kg tip load. Integration into a five-finger robotic hand (UTRF-RoboHand) demonstrates effective object manipulation across diverse scenarios, confirming that the proposed routing achieves predictable stiffness and reliable grasping performance with a minimal actuator count.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6b20\u9a71\u52a8\u808c\u8171\u9a71\u52a8\u7684\u673a\u5668\u4eba\u624b\u6307(UTRF)\uff0c\u901a\u8fc7\u540c\u6b65\u808c\u8171\u8def\u5f84\u8bbe\u8ba1\uff0c\u4f7f\u5f97\u6240\u6709\u5173\u8282\u4ee5\u56fa\u5b9a\u89d2\u901f\u5ea6\u6bd4\u8026\u5408\uff0c\u4ece\u800c\u5b9e\u73b0\u5355\u4e2a\u6267\u884c\u5668\u9a71\u52a8\u6574\u4e2a\u624b\u6307\u3002\u8be5\u8bbe\u8ba1\u51cf\u5c11\u4e86\u591a\u6307\u624b\u6240\u9700\u7684\u6267\u884c\u5668\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ed3\u6784\u7684\u521a\u6027\u548c\u987a\u5e94\u6027\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u9759\u6001\u8d1f\u8f7d\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u5c06\u5176\u96c6\u6210\u5230\u4e94\u6307\u673a\u5668\u4eba\u624b\u4e2d\u65f6\u7684\u6709\u6548\u7269\u4f53\u64cd\u4f5c\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u6b20\u9a71\u52a8\u808c\u8171\u9a71\u52a8\u673a\u5668\u4eba\u624b\u6307\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9ad8\u8d1f\u8f7d\u80fd\u529b\u548c\u9002\u5e94\u6027\u987a\u5e94\u6027\uff0c\u5c24\u5176\u662f\u5728\u7d27\u51d1\u578b\u8bbe\u8ba1\u4e2d\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u521b\u65b0\u7684\u808c\u8171\u8def\u5f84\u8bbe\u8ba1\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u51cf\u5c11\u6240\u9700\u6267\u884c\u5668\u7684\u6570\u91cf\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u7cfb\u7edf\u7684\u521a\u6027\u6216\u987a\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u540c\u6b65\u808c\u8171\u8def\u5f84\u7684\u6b20\u9a71\u52a8\u808c\u8171\u9a71\u52a8\u673a\u5668\u4eba\u624b\u6307\uff08UTRF\uff09\uff0c\u5176\u4e2d\u6240\u6709\u5173\u8282\u90fd\u6309\u7167\u56fa\u5b9a\u7684\u89d2\u901f\u5ea6\u6bd4\u673a\u68b0\u8026\u5408\uff0c\u5141\u8bb8\u4f7f\u7528\u5355\u4e00\u6267\u884c\u5668\u63a7\u5236\u6574\u4e2a\u624b\u6307\u3002\u5efa\u7acb\u4e86\u8003\u8651\u808c\u8171\u5f39\u6027\u7684\u624b\u6307\u8fd0\u52a8\u5b66\u548c\u9759\u6001\u6a21\u578b\u6765\u9884\u6d4b\u7ed3\u6784\u521a\u5ea6\u3002", "result": "\u539f\u578b\u624b\u6307\u5728\u9759\u8f7d\u8377\u6d4b\u8bd5\u4e0b\u663e\u793a\u51fa\u5e73\u5747\u504f\u8f6c\u9884\u6d4b\u8bef\u5dee\u4e3a1.0\u6beb\u7c73\uff08\u603b\u624b\u6307\u957f\u5ea6\u76840.322%\uff09\uff0c\u5e76\u57283\u516c\u65a4\u5c16\u7aef\u8d1f\u8f7d\u4e0b\u6d4b\u91cf\u5230\u521a\u5ea6\u4e3a1.2\u00d710^3 N/m\u3002\u5f53\u96c6\u6210\u5230\u4e94\u6307\u673a\u5668\u4eba\u624b\u4e2d\u65f6\uff0cUTRF-RoboHand\u5c55\u793a\u4e86\u8de8\u591a\u79cd\u573a\u666f\u7684\u6709\u6548\u7269\u4f53\u64cd\u7eb5\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u540c\u6b65\u808c\u8171\u8def\u5f84\u8bbe\u8ba1\u6709\u6548\u51cf\u5c11\u4e86\u6b20\u9a71\u52a8\u808c\u8171\u9a71\u52a8\u673a\u5668\u4eba\u624b\u6307\u6240\u9700\u7684\u6267\u884c\u5668\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u521a\u6027\u548c\u987a\u5e94\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u8bbe\u8ba1\u7684\u624b\u6307\u53ca\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u7684\u4e94\u6307\u673a\u5668\u4eba\u624b\u80fd\u591f\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u63d0\u4f9b\u53ef\u9760\u7684\u6293\u53d6\u8868\u73b0\u3002"}}
{"id": "2512.10394", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10394", "abs": "https://arxiv.org/abs/2512.10394", "authors": ["Weifan Guan", "Huasen Xi", "Chenxiao Zhang", "Aosheng Li", "Qinghao Hu", "Jian Cheng"], "title": "RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI", "comment": null, "summary": "Current embodied AI systems face severe engineering impediments, primarily characterized by poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration. To overcome these limitations, we propose RoboNeuron, a universal deployment framework for embodied intelligence. RoboNeuron is the first framework to deeply integrate the cognitive capabilities of Large Language Models (LLMs) and Vision-Language-Action (VLA) models with the real-time execution backbone of the Robot Operating System (ROS). We utilize the Model Context Protocol (MCP) as a semantic bridge, enabling the LLM to dynamically orchestrate underlying robotic tools. The framework establishes a highly modular architecture that strictly decouples sensing, reasoning, and control by leveraging ROS's unified communication interfaces. Crucially, we introduce an automated tool to translate ROS messages into callable MCP functions, significantly streamlining development. RoboNeuron significantly enhances cross-scenario adaptability and component flexibility, while establishing a systematic platform for horizontal performance benchmarking, laying a robust foundation for scalable real-world embodied applications.", "AI": {"tldr": "RoboNeuron\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u8ba4\u77e5\u80fd\u529b\u4e0e\u673a\u5668\u4eba\u64cd\u4f5c\u7cfb\u7edf(ROS)\u7684\u5b9e\u65f6\u6267\u884c\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u5b9e\u4f53AI\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u8de8\u573a\u666f\u9002\u5e94\u6027\u5dee\u3001\u6a21\u5757\u95f4\u8026\u5408\u50f5\u786c\u4ee5\u53ca\u63a8\u7406\u52a0\u901f\u788e\u7247\u5316\u7b49\u95ee\u9898\u3002", "motivation": "\u76ee\u524d\u7684\u5b9e\u4f53AI\u7cfb\u7edf\u9762\u4e34\u4e25\u91cd\u7684\u5de5\u7a0b\u969c\u788d\uff0c\u5305\u62ec\u8f83\u5dee\u7684\u8de8\u573a\u666f\u9002\u5e94\u80fd\u529b\u3001\u50f5\u786c\u7684\u6a21\u5757\u95f4\u8026\u5408\u53ca\u788e\u7247\u5316\u7684\u63a8\u7406\u52a0\u901f\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86RoboNeuron\u6846\u67b6\u3002", "method": "RoboNeuron\u662f\u9996\u4e2a\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u89c6\u89c9-\u8bed\u8a00-\u884c\u52a8\uff08VLA\uff09\u6a21\u578b\u7684\u8ba4\u77e5\u80fd\u529b\u4e0e\u673a\u5668\u4eba\u64cd\u4f5c\u7cfb\u7edf\uff08ROS\uff09\u7684\u5b9e\u65f6\u6267\u884c\u540e\u7aef\u6df1\u5ea6\u96c6\u6210\u7684\u901a\u7528\u90e8\u7f72\u6846\u67b6\u3002\u5b83\u4f7f\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4f5c\u4e3a\u8bed\u4e49\u6865\u6881\uff0c\u4f7fLLM\u80fd\u591f\u52a8\u6001\u5730\u7f16\u6392\u5e95\u5c42\u673a\u5668\u4eba\u5de5\u5177\u3002\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u4e00\u4e2a\u9ad8\u5ea6\u6a21\u5757\u5316\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u5229\u7528ROS\u7edf\u4e00\u7684\u901a\u4fe1\u63a5\u53e3\u4e25\u683c\u89e3\u8026\u611f\u77e5\u3001\u63a8\u7406\u548c\u63a7\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u53ef\u4ee5\u5c06ROS\u6d88\u606f\u8f6c\u6362\u4e3a\u53ef\u8c03\u7528\u7684MCP\u51fd\u6570\uff0c\u6781\u5927\u5730\u7b80\u5316\u4e86\u5f00\u53d1\u8fc7\u7a0b\u3002", "result": "RoboNeuron\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u573a\u666f\u9002\u5e94\u6027\u548c\u7ec4\u4ef6\u7075\u6d3b\u6027\uff0c\u5e76\u4e3a\u6c34\u5e73\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u5efa\u7acb\u4e86\u7cfb\u7edf\u5e73\u53f0\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u4f53\u5e94\u7528\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002", "conclusion": "RoboNeuron\u4ee3\u8868\u4e86\u5411\u66f4\u7075\u6d3b\u3001\u81ea\u9002\u5e94\u5f3a\u4e14\u6613\u4e8e\u6269\u5c55\u7684\u5b9e\u4f53AI\u7cfb\u7edf\u8fc8\u8fdb\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u5176\u8bbe\u8ba1\u6709\u52a9\u4e8e\u514b\u670d\u73b0\u6709\u6280\u672f\u4e2d\u7684\u4e3b\u8981\u6311\u6218\u3002"}}
{"id": "2512.10480", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10480", "abs": "https://arxiv.org/abs/2512.10480", "authors": ["Jiaqiang Zhang", "Xianjia Yu", "Sier Ha", "Paola Torrico Moron", "Sahar Salimpour", "Farhad Kerama", "Haizhou Zhang", "Tomi Westerlund"], "title": "Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS/UWB/IMU Fusion: A Comparison of EKF, FGO, and PF", "comment": "8 pages, 4 figures, submitted to The 17th International Conference on Ambient Systems, Networks and Technologies", "summary": "Accurate and continuous pedestrian positioning across outdoor-indoor environments remains challenging because GNSS, UWB, and inertial PDR are complementary yet individually fragile under signal blockage, multipath, and drift. This paper presents a unified GNSS/UWB/IMU fusion framework for seamless pedestrian localization and provides a controlled comparison of three probabilistic back-ends: an error-state extended Kalman filter, sliding-window factor graph optimization, and a particle filter. The system uses chest-mounted IMU-based PDR as the motion backbone and integrates absolute updates from GNSS outdoors and UWB indoors. To enhance transition robustness and mitigate urban GNSS degradation, we introduce a lightweight map-based feasibility constraint derived from OpenStreetMap building footprints, treating most building interiors as non-navigable while allowing motion inside a designated UWB-instrumented building. The framework is implemented in ROS 2 and runs in real time on a wearable platform, with visualization in Foxglove. We evaluate three scenarios: indoor (UWB+PDR), outdoor (GNSS+PDR), and seamless outdoor-indoor (GNSS+UWB+PDR). Results show that the ESKF provides the most consistent overall performance in our implementation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684GNSS/UWB/IMU\u878d\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u7f1d\u884c\u4eba\u5b9a\u4f4d\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e09\u79cd\u6982\u7387\u540e\u7aef\u65b9\u6cd5\uff1a\u8bef\u5dee\u72b6\u6001\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u3001\u6ed1\u52a8\u7a97\u53e3\u56e0\u5b50\u56fe\u4f18\u5316\u548c\u7c92\u5b50\u6ee4\u6ce2\u5668\u3002\u7cfb\u7edf\u4ee5\u57fa\u4e8e\u80f8\u90e8\u5b89\u88c5IMU\u7684PDR\u4f5c\u4e3a\u8fd0\u52a8\u57fa\u7840\uff0c\u5e76\u5728\u6237\u5916\u96c6\u6210GNSS\u7edd\u5bf9\u66f4\u65b0\uff0c\u5728\u5ba4\u5185\u96c6\u6210UWB\u3002\u901a\u8fc7\u5f15\u5165\u4eceOpenStreetMap\u5efa\u7b51\u8db3\u8ff9\u5f97\u51fa\u7684\u8f7b\u91cf\u7ea7\u5730\u56fe\u57fa\u53ef\u884c\u6027\u7ea6\u675f\u6765\u63d0\u9ad8\u8fc7\u6e21\u9c81\u68d2\u6027\u548c\u7f13\u89e3\u57ce\u5e02GNSS\u9000\u5316\u3002\u8be5\u6846\u67b6\u5728ROS 2\u4e2d\u5b9e\u73b0\uff0c\u53ef\u5728\u53ef\u7a7f\u6234\u5e73\u53f0\u4e0a\u5b9e\u65f6\u8fd0\u884c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eESKF\u5728\u6211\u4eec\u7684\u5b9e\u73b0\u4e2d\u63d0\u4f9b\u4e86\u6700\u4e00\u81f4\u7684\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u4e14\u8fde\u7eed\u5730\u8de8\u5ba4\u5185\u5916\u73af\u5883\u8fdb\u884c\u884c\u4eba\u5b9a\u4f4d\u4ecd\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3aGNSS\u3001UWB\u548c\u60ef\u6027PDR\u867d\u7136\u4e92\u8865\u4f46\u5404\u81ea\u5728\u4fe1\u53f7\u963b\u585e\u3001\u591a\u8def\u5f84\u6548\u5e94\u4ee5\u53ca\u6f02\u79fb\u60c5\u51b5\u4e0b\u8868\u73b0\u8106\u5f31\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u63d0\u4f9b\u66f4\u7a33\u5b9a\u53ef\u9760\u7684\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e00\u79cd\u7edf\u4e00\u7684GNSS/UWB/IMU\u878d\u5408\u67b6\u6784\uff0c\u5176\u4e2d\u57fa\u4e8e\u80f8\u90e8\u5b89\u88c5\u7684IMU\u7684PDR\u4f5c\u4e3a\u4e3b\u8981\u79fb\u52a8\u6a21\u578b\uff0c\u7ed3\u5408\u5ba4\u5916\u73af\u5883\u4e0b\u7684GNSS\u7edd\u5bf9\u4f4d\u7f6e\u66f4\u65b0\u4e0e\u5ba4\u5185\u73af\u5883\u4e2d\u7684UWB\u4fe1\u606f\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8eOpenStreetMap\u5efa\u7b51\u8f6e\u5ed3\u7684\u8f7b\u91cf\u7ea7\u5730\u56fe\u4e3a\u57fa\u7840\u7684\u53ef\u884c\u6027\u7ea6\u675f\u6761\u4ef6\uff0c\u4ee5\u589e\u5f3a\u8fc7\u6e21\u7a33\u5065\u6027\u548c\u51cf\u5c11\u57ce\u5e02\u73af\u5883\u4e2dGNSS\u6027\u80fd\u4e0b\u964d\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u73b0\u4e86\u80fd\u591f\u5b9e\u73b0\u5b9e\u65f6\u64cd\u4f5c\u7684ROS 2\u6846\u67b6\uff0c\u5e76\u5728\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002\u7ecf\u8fc7\u5bf9\u4e09\u79cd\u60c5\u51b5\uff08\u4ec5\u5ba4\u5185\u3001\u4ec5\u5ba4\u5916\u53ca\u5ba4\u5185\u5916\u8fde\u7eed\uff09\u7684\u8bc4\u4f30\u53d1\u73b0\uff0cESKF\u5728\u5f53\u524d\u5b9e\u73b0\u4e2d\u63d0\u4f9b\u4e86\u6700\u4e3a\u4e00\u81f4\u7684\u8868\u73b0\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684GNSS/UWB/IMU\u878d\u5408\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u884c\u4eba\u8de8\u5ba4\u5185\u5916\u73af\u5883\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u4e0e\u7a33\u5b9a\u6027\u3002\u7279\u522b\u5730\uff0c\u5f53\u4f7f\u7528\u8bef\u5dee\u72b6\u6001\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u4f5c\u4e3a\u540e\u7aef\u5904\u7406\u7b97\u6cd5\u65f6\uff0c\u8be5\u7cfb\u7edf\u8868\u73b0\u51fa\u6700\u4f73\u7684\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2512.10481", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10481", "abs": "https://arxiv.org/abs/2512.10481", "authors": ["Gaozhao Wang", "Xing Liu", "Zhenduo Ye", "Zhengxiong Liu", "Panfeng Huang"], "title": "Contact SLAM: An Active Tactile Exploration Policy Based on Physical Reasoning Utilized in Robotic Fine Blind Manipulation Tasks", "comment": "8 pages, 8 figures", "summary": "Contact-rich manipulation is difficult for robots to execute and requires accurate perception of the environment. In some scenarios, vision is occluded. The robot can then no longer obtain real-time scene state information through visual feedback. This is called ``blind manipulation\". In this manuscript, a novel physically-driven contact cognition method, called ``Contact SLAM\", is proposed. It estimates the state of the environment and achieves manipulation using only tactile sensing and prior knowledge of the scene. To maximize exploration efficiency, this manuscript also designs an active exploration policy. The policy gradually reduces uncertainties in the manipulation scene. The experimental results demonstrated the effectiveness and accuracy of the proposed method in several contact-rich tasks, including the difficult and delicate socket assembly task and block-pushing task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"Contact SLAM\"\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u901a\u8fc7\u89e6\u89c9\u611f\u77e5\u548c\u573a\u666f\u5148\u9a8c\u77e5\u8bc6\u6765\u4f30\u8ba1\u73af\u5883\u72b6\u6001\u5e76\u5b9e\u73b0\u64cd\u4f5c\u3002\u6b64\u5916\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4e3b\u52a8\u63a2\u7d22\u7b56\u7565\u4ee5\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\uff0c\u5e76\u5728\u591a\u79cd\u63a5\u89e6\u4e30\u5bcc\u7684\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u7531\u4e8e\u89c6\u89c9\u53ef\u80fd\u88ab\u906e\u6321\uff0c\u673a\u5668\u4eba\u65e0\u6cd5\u603b\u662f\u4f9d\u8d56\u89c6\u89c9\u53cd\u9988\u83b7\u53d6\u5b9e\u65f6\u573a\u666f\u72b6\u6001\u4fe1\u606f\uff0c\u5bfc\u81f4\u6267\u884c\u63a5\u89e6\u5bc6\u96c6\u578b\u64cd\u4f5c\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5373\u6240\u8c13\u7684\u201c\u76f2\u64cd\u4f5c\u201d\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u8ba9\u673a\u5668\u4eba\u80fd\u591f\u4ec5\u4f9d\u9760\u89e6\u89c9\u548c\u5df2\u77e5\u7684\u573a\u666f\u4fe1\u606f\u6765\u8fdb\u884c\u6709\u6548\u7684\u64cd\u4f5c\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u201cContact SLAM\u201d\u7684\u7269\u7406\u9a71\u52a8\u63a5\u89e6\u8ba4\u77e5\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u89e6\u89c9\u4f20\u611f\u548c\u573a\u666f\u5148\u9a8c\u77e5\u8bc6\u6765\u4f30\u8ba1\u73af\u5883\u72b6\u6001\u5e76\u5b8c\u6210\u64cd\u4f5c\u4efb\u52a1\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\uff0c\u6587\u4e2d\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u63a2\u7d22\u7b56\u7565\uff0c\u65e8\u5728\u9010\u6b65\u51cf\u5c11\u64cd\u4f5c\u573a\u666f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u201cContact SLAM\u201d\u65b9\u6cd5\u5728\u5305\u62ec\u63d2\u5ea7\u7ec4\u88c5\u4efb\u52a1\u548c\u63a8\u5757\u4efb\u52a1\u5728\u5185\u7684\u51e0\u79cd\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e86\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u201cContact SLAM\u201d\u65b9\u6cd5\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u6ca1\u6709\u89c6\u89c9\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u6709\u6548\u5730\u4f30\u8ba1\u73af\u5883\u72b6\u6001\u5e76\u5b8c\u6210\u590d\u6742\u7684\u64cd\u4f5c\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63a5\u89e6\u4e30\u5bcc\u573a\u666f\u4e0b\u5e94\u7528\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.10595", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10595", "abs": "https://arxiv.org/abs/2512.10595", "authors": ["Maximillian Fainkich", "Kiril Solovey", "Anna Clarke"], "title": "Motion Planning for Safe Landing of a Human-Piloted Parafoil", "comment": null, "summary": "Most skydiving accidents occur during the parafoil-piloting and landing stages and result from human lapses in judgment while piloting the parafoil. Training of novice pilots is protracted due to the lack of functional and easily accessible training simulators. Moreover, work on parafoil trajectory planning suitable for aiding human training remains limited. To bridge this gap, we study the problem of computing safe trajectories for human-piloted parafoil flight and examine how such trajectories fare against human-generated solutions. For the algorithmic part, we adapt the sampling-based motion planner Stable Sparse RRT (SST) by Li et al., to cope with the problem constraints while minimizing the bank angle (control effort) as a proxy for safety. We then compare the computer-generated solutions with data from human-generated parafoil flight, where the algorithm offers a relative cost improvement of 20\\%-80\\% over the performance of the human pilot. We observe that human pilots tend to, first, close the horizontal distance to the landing area, and then address the vertical gap by spiraling down to the suitable altitude for starting a landing maneuver. The algorithm considered here makes smoother and more gradual descents, arriving at the landing area at the precise altitude necessary for the final approach while maintaining safety constraints. Overall, the study demonstrates the potential of computer-generated guidelines, rather than traditional rules of thumb, which can be integrated into future simulators to train pilots for safer and more cost-effective flights.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u6ed1\u7fd4\u4f1e\u98de\u884c\u4e2d\u4eba\u4e3a\u5224\u65ad\u5931\u8bef\u5bfc\u81f4\u7684\u4e8b\u6545\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eStable Sparse RRT\u7b97\u6cd5\u6539\u8fdb\u7248\u7684\u8f68\u8ff9\u89c4\u5212\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u503e\u659c\u89d2\u5ea6\u6765\u4fdd\u8bc1\u5b89\u5168\uff0c\u5e76\u4e0e\u4eba\u7c7b\u98de\u884c\u5458\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\uff0c\u663e\u793a\u4e86\u8ba1\u7b97\u673a\u751f\u6210\u7684\u6307\u5bfc\u65b9\u9488\u5728\u8bad\u7ec3\u98de\u884c\u5458\u4ee5\u5b9e\u73b0\u66f4\u5b89\u5168\u548c\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u7684\u98de\u884c\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u6ed1\u7fd4\u4f1e\u98de\u884c\u9636\u6bb5\u7684\u4eba\u4e3a\u5224\u65ad\u5931\u8bef\u5bfc\u81f4\u4e86\u8bb8\u591a\u8df3\u4f1e\u4e8b\u6545\uff0c\u4e14\u65b0\u624b\u98de\u884c\u5458\u7f3a\u4e4f\u6709\u6548\u7684\u8bad\u7ec3\u6a21\u62df\u5668\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u9002\u5408\u8f85\u52a9\u4eba\u7c7b\u8bad\u7ec3\u7684\u6ed1\u7fd4\u4f1e\u8f68\u8ff9\u89c4\u5212\u65b9\u6848\u3002", "method": "\u7814\u7a76\u4eba\u5458\u8c03\u6574\u4e86Li\u7b49\u4eba\u63d0\u51fa\u7684\u57fa\u4e8e\u91c7\u6837\u7684\u8fd0\u52a8\u89c4\u5212\u5668Stable Sparse RRT (SST)\uff0c\u4ee5\u9002\u5e94\u6ed1\u7fd4\u4f1e\u98de\u884c\u7684\u95ee\u9898\u7ea6\u675f\uff0c\u5e76\u5c06\u6700\u5c0f\u5316\u503e\u659c\u89d2\u5ea6\uff08\u63a7\u5236\u52aa\u529b\uff09\u4f5c\u4e3a\u5b89\u5168\u6027\u7684\u4e00\u4e2a\u6307\u6807\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u5c06\u8ba1\u7b97\u673a\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4e0e\u4eba\u7c7b\u5b9e\u9645\u98de\u884c\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7b97\u6cd5\u751f\u6210\u7684\u98de\u884c\u8def\u5f84\u76f8\u5bf9\u4e8e\u4eba\u7c7b\u98de\u884c\u5458\u7684\u6210\u672c\u63d0\u9ad8\u4e8620%-80%\u3002\u6b64\u5916\uff0c\u89c2\u5bdf\u5230\u4eba\u7c7b\u98de\u884c\u5458\u503e\u5411\u4e8e\u5148\u7f29\u77ed\u6c34\u5e73\u8ddd\u79bb\u518d\u87ba\u65cb\u4e0b\u964d\u81f3\u5408\u9002\u7684\u7740\u9646\u9ad8\u5ea6\uff0c\u800c\u7b97\u6cd5\u5219\u80fd\u5e73\u6ed1\u5730\u9010\u6e10\u4e0b\u964d\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u7ea6\u675f\u7684\u540c\u65f6\u4e8e\u7cbe\u786e\u7684\u9ad8\u5ea6\u5230\u8fbe\u7740\u9646\u533a\u57df\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u7ecf\u9a8c\u6cd5\u5219\uff0c\u4f7f\u7528\u8ba1\u7b97\u673a\u751f\u6210\u7684\u6307\u5357\u53ef\u4ee5\u96c6\u6210\u5230\u672a\u6765\u7684\u6a21\u62df\u5668\u4e2d\uff0c\u5e2e\u52a9\u8bad\u7ec3\u98de\u884c\u5458\u6267\u884c\u66f4\u5b89\u5168\u3001\u6210\u672c\u66f4\u4f4e\u7684\u98de\u884c\u4efb\u52a1\u3002"}}
{"id": "2512.10605", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10605", "abs": "https://arxiv.org/abs/2512.10605", "authors": ["Lihuang Chen", "Xiangyu Luo", "Jun Meng"], "title": "LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator", "comment": null, "summary": "We propose LEO-RobotAgent, a general-purpose language-driven intelligent agent framework for robots. Under this framework, LLMs can operate different types of robots to complete unpredictable complex tasks across various scenarios. This framework features strong generalization, robustness, and efficiency. The application-level system built around it can fully enhance bidirectional human-robot intent understanding and lower the threshold for human-robot interaction. Regarding robot task planning, the vast majority of existing studies focus on the application of large models in single-task scenarios and for single robot types. These algorithms often have complex structures and lack generalizability. Thus, the proposed LEO-RobotAgent framework is designed with a streamlined structure as much as possible, enabling large models to independently think, plan, and act within this clear framework. We provide a modular and easily registrable toolset, allowing large models to flexibly call various tools to meet different requirements. Meanwhile, the framework incorporates a human-robot interaction mechanism, enabling the algorithm to collaborate with humans like a partner. Experiments have verified that this framework can be easily adapted to mainstream robot platforms including unmanned aerial vehicles (UAVs), robotic arms, and wheeled robot, and efficiently execute a variety of carefully designed tasks with different complexity levels. Our code is available at https://github.com/LegendLeoChen/LEO-RobotAgent.", "AI": {"tldr": "Researchers developed LEO-RobotAgent, a versatile and efficient framework that uses language models to control different types of robots for complex, varied tasks. It features an easy-to-use design for improved human-robot interaction and has been successfully tested on multiple robot platforms.", "motivation": "The motivation behind the LEO-RobotAgent framework is to address the limitations of existing robotic task planning systems, which are often designed for specific single-task scenarios and lack generalizability across different robot types. The aim is to create a more streamlined and adaptable system that can handle unpredictable, complex tasks in various environments, improving bidirectional human-robot communication and making it easier for non-experts to interact with robots.", "method": "The LEO-RobotAgent framework employs a simplified structure that allows large language models (LLMs) to think, plan, and act independently. It provides a modular toolkit that can be easily customized and registered by the LLMs according to the task requirements. Additionally, it integrates a mechanism for human-robot collaboration, enabling the LLMs to work alongside humans as partners.", "result": "Experiments demonstrated that the LEO-RobotAgent framework can be effectively adapted to a wide range of mainstream robot platforms, including unmanned aerial vehicles (UAVs), robotic arms, and wheeled robots. The framework was able to efficiently carry out a variety of tasks with differing levels of complexity, showcasing its adaptability and efficiency.", "conclusion": "The LEO-RobotAgent framework represents a significant advancement in the field of robotics, offering a highly generalized, robust, and efficient solution for controlling diverse types of robots through LLMs. Its ease of use and ability to facilitate better human-robot interaction make it a promising tool for both researchers and end-users. The open-source code further supports its accessibility and potential for future development."}}
{"id": "2512.10675", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10675", "abs": "https://arxiv.org/abs/2512.10675", "authors": ["Gemini Robotics Team", "Coline Devin", "Yilun Du", "Debidatta Dwibedi", "Ruiqi Gao", "Abhishek Jindal", "Thomas Kipf", "Sean Kirmani", "Fangchen Liu", "Anirudha Majumdar", "Andrew Marmon", "Carolina Parada", "Yulia Rubanova", "Dhruv Shah", "Vikas Sindhwani", "Jie Tan", "Fei Xia", "Ted Xiao", "Sherry Yang", "Wenhao Yu", "Allan Zhou"], "title": "Evaluating Gemini Robotics Policies in a Veo World Simulator", "comment": null, "summary": "Generative world models hold significant potential for simulating interactions with visuomotor policies in varied environments. Frontier video models can enable generation of realistic observations and environment interactions in a scalable and general manner. However, the use of video models in robotics has been limited primarily to in-distribution evaluations, i.e., scenarios that are similar to ones used to train the policy or fine-tune the base video model. In this report, we demonstrate that video models can be used for the entire spectrum of policy evaluation use cases in robotics: from assessing nominal performance to out-of-distribution (OOD) generalization, and probing physical and semantic safety. We introduce a generative evaluation system built upon a frontier video foundation model (Veo). The system is optimized to support robot action conditioning and multi-view consistency, while integrating generative image-editing and multi-view completion to synthesize realistic variations of real-world scenes along multiple axes of generalization. We demonstrate that the system preserves the base capabilities of the video model to enable accurate simulation of scenes that have been edited to include novel interaction objects, novel visual backgrounds, and novel distractor objects. This fidelity enables accurately predicting the relative performance of different policies in both nominal and OOD conditions, determining the relative impact of different axes of generalization on policy performance, and performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints. We validate these capabilities through 1600+ real-world evaluations of eight Gemini Robotics policy checkpoints and five tasks for a bimanual manipulator.", "AI": {"tldr": "\u672c\u62a5\u544a\u5c55\u793a\u4e86\u4e00\u79cd\u57fa\u4e8e\u524d\u6cbf\u89c6\u9891\u57fa\u7840\u6a21\u578b(Veo)\u7684\u751f\u6210\u8bc4\u4f30\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u652f\u6301\u673a\u5668\u4eba\u52a8\u4f5c\u6761\u4ef6\u548c\u591a\u89c6\u56fe\u4e00\u81f4\u6027\uff0c\u5e76\u96c6\u6210\u4e86\u751f\u6210\u56fe\u50cf\u7f16\u8f91\u548c\u591a\u89c6\u56fe\u8865\u5168\u529f\u80fd\uff0c\u4ee5\u5408\u6210\u6cbf\u591a\u4e2a\u6cdb\u5316\u8f74\u7684\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7684\u903c\u771f\u53d8\u5316\u3002\u901a\u8fc71600\u591a\u6b21\u771f\u5b9e\u4e16\u754c\u7684\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u89c6\u9891\u6a21\u578b\u5728\u673a\u5668\u4eba\u6280\u672f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u653f\u7b56\u8bc4\u4f30\u7528\u4f8b\u7684\u6574\u4e2a\u8303\u56f4\uff0c\u5305\u62ec\u8bc4\u4f30\u6807\u51c6\u6027\u80fd\u3001\u5206\u5e03\u5916(OOD)\u6cdb\u5316\u4ee5\u53ca\u7269\u7406\u548c\u8bed\u4e49\u5b89\u5168\u6027\u7684\u6d4b\u8bd5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u524d\u6cbf\u89c6\u9891\u57fa\u7840\u6a21\u578b\uff08Veo\uff09\u6784\u5efa\u7684\u751f\u6210\u8bc4\u4f30\u7cfb\u7edf\uff0c\u4f18\u5316\u4e86\u5bf9\u673a\u5668\u4eba\u52a8\u4f5c\u6761\u4ef6\u7684\u652f\u6301\u548c\u591a\u89c6\u56fe\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u6574\u5408\u4e86\u751f\u6210\u56fe\u50cf\u7f16\u8f91\u4e0e\u591a\u89c6\u56fe\u5b8c\u6210\u7684\u6280\u672f\uff0c\u4ee5\u6cbf\u7740\u591a\u4e2a\u6cdb\u5316\u8f74\u7efc\u5408\u51fa\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7684\u53d8\u5316\u7248\u672c\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u51c6\u786e\u6a21\u62df\u7ecf\u8fc7\u7f16\u8f91\u540e\u5305\u542b\u65b0\u4ea4\u4e92\u5bf9\u8c61\u3001\u65b0\u9896\u89c6\u89c9\u80cc\u666f\u53ca\u65b0\u5e72\u6270\u7269\u4f53\u7684\u573a\u666f\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u89c6\u9891\u6a21\u578b\u7684\u57fa\u7840\u80fd\u529b\uff0c\u4f7f\u5f97\u53ef\u4ee5\u51c6\u786e\u9884\u6d4b\u4e0d\u540c\u7b56\u7565\u5728\u5e38\u89c4\u548cOOD\u6761\u4ef6\u4e0b\u7684\u76f8\u5bf9\u8868\u73b0\uff0c\u786e\u5b9a\u4e0d\u540c\u7684\u6cdb\u5316\u8f74\u5bf9\u7b56\u7565\u6027\u80fd\u7684\u5f71\u54cd\u7a0b\u5ea6\uff0c\u5e76\u8fdb\u884c\u7b56\u7565\u5bf9\u6297\u4ee5\u63ed\u793a\u8fdd\u53cd\u7269\u7406\u6216\u8bed\u4e49\u5b89\u5168\u7ea6\u675f\u7684\u884c\u4e3a\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u89c6\u9891\u6a21\u578b\u4e0d\u4ec5\u9650\u4e8e\u540c\u5206\u5e03\u8bc4\u4f30\uff0c\u5728\u673a\u5668\u4eba\u9886\u57df\u4ece\u540d\u4e49\u6027\u80fd\u8bc4\u4f30\u5230\u5206\u5e03\u5916\u6cdb\u5316\uff0c\u4e43\u81f3\u7269\u7406\u4e0e\u8bed\u4e49\u5b89\u5168\u6027\u63a2\u67e5\u7b49\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u4e2d\u90fd\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002"}}
{"id": "2512.10698", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10698", "abs": "https://arxiv.org/abs/2512.10698", "authors": ["Jianbo Wang", "Galina Sidorenko", "Johan Thunberg"], "title": "How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning", "comment": null, "summary": "Connected and automated vehicles (CAVs) have the potential to enhance driving safety, for example by enabling safe vehicle following and more efficient traffic scheduling. For such future deployments, safety requirements should be addressed, where the primary such are avoidance of vehicle collisions and substantial mitigating of harm when collisions are unavoidable. However, conservative worst-case-based control strategies come at the price of reduced flexibility and may compromise overall performance. In light of this, we investigate how Deep Reinforcement Learning (DRL) can be leveraged to improve safety in multi-vehicle-following scenarios involving emergency braking. Specifically, we investigate how DRL with vehicle-to-vehicle communication can be used to ethically select an emergency breaking profile in scenarios where overall, or collective, three-vehicle harm reduction or collision avoidance shall be obtained instead of single-vehicle such. As an algorithm, we provide a hybrid approach that combines DRL with a previously published method based on analytical expressions for selecting optimal constant deceleration. By combining DRL with the previous method, the proposed hybrid approach increases the reliability compared to standalone DRL, while achieving superior performance in terms of overall harm reduction and collision avoidance.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7ed3\u5408\u8f66\u5bf9\u8f66\u901a\u4fe1\u6765\u63d0\u9ad8\u591a\u8f66\u8f86\u8ddf\u968f\u573a\u666f\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5728\u7d27\u6025\u5236\u52a8\u60c5\u51b5\u4e0b\u9009\u62e9\u80fd\u51cf\u5c11\u6574\u4f53\u4f24\u5bb3\u6216\u907f\u514d\u78b0\u649e\u7684\u7b56\u7565\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06DRL\u4e0e\u57fa\u4e8e\u89e3\u6790\u8868\u8fbe\u5f0f\u9009\u62e9\u6700\u4f18\u6052\u5b9a\u51cf\u901f\u7684\u65b9\u6cd5\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u589e\u52a0\u53ef\u9760\u6027\u5e76\u5b9e\u73b0\u66f4\u4f18\u7684\u6574\u4f53\u8868\u73b0\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u8054\u7f51\u548c\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66(CAVs)\u7684\u5b89\u5168\u6027\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u7d27\u6025\u5236\u52a8\u7684\u591a\u8f66\u8f86\u8ddf\u968f\u60c5\u666f\u4e2d\uff0c\u901a\u8fc7\u5bfb\u627e\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u907f\u514d\u78b0\u649e\u53c8\u80fd\u663e\u8457\u51cf\u8f7b\u4e0d\u53ef\u907f\u514d\u78b0\u649e\u65f6\u635f\u5bb3\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u514b\u670d\u8fc7\u4e8e\u4fdd\u5b88\u7684\u63a7\u5236\u7b56\u7565\u5e26\u6765\u7684\u7075\u6d3b\u6027\u964d\u4f4e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u7ed3\u5408\u8f66\u8f86\u95f4\u901a\u4fe1\u6280\u672f\uff0c\u5e76\u5c06\u5176\u4e0e\u4e00\u4e2a\u57fa\u4e8e\u89e3\u6790\u516c\u5f0f\u9009\u53d6\u6700\u4f73\u6052\u5b9a\u51cf\u901f\u7387\u7684\u65b9\u6cd5\u76f8\u878d\u5408\uff0c\u5f00\u53d1\u51fa\u4e00\u79cd\u65b0\u578b\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u8be5\u6df7\u5408\u65b9\u6cd5\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528DRL\u63d0\u9ad8\u4e86\u53ef\u9760\u6027\uff0c\u5728\u603b\u4f53\u4f24\u5bb3\u51cf\u5c11\u53ca\u907f\u514d\u78b0\u649e\u65b9\u9762\u8868\u73b0\u51fa\u4e86\u66f4\u4f18\u5f02\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408DRL\u4e0e\u73b0\u6709\u57fa\u4e8e\u89e3\u6790\u89e3\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5728\u591a\u8f66\u8f86\u8ddf\u968f\u60c5\u5883\u4e0b\u6539\u5584\u5b89\u5168\u72b6\u51b5\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u96c6\u4f53\u8003\u8651\u4e09\u8f86\u8f66\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u7d27\u6025\u5236\u52a8\u51b3\u7b56\u65f6\u3002"}}
{"id": "2512.10700", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10700", "abs": "https://arxiv.org/abs/2512.10700", "authors": ["Mohamed Elobaid", "Shinkyu Park", "Eric Feron"], "title": "On the Stabilization of Rigid Formations on Regular Curves", "comment": null, "summary": "This work deals with the problem of stabilizing a multi-agent rigid formation on a general class of planar curves. Namely, we seek to stabilize an equilateral polygonal formation on closed planar differentiable curves after a path sweep. The task of finding an inscribed regular polygon centered at the point of interest is solved via a randomized multi-start Newton-Like algorithm for which one is able to ascertain the existence of a minimizer. Then we design a continuous feedback law that guarantees convergence to, and sufficient sweeping of the curve, followed by convergence to the desired formation vertices while ensuring inter-agent avoidance. The proposed approach is validated through numerical simulations for different classes of curves and different rigid formations. Code: https://github.com/mebbaid/paper-elobaid-ifacwc-2026", "AI": {"tldr": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u5728\u4e00\u822c\u5e73\u9762\u66f2\u7ebf\u4e0a\u7a33\u5b9a\u591a\u667a\u80fd\u4f53\u521a\u6027\u7f16\u961f\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u901a\u8fc7\u8def\u5f84\u626b\u63cf\u540e\u5728\u95ed\u5408\u53ef\u5fae\u5e73\u9762\u4e0a\u7a33\u5b9a\u6b63\u591a\u8fb9\u5f62\u7f16\u961f\u3002\u91c7\u7528\u4e86\u4e00\u79cd\u968f\u673a\u591a\u8d77\u70b9\u7684\u7c7b\u725b\u987f\u7b97\u6cd5\u6765\u5bfb\u627e\u611f\u5174\u8da3\u7684\u70b9\u5904\u5185\u5207\u6b63\u591a\u8fb9\u5f62\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8fde\u7eed\u53cd\u9988\u5f8b\u786e\u4fdd\u6536\u655b\u5230\u76ee\u6807\u7f16\u961f\u9876\u70b9\u7684\u540c\u65f6\u907f\u514d\u667a\u80fd\u4f53\u95f4\u78b0\u649e\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5982\u4f55\u5728\u5404\u79cd\u5e73\u9762\u66f2\u7ebf\u73af\u5883\u4e0b\u5b9e\u73b0\u5e76\u4fdd\u6301\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7ec4\u6210\u7684\u521a\u6027\u51e0\u4f55\u56fe\u5f62\uff0c\u5177\u4f53\u662f\u8ba9\u8fd9\u4e9b\u667a\u80fd\u4f53\u80fd\u591f\u6cbf\u7740\u7ed9\u5b9a\u7684\u95ed\u5408\u66f2\u7ebf\u79fb\u52a8\uff0c\u6700\u7ec8\u5f62\u6210\u4e00\u4e2a\u7b49\u8fb9\u591a\u8fb9\u5f62\u9635\u578b\u3002", "method": "\u91c7\u7528\u4e86\u968f\u673a\u591a\u8d77\u70b9\u7684\u7c7b\u725b\u987f\u7b97\u6cd5\u6765\u5b9a\u4f4d\u9700\u8981\u5f62\u6210\u7684\u6b63\u591a\u8fb9\u5f62\u7684\u4f4d\u7f6e\uff1b\u63a5\u7740\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8fde\u7eed\u53cd\u9988\u63a7\u5236\u5f8b\uff0c\u7528\u4ee5\u786e\u4fdd\u6240\u6709\u667a\u80fd\u4f53\u53ef\u4ee5\u6cbf\u7740\u6307\u5b9a\u66f2\u7ebf\u79fb\u52a8\u76f4\u81f3\u8fbe\u5230\u5404\u81ea\u7684\u76ee\u6807\u4f4d\u7f6e\uff0c\u540c\u65f6\u4fdd\u8bc1\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u667a\u80fd\u4f53\u4e4b\u95f4\u4e0d\u4f1a\u53d1\u751f\u78b0\u649e\u3002", "result": "\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u66f2\u7ebf\u548c\u4e0d\u540c\u7684\u521a\u6027\u7f16\u961f\u7ed3\u6784\u90fd\u5c55\u793a\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u4fdd\u6301\u9884\u5b9a\u51e0\u4f55\u5f62\u72b6\u7684\u540c\u65f6\u5b8c\u6210\u5bf9\u7279\u5b9a\u8def\u5f84\u7684\u63a2\u7d22\u4efb\u52a1\u3002"}}
{"id": "2512.10891", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10891", "abs": "https://arxiv.org/abs/2512.10891", "authors": ["Anh-Quan Pham", "Marcel Hussing", "Shubhankar P. Patankar", "Dani S. Bassett", "Jorge Mendez-Mendez", "Eric Eaton"], "title": "Iterative Compositional Data Generation for Robot Control", "comment": null, "summary": "Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u7ec4\u5408\u6269\u6563\u53d8\u6362\u5668\uff0c\u53ef\u4ee5\u5c06\u8f6c\u6362\u5206\u89e3\u4e3a\u673a\u5668\u4eba\u3001\u7269\u4f53\u3001\u969c\u788d\u7269\u548c\u76ee\u6807\u7279\u5b9a\u7684\u7ec4\u4ef6\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002\u8be5\u6a21\u578b\u5728\u6709\u9650\u7684\u4efb\u52a1\u5b50\u96c6\u4e0a\u8bad\u7ec3\u540e\uff0c\u80fd\u591f\u96f6\u6837\u672c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8f6c\u6362\uff0c\u4ece\u800c\u5b66\u4e60\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u7ec4\u5408\u7684\u63a7\u5236\u7b56\u7565\u3002", "motivation": "\u7531\u4e8e\u6536\u96c6\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u7684\u6210\u672c\u5f88\u9ad8\uff0c\u56e0\u6b64\u65e0\u6cd5\u4e3a\u591a\u5bf9\u8c61\u3001\u591a\u673a\u5668\u4eba\u548c\u591a\u73af\u5883\u8bbe\u7f6e\u4e2d\u51fa\u73b0\u7684\u5927\u91cf\u4efb\u52a1\u83b7\u53d6\u6f14\u793a\u3002\u867d\u7136\u6700\u8fd1\u7684\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u4e3a\u5355\u4e2a\u4efb\u52a1\u5408\u6210\u6709\u7528\u7684\u6570\u636e\uff0c\u4f46\u5b83\u4eec\u6ca1\u6709\u5229\u7528\u673a\u5668\u4eba\u9886\u57df\u7684\u7ec4\u5408\u7ed3\u6784\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u7ec4\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u7ec4\u5408\u6269\u6563\u53d8\u6362\u5668\uff0c\u5b83\u5c06\u8f6c\u6362\u5206\u89e3\u6210\u4e0e\u673a\u5668\u4eba\u3001\u7269\u4f53\u3001\u969c\u788d\u7269\u4ee5\u53ca\u76ee\u6807\u76f8\u5173\u7684\u90e8\u5206\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u6765\u5b66\u4e60\u8fd9\u4e9b\u7ec4\u6210\u90e8\u5206\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u63a5\u7740\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u8fed\u4ee3\u81ea\u6211\u6539\u8fdb\u8fc7\u7a0b\uff0c\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u9a8c\u8bc1\u5408\u6210\u6570\u636e\uff0c\u5e76\u5c06\u5176\u7eb3\u5165\u540e\u7eed\u8bad\u7ec3\u8f6e\u6b21\u3002", "result": "\u76f8\u6bd4\u6574\u4f53\u5f0f\u548c\u786c\u7f16\u7801\u7684\u7ec4\u5408\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u96f6\u6837\u672c\u6027\u80fd\uff0c\u51e0\u4e4e\u89e3\u51b3\u4e86\u6240\u6709\u4fdd\u7559\u7684\u4efb\u52a1\uff0c\u5e76\u5c55\u793a\u4e86\u5b66\u4e60\u8868\u5f81\u4e2d\u51fa\u73b0\u4e86\u6709\u610f\u4e49\u7684\u7ec4\u5408\u7ed3\u6784\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u8bed\u4e49\u7ec4\u5408\u6269\u6563\u53d8\u6362\u5668\u4e0d\u4ec5\u80fd\u591f\u5728\u6709\u9650\u7684\u4efb\u52a1\u5b50\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd8\u80fd\u5bf9\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u7ec4\u5408\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e00\u79cd\u8fed\u4ee3\u81ea\u6211\u6539\u8fdb\u7684\u8fc7\u7a0b\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u8868\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u673a\u5668\u4eba\u4efb\u52a1\u65f6\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.10934", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10934", "abs": "https://arxiv.org/abs/2512.10934", "authors": ["Zamirddine Mari", "J\u00e9r\u00f4me Pasquet", "Julien Seinturier"], "title": "Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit", "comment": null, "summary": "Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics.\n  The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4f7f\u65e0\u4eba\u673a\u80fd\u591f\u5728\u672a\u77e5\u7684\u4e09\u7ef4\u7ba1\u9053\u4e2d\u5bfc\u822a\u3002\u901a\u8fc7\u7ed3\u5408LiDAR\u548c\u7ba1\u9053\u4e2d\u5fc3\u7684\u89c6\u89c9\u68c0\u6d4b\uff0c\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u4efb\u4f55\u51e0\u4f55\u4fe1\u606f\u9884\u77e5\uff0c\u5e76\u4e14\u5728\u9ad8\u903c\u771f\u5ea63D\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4f9d\u8d56\u4e8e\u660e\u786e\u51e0\u4f55\u6a21\u578b\u7684\u4f20\u7edf\u7b97\u6cd5\u3002", "motivation": "\u7531\u4e8e\u7ba1\u9053\u53d7\u9650\u7684\u51e0\u4f55\u5f62\u72b6\u3001\u5899\u58c1\u7684\u63a5\u8fd1\u4ee5\u53ca\u611f\u77e5\u9650\u5236\uff0c\u5728\u72ed\u7a84\u7ba1\u72b6\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u65e0\u4eba\u673a\u5bfc\u822a\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u56f0\u96be\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u6ca1\u6709\u4e8b\u5148\u4e86\u89e3\u5176\u51e0\u4f55\u7ed3\u6784\u7684\u60c5\u51b5\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ec5\u4f9d\u8d56\u5c40\u90e8\u89c2\u5bdf\uff08\u5982LiDAR\uff09\u548c\u6761\u4ef6\u6027\u89c6\u89c9\u8bc6\u522b\u7ba1\u9053\u4e2d\u5fc3\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u8bad\u7ec3\u65e0\u4eba\u673a\uff0c\u4f7f\u5176\u80fd\u591f\u6839\u636e\u672c\u5730\u4f20\u611f\u5668\u6570\u636e\uff08\u5305\u62ecLiDAR\u53ca\u5bf9\u7ba1\u9053\u4e2d\u5fc3\u70b9\u7684\u89c6\u89c9\u68c0\u6d4b\uff09\u81ea\u4e3b\u5bfc\u822a\u672a\u77e5\u4e09\u7ef4\u7ba1\u9053\u3002\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b9e\u65bd\u4e86\u6e10\u8fdb\u5f0f\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u9010\u6b65\u589e\u52a0\u66f2\u7387\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u63a5\u53ef\u89c1\u6027\u3001\u65b9\u5411\u8bb0\u5fc6\u4e0eLiDAR\u5bf9\u79f0\u7ebf\u7d22\u76f8\u7ed3\u5408\u7684\u8f6c\u5f2f\u534f\u5546\u673a\u5236\u4ee5\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u60c5\u51b5\u4e0b\u7684\u7a33\u5b9a\u5bfc\u822a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cPPO\u7b56\u7565\u5b66\u4f1a\u4e86\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u7684\u98de\u884c\u884c\u4e3a\uff0c\u5373\u4f7f\u5728\u6709\u9650\u83b7\u53d6\u51e0\u4f55\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u4e5f\u59cb\u7ec8\u4f18\u4e8e\u786e\u5b9a\u6027\u63a7\u5236\u5668\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u5728\u9ad8\u4fdd\u771f3D\u73af\u5883\u4e0b\u9a8c\u8bc1\u4e86\u6240\u5b66\u884c\u4e3a\u5411\u8fde\u7eed\u7269\u7406\u52a8\u529b\u5b66\u8fc1\u79fb\u7684\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u672a\u77e5\u7ba1\u72b6\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6846\u67b6\uff0c\u5e76\u4e3a\u5de5\u4e1a\u3001\u5730\u4e0b\u6216\u533b\u7597\u5e94\u7528\u4e2d\u7a7f\u8d8a\u72ed\u7a84\u4e14\u611f\u77e5\u80fd\u529b\u8f83\u5f31\u7684\u901a\u9053\u5f00\u8f9f\u4e86\u524d\u666f\u3002"}}
{"id": "2512.10946", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10946", "abs": "https://arxiv.org/abs/2512.10946", "authors": ["Wendi Chen", "Han Xue", "Yi Wang", "Fangyuan Zhou", "Jun Lv", "Yang Jin", "Shirun Tang", "Chuan Wen", "Cewu Lu"], "title": "ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning", "comment": "Project page: https://implicit-rdp.github.io", "summary": "Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aImplicitRDP\u7684\u89c6\u89c9-\u529b\u6269\u6563\u7b56\u7565\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6162\u901f-\u5feb\u901f\u5b66\u4e60\u673a\u5236\u548c\u57fa\u4e8e\u865a\u62df\u76ee\u6807\u7684\u8868\u793a\u6b63\u5219\u5316\u6280\u672f\uff0c\u6709\u6548\u6574\u5408\u4e86\u89c6\u89c9\u89c4\u5212\u4e0e\u53cd\u5e94\u5f0f\u529b\u63a7\u5236\uff0c\u4ece\u800c\u5728\u63a5\u89e6\u4e30\u5bcc\u7684\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u89c6\u89c9\u6216\u5206\u5c42\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4eba\u7c7b\u7ea7\u522b\u7684\u63a5\u89e6\u4e30\u5bcc\u64cd\u4f5c\u4f9d\u8d56\u4e8e\u89c6\u89c9\u548c\u529b\u611f\u6d4b\u4e24\u79cd\u5173\u952e\u6a21\u6001\uff0c\u4f46\u5b83\u4eec\u4e4b\u95f4\u5b58\u5728\u9891\u7387\u548c\u4fe1\u606f\u4e0a\u7684\u6839\u672c\u5dee\u5f02\uff0c\u4f7f\u5f97\u4fe1\u53f7\u6574\u5408\u53d8\u5f97\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u5145\u5206\u5229\u7528\u8fd9\u4e24\u79cd\u6a21\u6001\u7684\u4f18\u70b9\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7aef\u5230\u7aef\u7684\u89c6\u89c9-\u529b\u6269\u6563\u7b56\u7565\u6846\u67b6ImplicitRDP\uff0c\u8be5\u6846\u67b6\u5229\u7528\u7ed3\u6784\u5316\u6162\u901f-\u5feb\u901f\u5b66\u4e60\u673a\u5236\u6765\u5904\u7406\u5f02\u6b65\u89c6\u89c9\u4e0e\u529b\u4ee4\u724c\uff0c\u540c\u65f6\u5f15\u5165\u57fa\u4e8e\u865a\u62df\u76ee\u6807\u7684\u8868\u793a\u6b63\u5219\u5316\u4ee5\u9632\u6b62\u6a21\u6001\u5d29\u6e83\uff0c\u52a0\u5f3a\u7269\u7406\u57fa\u7840\u7684\u5b66\u4e60\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u63a5\u89e6\u4e30\u5bcc\u7684\u4efb\u52a1\u4e0a\uff0cImplicitRDP\u76f8\u6bd4\u7eaf\u89c6\u89c9\u6216\u5206\u5c42\u57fa\u7ebf\u65b9\u6cd5\u5c55\u73b0\u4e86\u66f4\u597d\u7684\u53cd\u5e94\u6027\u548c\u6210\u529f\u7387\uff0c\u4e14\u8bad\u7ec3\u6d41\u7a0b\u66f4\u52a0\u7b80\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5de7\u5999\u5730\u7ed3\u5408\u89c6\u89c9\u4e0e\u89e6\u89c9\u4fe1\u606f\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8\u673a\u5668\u4eba\u5728\u63a5\u89e6\u5bc6\u96c6\u578b\u64cd\u4f5c\u4e2d\u7684\u6027\u80fd\u3002\u63d0\u51fa\u7684ImplicitRDP\u4e0d\u4ec5\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u6311\u6218\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
