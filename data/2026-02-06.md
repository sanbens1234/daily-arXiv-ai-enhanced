<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Signal or 'Noise': Human Reactions to Robot Errors in the Wild](https://arxiv.org/abs/2602.05010)
*Maia Stiber,Sameer Khan,Russell Taylor,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 研究了人们在现实世界中对非社交机器人错误的社会反应，特别是在重复和群体互动中。通过部署一个咖啡机器人，研究发现参与者在遇到错误时会表现出多样化且丰富的社会信号，但这些信号也较为'嘈杂'。


<details>
  <summary>Details</summary>
Motivation: 探索在真实世界的、尤其是与非社交机器人进行重复和群体互动的场景下，人们对于机器人错误的社会反应是否如实验室环境中一样可靠且有用。

Method: 构建了一个咖啡机器人，并在一个公共场合进行了实地部署实验（N=49）。观察并分析了参与者在面对机器人错误及其他刺激时所表现出的社会信号。

Result: 参与者们在面对错误及其它刺激时确实表现出了多样的社会信号，尤其是在群体互动过程中。这些社会信号丰富但同时也很'嘈杂'。

Conclusion: 即使是在与非社交机器人的交互中，人们依然会使用丰富但可能较难直接解读的社会信号来响应错误等事件。这对于理解如何在真实世界的人机交互中利用社会信号管理错误提供了见解。

Abstract: In the real world, robots frequently make errors, yet little is known about people's social responses to errors outside of lab settings. Prior work has shown that social signals are reliable and useful for error management in constrained interactions, but it is unclear if this holds in the real world - especially with a non-social robot in repeated and group interactions with successive or propagated errors. To explore this, we built a coffee robot and conducted a public field deployment ($N = 49$). We found that participants consistently expressed varied social signals in response to errors and other stimuli, particularly during group interactions. Our findings suggest that social signals in the wild are rich (with participants volunteering information about the interaction), but "noisy." We discuss lessons, benefits, and challenges for using social signals in real-world HRI.

</details>


### [2] [Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping](https://arxiv.org/abs/2602.05029)
*Octavio Arriaga,Proneet Sharma,Jichen Guo,Marc Otto,Siddhant Kadwe,Rebecca Adam*

Main category: cs.RO

TL;DR: 本文提出了一种结合神经基础模型和基于物理的可微渲染的可微神经图形模型，能够从单个RGBD图像和边界框中估计出未见过物体的物理一致场景参数，从而实现零样本场景重建和机器人抓取。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的模型通过使用大量训练数据和测试时样本构建黑匣子场景表示来解决在新环境中有效操作的挑战。本研究旨在不依赖额外3D数据或测试时样本的情况下，进行零样本场景重建和机器人抓取，以提高机器人在新环境中的自主性、效率以及泛化能力。

Method: 引入了一个可微神经图形模型，该模型将神经基础模型与基于物理的可微渲染相结合，用于从单个RGBD图像和边界框估计先前未见物体的网格、光照条件、材质属性及其6D位姿等物理一致场景参数。方法涉及求解一系列约束优化问题。

Result: 所提方法在标准无模型少样本基准上进行了评估，并证明了其在无模型少样本姿态估计方面优于现有算法。此外，还通过将其应用于零样本抓取任务验证了场景重建的准确性。

Conclusion: 该方法为不需要依赖大量数据集或测试时采样的零样本、物理一致场景重建和抓取提供了可能性，指出了通向更高效、可解释且泛化的机器人在新环境下的自主性的路径。

Abstract: Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In this work, we introduce a differentiable neuro-graphics model that combines neural foundation models with physics-based differentiable rendering to perform zero-shot scene reconstruction and robot grasping without relying on any additional 3D data or test-time samples. Our model solves a series of constrained optimization problems to estimate physically consistent scene parameters, such as meshes, lighting conditions, material properties, and 6D poses of previously unseen objects from a single RGBD image and bounding boxes. We evaluated our approach on standard model-free few-shot benchmarks and demonstrated that it outperforms existing algorithms for model-free few-shot pose estimation. Furthermore, we validated the accuracy of our scene reconstructions by applying our algorithm to a zero-shot grasping task. By enabling zero-shot, physically-consistent scene reconstruction and grasping without reliance on extensive datasets or test-time sampling, our approach offers a pathway towards more data efficient, interpretable and generalizable robot autonomy in novel environments.

</details>


### [3] [Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking](https://arxiv.org/abs/2602.05079)
*Vinal Asodia,Iman Sharifi,Saber Fallah*

Main category: cs.RO

TL;DR: 本文提出了一种新的神经符号特征表示方法和软一阶逻辑奖励函数，以解决基于摄像头的深度强化学习方法中存在的问题。实验结果表明，该方法在提高策略鲁棒性和与安全相关的性能指标方面优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于摄像头的深度强化forcement学习方法很少将高层次的场景上下文整合到特征表示中，并且依赖于僵化、固定的奖励函数。为了解决这些问题，提出了一个新颖的管道来生成包含语义、空间和形状信息以及动态实体的空间增强特性的神经符号特征表示，并引入了软一阶逻辑（SFOL）奖励函数，通过符号推理模块平衡人类价值观。

Method: 通过从分割图中提取语义和空间谓词，并将其应用于语言规则以获得奖励权重，构建了一个能够产生包含语义、空间、形状信息及场景内动态实体的空间增强特征的神经符号特征表示的新颖流程。此外，还设计了一个软一阶逻辑(SFOL)奖励函数，旨在通过符号推理模块来平衡人的价值观念。

Result: 在CARLA仿真环境中进行的定量实验证明，所提出的神经符号表示法和SFOL奖励函数相较于基准表示法和奖励公式，在不同交通密度和遮挡水平下均能改善策略稳健性及相关安全性能指标。

Conclusion: 研究发现表明，将全面的表示方法和软推理机制融入强化学习中可以支持更加情境感知和价值观一致的自动驾驶决策制定。

Abstract: The problem with existing camera-based Deep Reinforcement Learning approaches is twofold: they rarely integrate high-level scene context into the feature representation, and they rely on rigid, fixed reward functions. To address these challenges, this paper proposes a novel pipeline that produces a neuro-symbolic feature representation that encompasses semantic, spatial, and shape information, as well as spatially boosted features of dynamic entities in the scene, with an emphasis on safety-critical road users. It also proposes a Soft First-Order Logic (SFOL) reward function that balances human values via a symbolic reasoning module. Here, semantic and spatial predicates are extracted from segmentation maps and applied to linguistic rules to obtain reward weights. Quantitative experiments in the CARLA simulation environment show that the proposed neuro-symbolic representation and SFOL reward function improved policy robustness and safety-related performance metrics compared to baseline representations and reward formulations across varying traffic densities and occlusion levels. The findings demonstrate that integrating holistic representations and soft reasoning into Reinforcement Learning can support more context-aware and value-aligned decision-making for autonomous driving.

</details>


### [4] [A Framework for Combining Optimization-Based and Analytic Inverse Kinematics](https://arxiv.org/abs/2602.05092)
*Thomas Cohn,Lihan Tang,Alexandre Amice,Russ Tedrake*

Main category: cs.RO

TL;DR: 提出了一种新的优化IK公式，通过将解析IK解作为变量替换来简化问题，从而提高了在各种挑战性IK问题（如碰撞避免、抓取选择和人形稳定性）中的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的解析和优化方法在解决逆运动学问题上各有优缺点，而结合两者优势的统一方法开发起来颇具挑战。特别是对于优化方法来说，关节角度与末端执行器姿态之间的复杂非线性关系以及额外的非凸约束条件如避碰，会导致高失败率。

Method: 研究者们提出了一种新颖的优化IK公式，该公式利用了解析IK解决方案作为变量替换，并且从根本上更易于被优化器求解。这一新方法在三种流行的求解器上进行了测试，这些求解器代表了约束非线性优化的三种不同范式。

Result: 实验比较表明，这种新配方在各种具有挑战性的IK问题上比旧配方及基线方法获得了更高的成功率，这些问题包括但不限于避碰、抓取选择和人形机器人的稳定性。

Conclusion: 这项工作展示了一种有效的方法，通过将解析解整合进优化过程中，以提高逆运动学问题解决方案的成功率和效率，特别是在处理复杂的非线性关系和附加约束时。

Abstract: Analytic and optimization methods for solving inverse kinematics (IK) problems have been deeply studied throughout the history of robotics. The two strategies have complementary strengths and weaknesses, but developing a unified approach to take advantage of both methods has proved challenging. A key challenge faced by optimization approaches is the complicated nonlinear relationship between the joint angles and the end-effector pose. When this must be handled concurrently with additional nonconvex constraints like collision avoidance, optimization IK algorithms may suffer high failure rates. We present a new formulation for optimization IK that uses an analytic IK solution as a change of variables, and is fundamentally easier for optimizers to solve. We test our methodology on three popular solvers, representing three different paradigms for constrained nonlinear optimization. Extensive experimental comparisons demonstrate that our new formulation achieves higher success rates than the old formulation and baseline methods across various challenging IK problems, including collision avoidance, grasp selection, and humanoid stability.

</details>


### [5] [PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation](https://arxiv.org/abs/2602.05156)
*Dong Ho Kang,Aaron Kim,Mingyo Seo,Kazuto Yokoyama,Tetsuya Narita,Luis Sentis*

Main category: cs.RO

TL;DR: 介绍了PLATO Hand，一种具有混合指尖设计的灵巧机器人手，该设计结合了刚性指甲和柔顺指腹，以适应不同物体几何形状的多样化交互模式。


<details>
  <summary>Details</summary>
Motivation: 为了实现对各种物体几何形状的精确操作，研究者们开发了一种新型的机器人手设计，其特点是混合指尖，即在柔顺的指腹中嵌入刚性指甲，从而改善抓握稳定性、力的可观察性和边缘敏感型操作任务的表现。

Method: 采用基于应变能的弯曲-压痕模型来指导指尖的设计，并解释引导接触如何保持局部压痕同时抑制整体弯曲。通过实验测试了该设计在捏合稳定性、力的可观察性以及纸张分离、卡片拾取和剥橙子等边缘敏感型操作任务中的表现。

Result: 实验结果表明，所提出的机器人手设计在捏合稳定性、力的可观察性方面有所改进，并且成功完成了如纸张分离、卡片拾取及剥橙子等对边缘敏感的操作任务。

Conclusion: 结合结构化的接触几何与力-运动透明机制提供了一个有原则的、物理体现的方法来进行精确操作，这标志着向更加灵活可靠的机器人手发展迈出的重要一步。

Abstract: We present the PLATO Hand, a dexterous robotic hand with a hybrid fingertip that embeds a rigid fingernail within a compliant pulp. This design shapes contact behavior to enable diverse interaction modes across a range of object geometries. We develop a strain-energy-based bending-indentation model to guide the fingertip design and to explain how guided contact preserves local indentation while suppressing global bending. Experimental results show that the proposed robotic hand design demonstrates improved pinching stability, enhanced force observability, and successful execution of edge-sensitive manipulation tasks, including paper singulation, card picking, and orange peeling. Together, these results show that coupling structured contact geometry with a force-motion transparent mechanism provides a principled, physically embodied approach to precise manipulation.

</details>


### [6] [Informative Path Planning with Guaranteed Estimation Uncertainty](https://arxiv.org/abs/2602.05198)
*Kalvik Jakkala,Saurav Agarwal,Jason O'Kane,Srinivas Akella*

Main category: cs.RO

TL;DR: 本文提出了一种三阶段方法，通过学习GP模型、转换为二进制覆盖图以及规划最短路径来确保环境监测机器人的空间场重建在用户指定的不确定性阈值下，同时减少了采样位置和行进距离。


<details>
  <summary>Details</summary>
Motivation: 环境监测机器人在进行空间场（如盐度、温度、测深）重建时面临着距离和能源的限制。传统的往返式割草机调查虽然提供了几何覆盖保证，但可能会因为过度采样可预测区域而浪费努力。相比之下，信息路径规划(IPP)方法利用空间相关性减少过度采样，但通常不提供重建质量的保证。因此，需要一种既能利用空间相关性又能在重建质量上提供保障的方法。

Method: 该论文提出了一种三阶段方法：首先从可用的先验信息中学习一个GP模型；接着将学到的GP核转化为每个候选传感位置的二进制覆盖图，显示哪些位置的不确定性可以降低到特定目标之下；最后规划一条近似最短路径，其组合覆盖满足全局不确定性约束。此外，还引入了非平稳核以捕捉空间变化的相关结构，并适应存在障碍物的非凸环境。

Result: 实验表明，与最近的基线相比，所提出的规划器使用更少的传感位置和更短的行进距离就能达到不确定性目标。实地实验进一步证明了该方法在真实世界中的可行性，特别是在地形测绘自主水面及水下航行器上的应用。

Conclusion: 本研究成功地结合了几何覆盖保证和信息路径规划的优势，开发出一种能够有效减少过度采样并确保重建质量的新方法。这种方法不仅适用于多种环境条件下的环境监测任务，而且具有实际应用价值。

Abstract: Environmental monitoring robots often need to reconstruct spatial fields (e.g., salinity, temperature, bathymetry) under tight distance and energy constraints. Classical boustrophedon lawnmower surveys provide geometric coverage guarantees but can waste effort by oversampling predictable regions. In contrast, informative path planning (IPP) methods leverage spatial correlations to reduce oversampling, yet typically offer no guarantees on reconstruction quality. This paper bridges these approaches by addressing informative path planning with guaranteed estimation uncertainty: computing the shortest path whose measurements ensure that the Gaussian-process (GP) posterior variance -- an intrinsic uncertainty measure that lower-bounds the mean-squared prediction error under the GP model -- falls below a user-specified threshold over the monitoring region.
  We propose a three-stage approach: (i) learn a GP model from available prior information; (ii) transform the learned GP kernel into binary coverage maps for each candidate sensing location, indicating which locations' uncertainty can be reduced below a specified target; and (iii) plan a near-shortest route whose combined coverage satisfies the global uncertainty constraint. To address heterogeneous phenomena, we incorporate a nonstationary kernel that captures spatially varying correlation structure, and we accommodate non-convex environments with obstacles. Algorithmically, we present methods with provable approximation guarantees for sensing-location selection and for the joint selection-and-routing problem under a travel budget. Experiments on real-world topographic data show that our planners meet the uncertainty target using fewer sensing locations and shorter travel distances than a recent baseline, and field experiments with bathymetry-mapping autonomous surface and underwater vehicles demonstrate real-world feasibility.

</details>


### [7] [MobileManiBench: Simplifying Model Verification for Mobile Manipulation](https://arxiv.org/abs/2602.05233)
*Wenbo Wang,Fangyun Wei,QiXiu Li,Xi Chen,Yaobo Liang,Chang Xu,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 提出了一个基于模拟的框架MobileManiBench，用于在真实世界部署前验证视觉-语言-动作模型，并通过强化学习自动生成多样化的操作轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型依赖于大量远程操作收集的数据集，这些数据集主要由静态桌面场景组成，限制了机器人操控的发展。

Method: 创建了一个名为MobileManiBench的大规模基准测试平台，支持两个移动平台（平行夹爪和灵巧手机器人），使用NVIDIA Isaac Sim和强化学习技术自动生成带有丰富注释的操作轨迹。

Result: 该平台能够执行超过100项任务，涵盖5种技能，在100个现实场景中生成30万个轨迹，为研究感知、推理和控制提供了宝贵见解。

Conclusion: 通过提供一个可控且可扩展的研究平台，加速了对于数据效率和泛化能力的研究，有助于推动机器人操控领域的发展。

Abstract: Vision-language-action models have advanced robotic manipulation but remain constrained by reliance on the large, teleoperation-collected datasets dominated by the static, tabletop scenes. We propose a simulation-first framework to verify VLA architectures before real-world deployment and introduce MobileManiBench, a large-scale benchmark for mobile-based robotic manipulation. Built on NVIDIA Isaac Sim and powered by reinforcement learning, our pipeline autonomously generates diverse manipulation trajectories with rich annotations (language instructions, multi-view RGB-depth-segmentation images, synchronized object/robot states and actions). MobileManiBench features 2 mobile platforms (parallel-gripper and dexterous-hand robots), 2 synchronized cameras (head and right wrist), 630 objects in 20 categories, 5 skills (open, close, pull, push, pick) with over 100 tasks performed in 100 realistic scenes, yielding 300K trajectories. This design enables controlled, scalable studies of robot embodiments, sensing modalities, and policy architectures, accelerating research on data efficiency and generalization. We benchmark representative VLA models and report insights into perception, reasoning, and control in complex simulated environments.

</details>


### [8] [Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot](https://arxiv.org/abs/2602.05265)
*Kalvik Jakkala,Jason O'Kane*

Main category: cs.RO

TL;DR: 本文提出了一种基于最少传感器策略的水下自主检测方法，使自由游动的水下机器人能够仅使用IMU、压力传感器和两个声呐（一个向下发射的单波束声呐和一个旋转360度声呐）在已知半径的淹没管道中居中并行进。通过实验验证了该系统能够在环境流速及结构变形的情况下实现稳定的居中和全管穿越。


<details>
  <summary>Details</summary>
Motivation: 由于受限的几何形状、浑浊度以及可靠的定位线索稀缺，对淹没管道进行自主水下检查是具有挑战性的。因此，需要一种能有效利用有限传感设备的方法来完成此类任务。

Method: 开发了一种计算效率高的方法，从单波束声呐强度数据中提取距离估计值，从而能够在嘈杂和反射条件下可靠地检测到墙壁。结合两种声呐的距离信息建立了一个闭式几何模型以估计管道中心，并采用自适应的信心加权比例-微分(PD)控制器保持穿越过程中的对齐。整个系统无需多普勒速度记录仪、外部跟踪或复杂的多传感器阵列。

Result: 在直径为46厘米的淹没管道内，利用Blue Robotics BlueROV2重型遥控车辆进行了实验，证明了即使存在环境流动和结构变形，该系统仍可实现稳定居中及成功全程穿越。

Conclusion: 结果表明，依靠轻量级且计算高效的感知与处理架构，可以在封闭环境中实现可靠的管道内导航与检查，这推动了自主水下检查的实际应用可能性。

Abstract: Autonomous underwater inspection of submerged pipelines is challenging due to confined geometries, turbidity, and the scarcity of reliable localization cues. This paper presents a minimal-sensing strategy that enables a free-swimming underwater robot to center itself and traverse a flooded pipe of known radius using only an IMU, a pressure sensor, and two sonars: a downward-facing single-beam sonar and a rotating 360 degree sonar. We introduce a computationally efficient method for extracting range estimates from single-beam sonar intensity data, enabling reliable wall detection in noisy and reverberant conditions. A closed-form geometric model leverages the two sonar ranges to estimate the pipe center, and an adaptive, confidence-weighted proportional-derivative (PD) controller maintains alignment during traversal. The system requires no Doppler velocity log, external tracking, or complex multi-sensor arrays. Experiments in a submerged 46 cm-diameter pipe using a Blue Robotics BlueROV2 heavy remotely operated vehicle demonstrate stable centering and successful full-pipe traversal despite ambient flow and structural deformations. These results show that reliable in-pipe navigation and inspection can be achieved with a lightweight, computationally efficient sensing and processing architecture, advancing the practicality of autonomous underwater inspection in confined environments.

</details>


### [9] [Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions](https://arxiv.org/abs/2602.05273)
*Hengxuan Xu,Fengbo Lan,Zhixin Zhao,Shengjie Wang,Mengqiao Liu,Jieqian Sun,Yu Cheng,Tao Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为AIDE的双流框架，结合了交互式探索和视觉-语言推理，以解决机器人在模糊指令下识别任务相关物体的挑战。该方法在模拟和真实环境中的实验表明，在不同开放场景中执行任务的成功率超过80%，并且在10Hz下的闭环连续执行准确度超过95%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉-语言模型的方法在根据模糊的人类指令使机器人能够在不熟悉的环境中探索并采取行动方面存在不足，主要原因是推理效率低下以及缺乏与环境的互动，这阻碍了实时任务规划和执行。

Method: 提出了Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE)，一个整合了交互式探索与视觉-语言推理的双流架构。其中，多阶段推理(MSI)作为决策流，加速决策(ADM)作为执行流，支持零样本功能分析及对模糊指示的理解。

Result: 广泛的仿真和现实世界环境测试显示，AIDE在多样化开放场景中的任务规划成功率超过了80%，并在10赫兹频率下实现超过95%的闭环持续执行精度，优于当前基于VLM的方法。

Conclusion: 通过引入AIDE框架，研究有效地解决了机器人在处理含糊指令时识别任务相关对象的问题，提高了任务规划与执行的效率和准确性。

Abstract: Enabling robots to explore and act in unfamiliar environments under ambiguous human instructions by interactively identifying task-relevant objects (e.g., identifying cups or beverages for "I'm thirsty") remains challenging for existing vision-language model (VLM)-based methods. This challenge stems from inefficient reasoning and the lack of environmental interaction, which hinder real-time task planning and execution. To address this, We propose Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE), a dual-stream framework that integrates interactive exploration with vision-language reasoning, where Multi-Stage Inference (MSI) serves as the decision-making stream and Accelerated Decision-Making (ADM) as the execution stream, enabling zero-shot affordance analysis and interpretation of ambiguous instructions. Extensive experiments in simulation and real-world environments show that AIDE achieves the task planning success rate of over 80\% and more than 95\% accuracy in closed-loop continuous execution at 10 Hz, outperforming existing VLM-based methods in diverse open-world scenarios.

</details>


### [10] [Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework](https://arxiv.org/abs/2602.05310)
*Jipeng Kong,Xinzhe Liu,Yuhang Lin,Jinrui Han,Sören Schwertfeger,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 本文提出了一种名为PAiD的渐进式架构，用于解决人形机器人在足球技能学习中的感知-动作集成问题。通过将技能学习分解为三个阶段：基于人体运动跟踪的动作技能获取、轻量级感知-动作集成以实现位置泛化以及物理感知仿真到现实世界的迁移，该方法提高了技能学习的稳定性和适应性。实验表明，在Unitree G1机器人上实现了高保真度的人类踢球行为，并且在多种条件下表现出稳健性能。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人参与足球运动面临的主要挑战包括模块间不稳定性和端到端框架中训练目标冲突等问题。为了克服这些问题并开发出更加高效稳定的解决方案，作者提出了PAiD架构。

Method: PAiD架构采用分阶段策略来解决足球技能的学习问题，具体分为：通过人类动作追踪获得基本动作技能；利用轻量级感知-动作整合促进位置上的泛化能力；并通过物理意识的模拟到真实环境转换减少仿真与实际之间的差距。

Result: 研究结果表明，使用PAiD架构可以在Unitree G1机器人平台上实现高质量的人类踢球模仿，并且在不同场景下（如静态或滚动球体、各种位置及干扰因素）均能保持一致性的表现。此外，该方案还支持从室内到室外环境的应用扩展。

Conclusion: 本研究提出的PAiD架构不仅为人形机器人提供了更为可靠和高效的足球技能学习途径，同时也为复杂具身技能的学习提供了一个可扩展的方法论。

Abstract: Soccer presents a significant challenge for humanoid robots, demanding tightly integrated perception-action capabilities for tasks like perception-guided kicking and whole-body balance control. Existing approaches suffer from inter-module instability in modular pipelines or conflicting training objectives in end-to-end frameworks. We propose Perception-Action integrated Decision-making (PAiD), a progressive architecture that decomposes soccer skill acquisition into three stages: motion-skill acquisition via human motion tracking, lightweight perception-action integration for positional generalization, and physics-aware sim-to-real transfer. This staged decomposition establishes stable foundational skills, avoids reward conflicts during perception integration, and minimizes sim-to-real gaps. Experiments on the Unitree G1 demonstrate high-fidelity human-like kicking with robust performance under diverse conditions-including static or rolling balls, various positions, and disturbances-while maintaining consistent execution across indoor and outdoor scenarios. Our divide-and-conquer strategy advances robust humanoid soccer capabilities and offers a scalable framework for complex embodied skill acquisition. The project page is available at https://soccer-humanoid.github.io/.

</details>


### [11] [RoboPaint: From Human Demonstration to Any Robot and Any View](https://arxiv.org/abs/2602.05325)
*Jiacheng Fan,Zhiyue Zhao,Yiqian Zhang,Chao Chen,Peide Wang,Hengdi Zhang,Zhengxue Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种Real-Sim-Real数据收集和编辑流程，将人类演示转换为机器人可执行的特定环境训练数据，无需直接遥控操作。通过标准化的数据收集室来捕获多模态的人类演示，并引入一种触觉感知重定向方法，将人手状态映射到机器人dex-hand状态。实验证明了这种方法的有效性，提供了一种成本效益高且性能损失小的解决方案。


<details>
  <summary>Details</summary>
Motivation: 获取大规模、高保真的机器人演示数据是扩展视觉-语言-动作（VLA）模型在灵巧操作领域中的关键瓶颈。

Method: 提出了一个Real-Sim-Real数据收集及编辑流程，该流程能够基于人类演示创建机器人可执行的特定环境训练数据，而无需直接进行机器人远程操作。首先，在标准化的数据采集室内录制多模式人类演示（同步3个RGB-D视频、11个RGB视频、29自由度手套关节角度以及14通道触觉信号）。接着，介绍了一种触觉感知重定位方法，利用几何与力导向优化技术将人类手部状态映射至机器人dex-hand状态。最后，将重新定位后的机器人轨迹渲染到照片级真实感的Isaac Sim环境中以构建机器人训练数据集。

Result: (1) 重新定位后的dex-hand轨迹在10种多样化的物体操控任务上达到了84%的成功率。(2) 完全使用生成的数据训练的VLA策略(Pi0.5) 在三个代表性任务（即拾取放置、推动物体和倾倒）上平均成功率为80%。

Conclusion: 通过我们的Real-Sim-Real数据流程，可以从人类演示中高效地“绘制”出机器人训练数据。我们提供的是一种对于复杂灵巧操作而言既具成本效益又能保持最小性能损失的替代方案。

Abstract: Acquiring large-scale, high-fidelity robot demonstration data remains a critical bottleneck for scaling Vision-Language-Action (VLA) models in dexterous manipulation. We propose a Real-Sim-Real data collection and data editing pipeline that transforms human demonstrations into robot-executable, environment-specific training data without direct robot teleoperation. Standardized data collection rooms are built to capture multimodal human demonstrations (synchronized 3 RGB-D videos, 11 RGB videos, 29-DoF glove joint angles, and 14-channel tactile signals). Based on these human demonstrations, we introduce a tactile-aware retargeting method that maps human hand states to robot dex-hand states via geometry and force-guided optimization. Then the retargeted robot trajectories are rendered in a photorealistic Isaac Sim environment to build robot training data. Real world experiments have demonstrated: (1) The retargeted dex-hand trajectories achieve an 84\% success rate across 10 diverse object manipulation tasks. (2) VLA policies (Pi0.5) trained exclusively on our generated data achieve 80\% average success rate on three representative tasks, i.e., pick-and-place, pushing and pouring. To conclude, robot training data can be efficiently "painted" from human demonstrations using our real-sim-real data pipeline. We offer a scalable, cost-effective alternative to teleoperation with minimal performance loss for complex dexterous manipulation.

</details>


### [12] [Benchmarking Affordance Generalization with BusyBox](https://arxiv.org/abs/2602.05441)
*Dean Fortier,Timothy Adamson,Tess Hellebrekers,Teresa LaScala,Kofi Ennin,Michael Murray,Andrey Kolobov,Galen Mullins*

Main category: cs.RO

TL;DR: 本文提出了BusyBox，一个用于系统地半自动评估视觉-语言-行动（VLA）模型在可操作性泛化方面能力的物理基准。BusyBox由6个模块组成，可以互换和旋转以创建多种变体，对现有的强开权重VLA模型构成了挑战。为了便于研究社区使用，提供了CAD文件、物料清单以及带注释的数据集，并开放了所有相关材料。


<details>
  <summary>Details</summary>
Motivation: 尽管单任务策略仍然提供有竞争力的表现，但VLA越来越能够处理训练集中未见过的指令和环境。VLA需要具备的关键元技能之一是可操作性泛化——即操纵具有熟悉物理特征的新对象的能力。目前，这一领域的评估基准还比较缺乏。

Method: 设计并构建了名为BusyBox的物理测试平台，该平台包括6个不同的互动模块，可通过交换和旋转这些模块来创建多种视觉外观不同但可操作性相同的BusyBox变体。此外，还为研究者们提供了CAD文件以便3D打印部件，物料清单用以组装电子元件，并发布了一个利用双手机器人收集的语言注释演示数据集。

Result: 实验证明，即使是对于像$π_{0.5}$和GR00T-N1.6这样的强大开权重VLA模型来说，在不同BusyBox变体之间实现泛化也是非常具有挑战性的。

Conclusion: 通过引入BusyBox作为评估工具，这项工作不仅突出了当前VLA模型在面对新物体时的可操作性泛化限制，同时也为未来的研究提供了宝贵的资源。

Abstract: Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their training set. While generalization in vision and language space is undoubtedly important for robust versatile behaviors, a key meta-skill VLAs need to possess is affordance generalization -- the ability to manipulate new objects with familiar physical features.
  In this work, we present BusyBox, a physical benchmark for systematic semi-automatic evaluation of VLAs' affordance generalization. BusyBox consists of 6 modules with switches, sliders, wires, buttons, a display, and a dial. The modules can be swapped and rotated to create a multitude of BusyBox variations with different visual appearances but the same set of affordances. We empirically demonstrate that generalization across BusyBox variants is highly challenging even for strong open-weights VLAs such as $π_{0.5}$ and GR00T-N1.6. To encourage the research community to evaluate their own VLAs on BusyBox and to propose new affordance generalization experiments, we have designed BusyBox to be easy to build in most robotics labs. We release the full set of CAD files for 3D-printing its parts as well as a bill of materials for (optionally) assembling its electronics. We also publish a dataset of language-annotated demonstrations that we collected using the common bimanual Mobile Aloha robot on the canonical BusyBox configuration. All of the released materials are available at https://microsoft.github.io/BusyBox.

</details>


### [13] [Ontology-Driven Robotic Specification Synthesis](https://arxiv.org/abs/2602.05456)
*Maksym Figat,Ryan M. Mackey,Michel D. Ingham*

Main category: cs.RO

TL;DR: 该论文提出了一种基于本体的层次化方法RSTM2，利用带资源的随机时间Petri网来支持机器人系统在关键任务中的安全性和任务执行能力。通过蒙特卡洛模拟实现架构权衡、资源配置及性能分析，并支持未来复杂多机器人系统的自主规范合成。


<details>
  <summary>Details</summary>
Motivation: 为了解决安全和任务关键应用中机器人系统工程从高层次目标到形式化可执行规范之间的差距问题。

Method: 提出了机器人系统任务到模型转换方法论（RSTM2），这是一种基于本体的层次化方法，使用了带资源的随机时间Petri网，允许在任务、系统以及子系统层面进行蒙特卡洛模拟。

Result: 通过一个假设案例研究展示了RSTM2方法如何支持架构决策、资源配置以及不确定性条件下的性能分析；同时，本体概念进一步促进了可解释的人工智能助手的发展，有助于完全自动化的规范合成。

Conclusion: RSTM2方法特别适用于像NASA CADRE任务这样的复杂多机器人系统，代表了未来去中心化、具备资源意识并能够适应环境变化的自治系统。

Abstract: This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.

</details>


### [14] [TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation](https://arxiv.org/abs/2602.05468)
*Pranav Ponnivalavan,Satoshi Funabashi,Alexander Schmitz,Tetsuya Ogata,Shigeki Sugano*

Main category: cs.RO

TL;DR: 本文介绍了一种名为TaSA的两阶段深度预测学习框架，通过学习自触觉动态并将其纳入运动学习阶段来强调物体接触信号，从而提高机器人灵巧操作的成功率。


<details>
  <summary>Details</summary>
Motivation: 目前，对于机器人手来说，实现如人类般多样的手持操作（例如捏物和使用工具）仍然是一项未解决的问题。这类灵活操作需要区分由自身接触产生的触觉感觉和外部接触引起的触觉感觉。忽略自我接触的传统方法虽然简化了问题，但限制了在不可避免地会发生自我接触的真实世界场景中的泛化能力。受人类通过预测机制克服这一挑战的启发，本研究旨在开发一种能有效处理自触觉信息的方法以增强机器人的操纵能力。

Method: 提出了TaSA（Tactile Sensory Attenuation）框架，它是一个两阶段的学习过程。第一阶段专注于学习自触觉动态，即机器人自身动作如何产生触觉反馈；第二阶段则将此模型应用于运动学习中，目的是在执行任务时突出与物体接触相关的信号。该方法基于感官衰减原理设计，允许系统区分可预见的自触感信号与其他重要刺激。

Result: 通过对一系列精细触觉分辨任务进行评估，包括铅笔芯插入自动铅笔、硬币投入槽口以及固定回形针到纸上等，结果显示，在所有测试任务中，采用TaSA训练的策略相较于基准方法取得了显著更高的成功率。这表明基于感官衰减原理构建的结构化触觉感知对于提升机器人灵巧操控至关重要。

Conclusion: 研究表明，通过引入模仿人类感知机制的TaSA框架，能够有效地区分自触觉信号与外部触觉信号，进而极大地提高了机器人完成复杂操纵任务的成功率。这为未来开发更加灵活且适应性强的机器人提供了新的思路和技术支持。

Abstract: Humans can achieve diverse in-hand manipulations, such as object pinching and tool use, which often involve simultaneous contact between the object and multiple fingers. This is still an open issue for robotic hands because such dexterous manipulation requires distinguishing between tactile sensations generated by their self-contact and those arising from external contact. Otherwise, object/robot breakage happens due to contacts/collisions. Indeed, most approaches ignore self-contact altogether, by constraining motion to avoid/ignore self-tactile information during contact. While this reduces complexity, it also limits generalization to real-world scenarios where self-contact is inevitable. Humans overcome this challenge through self-touch perception, using predictive mechanisms that anticipate the tactile consequences of their own motion, through a principle called sensory attenuation, where the nervous system differentiates predictable self-touch signals, allowing novel object stimuli to stand out as relevant. Deriving from this, we introduce TaSA, a two-phased deep predictive learning framework. In the first phase, TaSA explicitly learns self-touch dynamics, modeling how a robot's own actions generate tactile feedback. In the second phase, this learned model is incorporated into the motion learning phase, to emphasize object contact signals during manipulation. We evaluate TaSA on a set of insertion tasks, which demand fine tactile discrimination: inserting a pencil lead into a mechanical pencil, inserting coins into a slot, and fixing a paper clip onto a sheet of paper, with various orientations, positions, and sizes. Across all tasks, policies trained with TaSA achieve significantly higher success rates than baseline methods, demonstrating that structured tactile perception with self-touch based on sensory attenuation is critical for dexterous robotic manipulation.

</details>


### [15] [DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter](https://arxiv.org/abs/2602.05513)
*Xukun Li,Yu Sun,Lei Zhang,Bosheng Huang,Yibo Peng,Yuan Meng,Haojun Jiang,Shaoxuan Xie,Guacai Yao,Alois Knoll,Zhenshan Bing,Xinlong Wang,Zhenguo Sun*

Main category: cs.RO

TL;DR: 提出了DECO框架，这是一种基于DiT的策略，能够解耦多模态条件。通过联合自注意力机制处理图像和动作令牌的交互，而本体感觉状态和可选条件则通过自适应层归一化注入。触觉信号通过交叉注意力机制注入，并使用轻量级的LoRA适配器对预训练策略进行高效微调。此外，还推出了DECO-50数据集，用于双手机巧操作任务，包含4个场景28个子任务，超过50小时的数据记录，约5百万帧，以及8,000条成功轨迹。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效处理多模态输入（如图像、动作、本体感觉及触觉信息）的策略，以改进机器人在复杂环境下的灵巧操作能力。

Method: 设计了一种名为DECO的新框架，该框架基于DiT（Diverse Information Transformer），并通过不同的机制来处理不同类型的输入：图像与动作令牌之间采用联合自注意力；本体感受态和额外条件通过自适应层标准化加入；触觉信号则是经由跨注意力机制整合。为提高预训练模型适应特定任务的能力，引入了基于LoRA（Low-Rank Adaptation）的方法来进行微调。

Result: DECO框架不仅提供了处理多样化输入的有效手段，而且通过配套的DECO-50数据集进一步验证了其在双手机巧操作任务上的潜力。这个数据集覆盖了广泛的场景和子任务，为研究者们提供了一个丰富的测试平台。

Conclusion: DECO框架及其伴随的DECO-50数据集代表了向更加灵活且适应性强的机器人操控系统迈进的重要一步。它们共同促进了机器人在面对包含多种感官信息的任务时的表现。

Abstract: Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected via cross attention, while a lightweight LoRA-based adapter is used to efficiently fine-tune the pretrained policy. DECO is also accompanied by DECO-50, a bimanual dexterous manipulation dataset with tactile sensing, consisting of 4 scenarios and 28 sub-tasks, covering more than 50 hours of data, approximately 5 million frames, and 8,000 successful trajectories.

</details>


### [16] [Virtual-Tube-Based Cooperative Transport Control for Multi-UAV Systems in Constrained Environments](https://arxiv.org/abs/2602.05516)
*Runxiao Liu,Pengda Mao,Xiangli Le,Shuang Gu,Yapeng Chen,Quan Quan*

Main category: cs.RO

TL;DR: 提出了一种基于虚拟管理论和耗散系统理论的新型控制框架，用于多无人机在受限环境中协同运输悬吊负载。该框架计算开销小，能动态调整无人机配置以适应障碍布局，并确保了高稳定性和鲁棒性。通过大量仿真及户外实验验证了其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 为了提高多无人机在复杂且充满障碍物的环境下协同运输悬吊负载的能力，同时保持系统的高效、稳定和鲁棒性。

Method: 采用虚拟管理论和耗散系统理论相结合的方法，设计出一种新的控制框架，该框架能够实现低计算量下的张力分布与协调运输，并根据障碍物布局动态调整无人机配置。

Result: 所提方法通过广泛的仿真测试显示了其可扩展性，适用于大规模多无人机系统；并且在户外实际场景中的实验进一步证明了该方法在现实条件下的可行性和鲁棒性。

Conclusion: 本文提出的控制框架为多无人机在受限环境中的协同运输任务提供了一个高效稳定的解决方案，具有良好的实用价值和发展前景。

Abstract: This paper proposes a novel control framework for cooperative transportation of cable-suspended loads by multiple unmanned aerial vehicles (UAVs) operating in constrained environments. Leveraging virtual tube theory and principles from dissipative systems theory, the framework facilitates efficient multi-UAV collaboration for navigating obstacle-rich areas. The proposed framework offers several key advantages. (1) It achieves tension distribution and coordinated transportation within the UAV-cable-load system with low computational overhead, dynamically adapting UAV configurations based on obstacle layouts to facilitate efficient navigation. (2) By integrating dissipative systems theory, the framework ensures high stability and robustness, essential for complex multi-UAV operations. The effectiveness of the proposed approach is validated through extensive simulations, demonstrating its scalability for large-scale multi-UAV systems. Furthermore, the method is experimentally validated in outdoor scenarios, showcasing its practical feasibility and robustness under real-world conditions.

</details>


### [17] [TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards](https://arxiv.org/abs/2602.05596)
*Hokyun Lee,Woo-Jeong Baek,Junhyeok Cha,Jaeheung Park*

Main category: cs.RO

TL;DR: 本文提出了TOLEBI，一个用于双足行走的容错学习框架，能够处理机器人在运行过程中遇到的硬件故障。通过模拟中的故障注入和仿真到现实的转移，结合在线关节状态模块，实现了对真实世界条件下关节状态的分类。实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管目前的研究成果在双足行走任务上取得了高成功率，但对于开发能够应对运动过程中可能出现的硬件故障的方法却鲜有关注。然而，在实际环境中，环境干扰或突然发生的硬件故障可能会导致严重后果。因此，需要一种能够在发生故障时仍能保证双足机器人正常运作的方法。

Method: 提出了一种名为TOLEBI（A faulT-tOlerant Learning framEwork for Bipedal locomotIon）的学习框架，它能够在操作期间处理机器人的故障。具体来说，在模拟中注入关节锁定、断电以及外部干扰等故障情况来学习容错行走策略，并通过从模拟到真实的迁移将学到的策略应用于实际机器人。此外，还加入了一个在线关节状态模块，可以在实际条件下根据实时观察来分类关节状况。

Result: 在人形机器人TOCABI上的真实世界与模拟验证实验表明，所提出的方案是可行的。这标志着据我们所知首个基于学习的双足行走容错框架的诞生，促进了该领域内高效学习方法的发展。

Conclusion: 本研究成功地开发并验证了第一个针对双足行走设计的容错学习框架——TOLEBI。该框架不仅能够提高双足机器人面对突发故障时的适应能力，而且为未来在此方向上的进一步研究奠定了基础。

Abstract: With the growing employment of learning algorithms in robotic applications, research on reinforcement learning for bipedal locomotion has become a central topic for humanoid robotics. While recently published contributions achieve high success rates in locomotion tasks, scarce attention has been devoted to the development of methods that enable to handle hardware faults that may occur during the locomotion process. However, in real-world settings, environmental disturbances or sudden occurrences of hardware faults might yield severe consequences. To address these issues, this paper presents TOLEBI (A faulT-tOlerant Learning framEwork for Bipedal locomotIon) that handles faults on the robot during operation. Specifically, joint locking, power loss and external disturbances are injected in simulation to learn fault-tolerant locomotion strategies. In addition to transferring the learned policy to the real robot via sim-to-real transfer, an online joint status module incorporated. This module enables to classify joint conditions by referring to the actual observations at runtime under real-world conditions. The validation experiments conducted both in real-world and simulation with the humanoid robot TOCABI highlight the applicability of the proposed approach. To our knowledge, this manuscript provides the first learning-based fault-tolerant framework for bipedal locomotion, thereby fostering the development of efficient learning methods in this field.

</details>


### [18] [HiCrowd: Hierarchical Crowd Flow Alignment for Dense Human Environments](https://arxiv.org/abs/2602.05608)
*Yufei Zhu,Shih-Min Yang,Martin Magnusson,Allan Wang*

Main category: cs.RO

TL;DR: 提出了HiCrowd框架，结合强化学习和模型预测控制来解决机器人在密集人群中导航时遇到的冻结问题。通过利用周围行人的运动作为指导，提高了导航效率和安全性，减少了机器人的冻结行为。


<details>
  <summary>Details</summary>
Motivation: 为了解决移动机器人在密集人群中导航时遇到的冻结问题，即机器人难以找到安全路径而停滞不前的问题。

Method: 开发了一个名为HiCrowd的层次化框架，该框架将强化学习与模型预测控制相结合。高层策略使用强化学习生成跟随点以使机器人与合适的行人组对齐；低层则采用模型预测控制进行短期规划，确保安全地跟踪这些指引。

Result: 实验结果表明，无论是离线（重放记录的人类轨迹）还是在线（模拟中人类轨迹更新以响应机器人）环境下，所提出的方法在导航效率和安全性方面均优于反应式和基于学习的基线方法，并且显著减少了机器人的冻结现象。

Conclusion: 利用人类运动作为指导而非单纯将其视为动态障碍物，对于提高机器人在人群中的导航效率和安全性具有重要意义。

Abstract: Navigating through dense human crowds remains a significant challenge for mobile robots. A key issue is the freezing robot problem, where the robot struggles to find safe motions and becomes stuck within the crowd. To address this, we propose HiCrowd, a hierarchical framework that integrates reinforcement learning (RL) with model predictive control (MPC). HiCrowd leverages surrounding pedestrian motion as guidance, enabling the robot to align with compatible crowd flows. A high-level RL policy generates a follow point to align the robot with a suitable pedestrian group, while a low-level MPC safely tracks this guidance with short horizon planning. The method combines long-term crowd aware decision making with safe short-term execution. We evaluate HiCrowd against reactive and learning-based baselines in offline setting (replaying recorded human trajectories) and online setting (human trajectories are updated to react to the robot in simulation). Experiments on a real-world dataset and a synthetic crowd dataset show that our method outperforms in navigation efficiency and safety, while reducing freezing behaviors. Our results suggest that leveraging human motion as guidance, rather than treating humans solely as dynamic obstacles, provides a powerful principle for safe and efficient robot navigation in crowds.

</details>


### [19] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出了一种神经形态控制框架，用于视觉引导的导航和跟踪，通过动态分岔机制解决决策问题，具有实时自主性、低计算负担，并在仿真环境和实验四旋翼平台上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 机器人导航一直难以调和基于传感器的反应式控制与基于模型的规划器之间的关系。当目标之间没有明显首选项时，这种二元性变得尤为关键，使得反应系统在没有大量计算的情况下打破对称性变得困难。

Method: 该研究提出了一种节约资源的神经形态控制框架，旨在为视觉引导的导航和追踪架起桥梁。利用来自机载摄像头的图像像素作为输入，动态神经元群体直接将视觉目标刺激转化为自我中心运动指令。一个动态分叉机制通过延迟决定直到由环境几何形状引发的关键点来解决犹豫不决的问题。

Result: 所提出的神经形态控制器能够在保持最小计算负担的同时提供实时自主能力，并且参数数量少且易于解释。此外，它还可以无缝集成到特定应用的图像处理管道中。研究方法已经在模拟环境中以及实验性的四旋翼平台上得到了验证。

Conclusion: 本文介绍了一种新颖的神经形态控制框架，它能够有效结合视觉信息与自主导航，通过一种创新的方法解决了传统上存在的决策难题，展示了其在实际应用场景中的潜力。

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>


### [20] [Scalable and General Whole-Body Control for Cross-Humanoid Locomotion](https://arxiv.org/abs/2602.05791)
*Yufei Xue,YunFeng Lin,Wentao Dong,Yang Tang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Minghuan Liu,Weinan Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为XHugWBC的新型跨实体训练框架，通过物理一致的形态随机化、跨多种类人机器人语义对齐的观察和动作空间以及有效的策略架构来实现通用类人控制。该控制器在十二个模拟类人机器人和七个真实世界机器人上进行了实验，展示了强大的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的全身控制器大多需要特定于机器人的训练，而本文旨在研究跨实体的类人机器人控制问题，并展示一个单一策略如何能够通过一次训练就稳健地泛通用于广泛的设计各异的类人机器人。

Method: 引入了XHugWBC框架，其特点是：1) 物理一致性的形态随机化；2) 跨不同类人机器人的语义对齐观测与动作空间；3) 有效建模形态学与动力学特性的政策架构。通过从多样化随机化的实体中学习运动先验，该策略获得了一种支持零样本转移到先前未见过的机器人上的强结构偏置。

Result: 在十二个仿真类人机器人及七个实际机器人上进行的实验表明，所得到的通用控制器具有很强的泛化能力和鲁棒性。

Conclusion: 研究表明，XHugWBC框架使得一个单独训练的策略可以很好地适应各种不同的类人机器人设计，为开发更加灵活多用途的类人机器人控制系统提供了新的方法。

Abstract: Learning-based whole-body controllers have become a key driver for humanoid robots, yet most existing approaches require robot-specific training. In this paper, we study the problem of cross-embodiment humanoid control and show that a single policy can robustly generalize across a wide range of humanoid robot designs with one-time training. We introduce XHugWBC, a novel cross-embodiment training framework that enables generalist humanoid control through: (1) physics-consistent morphological randomization, (2) semantically aligned observation and action spaces across diverse humanoid robots, and (3) effective policy architectures modeling morphological and dynamical properties. XHugWBC is not tied to any specific robot. Instead, it internalizes a broad distribution of morphological and dynamical characteristics during training. By learning motion priors from diverse randomized embodiments, the policy acquires a strong structural bias that supports zero-shot transfer to previously unseen robots. Experiments on twelve simulated humanoids and seven real-world robots demonstrate the strong generalization and robustness of the resulting universal controller.

</details>


### [21] [Residual Reinforcement Learning for Waste-Container Lifting Using Large-Scale Cranes with Underactuated Tools](https://arxiv.org/abs/2602.05895)
*Qi Li,Karsten Berns*

Main category: cs.RO

TL;DR: 本文研究了城市环境中由配备欠驱动卸料装置的液压装载起重机执行的废物容器回收任务中的集装箱吊装阶段，并提出了一种残差强化学习方法，该方法结合了标称笛卡尔控制器和学习到的残差策略。所有实验均在仿真中进行。结果表明，与仅使用标称控制器相比，该方法提高了跟踪精度、减少了振荡并提高了吊装成功率。


<details>
  <summary>Details</summary>
Motivation: 在城市环境中的废物容器回收任务中，特别是在集装箱吊装阶段，由于卸料单元钩子与集装箱环之间的几何公差相对较小，因此精确轨迹跟踪和摆动抑制至关重要。为了解决这一问题，论文提出了一个结合标称笛卡尔控制器和通过学习得到的残差策略的残差强化学习方法，以提高操作精度和鲁棒性。

Method: 采用了一个基于导纳控制的标称控制器来实现轨迹跟踪和考虑摆动效应的阻尼控制，然后利用带零空间姿态项的阻尼最小二乘逆运动学生成关节速度命令。此外，在Isaac Lab中训练了一个PPO算法支持的残差策略，用以补偿未建模的动力学及参数变化，从而增强系统精度和鲁棒性。还应用了随机化情节初始化和领域随机化技术，以进一步提高对不同负载属性、执行器增益以及被动关节参数变化情况下的泛化能力。

Result: 仿真结果显示，与单独使用标称控制器相比，所提方法能够显著改善轨迹跟踪精度、减少振荡现象，并且提升集装箱吊装的成功率。

Conclusion: 通过结合传统的标称笛卡尔控制器与基于PPO训练的残差策略，本研究提出的残差强化学习方法有效地解决了城市环境中废物容器回收任务面临的挑战，特别是在集装箱吊装阶段。它不仅提高了系统的精度和鲁棒性，而且展示了良好的适应性和泛化性能。

Abstract: This paper studies the container lifting phase of a waste-container recycling task in urban environments, performed by a hydraulic loader crane equipped with an underactuated discharge unit, and proposes a residual reinforcement learning (RRL) approach that combines a nominal Cartesian controller with a learned residual policy. All experiments are conducted in simulation, where the task is characterized by tight geometric tolerances between the discharge-unit hooks and the container rings relative to the overall crane scale, making precise trajectory tracking and swing suppression essential. The nominal controller uses admittance control for trajectory tracking and pendulum-aware swing damping, followed by damped least-squares inverse kinematics with a nullspace posture term to generate joint velocity commands. A PPO-trained residual policy in Isaac Lab compensates for unmodeled dynamics and parameter variations, improving precision and robustness without requiring end-to-end learning from scratch. We further employ randomized episode initialization and domain randomization over payload properties, actuator gains, and passive joint parameters to enhance generalization. Simulation results demonstrate improved tracking accuracy, reduced oscillations, and higher lifting success rates compared to the nominal controller alone.

</details>


### [22] [From Bench to Flight: Translating Drone Impact Tests into Operational Safety Limits](https://arxiv.org/abs/2602.05922)
*Aziz Mohamed Mili,Louis Catar,Paul Gérard,Ilyass Tabiai,David St-Onge*

Main category: cs.RO

TL;DR: 本文介绍了一个端到端的开源工具链，能够将实验台冲击测试转化为可用于无人机的安全控制器。通过该工具链，可以根据实际测量的风险来调整无人机的动作限制，从而在满足安全利益相关者设定的力量约束的同时保持任务吞吐量。


<details>
  <summary>Details</summary>
Motivation: 室内微型飞行器（MAV）越来越多地被用于需要接近人类的任务中，但实践者缺乏基于测量冲击风险来调整运动限制的实际方法。

Method: 首先描述了一种紧凑且可复制的冲击装置和协议，用于捕捉不同无人机类别和接触表面的力-时间分布。其次提供了数据驱动模型，将预碰撞速度映射为冲量和接触持续时间，可以直接计算出目标力限制下的速度界限。最后发布了脚本和一个ROS2节点，在线执行这些边界并记录合规情况，支持特定设施政策。

Result: 该工作流程在多个商用现成四旋翼无人机和代表性室内资产上得到了验证，证明了所推导的安全控制器能够在满足安全利益相关者指定的力量约束的同时保持任务吞吐量。

Conclusion: 贡献在于提供了一个从测量冲击到运行时限制的实际桥梁，包括可共享的数据集、代码以及团队可以采用以认证靠近人类操作的室内MAV过程。

Abstract: Indoor micro-aerial vehicles (MAVs) are increasingly used for tasks that require close proximity to people, yet practitioners lack practical methods to tune motion limits based on measured impact risk. We present an end-to-end, open toolchain that converts benchtop impact tests into deployable safety governors for drones. First, we describe a compact and replicable impact rig and protocol for capturing force-time profiles across drone classes and contact surfaces. Second, we provide data-driven models that map pre-impact speed to impulse and contact duration, enabling direct computation of speed bounds for a target force limit. Third, we release scripts and a ROS2 node that enforce these bounds online and log compliance, with support for facility-specific policies. We validate the workflow on multiple commercial off-the-shelf quadrotors and representative indoor assets, demonstrating that the derived governors preserve task throughput while meeting force constraints specified by safety stakeholders. Our contribution is a practical bridge from measured impacts to runtime limits, with shareable datasets, code, and a repeatable process that teams can adopt to certify indoor MAV operations near humans.

</details>


### [23] [Visuo-Tactile World Models](https://arxiv.org/abs/2602.06001)
*Carolina Higuera,Sergio Arnaud,Byron Boots,Mustafa Mukadam,Francois Robert Hogan,Franziska Meier*

Main category: cs.RO

TL;DR: 本研究引入了多任务视觉触觉世界模型（VT-WM），通过触觉推理捕捉接触物理。相比仅依赖视觉的模型，VT-WM在处理遮挡或接触状态模糊时表现更佳，并且在保持物体恒常性和遵守运动定律方面提高了性能。此外，VT-WM在实际机器人实验中表现出色，特别是在多步骤、接触密集的任务中显著提高了成功率，并且能够快速适应新任务。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决现有基于纯视觉的模型在面对遮挡或者接触状态不明确时所出现的问题，如物体消失、瞬移或违反基本物理规则移动等。通过结合视觉和触觉感知，旨在提高机器人对物体交互的理解能力。

Method: 研究人员开发了一种名为VT-WM的新方法，它是一种多任务视觉触觉世界模型，能够利用触觉信息来增强对于接触丰富操作任务的理解。该模型通过对一系列接触丰富的操作任务进行训练，从而改进了在预测未来场景时的物理真实性。

Result: 结果表明，与仅使用视觉信息的方法相比，VT-WM在维持物体恒常性方面提高了33%的表现，在遵守运动定律方面提高了29%。在无需额外训练的实际机器人测试中，VT-WM达到了高达35%的成功率提升。此外，VT-WM还展示了强大的下游适应能力，能够仅凭少量示例就有效地将其学到的接触动力学应用于新的任务。

Conclusion: 结论是，通过将触觉信息纳入考虑范围，VT-WM不仅改善了机器人对物理世界的理解，而且在执行复杂任务时提供了更高的可靠性和准确性。这表明，整合多种感官输入可以显著提高机器人的整体性能。

Abstract: We introduce multi-task Visuo-Tactile World Models (VT-WM), which capture the physics of contact through touch reasoning. By complementing vision with tactile sensing, VT-WM better understands robot-object interactions in contact-rich tasks, avoiding common failure modes of vision-only models under occlusion or ambiguous contact states, such as objects disappearing, teleporting, or moving in ways that violate basic physics. Trained across a set of contact-rich manipulation tasks, VT-WM improves physical fidelity in imagination, achieving 33% better performance at maintaining object permanence and 29% better compliance with the laws of motion in autoregressive rollouts. Moreover, experiments show that grounding in contact dynamics also translates to planning. In zero-shot real-robot experiments, VT-WM achieves up to 35% higher success rates, with the largest gains in multi-step, contact-rich tasks. Finally, VT-WM demonstrates significant downstream versatility, effectively adapting its learned contact dynamics to a novel task and achieving reliable planning success with only a limited set of demonstrations.

</details>


### [24] [CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction](https://arxiv.org/abs/2602.06038)
*Xiaopan Zhang,Zejin Wang,Zhixu Li,Jianpeng Yao,Jiachen Li*

Main category: cs.RO

TL;DR: 本文提出了一种名为CommCP的新型基于大语言模型的去中心化通信框架，用于解决多机器人在完成自然语言任务时的信息收集与协作问题。实验结果表明，该框架能显著提高任务成功率和探索效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决多个异构机器人在执行由自然语言给出的任务时需要协同工作的问题，特别是在有效信息收集方面面临的挑战。

Method: 提出了一个名为CommCP的新框架，它使用了共形预测来校准生成的消息，从而减少接收者的干扰并提高通信可靠性。

Result: 实验结果证明了CommCP相比基线方法，在任务成功率和探索效率上有显著提升。

Conclusion: 通过引入CommCP框架，可以有效地改善多智能体多任务具身问答（MM-EQA）场景下的信息收集过程及团队协作效率。

Abstract: To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.

</details>
