<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [FICO: Finite-Horizon Closed-Loop Factorization for Unified Multi-Agent Path Finding](https://arxiv.org/abs/2511.13961)
*Jiarui Li,Alessandro Zanardi,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: 本文提出了一种系统级框架，用于多智能体路径查找问题（MAPF），该框架整合了规划与执行过程，适用于不同变体，并且明确地建模不确定性。核心是基于有限时间闭环分解算法（FICO）的MAPF系统，能够实现实时响应，适应执行期间的不确定性，并大幅减少计算时间、提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体路径查找方法大多将规划和执行视为独立的过程，并以特定方式处理问题的不同变体，缺乏对不确定性的显式建模。为了解决这些问题，作者提出了一个统一的系统级框架，旨在更好地整合规划与执行流程，同时考虑各种变体及不确定性因素。

Method: 文章介绍了一个称为MAPF系统的正式模型，它将MAPF视作控制设计问题，涵盖了经典形式和不确定性感知形式。为解决这一问题，研究者引入了有限时间闭环分解（FICO）算法，该算法受到滚动时域控制启发，利用组合结构实现高效的闭环操作。

Result: 通过广泛案例研究表明，相比开环基准方案，FICO算法能够将计算时间降低最多两个数量级，在存在随机延迟和智能体到达的情况下显著提高了吞吐量。此外，该算法支持实时响应，在毫秒内开始执行，可以扩展至数千个智能体，并能无缝适应执行期间出现的各种不确定性。

Conclusion: 这些结果为通过系统级建模、分解以及闭环设计来分析和推进MAPF奠定了坚实的基础。

Abstract: Multi-Agent Path Finding is a fundamental problem in robotics and AI, yet most existing formulations treat planning and execution separately and address variants of the problem in an ad hoc manner. This paper presents a system-level framework for MAPF that integrates planning and execution, generalizes across variants, and explicitly models uncertainties. At its core is the MAPF system, a formal model that casts MAPF as a control design problem encompassing classical and uncertainty-aware formulations. To solve it, we introduce Finite-Horizon Closed-Loop Factorization (FICO), a factorization-based algorithm inspired by receding-horizon control that exploits compositional structure for efficient closed-loop operation. FICO enables real-time responses -- commencing execution within milliseconds -- while scaling to thousands of agents and adapting seamlessly to execution-time uncertainties. Extensive case studies demonstrate that it reduces computation time by up to two orders of magnitude compared with open-loop baselines, while delivering significantly higher throughput under stochastic delays and agent arrivals. These results establish a principled foundation for analyzing and advancing MAPF through system-level modeling, factorization, and closed-loop design.

</details>


### [2] [LIO-MARS: Non-uniform Continuous-time Trajectories for Real-time LiDAR-Inertial-Odometry](https://arxiv.org/abs/2511.13985)
*Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 提出了一种新的激光雷达-惯性里程计(LIO)方法，通过连续时间B样条轨迹联合对齐多分辨率的表面地图，并使用非均匀时间结点布局的新扫描窗口来确保整个轨迹的连续性。此外，该方法还通过Kronecker和与积加速了关键协方差和GMM计算，结合IMU伪测量进一步提高了鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高搜索与救援任务中飞行机器人在复杂环境中的实时感知能力，需要一种能够有效融合激光雷达（LiDAR）和惯性测量单元（IMU）数据的方法来实现更准确、更鲁棒的定位和建图。

Method: 基于MARS激光雷达里程计，引入了一种激光雷达-惯导里程计(LIO)，它利用连续时间B样条轨迹模型将多分辨率的表面地图与高斯混合模型(GMM)一起对齐。采用新颖的扫描窗口技术，通过非均匀的时间节点分布保证了整个运动轨迹上的平滑过渡。同时，通过克罗内克和及乘积优化了必要的协方差和GMM计算效率，并使用无迹变换去除表面点偏斜，以及将扫描分割成段以利于运动补偿。

Result: 广泛评估表明，在手持设备、地面车辆和空中载具等不同平台收集的数据集上，所提出的LIO-MARS系统相较于最近的其他LIO系统展示了顶尖水平的质量表现。

Conclusion: 本研究开发的LIO-MARS系统显著增强了无人机在搜救行动中的自主导航能力，通过改进的传感器融合技术和高效的计算方法，实现了更稳定且精确的位置估计。

Abstract: Autonomous robotic systems heavily rely on environment knowledge to safely navigate. For search & rescue, a flying robot requires robust real-time perception, enabled by complementary sensors. IMU data constrains acceleration and rotation, whereas LiDAR measures accurate distances around the robot. Building upon the LiDAR odometry MARS, our LiDAR-inertial odometry (LIO) jointly aligns multi-resolution surfel maps with a Gaussian mixture model (GMM) using a continuous-time B-spline trajectory. Our new scan window uses non-uniform temporal knot placement to ensure continuity over the whole trajectory without additional scan delay. Moreover, we accelerate essential covariance and GMM computations with Kronecker sums and products by a factor of 3.3. An unscented transform de-skews surfels, while a splitting into intra-scan segments facilitates motion compensation during spline optimization. Complementary soft constraints on relative poses and preintegrated IMU pseudo-measurements further improve robustness and accuracy. Extensive evaluation showcases the state-of-the-art quality of our LIO-MARS w.r.t. recent LIO systems on various handheld, ground and aerial vehicle-based datasets.

</details>


### [3] [Searching in Space and Time: Unified Memory-Action Loops for Open-World Object Retrieval](https://arxiv.org/abs/2511.14004)
*Taijing Chen,Sateesh Kumar,Junhong Xu,George Pavlakos,J oydeep Biswas,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: 提出了STAR框架，该框架统一了长期记忆查询和实体动作，以支持动态开放环境中的物体检索任务。通过结合非参数长期记忆、工作记忆以及视觉-语言模型，STAR能够在每个步骤选择时间或空间动作。实验表明，STAR在STARBench基准测试中以及Tiago机器人上的表现优于基于场景图和其他仅依赖记忆的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方法只能解决部分问题：场景图可以捕捉空间关系但忽略了时间定位，时间推理方法可以建模动态变化但不支持实体交互，而动态场景图虽然能够处理两者但仍然局限于封闭世界和固定词汇表。服务机器人需要在一个动态且开放的世界环境中根据属性、空间上下文或过去的状态来检索物体。

Method: 提出了一种名为STAR（SpatioTemporal Active Retrieval）的新框架，它将记忆查询与实体行动整合到一个决策循环中。STAR利用非参数化的长期记忆和工作记忆来支持高效回忆，并使用视觉-语言模型在每一步选择时间或空间行动。此外，还引入了STARBench作为跨模拟和真实环境的时空物体搜索任务的基准。

Result: 在STARBench基准测试和Tiago机器人上的实验显示，STAR持续优于基于场景图和其他只依靠记忆的方法，证明了将时间搜索和空间搜索视为统一问题的好处。

Conclusion: STAR框架通过整合长期记忆与即时行动，在动态开放环境中为服务机器人提供了一个更有效的物体检索解决方案。

Abstract: Service robots must retrieve objects in dynamic, open-world settings where requests may reference attributes ("the red mug"), spatial context ("the mug on the table"), or past states ("the mug that was here yesterday"). Existing approaches capture only parts of this problem: scene graphs capture spatial relations but ignore temporal grounding, temporal reasoning methods model dynamics but do not support embodied interaction, and dynamic scene graphs handle both but remain closed-world with fixed vocabularies. We present STAR (SpatioTemporal Active Retrieval), a framework that unifies memory queries and embodied actions within a single decision loop. STAR leverages non-parametric long-term memory and a working memory to support efficient recall, and uses a vision-language model to select either temporal or spatial actions at each step. We introduce STARBench, a benchmark of spatiotemporal object search tasks across simulated and real environments. Experiments in STARBench and on a Tiago robot show that STAR consistently outperforms scene-graph and memory-only baselines, demonstrating the benefits of treating search in time and search in space as a unified problem.

</details>


### [4] [FACA: Fair and Agile Multi-Robot Collision Avoidance in Constrained Environments with Dynamic Priorities](https://arxiv.org/abs/2511.14024)
*Jaskirat Singh,Rohan Chandra*

Main category: cs.RO

TL;DR: 本文提出了一种名为FACA的公平且敏捷的避碰方法，通过让机器人使用自然语言相互交流来协调任务。实验表明，FACA在保持安全边际的同时，比基线方法提高了超过3.5倍的任务完成效率，时间减少了70%以上。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在救援、物资运送等关键应用中面临的主要挑战是需要在狭小且拥挤的空间内高速导航，并且在紧急响应情况下角色和优先级可能迅速变化。为了在这种环境中顺利完成任务，机器人不仅需要保证安全性，还需要具备足够的灵活性以快速改变路径。

Method: 提出了FACA方法，这是一种公平且敏捷的避碰策略，它允许机器人通过自然语言进行沟通协调任务。FACA利用一种新颖的人工势场算法，在出现冲突时自动创建‘环岛’效应，从而平衡了安全性和灵活性之间的关系。

Result: 实验结果显示，与基准方法相比，FACA能够将任务完成速度提高超过3.5倍，同时减少超过70%的时间消耗，而且在整个过程中保持了良好的安全性能。

Conclusion: FACA提供了一种有效的解决方案，使多机器人系统能够在复杂且动态变化的环境中更高效地执行任务，其通过自然语言通信和创新性的避碰算法显著提升了系统的灵活性和安全性。

Abstract: Multi-robot systems are increasingly being used for critical applications such as rescuing injured people, delivering food and medicines, and monitoring key areas. These applications usually involve navigating at high speeds through constrained spaces such as small gaps. Navigating such constrained spaces becomes particularly challenging when the space is crowded with multiple heterogeneous agents all of which have urgent priorities. What makes the problem even harder is that during an active response situation, roles and priorities can quickly change on a dime without informing the other agents. In order to complete missions in such environments, robots must not only be safe, but also agile, able to dodge and change course at a moment's notice. In this paper, we propose FACA, a fair and agile collision avoidance approach where robots coordinate their tasks by talking to each other via natural language (just as people do). In FACA, robots balance safety with agility via a novel artificial potential field algorithm that creates an automatic ``roundabout'' effect whenever a conflict arises. Our experiments show that FACA achieves a improvement in efficiency, completing missions more than 3.5X faster than baselines with a time reduction of over 70% while maintaining robust safety margins.

</details>


### [5] [BIM-Discrepancy-Driven Active Sensing for Risk-Aware UAV-UGV Navigation](https://arxiv.org/abs/2511.14037)
*Hesam Mojtahedi,Reza Akhavian*

Main category: cs.RO

TL;DR: 该论文提出了一种基于BIM差异驱动的主动感知框架，用于动态建筑环境中的无人机和无人地面车辆之间的协作导航。通过融合实时LiDAR数据与BIM先验信息来维护一个不断更新的2D占用地图，并采用统一的走廊风险指标量化导航安全性。当风险超过安全阈值时，无人机将自动重新扫描受影响区域以减少不确定性并支持安全路径重规划。实验验证表明，与静态BIM导航相比，此方法能显著降低平均走廊风险及地图熵，并在任务时间上具有优势。


<details>
  <summary>Details</summary>
Motivation: 传统的导航方法依赖于静态的建筑信息模型（BIM）或有限的车载感知能力，在动态变化的建筑环境中不够灵活且安全性较低。为解决这一问题，研究者开发了一个新的框架，旨在通过结合BIM先验信息与自适应空中传感技术提高导航的安全性和效率。

Method: 本研究提出的方法是构建一个基于BIM不一致性的主动感知系统，利用来自空地机器人的实时LiDAR数据与BIM先验信息相融合，生成一个持续更新的二维占用地图。定义了综合考虑占用不确定性、BIM图差异以及通道宽度等因素的统一走廊风险度量标准。一旦检测到的风险水平超出预设的安全界限，无人机会自动对相关区域进行再扫描，从而减少不确定因素并允许安全地重新规划路线。

Result: 在PX4-Gazebo仿真平台上的测试结果表明，与仅使用静态BIM的传统导航方式相比，所提方法能够使平均走廊风险降低58%，地图熵减少43%，同时保持至少0.4米的安全距离。此外，相较于基于边界的探索策略，新方法能在一半的时间内达到相似程度的信息不确定性削减效果。

Conclusion: 研究表明，将BIM先验知识同风险适应性空中探测技术相结合，可以实现针对建筑机器人应用的高度可扩展、具备不确定性意识的自主导航解决方案。

Abstract: This paper presents a BIM-discrepancy-driven active sensing framework for cooperative navigation between unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) in dynamic construction environments. Traditional navigation approaches rely on static Building Information Modeling (BIM) priors or limited onboard perception. In contrast, our framework continuously fuses real-time LiDAR data from aerial and ground robots with BIM priors to maintain an evolving 2D occupancy map. We quantify navigation safety through a unified corridor-risk metric integrating occupancy uncertainty, BIM-map discrepancy, and clearance. When risk exceeds safety thresholds, the UAV autonomously re-scans affected regions to reduce uncertainty and enable safe replanning. Validation in PX4-Gazebo simulation with Robotec GPU LiDAR demonstrates that risk-triggered re-scanning reduces mean corridor risk by 58% and map entropy by 43% compared to static BIM navigation, while maintaining clearance margins above 0.4 m. Compared to frontier-based exploration, our approach achieves similar uncertainty reduction in half the mission time. These results demonstrate that integrating BIM priors with risk-adaptive aerial sensing enables scalable, uncertainty-aware autonomy for construction robotics.

</details>


### [6] [FlexiCup: Wireless Multimodal Suction Cup with Dual-Zone Vision-Tactile Sensing](https://arxiv.org/abs/2511.14139)
*Junhao Gong,Shoujie Li,Kit-Wa Sou,Changqing Guo,Hourong Huang,Tong Wu,Yifan Xie,Chenxin Liang,Chuqiao Lyu,Xiaojun Liang,Wenbo Ding*

Main category: cs.RO

TL;DR: 本文介绍了一种名为FlexiCup的无线多模态吸盘，它集成了双区视觉触觉传感功能。通过中心区域的视觉和触觉模式切换以及周边区域的空间感知，实现了接触感知操作。该设备支持真空与伯努利两种吸力模式，并且在结构化表面抓取测试中表现良好。此外，基于扩散的端到端学习方法在倾斜运输和橙子提取任务上也取得了不错的效果。


<details>
  <summary>Details</summary>
Motivation: 传统吸盘缺乏在非结构化环境中进行接触感知操作所需的传感能力。本研究旨在开发一种具备集成视觉触觉传感的新型吸盘，以提高其在复杂环境下的适应性和操作性能。

Method: 设计并实现了一款名为FlexiCcup的无线多模态吸盘，它能够通过控制照明来切换中央区域的视觉与触觉传感模式，同时边缘区域提供持续的空间意识用于接近规划。该装置支持通过模块化机械配置实现真空和伯努利两种吸力模式，并且具有完全无线自主性，包括机载计算和供电。

Result: 实验验证了硬件在不同障碍物密度下的结构化表面上执行感知驱动抓握时的表现，真空模式下平均成功率为90.0%，伯努利模式下为86.7%。基于扩散的端到端学习方法在倾斜运输任务上的成功率为73.3%，在橙子提取任务上为66.7%。消融研究表明，利用多头注意力机制协调双区观察可使接触感知操作性能提高13%。

Conclusion: FlexiCup展示了其作为一款先进的、多功能的吸盘工具，在处理复杂环境中的物体抓取任务方面的潜力。通过整合视觉-触觉传感技术及采用不同的吸力模式，FlexiCup不仅提高了抓取成功率还增强了对周围环境的理解。

Abstract: Conventional suction cups lack sensing capabilities for contact-aware manipulation in unstructured environments. This paper presents FlexiCup, a fully wireless multimodal suction cup that integrates dual-zone vision-tactile sensing. The central zone dynamically switches between vision and tactile modalities via illumination control for contact detection, while the peripheral zone provides continuous spatial awareness for approach planning. FlexiCup supports both vacuum and Bernoulli suction modes through modular mechanical configurations, achieving complete wireless autonomy with onboard computation and power. We validate hardware versatility through dual control paradigms. Modular perception-driven grasping across structured surfaces with varying obstacle densities demonstrates comparable performance between vacuum (90.0% mean success) and Bernoulli (86.7% mean success) modes. Diffusion-based end-to-end learning achieves 73.3% success on inclined transport and 66.7% on orange extraction tasks. Ablation studies confirm that multi-head attention coordinating dual-zone observations provides 13% improvements for contact-aware manipulation. Hardware designs and firmware are available at https://anonymous.4open.science/api/repo/FlexiCup-DA7D/file/index.html?v=8f531b44.

</details>


### [7] [AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models](https://arxiv.org/abs/2511.14148)
*Yuhua Jiang,Shuang Cheng,Yan Ding,Feifei Gao,Biqing Qi*

Main category: cs.RO

TL;DR: 本文提出了一种新的框架AsyncVLA，通过引入异步流匹配（AFM）和动作上下文感知来提高长时间任务中动作生成的稳定性，并且引入了置信度评分机制以允许模型在执行前选择性地优化不准确的动作令牌。此外，还提出了一种统一训练过程来同时支持同步流匹配（SFM）与AFM模式，从而改善KV缓存利用效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于流匹配（FM）生成动作的视觉-语言-动作（VLA）模型依赖于刚性和统一的时间表安排，缺乏对动作上下文的理解及异步自我修正能力，导致在长期任务中容易因单个动作错误而引发连锁失败。

Method: 提出了异步流匹配VLA（AsyncVLA），该框架采用非均匀时间表生成动作令牌并考虑到了动作上下文；引入置信度评分器评估初始生成动作的信心水平，使得模型能够在执行之前有选择地精炼那些不够精确的动作令牌；设计了一种适用于同步流匹配（SFM）与异步流匹配（AFM）的统一训练流程。

Result: 广泛的实验表明，AsyncVLA不仅数据效率高而且具有自我修正的能力，在一般具身评估中的表现达到了最先进的水平。

Conclusion: 通过引入异步处理机制和自信度评分调整，AsyncVLA为构建更加灵活可靠的机器人提供了新的思路和技术手段。

Abstract: Vision-language-action (VLA) models have recently emerged as a powerful paradigm for building generalist robots. However, traditional VLA models that generate actions through flow matching (FM) typically rely on rigid and uniform time schedules, i.e., synchronous FM (SFM). Without action context awareness and asynchronous self-correction, SFM becomes unstable in long-horizon tasks, where a single action error can cascade into failure. In this work, we propose asynchronous flow matching VLA (AsyncVLA), a novel framework that introduces temporal flexibility in asynchronous FM (AFM) and enables self-correction in action generation. AsyncVLA breaks from the vanilla SFM in VLA models by generating the action tokens in a non-uniform time schedule with action context awareness. Besides, our method introduces the confidence rater to extract confidence of the initially generated actions, enabling the model to selectively refine inaccurate action tokens before execution. Moreover, we propose a unified training procedure for SFM and AFM that endows a single model with both modes, improving KV-cache utilization. Extensive experiments on robotic manipulation benchmarks demonstrate that AsyncVLA is data-efficient and exhibits self-correction ability. AsyncVLA achieves state-of-the-art results across general embodied evaluations due to its asynchronous generation in AFM. Our code is available at https://github.com/YuhuaJiang2002/AsyncVLA.

</details>


### [8] [RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action](https://arxiv.org/abs/2511.14161)
*Xiaoquan Sun,Ruijian Zhang,Kang Pang,Bingchen Miao,Yuxiang Tan,Zhen Yang,Ming Li,Jiayu Chen*

Main category: cs.RO

TL;DR: 提出了RoboTidy，一个统一的基准测试平台，支持基于语言指导的家庭整理任务，包括视觉-语言-动作（VLA）和视觉-语言-导航（VLN）的训练与评估。该平台提供了500个逼真的3D高斯渲染家庭场景，并附带了大量的操作演示轨迹和导航轨迹，以支持少量样本及大规模训练，并在真实世界中进行了部署。


<details>
  <summary>Details</summary>
Motivation: 当前的基准测试未能充分模拟用户偏好或支持移动性，且泛化能力差，难以全面评估集成的语言到行动的能力。为了改进这一情况，研究者们开发了RoboTidy，旨在为基于语言指导的家庭整理提供更加综合性的评价标准。

Method: 通过构建包含500个高度写实的3D高斯渲染家庭场景的RoboTidy平台来实现，这些场景覆盖了500种物体和容器，并且定义了整理任务为“动作(对象, 容器)”列表形式。此外，还提供了6400条高质量的操作示范轨迹以及1500条导航轨迹用于支持从少量示例到大规模训练的需求。

Result: RoboTidy不仅能够促进对语言引导型机器人的整体性和现实性评估，而且还在真实环境中成功部署实施了物品整理功能，证明其作为端到端家庭整理基准的有效性。

Conclusion: RoboTidy作为一个可扩展的平台，填补了具身AI领域的一个关键空白，它促进了基于语言指导的机器人技术的发展，同时为未来的研究提供了一个强大的基准工具。

Abstract: Household tidying is an important application area, yet current benchmarks neither model user preferences nor support mobility, and they generalize poorly, making it hard to comprehensively assess integrated language-to-action capabilities. To address this, we propose RoboTidy, a unified benchmark for language-guided household tidying that supports Vision-Language-Action (VLA) and Vision-Language-Navigation (VLN) training and evaluation. RoboTidy provides 500 photorealistic 3D Gaussian Splatting (3DGS) household scenes (covering 500 objects and containers) with collisions, formulates tidying as an "Action (Object, Container)" list, and supplies 6.4k high-quality manipulation demonstration trajectories and 1.5k naviagtion trajectories to support both few-shot and large-scale training. We also deploy RoboTidy in the real world for object tidying, establishing an end-to-end benchmark for household tidying. RoboTidy offers a scalable platform and bridges a key gap in embodied AI by enabling holistic and realistic evaluation of language-guided robots.

</details>


### [9] [Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion](https://arxiv.org/abs/2511.14178)
*Zhuo Li,Junjia Liu,Zhipeng Dong,Tao Teng,Quentin Rouxel,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 介绍了VLA-Pilot，一种无需额外微调或数据收集即可实现预训练VLA模型零样本部署的方法。通过在六个真实世界操作任务上的评估，证明了该方法能够显著提高预训练VLA策略的成功率，促进其在不同任务和机器人实体上的鲁棒性零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作（VLA）模型在实际机器人操控中展现出巨大潜力，但预训练的VLA策略在下游部署时仍面临显著性能下降的问题。虽然微调可以缓解这一问题，但因需要昂贵的演示收集和大量计算资源，在现实中并不实用。

Method: 提出了VLA-Pilot，这是一种即插即用的推理时间策略引导方法，旨在实现预训练VLA模型的零样本部署，而不需要任何额外的微调或数据收集过程。

Result: 实验结果表明，VLA-Pilot大幅提升了现成预训练VLA策略的成功率，并且能够在不同的任务与机器人实体之间实现稳定的零样本泛化表现。

Conclusion: VLA-Pilot提供了一种有效的解决方案来改善预训练VLA模型在没有额外调整情况下的实际应用性能，为解决预训练模型在新环境中的适应性问题开辟了新的途径。

Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential in real-world robotic manipulation. However, pre-trained VLA policies still suffer from substantial performance degradation during downstream deployment. Although fine-tuning can mitigate this issue, its reliance on costly demonstration collection and intensive computation makes it impractical in real-world settings. In this work, we introduce VLA-Pilot, a plug-and-play inference-time policy steering method for zero-shot deployment of pre-trained VLA without any additional fine-tuning or data collection. We evaluate VLA-Pilot on six real-world downstream manipulation tasks across two distinct robotic embodiments, encompassing both in-distribution and out-of-distribution scenarios. Experimental results demonstrate that VLA-Pilot substantially boosts the success rates of off-the-shelf pre-trained VLA policies, enabling robust zero-shot generalization to diverse tasks and embodiments. Experimental videos and code are available at: https://rip4kobe.github.io/vla-pilot/.

</details>


### [10] [Dual-Variable Force Characterisation method for Human-Robot Interaction in Wearable Robotics](https://arxiv.org/abs/2511.14327)
*Felipe Ballen-Moreno,Pasquale Ferrentino,Milan Amighi,Bram Vanderborght,Tom Verstraten*

Main category: cs.RO

TL;DR: 本文提出了一种双变量表征方法，通过分析不同场景和材料模型下的归一化均方误差(NMSE)，来识别可靠的材料参数并评估单变量拟合对力和扭矩响应的影响。这种方法强调了在可穿戴机器人与用户之间的物理交互中，尤其是在袖套和人体肢体的仿真过程中考虑两个变量的重要性。


<details>
  <summary>Details</summary>
Motivation: 理解与可穿戴机器人的物理交互对于确保安全性和舒适性至关重要。然而，这种交互在两个关键方面是复杂的：运动涉及的复杂性以及软组织的非线性行为。尽管有限建模和软组织特征提供了关于压力分布和剪切应力的重要见解，但当前的特征方法通常只依赖于沿一个自由度的单一拟合变量，这限制了它们的应用范围，因为与可穿戴机器人的交互往往涉及多个自由度。

Method: 本研究引入了一种新的双变量表征方法，该方法同时考虑了法向力和切向力，旨在确定可靠的材料参数，并评价单变量拟合对力和扭矩响应的影响。通过对不同情况下及材料模型中的归一化均方误差进行分析，展示了在表征过程中结合两个变量的重要性。

Result: 所提出的方法显示了将两个变量纳入表征过程的重要性，通过比较不同场景和材料模型下NMSE的变化，为尽可能接近真实情况的模拟奠定了基础，特别是涉及到可穿戴机器人与用户之间物理互动时的袖套和人体肢体部分。

Conclusion: 双变量表征方法对于准确模拟可穿戴机器人与用户肢体间的相互作用非常关键，它不仅有助于更精确地识别材料参数，还能改善力和扭矩响应的预测准确性。

Abstract: Understanding the physical interaction with wearable robots is essential to ensure safety and comfort. However, this interaction is complex in two key aspects: (1) the motion involved, and (2) the non-linear behaviour of soft tissues. Multiple approaches have been undertaken to better understand this interaction and to improve the quantitative metrics of physical interfaces or cuffs. As these two topics are closely interrelated, finite modelling and soft tissue characterisation offer valuable insights into pressure distribution and shear stress induced by the cuff. Nevertheless, current characterisation methods typically rely on a single fitting variable along one degree of freedom, which limits their applicability, given that interactions with wearable robots often involve multiple degrees of freedom. To address this limitation, this work introduces a dual-variable characterisation method, involving normal and tangential forces, aimed at identifying reliable material parameters and evaluating the impact of single-variable fitting on force and torque responses. This method demonstrates the importance of incorporating two variables into the characterisation process by analysing the normalized mean square error (NMSE) across different scenarios and material models, providing a foundation for simulation at the closest possible level, with a focus on the cuff and the human limb involved in the physical interaction between the user and the wearable robot.

</details>


### [11] [MA-SLAM: Active SLAM in Large-Scale Unknown Environment using Map Aware Deep Reinforcement Learning](https://arxiv.org/abs/2511.14330)
*Yizhen Yin,Yuhua Qi,Dapeng Feng,Hongbo Chen,Hongjun Ma,Jin Wu,Yi Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习的地图感知主动SLAM系统（MA-SLAM），旨在解决大规模环境下的高效探索问题。通过引入一种新颖的结构化地图表示方法和先进的全局规划器来优化探索路径，实验表明该方法在减少探索时间和距离方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前的主动SLAM方法在小范围、受控环境中表现良好，但在大规模及多样化环境下应用时面临长时间探索与非最优发现路径的问题。为了解决这一挑战，提高在大规模环境中的探索效率，作者们提出了新的解决方案。

Method: 提出了名为MA-SLAM的新系统，它利用深度强化学习(DRL)并结合创新性的结构化地图表示方式。这种表示法通过对空间数据进行离散化处理，并整合边界点与历史轨迹信息，有效概括了已访问区域，作为DRL决策模块的输入。此外，还开发了一个高级全局规划器，通过利用远距离目标点来优化探索路径，而不是逐个预测下一步动作。

Result: 在三个模拟环境以及一个真实的无人地面车辆(UGV)上进行了测试，结果表明，相较于最先进的方法，所提方案能够显著缩短探索所需的时间和行进距离。

Conclusion: MA-SLAM系统展示了其在大规模环境中实现更高效探索的能力，为解决主动SLAM领域内存在的挑战提供了新的视角和技术手段。

Abstract: Active Simultaneous Localization and Mapping (Active SLAM) involves the strategic planning and precise control of a robotic system's movement in order to construct a highly accurate and comprehensive representation of its surrounding environment, which has garnered significant attention within the research community. While the current methods demonstrate efficacy in small and controlled settings, they face challenges when applied to large-scale and diverse environments, marked by extended periods of exploration and suboptimal paths of discovery. In this paper, we propose MA-SLAM, a Map-Aware Active SLAM system based on Deep Reinforcement Learning (DRL), designed to address the challenge of efficient exploration in large-scale environments. In pursuit of this objective, we put forward a novel structured map representation. By discretizing the spatial data and integrating the boundary points and the historical trajectory, the structured map succinctly and effectively encapsulates the visited regions, thereby serving as input for the deep reinforcement learning based decision module. Instead of sequentially predicting the next action step within the decision module, we have implemented an advanced global planner to optimize the exploration path by leveraging long-range target points. We conducted experiments in three simulation environments and deployed in a real unmanned ground vehicle (UGV), the results demonstrate that our approach significantly reduces both the duration and distance of exploration compared with state-of-the-art methods.

</details>


### [12] [Simultaneous Localization and 3D-Semi Dense Mapping for Micro Drones Using Monocular Camera and Inertial Sensors](https://arxiv.org/abs/2511.14335)
*Jeryes Danial,Yosi Ben Asher,Itzik Klein*

Main category: cs.RO

TL;DR: 本文提出了一种边缘感知的轻量级单目SLAM系统，结合了基于稀疏关键点的姿态估计和密集边缘重建，通过深度学习进行深度预测和边缘检测，并利用扩展卡尔曼滤波融合惯性数据以解决尺度模糊问题，提高了精度，在低功耗平台上实现实时运行。


<details>
  <summary>Details</summary>
Motivation: 现有的单目SLAM算法要么缺乏详细的几何信息（稀疏方法），要么计算成本高（学习驱动的方法）。此外，单目SLAM还面临尺度模糊的问题，这影响了其准确性。为了解决这些问题，提出了一个新系统。

Method: 本研究采用深度学习来进行深度预测和边缘检测，接着通过优化来细化关键点和边缘，确保几何一致性。同时，使用扩展卡尔曼滤波将惯性数据与视觉数据融合，以解决尺度不确定性并提高精度。

Result: 该系统在DJI Tello无人机上进行了测试，证明能够在资源受限环境下实现实时地图构建与导航。此外，还在室内走廊和TUM RGBD数据集上展示了鲁棒的自主导航和避障能力。

Conclusion: 所提出的方法提供了一个有效且实用的解决方案，适用于资源受限环境下的实时地图构建与导航任务，具有较好的实际应用前景。

Abstract: Monocular simultaneous localization and mapping (SLAM) algorithms estimate drone poses and build a 3D map using a single camera. Current algorithms include sparse methods that lack detailed geometry, while learning-driven approaches produce dense maps but are computationally intensive. Monocular SLAM also faces scale ambiguities, which affect its accuracy. To address these challenges, we propose an edge-aware lightweight monocular SLAM system combining sparse keypoint-based pose estimation with dense edge reconstruction. Our method employs deep learning-based depth prediction and edge detection, followed by optimization to refine keypoints and edges for geometric consistency, without relying on global loop closure or heavy neural computations. We fuse inertial data with vision by using an extended Kalman filter to resolve scale ambiguity and improve accuracy. The system operates in real time on low-power platforms, as demonstrated on a DJI Tello drone with a monocular camera and inertial sensors. In addition, we demonstrate robust autonomous navigation and obstacle avoidance in indoor corridors and on the TUM RGBD dataset. Our approach offers an effective, practical solution to real-time mapping and navigation in resource-constrained environments.

</details>


### [13] [Going Places: Place Recognition in Artificial and Natural Systems](https://arxiv.org/abs/2511.14341)
*Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 本综述结合了机器人系统、动物研究和人类研究的发现，探讨了不同系统如何编码和回忆地点，并提出了统一的概念集合来考虑和发展地点识别机制。


<details>
  <summary>Details</summary>
Motivation: 地点识别对于生物导航和自主系统至关重要。本文旨在通过连接人工地点识别系统未来的发展与动物导航研究及人类空间认知研究的见解，促进人工智能定位的创新。

Method: 本文通过综合分析机器人系统、动物以及人类在地点编码与回忆中采用的计算和表示策略，如拓扑映射、线索整合和记忆管理等方法来进行研究。

Result: 研究表明，动物系统展示了多模态导航和环境适应的进化机制；人类研究则提供了关于语义地点概念、文化影响和内省能力的独特见解；而人工系统则展示了可扩展架构和数据驱动模型的优势。

Conclusion: 本文提出了一套统一的概念来思考和发展地点识别机制，并指出了诸如泛化能力、鲁棒性和环境变异性等关键挑战。

Abstract: Place recognition, the ability to identify previously visited locations, is critical for both biological navigation and autonomous systems. This review synthesizes findings from robotic systems, animal studies, and human research to explore how different systems encode and recall place. We examine the computational and representational strategies employed across artificial systems, animals, and humans, highlighting convergent solutions such as topological mapping, cue integration, and memory management. Animal systems reveal evolved mechanisms for multimodal navigation and environmental adaptation, while human studies provide unique insights into semantic place concepts, cultural influences, and introspective capabilities. Artificial systems showcase scalable architectures and data-driven models. We propose a unifying set of concepts by which to consider and develop place recognition mechanisms and identify key challenges such as generalization, robustness, and environmental variability. This review aims to foster innovations in artificial localization by connecting future developments in artificial place recognition systems to insights from both animal navigation research and human spatial cognition studies.

</details>


### [14] [Perception-aware Exploration for Consumer-grade UAVs](https://arxiv.org/abs/2511.14393)
*Svetlana Seliunina,Daniel Schleich,Sven Behnke*

Main category: cs.RO

TL;DR: 本文扩展了当前最先进的自主多无人机探索方法，使其适用于消费级无人机，并提出了一种能够平衡分配工作负载的半分布式通信方案。


<details>
  <summary>Details</summary>
Motivation: 作者希望将先进的自主多无人机探索技术应用于消费级无人机上，以克服这些设备硬件限制的同时，实现环境的安全探索和地图重建。

Method: 提出了一个流程，该流程选择视点对来估计深度并规划满足里程计估计所需运动约束的轨迹；对于多无人机探索，还提出了一种可以平衡分配工作负荷的半分布式通信方案。

Result: 通过不同数量无人机参与下的模拟测试表明，即使在消费级无人机硬件有限的情况下，所提模型也能够安全地探索环境并重建地图。

Conclusion: 这项研究表明，通过适当的方法论设计，即使是消费级无人机也能有效地参与到复杂的多无人机协作任务中去。

Abstract: In our work, we extend the current state-of-the-art approach for autonomous multi-UAV exploration to consumer-level UAVs, such as the DJI Mini 3 Pro. We propose a pipeline that selects viewpoint pairs from which the depth can be estimated and plans the trajectory that satisfies motion constraints necessary for odometry estimation. For the multi-UAV exploration, we propose a semi-distributed communication scheme that distributes the workload in a balanced manner. We evaluate our model performance in simulation for different numbers of UAVs and prove its ability to safely explore the environment and reconstruct the map even with the hardware limitations of consumer-grade UAVs.

</details>


### [15] [Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning](https://arxiv.org/abs/2511.14396)
*Xiuxiu Qi,Yu Yang,Jiannong Cao,Luyao Bai,Chongshan Fan,Chengtai Cao,Hongpeng Wang*

Main category: cs.RO

TL;DR: 本文提出了一种新的行为克隆框架CCoL，通过视觉、语言和本体感觉输入的连续协同学习，确保了时间上一致的执行和细粒度的语义基础，有效解决了语义-物理错位问题。实验表明，CCoL在多个模拟套件中平均提高了8.0%的表现，在实际双臂插入任务中最高可达19.2%的相对增益，并且在真实世界测试中也展现了对未见及噪声物体状态的良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于行为克隆（BC）的方法在解决序列动作决策中的累积误差时存在物理不连续性和语义-物理错位问题，导致动作复制不准确和执行间歇性。为了解决这些问题，提高BC性能，特别是增强人类-机器人交互的有效性，提出了新的方法。

Method: 提出的Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL)框架结合了视觉、语言以及本体感受输入来进行连续的学习过程，同时采用双向交叉注意力机制将语言语义锚定到视动表示中，从而学习上下文信息以生成更准确的动作。

Result: CCoL在三个模拟环境下的表现优于现有方法，平均相对提升了8.0%，特别是在人为演示的双臂插入任务中达到了最高19.2%的相对收益。此外，在一个7自由度机器人上的现实世界测试进一步证实了该方法对于未见过或含噪物体状态下的泛化能力。

Conclusion: 通过引入连续视觉-语言-动作共学与语义-物理对齐(CCooL)框架，成功地克服了行为克隆中存在的关键挑战，包括物理不连续性和语义-物理错位问题，显著提高了动作复制的准确性和流畅性。

Abstract: Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL's generalization under unseen and noisy object states.

</details>


### [16] [Mutation Testing for Industrial Robotic Systems](https://arxiv.org/abs/2511.14432)
*Marcela Gonçalves dos Santos,Sylvain Hallé,Fábio Petrillo*

Main category: cs.RO

TL;DR: 本文提出了一种针对工业机器人系统(IRS)的变异测试方法，通过定义特定领域的变异算子来更好地捕捉机器人动作和传感器读数的语义。实验表明，与传统方法相比，该方法能够生成更有意义的变体，并减少无效或等价情况的数量，从而有助于提高测试套件的质量，使工业机器人系统更加安全可靠。


<details>
  <summary>Details</summary>
Motivation: 传统的变异测试技术在处理涉及基于消息的命令以及与物理世界交互的机器人程序时效果不佳。为了提高工业机器人软件的可靠性，减少因故障导致的严重事故和高昂停机成本，需要开发更适合此类系统的变异测试方法。

Method: 文章提出了一种新的方法论，用于在高层次读写操作层面生成有意义的变异体，这包括了移动、夹爪动作及传感器噪声注入等方面。通过为工业机器人系统设计领域特定的变异算子，以更好地反映机器人行为及其与环境互动的真实情况。

Result: 在一个拾取放置场景中的实证研究表明，所提出的方法相比传统变异算子能够产生更具信息量的变异体，并且显著减少了无效或等价变异体的数量。

Conclusion: 研究结果展示了将变异测试应用于工业机器人系统中可以有效提升测试套件的质量，进而对构建更安全、更可靠的工业机器人系统具有重要意义。

Abstract: Industrial robotic systems (IRS) are increasingly deployed in diverse environments, where failures can result in severe accidents and costly downtime. Ensuring the reliability of the software controlling these systems is therefore critical. Mutation testing, a technique widely used in software engineering, evaluates the effectiveness of test suites by introducing small faults, or mutants, into the code. However, traditional mutation operators are poorly suited to robotic programs, which involve message-based commands and interactions with the physical world. This paper explores the adaptation of mutation testing to IRS by defining domain-specific mutation operators that capture the semantics of robot actions and sensor readings. We propose a methodology for generating meaningful mutants at the level of high-level read and write operations, including movement, gripper actions, and sensor noise injection. An empirical study on a pick-and-place scenario demonstrates that our approach produces more informative mutants and reduces the number of invalid or equivalent cases compared to conventional operators. Results highlight the potential of mutation testing to enhance test suite quality and contribute to safer, more reliable industrial robotic systems.

</details>


### [17] [Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies](https://arxiv.org/abs/2511.14434)
*Marlow Fawn,Matthias Scheutz*

Main category: cs.RO

TL;DR: 提出了一种方法，通过结合基于信号时序逻辑(STL)规范的谐波控制Lyapunov障碍函数(HCLBFs)与任何给定的机器人策略，将不安全的策略转化为具有形式化保证的安全策略。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人在执行任务时的安全性，同时保持任务驱动的行为。

Method: 通过利用从STL规范派生出的HCLBFs生成的安全证书，与现有机器人策略相结合，从而产生既能保证安全性又能保持任务导向行为的指令。

Result: 通过一个简单的概念验证实现，展示了经过强化学习训练的、面向对象的力基策略，在结合了安全约束后，能够使静止的机械臂在移动任务中避开桌面上的障碍物。

Conclusion: 该方法不仅可以确保机器人的操作安全，还可以推广到更复杂的规定和动态任务环境中。

Abstract: We propose a method for combining Harmonic Control Lyapunov-Barrier Functions (HCLBFs) derived from Signal Temporal Logic (STL) specifications with any given robot policy to turn an unsafe policy into a safe one with formal guarantees.  The two components are combined via HCLBF-derived safety certificates, thus producing commands that preserve both safety and task-driven behavior.  We demonstrate with a simple proof-of-concept implementation for an object-centric force-based policy trained through reinforcement learning for a movement task of a stationary robot arm that is able to avoid colliding with obstacles on a table top after combining the policy with the safety constraints.  The proposed method can be generalized to more complex specifications and dynamic task settings.

</details>


### [18] [Advancing Minimally Invasive Precision Surgery in Open Cavities with Robotic Flexible Endoscopy](https://arxiv.org/abs/2511.14458)
*Michelle Mattille,Alexandre Mesot,Miriam Weisskopf,Nicole Ochsenbein-Kölble,Ueli Moehrlen,Bradley J. Nelson,Quentin Boehler*

Main category: cs.RO

TL;DR: 本文介绍了一种结合磁驱动柔性内窥镜与遥操作及半自主导航能力的机器人平台，旨在解决开放腔体内微创手术中的控制难题，并通过实时重建内窥镜场景马赛克来增强手术视野。该系统在羊模型中进行了活体验证。


<details>
  <summary>Details</summary>
Motivation: 尽管柔性机器人在提高微创手术灵活性、精确度和安全性方面潜力巨大，但在开放腔体内的内窥镜干预仍面临挑战，包括缺乏解剖学约束导致控制复杂以及内窥镜有限视野限制了情境意识。

Method: 研究者开发了一个整合了磁驱动柔性内窥镜、远程操作和半自动导航功能的机器人平台，用于执行靶向激光消融。此外，该平台能够实时重建内窥镜场景的马赛克图像，以提供扩展且连续的视觉背景。

Result: 该系统在活体羊模型中成功验证了其克服微创手术在开放空间进行时关键限制的能力。

Conclusion: 所提出的机器人平台证明了它在改善开放空间内微创手术控制、提高手术精准度方面的潜力，特别是在复杂的胎儿镜激光凝固手术中表现出了良好的应用前景。

Abstract: Flexible robots hold great promise for enhancing minimally invasive surgery (MIS) by providing superior dexterity, precise control, and safe tissue interaction. Yet, translating these advantages into endoscopic interventions within open cavities remains challenging. The lack of anatomical constraints and the inherent flexibility of such devices complicate their control, while the limited field of view of endoscopes restricts situational awareness. We present a robotic platform designed to overcome these challenges and demonstrate its potential in fetoscopic laser coagulation, a complex MIS procedure typically performed only by highly experienced surgeons. Our system combines a magnetically actuated flexible endoscope with teleoperated and semi-autonomous navigation capabilities for performing targeted laser ablations. To enhance surgical awareness, the platform reconstructs real-time mosaics of the endoscopic scene, providing an extended and continuous visual context. The ability of this system to address the key limitations of MIS in open spaces is validated in vivo in an ovine model.

</details>


### [19] [Aerial Assistance System for Automated Firefighting during Turntable Ladder Operations](https://arxiv.org/abs/2511.14504)
*Jan Quenzel,Valerij Sekin,Daniel Schleich,Alexander Miller,Merlin Stampa,Norbert Pahlke,Christof Röhrig,Sven Behnke*

Main category: cs.RO

TL;DR: 本文提出了一种结合了安装在云梯上的电动消防监视器和无人机的自动辅助灭火系统，该系统能够准确定位热源并引导水柱到达检测到的热源。初步测试表明，该辅助系统成功定位了多个热源，并将水柱导向火源。


<details>
  <summary>Details</summary>
Motivation: 工业设施中的火灾对消防员来说是一个特殊的挑战，因为建筑物的规模庞大，视觉障碍影响了灭火精度，同时对火灾位置的不准确评估增加了整体损害并延长了消防队的操作时间。

Method: 研究人员开发了一个自动化的灭火辅助系统，该系统利用安装在云梯上的电动消防监视器以及来自无人驾驶飞行器（UAV）的空中支持。UAV能够自主飞行并在无障碍物的飞行通道内探测和定位热源。操作员通过手持控制器监督操作，并选择可触及的火点。一旦选定目标后，UAV会自动规划并移动到两个三角测量位置之间以继续进行火源定位。与此同时，系统调整消防监视器的方向确保水流能够到达检测到的热源。

Result: 在初步测试中，该辅助系统成功地定位了多个热源，并且能够将水柱导向这些火源。

Conclusion: 提出的自动化辅助系统为提高工业设施中火灾扑救效率提供了新的解决方案，通过精确的火源定位和有效的水流导向来减少损失和缩短操作时间。

Abstract: Fires in industrial facilities pose special challenges to firefighters, e.g., due to the sheer size and scale of the buildings. The resulting visual obstructions impair firefighting accuracy, further compounded by inaccurate assessments of the fire's location. Such imprecision simultaneously increases the overall damage and prolongs the fire-brigades operation unnecessarily.
  We propose an automated assistance system for firefighting using a motorized fire monitor on a turntable ladder with aerial support from an unmanned aerial vehicle (UAV). The UAV flies autonomously within an obstacle-free flight funnel derived from geodata, detecting and localizing heat sources. An operator supervises the operation on a handheld controller and selects a fire target in reach. After the selection, the UAV automatically plans and traverses between two triangulation poses for continued fire localization. Simultaneously, our system steers the fire monitor to ensure the water jet reaches the detected heat source. In preliminary tests, our assistance system successfully localized multiple heat sources and directed a water jet towards the fires.

</details>


### [20] [Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language](https://arxiv.org/abs/2511.14565)
*Minyoung Hwang,Alexandra Forsey-Smerek,Nathaniel Dennler,Andreea Bobu*

Main category: cs.RO

TL;DR: 本文提出了一种名为Masked IRL的框架，该框架利用大型语言模型从自然语言指令中推断状态相关性掩码，并在存在模糊指令时使用LLM推理来澄清。这使得机器人能够更好地适应用户偏好，同时提高样本效率、泛化能力和对模糊语言的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于演示的学习奖励函数方法往往因为数据有限而过度拟合于偶然的相关性上，导致无法很好地泛化。自然语言可以更直接地指明机器人应该关注的重点，但目前的方法通常只是简单地将指令作为条件信号处理，未能充分利用其潜力来解决这种不确定性。此外，实际中的指令本身也常常是模棱两可的，简单的条件设置并不可靠。

Method: 提出了Masked Inverse Reinforcement Learning (Masked IRL)框架，该方法利用大型语言模型(LLMs)结合了两种输入类型的优势：演示展示了如何行动，而语言则指出了哪些是重要的。Masked IRL能够根据自然语言指令推断出与状态相关的掩码，并强制执行对于无关状态组件的不变性。当指令不够明确时，它会利用LLM的推理能力，在演示的情境下澄清这些指令。

Result: 通过模拟和真实机器人实验表明，Masked IRL相比之前的语言条件逆向强化学习方法，在性能上提高了最多15%，同时所需的数据量减少了至多4.7倍。

Conclusion: Masked IRL通过有效整合自然语言与演示信息，为机器人学习提供了更加高效且强大的途径，特别是在处理含糊不清的语言指令方面表现出了显著优势。

Abstract: Robots can adapt to user preferences by learning reward functions from demonstrations, but with limited data, reward models often overfit to spurious correlations and fail to generalize. This happens because demonstrations show robots how to do a task but not what matters for that task, causing the model to focus on irrelevant state details. Natural language can more directly specify what the robot should focus on, and, in principle, disambiguate between many reward functions consistent with the demonstrations. However, existing language-conditioned reward learning methods typically treat instructions as simple conditioning signals, without fully exploiting their potential to resolve ambiguity. Moreover, real instructions are often ambiguous themselves, so naive conditioning is unreliable. Our key insight is that these two input types carry complementary information: demonstrations show how to act, while language specifies what is important. We propose Masked Inverse Reinforcement Learning (Masked IRL), a framework that uses large language models (LLMs) to combine the strengths of both input types. Masked IRL infers state-relevance masks from language instructions and enforces invariance to irrelevant state components. When instructions are ambiguous, it uses LLM reasoning to clarify them in the context of the demonstrations. In simulation and on a real robot, Masked IRL outperforms prior language-conditioned IRL methods by up to 15% while using up to 4.7 times less data, demonstrating improved sample-efficiency, generalization, and robustness to ambiguous language. Project page: https://MIT-CLEAR-Lab.github.io/Masked-IRL and Code: https://github.com/MIT-CLEAR-Lab/Masked-IRL

</details>


### [21] [Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks](https://arxiv.org/abs/2511.14592)
*Xianhui Meng,Yuchen Zhang,Zhijian Huang,Zheng Lu,Ziling Ji,Yaoyao Yin,Hongyuan Zhang,Guangfeng Jiang,Yandan Lin,Long Chen,Hangjun Ye,Li Zhang,Jun Liu,Xiaoshuai Hao*

Main category: cs.RO

TL;DR: 本文介绍了DSBench，这是首个全面的驾驶安全基准，旨在评估视觉-语言模型（VLMs）在处理外部环境风险和车内驾驶行为安全方面的表现。通过构建一个包含98,000个实例的数据集并进行微调，可以显著提高现有VLMs的安全性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏同时评估外部环境风险和车内驾驶行为安全性的综合基准，使得视觉-语言模型（VLMs）在安全关键场景中的适用性尚未得到充分探索，从而引发了安全问题。

Method: 创建了名为DSBench的驾驶安全基准，它分为两大类：外部环境风险与车内驾驶行为安全，并细分为10个主要类别及28个子类别。此外，还构建了一个专注于车内和外部安全场景的大规模数据集，用以微调现有的VLMs。

Result: 对多种主流开源和闭源VLMs进行了广泛评估，在复杂的安全关键情况下发现其性能明显下降。而通过对特定数据集的微调，能够显著提升这些模型的安全表现。

Conclusion: DSBench为评估VLMs在安全关键情境下的表现提供了统一方法，强调了当前技术存在的安全隐患，并展示了通过针对性训练来改善安全性的可能性。

Abstract: Vision-Language Models (VLMs) show great promise for autonomous driving, but their suitability for safety-critical scenarios is largely unexplored, raising safety concerns. This issue arises from the lack of comprehensive benchmarks that assess both external environmental risks and in-cabin driving behavior safety simultaneously. To bridge this critical gap, we introduce DSBench, the first comprehensive Driving Safety Benchmark designed to assess a VLM's awareness of various safety risks in a unified manner. DSBench encompasses two major categories: external environmental risks and in-cabin driving behavior safety, divided into 10 key categories and a total of 28 sub-categories. This comprehensive evaluation covers a wide range of scenarios, ensuring a thorough assessment of VLMs' performance in safety-critical contexts. Extensive evaluations across various mainstream open-source and closed-source VLMs reveal significant performance degradation under complex safety-critical situations, highlighting urgent safety concerns. To address this, we constructed a large dataset of 98K instances focused on in-cabin and external safety scenarios, showing that fine-tuning on this dataset significantly enhances the safety performance of existing VLMs and paves the way for advancing autonomous driving technology. The benchmark toolkit, code, and model checkpoints will be publicly accessible.

</details>
