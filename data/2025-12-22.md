<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Lang2Manip: A Tool for LLM-Based Symbolic-to-Geometric Planning for Manipulation](https://arxiv.org/abs/2512.17062)
*Muhayy Ud Din,Jan Rosell,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: 本文提出了一种将基于大语言模型的符号规划器与Kautham运动规划框架相连接的统一管道，实现了通用化、机器人无关的从符号到几何的操作。该系统能够将语言指令转换成符号动作，并使用Kautham提供的任一规划器计算和执行无障碍轨迹，无需额外编码，从而为跨机器人的语言驱动TAMP提供了一个灵活且可扩展的工具。


<details>
  <summary>Details</summary>
Motivation: 尽管最近在大型语言模型上的进展使得机器人可以从自然语言生成符号计划，但在模拟中执行这些计划通常需要特定于机器人的工程或依赖于规划器的集成。这限制了系统的灵活性和泛化能力。

Method: 开发了一种新的统一管道，该管道整合了基于大型语言模型（LLMs）的符号规划器与Kautham运动规划框架，以支持多种工业操作器的ROS兼容性，并在一个接口下提供几何、运动学动态、物理驱动及约束基础的运动规划服务。

Result: 通过所提出的系统，可以将自然语言指示转化为具体的符号行动，并利用Kautham中的任意一个规划器自动计算并执行无障碍路径，而无需进行额外编程工作。这一成果意味着我们拥有了一个高度灵活且易于扩展的语言驱动任务与运动规划解决方案，适用于各种类型的机器人以及不同的操作任务。

Conclusion: 这项研究展示了一种有效的方法来桥接符号规划与实际物理执行之间的差距，促进了更加灵活高效的人机交互方式，特别是在复杂环境下的机器人操作领域内。

Abstract: Simulation is essential for developing robotic manipulation systems, particularly for task and motion planning (TAMP), where symbolic reasoning interfaces with geometric, kinematic, and physics-based execution. Recent advances in Large Language Models (LLMs) enable robots to generate symbolic plans from natural language, yet executing these plans in simulation often requires robot-specific engineering or planner-dependent integration. In this work, we present a unified pipeline that connects an LLM-based symbolic planner with the Kautham motion planning framework to achieve generalizable, robot-agnostic symbolic-to-geometric manipulation. Kautham provides ROS-compatible support for a wide range of industrial manipulators and offers geometric, kinodynamic, physics-driven, and constraint-based motion planning under a single interface. Our system converts language instructions into symbolic actions and computes and executes collision-free trajectories using any of Kautham's planners without additional coding. The result is a flexible and scalable tool for language-driven TAMP that is generalized across robots, planning modalities, and manipulation tasks.

</details>


### [2] [Towards Senior-Robot Interaction: Reactive Robot Dog Gestures](https://arxiv.org/abs/2512.17136)
*Chunyang Meng,Eduardo B. Sandoval,Ricardo Sosa,Francisco Cruz*

Main category: cs.RO

TL;DR: 本文介绍了一种面向老年人的四足机器人系统，该系统通过手势和头部动作识别来实现更直观的用户输入，并使用基于课程的强化学习训练了更具社交表现力的输出。实际测试证明了该框架的可行性与社交表达性，同时也指出了从模拟到现实应用中的一些挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，许多老年人面临孤独问题。陪伴型机器人提供了一种潜在解决方案，但现有陪伴型机器人功能有限，而任务导向型机器人又缺乏社交互动设计，限制了它们对老年人的适用性和接受度。

Method: 作者为四足机器人开发了一个面向老年人的系统，该系统包括一个基于MediaPipe的手势和头部运动识别模块，用于无需遥控器即可控制机器人；同时，利用Isaac Gym中的基于课程的强化学习方法训练了一系列从站立到三腿平衡及腿部伸展等复杂动作，以增强机器人的社交表现力。

Result: 在仿真环境中，最终测试平均成功率达到95%以上，并在一个Unitree机器人上验证了一个关键社交手势（抬爪）。真实世界测试表明此框架具有可行性和社会表达能力，但也揭示了从仿真到现实中关节顺从性、负载分布以及平衡控制等方面的挑战。

Conclusion: 这些贡献促进了实用四足机器人作为老年人社交伴侣的发展，为从模拟到现实世界的适应提供了路径，并为未来用户研究提供了信息。

Abstract: As the global population ages, many seniors face the problem of loneliness. Companion robots offer a potential solution. However, current companion robots often lack advanced functionality, while task-oriented robots are not designed for social interaction, limiting their suitability and acceptance by seniors. Our work introduces a senior-oriented system for quadruped robots that allows for more intuitive user input and provides more socially expressive output. For user input, we implemented a MediaPipe-based module for hand gesture and head movement recognition, enabling control without a remote. For output, we designed and trained robotic dog gestures using curriculum-based reinforcement learning in Isaac Gym, progressing from simple standing to three-legged balancing and leg extensions, and more. The final tests achieved over 95\% success on average in simulation, and we validated a key social gesture (the paw-lift) on a Unitree robot. Real-world tests demonstrated the feasibility and social expressiveness of this framework, while also revealing sim-to-real challenges in joint compliance, load distribution, and balance control. These contributions advance the development of practical quadruped robots as social companions for the senior and outline pathways for sim-to-real adaptation and inform future user studies.

</details>


### [3] [Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots](https://arxiv.org/abs/2512.17183)
*Gang Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种创新的端到端框架，用于合成语义上有意义的共话语手势，并在类人机器人上实时部署。通过将先进的手势生成技术与稳健的物理控制相结合，解决了为机器人创造自然、富有表现力的非语言交流的问题。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人能够拥有自然且富有表现力的非语言沟通方式，本文旨在开发一种能够根据语音输入自动生成并执行复杂动作的系统。

Method: 该研究采用了基于大型语言模型（LLMs）和自回归Motion-GPT模型的生成检索机制来从语音输入中提取表达性参考动作。此外，还结合了高保真模仿学习控制策略MotionTracker，以确保Unitree G1类人机器人能够动态执行这些复杂动作同时保持平衡。

Result: 经过全面评估，证明所提出的综合系统能够产生语义恰当且节奏一致的手势，并且这些手势可以被物理机器人准确地追踪和执行。

Conclusion: 据我们所知，这项工作代表了朝向通用现实世界应用迈出的重要一步，提供了一个完整的自动、语义感知、共话语手势生成以及同步实时物理部署于类人机器人的管道。

Abstract: We present an innovative end-to-end framework for synthesizing semantically meaningful co-speech gestures and deploying them in real-time on a humanoid robot. This system addresses the challenge of creating natural, expressive non-verbal communication for robots by integrating advanced gesture generation techniques with robust physical control. Our core innovation lies in the meticulous integration of a semantics-aware gesture synthesis module, which derives expressive reference motions from speech input by leveraging a generative retrieval mechanism based on large language models (LLMs) and an autoregressive Motion-GPT model. This is coupled with a high-fidelity imitation learning control policy, the MotionTracker, which enables the Unitree G1 humanoid robot to execute these complex motions dynamically and maintain balance. To ensure feasibility, we employ a robust General Motion Retargeting (GMR) method to bridge the embodiment gap between human motion data and the robot platform. Through comprehensive evaluation, we demonstrate that our combined system produces semantically appropriate and rhythmically coherent gestures that are accurately tracked and executed by the physical robot. To our knowledge, this work represents a significant step toward general real-world use by providing a complete pipeline for automatic, semantic-aware, co-speech gesture generation and synchronized real-time physical deployment on a humanoid robot.

</details>


### [4] [Design and Research of a Self-Propelled Pipeline Robot Based on Force Analysis and Dynamic Simulation](https://arxiv.org/abs/2512.17212)
*Yan Gao,Jiliang Wang,Ming Cheng,Tianyun Huang*

Main category: cs.RO

TL;DR: 本研究设计了一种自推进的管道机器人，旨在解决传统缆绳式检测机器人的移动范围和可达性受限的问题。通过采用轮式配置和模块化设计，并利用SolidWorks建模与ADAMS动态仿真优化了驱动模块及运动控制策略，实验证明该机器人能够稳定穿越各种复杂管道环境，为中低压城市燃气管道检测提供了技术可行性参考。


<details>
  <summary>Details</summary>
Motivation: 传统的缆绳式检测机器人由于受到电缆长度和重量的限制，在移动范围和可到达性方面存在很大局限。为了解决这些问题，特别是垂直攀爬失败和T型分支管道通过性差等核心挑战，本文提出了一种基于力分析和动态仿真的自推进管道机器人设计方案。

Method: 采用轮式布局和模块化设计理念来优先满足机体运动控制的核心需求；首先使用SolidWorks完成机器人三维建模，然后将模型导入到ADAMS软件中进行动力学仿真分析，以此为基础对驱动模块以及运动控制策略进行了优化。

Result: 通过构建亚克力管道实验平台验证了机器人的动态性能表现，结果表明该机器人能够通过调整自身姿态以克服障碍物并选择方向前进，展示了其在多种复杂管道场景下稳定行进的能力。

Conclusion: 这项工作展示了一个具有技术可行性的方案，即利用自推进管道机器人来进行中低压城市燃气管道的检查作业，为相关领域的应用提供了有价值的参考。

Abstract: In pipeline inspection, traditional tethered inspection robots are severely constrained by cable length and weight, which greatly limit their travel range and accessibility. To address these issues, this paper proposes a self-propelled pipeline robot design based on force analysis and dynamic simulation, with a specific focus on solving core challenges including vertical climbing failure and poor passability in T-branch pipes. Adopting a wheeled configuration and modular design, the robot prioritizes the core demand of body motion control. Specifically, 3D modeling of the robot was first completed using SolidWorks. Subsequently, the model was imported into ADAMS for dynamic simulation, which provided a basis for optimizing the drive module and motion control strategy.To verify the robot's dynamic performance, an experimental platform with acrylic pipes was constructed. Through adjusting its body posture to surmount obstacles and select directions, the robot has demonstrated its ability to stably traverse various complex pipeline scenarios. Notably, this work offers a technical feasibility reference for the application of pipeline robots in the inspection of medium and low-pressure urban gas pipelines.

</details>


### [5] [Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines](https://arxiv.org/abs/2512.17215)
*Yan Gao,Jiliang Wang,Minghan Wang,Xiaohua Chen,Demin Chen,Zhiyong Ren,Tian-Yun Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩展卡尔曼滤波（EKF）的管道机器人定位方法，通过结合惯性测量单元（IMU）与轮式里程计来提高复杂弯曲管道中的定位精度。实验结果验证了该算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对现有管道定位方法在面对复杂弯曲线缆场景时因电缆缠绕、设备灵活性不足等问题而失效的情况，以及传统视觉和激光制图技术受光照条件和特征不足影响的问题，提出了更适应管道环境因素的解决方案。

Method: 采用一种基于扩展卡尔曼滤波的位置估计方法，首先利用惯性测量单元获取机体姿态角初步信息，然后运用扩展卡尔曼滤波算法优化姿态角估计准确性，最后结合轮式里程计实现高精度定位。

Result: 通过自走式管道机器人在矩形环路管道中进行测试，结果表明所提出的航位推算算法有效提升了复杂弯曲管道内的定位精度。

Conclusion: 本研究开发的基于EKF的管道机器人定位方案能够较好地解决复杂及弯曲管道内部精确定位问题，为管道检测提供了新的技术支持。

Abstract: In the field of gas pipeline location, existing pipeline location methods mostly rely on pipeline location instruments. However, when faced with complex and curved pipeline scenarios, these methods often fail due to problems such as cable entanglement and insufficient equipment flexibility. To address this pain point, we designed a self-propelled pipeline robot. This robot can autonomously complete the location work of complex and curved pipelines in complex pipe networks without external dragging. In terms of pipeline mapping technology, traditional visual mapping and laser mapping methods are easily affected by lighting conditions and insufficient features in the confined space of pipelines, resulting in mapping drift and divergence problems. In contrast, the pipeline location method that integrates inertial navigation and wheel odometers is less affected by pipeline environmental factors. Based on this, this paper proposes a pipeline robot location method based on extended Kalman filtering (EKF). Firstly, the body attitude angle is initially obtained through an inertial measurement unit (IMU). Then, the extended Kalman filtering algorithm is used to improve the accuracy of attitude angle estimation. Finally, high-precision pipeline location is achieved by combining wheel odometers. During the testing phase, the roll wheels of the pipeline robot needed to fit tightly against the pipe wall to reduce slippage. However, excessive tightness would reduce the flexibility of motion control due to excessive friction. Therefore, a balance needed to be struck between the robot's motion capability and positioning accuracy. Experiments were conducted using the self-propelled pipeline robot in a rectangular loop pipeline, and the results verified the effectiveness of the proposed dead reckoning algorithm.

</details>


### [6] [A Service Robot's Guide to Interacting with Busy Customers](https://arxiv.org/abs/2512.17241)
*Suraj Nukala,Meera Sushma,Leimin Tian,Akansel Cosgun,Dana Kulic*

Main category: cs.RO

TL;DR: 本研究通过使用Temi机器人在模拟餐厅场景中进行实验，探讨了服务机器人常用的三种交流方式（声音/语音、视觉显示和微动作）在吸引顾客注意力和传达意图方面的有效性。结果显示，虽然语音在吸引注意力方面非常有效，但在清晰传达意图方面效果较差；参与者认为视觉是最有效的传达意图的方式，其次是语音，而微动作的效果最差。


<details>
  <summary>Details</summary>
Motivation: 随着服务机器人在酒店业中的使用日益增多，了解如何有效地与忙碌的顾客沟通变得尤为重要。

Method: 采用Temi机器人模拟送餐任务，并让参与者参与打字游戏（MonkeyType）以模仿忙碌状态。第一部分比较非语言听觉提示与基线条件对单杯送餐任务时注意力吸引的影响；第二部分评估语音、视觉显示、微动作及其多模态组合在双杯送餐任务中传达特定意图的有效性。

Result: 语音在吸引注意力方面表现出色，但不太能清晰地传达意图；视觉显示被评为传达意图最有效的方式，其次是语音，微动作排名最低。

Conclusion: 这些发现为优化服务机器人的沟通策略提供了见解，强调了在动态服务环境中增强用户体验时吸引注意力与传达意图之间不同作用的重要性。

Abstract: The growing use of service robots in hospitality highlights the need to understand how to effectively communicate with pre-occupied customers. This study investigates the efficacy of commonly used communication modalities by service robots, namely, acoustic/speech, visual display, and micromotion gestures in capturing attention and communicating intention with a user in a simulated restaurant scenario. We conducted a two-part user study (N=24) using a Temi robot to simulate delivery tasks, with participants engaged in a typing game (MonkeyType) to emulate a state of busyness. The participants' engagement in the typing game is measured by words per minute (WPM) and typing accuracy. In Part 1, we compared non-verbal acoustic cue versus baseline conditions to assess attention capture during a single-cup delivery task. In Part 2, we evaluated the effectiveness of speech, visual display, micromotion and their multimodal combination in conveying specific intentions (correct cup selection) during a two-cup delivery task. The results indicate that, while speech is highly effective in capturing attention, it is less successful in clearly communicating intention. Participants rated visual as the most effective modality for intention clarity, followed by speech, with micromotion being the lowest ranked.These findings provide insights into optimizing communication strategies for service robots, highlighting the distinct roles of attention capture and intention communication in enhancing user experience in dynamic hospitality settings.

</details>


### [7] [RecipeMasterLLM: Revisiting RoboEarth in the Era of Large Language Models](https://arxiv.org/abs/2512.17309)
*Asil Kaan Bozcuoglu,Ziyuan Liu*

Main category: cs.RO

TL;DR: 本文提出了RecipeMasterLLM，一种高级规划器，它利用经过微调的大语言模型（LLM）根据用户提示生成OWL动作本体，旨在自动化RoboEarth标准化知识图谱中的知识获取过程。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的快速发展，作者认为可以显著地自动化机器人通过RoboEarth共享和交换知识的过程。

Method: 提出了一种名为RecipeMasterLLM的高级规划器，该规划器基于标准知识图谱生成OWL动作本体。该方法使用专门训练以理解并产生与RoboEarth标准知识图谱一致的动作描述的语言模型，并在检索增强生成（RAG）阶段向LLM提供环境知识以提高上下文理解和生成动作描述的准确性。

Result: 文章主要集中在介绍新方法的概念框架及其潜在优势，具体的实验结果或性能评估未在此摘要中给出。

Conclusion: RecipeMasterLLM为利用大语言模型自动扩展RoboEarth知识库提供了新的方向，强调了在生成动作描述时考虑环境信息的重要性。

Abstract: RoboEarth was a pioneering initiative in cloud robotics, establishing a foundational framework for robots to share and exchange knowledge about actions, objects, and environments through a standardized knowledge graph. Initially, this knowledge was predominantly hand-crafted by engineers using RDF triples within OWL Ontologies, with updates, such as changes in an object's pose, being asserted by the robot's control and perception routines. However, with the advent and rapid development of Large Language Models (LLMs), we believe that the process of knowledge acquisition can be significantly automated. To this end, we propose RecipeMasterLLM, a high-level planner, that generates OWL action ontologies based on a standardized knowledge graph in response to user prompts. This architecture leverages a fine-tuned LLM specifically trained to understand and produce action descriptions consistent with the RoboEarth standardized knowledge graph. Moreover, during the Retrieval-Augmented Generation (RAG) phase, environmental knowledge is supplied to the LLM to enhance its contextual understanding and improve the accuracy of the generated action descriptions.

</details>


### [8] [Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks](https://arxiv.org/abs/2512.17321)
*Momina Liaqat Ali,Muhammad Abid*

Main category: cs.RO

TL;DR: 本文提出了一种模块化的神经-符号控制框架，旨在解决大型语言模型在连续控制应用中的不稳定、收敛慢和幻觉动作问题。通过将低级运动执行与高级语义推理区分开来，并结合轻量级神经增量控制器和局部部署的大型语言模型，该方法在平面操作环境中实现了比仅使用大型语言模型更高的成功率和效率，平均步骤减少超过70%，速度提升高达8.83倍。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）已成为实体系统中基于语言条件控制的有效工具，但它们直接应用于连续控制时仍面临不稳定性、收敛缓慢以及产生幻觉动作的问题。为了解决这些问题，研究提出了一个能够明确区分低级别运动执行与高级别语义推理的模块化神经-符号控制框架。

Method: 本研究设计了一个神经-符号控制架构，其中轻量级神经德尔塔控制器负责在连续空间内执行有界、增量的动作；而本地部署的大型语言模型则负责解释符号任务。实验评估是在一个平面操作设定下进行的，对象之间的空间关系由语言指定。通过对多种任务及本地语言模型（如Mistral, Phi, LLaMA-3.2等）的广泛测试，比较了纯LLM控制、纯神经控制与提出的LLM+DL框架的效果。

Result: 结果表明，相比只使用大型语言模型的方法，神经-符号集成方式在提高成功率和效率方面表现出色，平均步数减少了超过70%，最高速度提升了8.83倍，并且对语言模型的质量具有鲁棒性。此外，该框架通过让大型语言模型输出符号指令并交由经过几何数据训练的神经控制器执行未解释的任务，从而增强了可解释性、稳定性和泛化能力，无需依赖强化学习或昂贵的rollouts。

Conclusion: 实验证据显示，神经-符号分解提供了一种可扩展且有原则的方法来整合语言理解与实时控制，促进了可靠且高效的语言引导实体系统的开发。

Abstract: Although large language models (LLMs) have recently become effective tools for language-conditioned control in embodied systems, instability, slow convergence, and hallucinated actions continue to limit their direct application to continuous control. A modular neuro-symbolic control framework that clearly distinguishes between low-level motion execution and high-level semantic reasoning is proposed in this work. While a lightweight neural delta controller performs bounded, incremental actions in continuous space, a locally deployed LLM interprets symbolic tasks. We assess the suggested method in a planar manipulation setting with spatial relations between objects specified by language. Numerous tasks and local language models, such as Mistral, Phi, and LLaMA-3.2, are used in extensive experiments to compare LLM-only control, neural-only control, and the suggested LLM+DL framework. In comparison to LLM-only baselines, the results show that the neuro-symbolic integration consistently increases both success rate and efficiency, achieving average step reductions exceeding 70% and speedups of up to 8.83x while remaining robust to language model quality. The suggested framework enhances interpretability, stability, and generalization without any need of reinforcement learning or costly rollouts by controlling the LLM to symbolic outputs and allocating uninterpreted execution to a neural controller trained on artificial geometric data. These outputs show empirically that neuro-symbolic decomposition offers a scalable and principled way to integrate language understanding with ongoing control, this approach promotes the creation of dependable and effective language-guided embodied systems.

</details>


### [9] [Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation](https://arxiv.org/abs/2512.17349)
*Xijie Huang,Jinhan Li,Tianyue Wu,Xin Zhou,Zhichao Han,Fei Gao*

Main category: cs.RO

TL;DR: 本文提出了一种结合3D高斯点绘环境与对抗域适应的框架，以解决仅使用单目RGB图像的飞行机器人在复杂环境中导航的问题。通过在高保真模拟中训练并明确减少特征差异，该方法确保策略依赖于领域不变的线索，实现了稳健的零样本转移到物理世界，使得在不同光照条件下也能安全敏捷地飞行。


<details>
  <summary>Details</summary>
Motivation: 当前自主导航系统主要依赖激光雷达和深度摄像头，但一个基本问题仍未解决：仅使用单目RGB图像的飞行机器人能否在复杂的环境中导航？考虑到现实世界数据收集的成本高昂，通过仿真学习策略提供了一条有希望的道路，但直接将这些策略部署到实际世界受到显著的仿真到现实感知差距的影响。

Method: 本文提出了一个结合了3D高斯点绘(3DGS)环境的真实感与对抗域适应（Adversarial Domain Adaptation）的框架。通过在这种高保真度的模拟环境中进行训练，并且明确地最小化特征差异，旨在让所学得的策略能够依靠那些跨域保持一致性的视觉线索。

Result: 实验结果表明，通过这种方法训练得到的策略可以实现向物理世界的稳健零样本迁移，允许飞行器在结构化程度低、光照条件多变的实际环境中安全快速地飞行。

Conclusion: 研究展示了一种有效的方法，利用3DGS与对抗域适应相结合的方式，解决了单目RGB图像用于飞行机器人导航时面临的挑战，证明了即使没有深度传感器的帮助，飞行机器人也能成功地在复杂且光照变化大的环境中导航。

Abstract: Modern autonomous navigation systems predominantly rely on lidar and depth cameras. However, a fundamental question remains: Can flying robots navigate in clutter using solely monocular RGB images? Given the prohibitive costs of real-world data collection, learning policies in simulation offers a promising path. Yet, deploying such policies directly in the physical world is hindered by the significant sim-to-real perception gap. Thus, we propose a framework that couples the photorealism of 3D Gaussian Splatting (3DGS) environments with Adversarial Domain Adaptation. By training in high-fidelity simulation while explicitly minimizing feature discrepancy, our method ensures the policy relies on domain-invariant cues. Experimental results demonstrate that our policy achieves robust zero-shot transfer to the physical world, enabling safe and agile flight in unstructured environments with varying illumination.

</details>


### [10] [TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data](https://arxiv.org/abs/2512.17370)
*Deqing Liu,Yinfeng Gao,Deheng Qian,Qichao Zhang,Xiaoqing Ye,Junyu Han,Yupeng Zheng,Xueyi Liu,Zhongpu Xia,Dawei Ding,Yifeng Pan,Dongbin Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种名为TakeAD的新框架，通过利用专家接管数据来优化预训练的模仿学习策略，从而提高闭环驾驶性能。该方法结合了DAgger和DPO技术，使策略能够逐步学习处理接管情况下的恢复策略，减少了开环训练与闭环部署之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶方法通常依赖于模仿学习（IL），但在开放环路训练与封闭环路部署之间存在不匹配问题，这导致在实际操作中频繁发生驾驶员主动干预系统的情况。如何有效利用这些来自系统脱开场景中的专家接管数据，并以此扩展IL策略的能力是一个有价值但尚未被充分探索的挑战。

Method: 提出了一个名为TakeAD的新颖偏好基后优化框架，旨在通过使用脱开场景中的专家接管数据来微调预训练的IL策略，以增强闭环驾驶表现。首先设计了一个高效的专家接管数据收集流程；然后，该后优化框架将迭代的数据集聚合（DAgger）用于模仿学习，并直接偏好优化（DPO）以实现偏好对齐。DAgger阶段让策略通过直接模仿专家干预获得处理脱开状态的基本能力；随后，DPO阶段进一步调整策略的行为，使其更好地符合专家在脱开情境下的偏好。

Result: 通过多次迭代，策略逐渐学会了针对脱开状态的恢复策略，从而缩小了开环差距。在闭环Bench2Drive基准测试上的实验表明，与纯IL方法相比，本方法更有效，全面消融研究也证实了每个组件的作用。

Conclusion: TakeAD框架通过结合DAgger和DPO成功地利用了专家接管数据来改善预训练IL策略，在处理自动驾驶过程中遇到的系统脱开情景时表现出色，为解决开环与闭环执行间的差异提供了新的解决方案。

Abstract: Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component.

</details>


### [11] [Personalized Gait Patterns During Exoskeleton-Aided Training May Have Minimal Effect on User Experience. Insights from a Pilot Study](https://arxiv.org/abs/2512.17425)
*Beatrice Luciani,Katherine Lin Poggensee,Heike Vallery,Alex van den Berg,Severin David Woernle,Mostafa Mogharabi,Stefano Dalla Gasperina,Laura Marchal-Crespo*

Main category: cs.RO

TL;DR: 本文提出了一种用于外骨骼的数据驱动步态个性化框架，支持多平面运动，并通过实验评估了其舒适性、自然性和整体体验。虽然在不同模式条件下没有发现显著差异，但结果表明参与者可能适应了外骨骼内的行走，强调了在设计个性化步态控制器时整合主观反馈的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数外骨骼依赖于预先录制且非个性化的步态轨迹，这可能会限制动作的自然度和用户的舒适度。为了解决这个问题，研究者们开发了一个能够支持包括髋关节外展/内收以及骨盆平移和旋转在内的多平面运动的数据驱动步态个性化框架。

Method: 研究人员使用回归模型来生成个性化轨迹，这些模型基于来自规范数据库的人体测量学、人口统计学和步行速度数据进行训练。然后，在一个包含10名无损伤参与者的内部主题实验中，对这些个性化轨迹进行了关于舒适度、自然性和总体体验方面的评估，并与同一数据库中的两个标准模式进行了比较：一个是所有轨迹的平均值，另一个是随机选择的。

Result: 尽管所有轨迹都以高精度执行，但在不同模式条件之间并未发现明显差异。不过，后来试验中的模式条件被评为比第一次试验更舒适、更自然，表明参与者可能已经适应了在外骨骼内行走，而不管所施加的步态模式如何。

Conclusion: 研究发现强调了在设计个性化步态控制器时考虑用户适应过程并整合主观反馈的重要性。

Abstract: Robot-aided gait rehabilitation facilitates high-intensity and repeatable therapy. However, most exoskeletons rely on pre-recorded, non-personalized gait trajectories constrained to the sagittal plane, potentially limiting movement naturalness and user comfort. We present a data-driven gait personalization framework for an exoskeleton that supports multi-planar motion, including hip abduction/adduction and pelvic translation and rotation. Personalized trajectories to individual participants were generated using regression models trained on anthropometric, demographic, and walking speed data from a normative database. In a within-subject experiment involving ten unimpaired participants, these personalized trajectories were evaluated in regard to comfort, naturalness, and overall experience and compared against two standard patterns from the same database: one averaging all the trajectories, and one randomly selected. We did not find relevant differences across pattern conditions, despite all trajectories being executed with high accuracy thanks to a stiff position-derivative controller. We found, however, that pattern conditions in later trials were rated as more comfortable and natural than those in the first trial, suggesting that participants might have adapted to walking within the exoskeleton, regardless of the enforced gait pattern. Our findings highlight the importance of integrating subjective feedback when designing personalized gait controllers and accounting for user adaptation during experimentation.

</details>


### [12] [ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination](https://arxiv.org/abs/2512.17435)
*Teng Wang,Xinxin Zhao,Wenzhe Cai,Changyin Sun*

Main category: cs.RO

TL;DR: 本研究提出了一种基于视觉-语言模型（VLMs）的无地图视觉导航框架ImagineNav++，通过想象未来的观察图像来指导机器人选择最佳视角，并利用选择性聚焦记忆机制保持空间一致性，从而在开放词汇对象和实例导航基准测试中达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 虽然最近的方法已经利用大型语言模型（LLMs）来结合常识推理并提高探索效率，但它们的规划仍然受限于文本表示，无法充分捕捉空间占用或场景几何形状——这些是导航决策的关键因素。这项工作旨在探索视觉-语言模型是否能够仅使用机载RGB/RGB-D流实现无地图视觉导航，发挥其在空间感知和规划方面的潜力。

Method: ImagineNav++框架首先通过一个未来视图想象模块提炼人类导航偏好，生成具有高探索潜力的语义上有意义的视角。这些被想象出的视点作为视觉提示供VLM识别最有信息量的视角。为了维持空间一致性，研究者开发了选择性聚焦记忆机制，它通过稀疏到密集的框架层次化地整合关键帧观察，为长期空间推理构建了一个紧凑而全面的记忆。

Result: 广泛的实验表明，ImagineNav++在无地图设置下实现了最先进的性能，甚至超过了大多数基于地图的方法，突出了场景想象和记忆在基于VLM的空间推理中的重要性。

Conclusion: 研究表明，通过将导航规划转化为简单的最佳视角图像选择问题，并结合有效的记忆机制以保持空间连续性，基于视觉-语言模型的系统能够在没有预先绘制地图的情况下成功执行复杂的导航任务。

Abstract: Visual navigation is a fundamental capability for autonomous home-assistance robots, enabling long-horizon tasks such as object search. While recent methods have leveraged Large Language Models (LLMs) to incorporate commonsense reasoning and improve exploration efficiency, their planning remains constrained by textual representations, which cannot adequately capture spatial occupancy or scene geometry--critical factors for navigation decisions. We explore whether Vision-Language Models (VLMs) can achieve mapless visual navigation using only onboard RGB/RGB-D streams, unlocking their potential for spatial perception and planning. We achieve this through an imagination-powered navigation framework, ImagineNav++, which imagines future observation images from candidate robot views and translates navigation planning into a simple best-view image selection problem for VLMs. First, a future-view imagination module distills human navigation preferences to generate semantically meaningful viewpoints with high exploration potential. These imagined views then serve as visual prompts for the VLM to identify the most informative viewpoint. To maintain spatial consistency, we develop a selective foveation memory mechanism, which hierarchically integrates keyframe observations via a sparse-to-dense framework, constructing a compact yet comprehensive memory for long-term spatial reasoning. This approach transforms goal-oriented navigation into a series of tractable point-goal navigation tasks. Extensive experiments on open-vocabulary object and instance navigation benchmarks show that ImagineNav++ achieves SOTA performance in mapless settings, even surpassing most map-based methods, highlighting the importance of scene imagination and memory in VLM-based spatial reasoning.

</details>


### [13] [Adaptive Covariance and Quaternion-Focused Hybrid Error-State EKF/UKF for Visual-Inertial Odometry](https://arxiv.org/abs/2512.17505)
*Ufuk Asil,Efendi Nasibov*

Main category: cs.RO

TL;DR: 本研究提出了一种新的视觉-惯性里程计（VIO）方法，专为无人机设计，能够应对环境挑战并动态评估传感器可靠性。该方法通过结合误差状态扩展卡尔曼滤波器（ESKF）和比例无迹卡尔曼滤波器（SUKF）来处理IMU数据，并根据图像熵等指标评估视觉测量的可靠性。实验结果表明，该方法在复杂环境中提高了定位精度的同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了提高无人机在面对环境挑战时的导航准确性与稳定性，同时减少计算资源消耗，提出了一个鲁棒且能动态评估传感器可靠性的混合视觉-惯性里程计系统。

Method: 该研究采用了一种松耦合传感器融合架构，利用一种新颖的以四元数为重点的误差状态EKF/UKF架构处理IMU数据。首先使用ESKF传播整个状态，随后应用SUKF步骤专门细化方向估计。此外，基于图像熵、强度变化等因素对视觉测量的可靠性进行动态评分，进而调整测量噪声协方差以保证即使在恶劣条件下也能稳定估计姿态。

Result: 通过对EuRoC MAV数据集的全面实验分析，证明了所提方法相比基于ESKF的方法，在困难场景下的位置精度平均提高了49%，旋转精度平均提升了57%；同时，相较于全SUKF实现，达到了相近的精度但计算成本减少了约48%。

Conclusion: 提出的新型VIO方法有效地平衡了计算效率与估计精度之间的关系，显著提升了无人机在复杂及传感器可靠性变化环境中的姿态估计性能。

Abstract: This study presents an innovative hybrid Visual-Inertial Odometry (VIO) method for Unmanned Aerial Vehicles (UAVs) that is resilient to environmental challenges and capable of dynamically assessing sensor reliability. Built upon a loosely coupled sensor fusion architecture, the system utilizes a novel hybrid Quaternion-focused Error-State EKF/UKF (Qf-ES-EKF/UKF) architecture to process inertial measurement unit (IMU) data. This architecture first propagates the entire state using an Error-State Extended Kalman Filter (ESKF) and then applies a targeted Scaled Unscented Kalman Filter (SUKF) step to refine only the orientation. This sequential process blends the accuracy of SUKF in quaternion estimation with the overall computational efficiency of ESKF. The reliability of visual measurements is assessed via a dynamic sensor confidence score based on metrics, such as image entropy, intensity variation, motion blur, and inference quality, adapting the measurement noise covariance to ensure stable pose estimation even under challenging conditions. Comprehensive experimental analyses on the EuRoC MAV dataset demonstrate key advantages: an average improvement of 49% in position accuracy in challenging scenarios, an average of 57% in rotation accuracy over ESKF-based methods, and SUKF-comparable accuracy achieved with approximately 48% lower computational cost than a full SUKF implementation. These findings demonstrate that the presented approach strikes an effective balance between computational efficiency and estimation accuracy, and significantly enhances UAV pose estimation performance in complex environments with varying sensor reliability.

</details>


### [14] [Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests](https://arxiv.org/abs/2512.17553)
*Guglielmo Del Col,Väinö Karjalainen,Teemu Hakala,Yibo Zhang,Eija Honkavaara*

Main category: cs.RO

TL;DR: 本文提出了一种改进的基于深度学习的导航框架，该框架集成了语义增强的深度编码和神经运动基元评估，以在杂乱的森林中实现稳健飞行。通过增加几个模块来解决实际部署中的限制，包括侧向控制、时间一致性机制、基于立体视觉的视觉-惯性里程计解决方案以及实时过滤不安全动作的安全监督层。实验表明，该方法在高度杂乱的森林环境中具有更高的成功率、更稳定的轨迹和更好的避障性能。


<details>
  <summary>Details</summary>
Motivation: 自主空中导航在密集自然环境中面临许多挑战，如可见度有限、细小且不规则的障碍物、无GNSS操作及感知能力下降等问题。为了解决这些问题，研究者们希望开发出一种能够在这种复杂环境下有效工作的导航系统。

Method: 本研究提出了一个改良版的基于深度学习的导航框架，它结合了语义增强的深度编码与神经运动原评估，旨在提高在繁杂森林环境下的飞行稳定性。相较于原始sevae-ORACLE算法，新方案增加了几个关键组件：横向操控功能、用于抑制振荡规划决策的时间一致性机制、抗漂移的状态估计用立体视觉-惯性里程计算法、以及实时筛选危险行为的安全监管层级。此外还引入了深度细化步骤以更好地表示细枝并减少立体噪声，并通过GPU优化将机载推理吞吐量从4Hz提升至10Hz。

Result: 所提出的导航方法在相同环境条件和硬件约束下与几种现有的基于学习的导航方法进行了比较测试，结果显示其在高密度森林环境中表现出更高的成功率、更稳定的飞行路径及更佳的碰撞规避效果。该系统被安装在一个定制四旋翼无人机上，在三个北方森林环境中进行实地测试，成功完成了所有中等和高密度杂草覆盖区域的完全自主飞行任务，以及15次高密度灌木丛下飞行中的12次。

Conclusion: 实验结果表明，所提出的方法相比现有导航技术，在复杂的自然环境中提供了更高的可靠性和安全性。特别是在高度密集的植被条件下，该系统展示了显著的优势。

Abstract: Autonomous aerial navigation in dense natural environments remains challenging due to limited visibility, thin and irregular obstacles, GNSS-denied operation, and frequent perceptual degradation. This work presents an improved deep learning-based navigation framework that integrates semantically enhanced depth encoding with neural motion-primitive evaluation for robust flight in cluttered forests. Several modules are incorporated on top of the original sevae-ORACLE algorithm to address limitations observed during real-world deployment, including lateral control for sharper maneuvering, a temporal consistency mechanism to suppress oscillatory planning decisions, a stereo-based visual-inertial odometry solution for drift-resilient state estimation, and a supervisory safety layer that filters unsafe actions in real time. A depth refinement stage is included to improve the representation of thin branches and reduce stereo noise, while GPU optimization increases onboard inference throughput from 4 Hz to 10 Hz.
  The proposed approach is evaluated against several existing learning-based navigation methods under identical environmental conditions and hardware constraints. It demonstrates higher success rates, more stable trajectories, and improved collision avoidance, particularly in highly cluttered forest settings. The system is deployed on a custom quadrotor in three boreal forest environments, achieving fully autonomous completion in all flights in moderate and dense clutter, and 12 out of 15 flights in highly dense underbrush. These results demonstrate improved reliability and safety over existing navigation methods in complex natural environments.

</details>


### [15] [Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration](https://arxiv.org/abs/2512.17560)
*M. Faroni,A. Spano,A. M. Zanchettin,P. Rocco*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度学习的安全意识方法，使协作机器人能够在保证安全的同时优化任务选择，从而减少周期时间。实验表明该方法在拣选和包装场景中显著降低了周期时间。


<details>
  <summary>Details</summary>
Motivation: 传统的人机协作机器人安全保障措施在频繁的人类互动下会增加机器人的循环时间，从而影响效率。本文旨在不依赖于事先的安全逻辑知识的情况下，通过一种新的方法来缓解这种效率损失。

Method: 使用深度学习模型，让机器人根据执行数据学习系统状态与由安全引起的减速之间的关系。此框架并不直接预测人类动作，而是直接建模交互效应对机器人速度的影响，简化了实现过程，并提高了对不同安全逻辑的通用性。运行时，所学模型会优化任务选择以最小化循环时间同时遵守安全要求。

Result: 在拣选和包装场景中的实验显示，采用本方法后循环时间有了显著下降。

Conclusion: 提出的这种方法能够有效地在保持安全标准的同时提高人机协作机器人的工作效率。

Abstract: Ensuring human safety in collaborative robotics can compromise efficiency because traditional safety measures increase robot cycle time when human interaction is frequent. This paper proposes a safety-aware approach to mitigate efficiency losses without assuming prior knowledge of safety logic. Using a deep-learning model, the robot learns the relationship between system state and safety-induced speed reductions based on execution data. Our framework does not explicitly predict human motions but directly models the interaction effects on robot speed, simplifying implementation and enhancing generalizability to different safety logics. At runtime, the learned model optimizes task selection to minimize cycle time while adhering to safety requirements. Experiments on a pick-and-packaging scenario demonstrated significant reductions in cycle times.

</details>


### [16] [Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation](https://arxiv.org/abs/2512.17568)
*Kangchen Lv,Mingrui Yu,Yongyi Jia,Chenyu Zhang,Xiang Li*

Main category: cs.RO

TL;DR: 该论文提出了一种具有3D空间一致性表示的仿生学习框架，通过将机器人状态和动作都表示为一组位于机械臂上的3D点，提高了策略学习的样本效率和空间泛化能力。此外，还通过结合运动学先验到扩散过程，并利用基于优化的全身逆运动学求解器来计算关节角度命令，以确保输出动作的运动学可行性。实验结果表明了该方法在身体感知操控策略学习方面相较于现有方法具有更高的成功率和更强的空间泛化性。


<details>
  <summary>Details</summary>
Motivation: 在许多涉及身体避碰或身体-物体交互的操作场景中，仅考虑末端执行器的姿态来进行策略学习是不够的，需要对整个机械臂的运动学有全面的认识。传统的全臂操作方法是在机器人的关节空间中学习动作，但这种做法增加了策略学习的复杂度，因为要在任务空间（即3D空间）内实现泛化，政策必须内在地理解非线性的手臂运动学，而这很难从有限的演示中学到。

Method: 本文提出了一个具备运动学意识的模仿学习框架，其中任务、观察和行动空间都统一在相同的3D空间中表示。具体来说，使用机械臂上的一组3D点来同时表示机器人状态和动作，这些表示自然地与3D点云观察对齐。进一步，在扩散策略的基础上，将运动学先验融入到扩散过程中，保证输出动作的运动学可行性。最后，通过一种基于优化的整体逆运动学求解器来计算出用于执行的关节角度指令。

Result: 仿真和实际世界中的实验结果显示，所提出的方法相比现有方法，在身体感知操纵策略学习中展现出更高的成功率以及更强大的空间泛化性能。

Conclusion: 通过采用一致的任务、观察及动作空间表示形式，以及结合运动学先验知识，本文所提出的框架有效地提升了针对机械臂控制的策略学习效果，特别是在样本效率、空间泛化能力和全臂控制方面。

Abstract: Whole-body control of robotic manipulators with awareness of full-arm kinematics is crucial for many manipulation scenarios involving body collision avoidance or body-object interactions, which makes it insufficient to consider only the end-effector poses in policy learning. The typical approach for whole-arm manipulation is to learn actions in the robot's joint space. However, the unalignment between the joint space and actual task space (i.e., 3D space) increases the complexity of policy learning, as generalization in task space requires the policy to intrinsically understand the non-linear arm kinematics, which is difficult to learn from limited demonstrations. To address this issue, this letter proposes a kinematics-aware imitation learning framework with consistent task, observation, and action spaces, all represented in the same 3D space. Specifically, we represent both robot states and actions using a set of 3D points on the arm body, naturally aligned with the 3D point cloud observations. This spatially consistent representation improves the policy's sample efficiency and spatial generalizability while enabling full-body control. Built upon the diffusion policy, we further incorporate kinematics priors into the diffusion processes to guarantee the kinematic feasibility of output actions. The joint angle commands are finally calculated through an optimization-based whole-body inverse kinematics solver for execution. Simulation and real-world experimental results demonstrate higher success rates and stronger spatial generalizability of our approach compared to existing methods in body-aware manipulation policy learning.

</details>


### [17] [Vidarc: Embodied Video Diffusion Model for Closed-loop Control](https://arxiv.org/abs/2512.17661)
*Yao Feng,Chendong Xiang,Xinyi Mao,Hengkai Tan,Zuyue Zhang,Shuhe Huang,Kaiwen Zheng,Haitian Liu,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种名为Vidarc的新方法，它结合了视频扩散模型和掩蔽的逆动力学模型，以实现快速准确的闭环控制。该方法在预训练阶段使用了大规模跨实体数据集，并在实际部署中超过了现有技术，在成功率上提高了至少15%，延迟降低了91%。


<details>
  <summary>Details</summary>
Motivation: 机器人手臂在数据稀缺环境下的操作由于复杂的物理交互和多样的情境而极具挑战性。尽管基于视频的方法通过利用互联网规模的视频数据进行预训练展现了捕捉和转移时间与物理交互的巨大潜力，但这些方法通常没有针对特定实体的闭环控制进行优化，导致高延迟和不足的实际应用基础。

Method: 提出了一种新的自回归体现视频扩散方法——Vidarc（Video Diffusion for Action Reasoning and Closed-loop Control），该方法通过动作相关掩码对视频预测进行实地化，并通过缓存自回归生成整合实时反馈来实现快速且准确的闭环控制。

Result: Vidarc经过一百万次跨实体事件预训练后，相比最先进基线，在现实世界部署中实现了至少15%更高的成功率以及91%的延迟减少。此外，还强调了其在之前未见过的机器人平台上的鲁棒泛化能力和错误纠正能力。

Conclusion: Vidarc为解决数据稀缺环境中机器人手臂操纵问题提供了一个有效解决方案，通过增强视频预测与实时反馈相结合的方式，显著提高了控制精度和响应速度，同时展示了强大的泛化性能。

Abstract: Robotic arm manipulation in data-scarce settings is a highly challenging task due to the complex embodiment dynamics and diverse contexts. Recent video-based approaches have shown great promise in capturing and transferring the temporal and physical interactions by pre-training on Internet-scale video data. However, such methods are often not optimized for the embodiment-specific closed-loop control, typically suffering from high latency and insufficient grounding. In this paper, we present Vidarc (Video Diffusion for Action Reasoning and Closed-loop Control), a novel autoregressive embodied video diffusion approach augmented by a masked inverse dynamics model. By grounding video predictions with action-relevant masks and incorporating real-time feedback through cached autoregressive generation, Vidarc achieves fast, accurate closed-loop control. Pre-trained on one million cross-embodiment episodes, Vidarc surpasses state-of-the-art baselines, achieving at least a 15% higher success rate in real-world deployment and a 91% reduction in latency. We also highlight its robust generalization and error correction capabilities across previously unseen robotic platforms.

</details>


### [18] [A Dual Quaternion based RRT* Path Planning Approach for Satellite Rendezvous and Docking](https://arxiv.org/abs/2512.17680)
*Ana Stankovic,Mohamed Khalil Ben-Larbi,Wolfgang H. Müller*

Main category: cs.RO

TL;DR: 该论文提出了一种基于双四元数表示的采样运动规划器，能够在避开禁区约束的情况下为卫星交会对接生成平滑无碰撞的六自由度姿态轨迹。通过将双四元数代数直接集成到RRT*框架中，实现了SE(3)中的自然螺旋运动插值，并且在多障碍物场景下进行了演示。与使用分离平移和四元数转向的标准RRT*相比，所提方法展示了更好的姿态连续性和避障性能。


<details>
  <summary>Details</summary>
Motivation: 为了在存在禁区约束条件下实现卫星交会对接任务时能够生成平滑且无碰撞的姿态路径，需要一种能够有效处理复杂环境同时保持姿态连续性的运动规划方法。

Method: 提出的方法是基于双四元数的RRT*（快速随机树*）运动规划算法，该算法直接利用双四元数代数来支持SE(3)空间中的自然螺旋运动插值。整个规划器已经用Python实现，并在一个代表性的多障碍物场景中进行了测试。

Result: 实验结果表明，相比于传统分离平移和旋转处理方式下的RRT*，本方法能提供更优的姿态连续性以及避障能力。但该方法主要关注于运动学层面，未考虑相对轨道动力学因素。

Conclusion: 该研究展示了一种新的基于双四元数的RRT*算法，在卫星交会对接任务中表现出色，尤其是在处理姿态连续性和避障方面。然而，对于实际应用而言，仍需进一步结合动力学约束优化最终路径。

Abstract: This paper proposes a sampling-based motion planner that employs a dual quaternion representation to generate smooth, collision-free six-degree-of-freedom pose trajectories for satellite rendezvous and docking under keep-out zone constraints. The proposed planner integrates the dual quaternion algebra directly into an RRT* framework, thereby enabling natural screw motion interpolation in SE(3). The dual quaternion-based RRT* has been implemented in Python and demonstrated on a representative multi-obstacle scenario. A comparison with a standard RRT* using separate translation and quaternion steering highlights the enhanced pose continuity and obstacle avoidance of the proposed method. The present approach is purely kinematic in nature and does not take into account relative orbital dynamics. Consequently, the resulting path provides a preliminary estimate for a subsequent optimisation-based trajectory planner, which will refine the motion with dynamic constraints for the purpose of practical satellite rendezvous and docking missions.

</details>


### [19] [UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation](https://arxiv.org/abs/2512.17764)
*Kangchen Lv,Mingrui Yu,Shihefeng Wang,Xiangyang Ji,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种名为UniStateDLO的新方法，它是一个完整的基于深度学习的可变形线性物体（如电缆、绳索）感知管道，能够在严重遮挡的情况下实现鲁棒的状态估计和跟踪。该方法通过合成数据集训练，展示了零样本从模拟到现实的泛化能力，并在仿真和真实世界实验中超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉的方法在处理可变形线性物体（DLOs）时面临诸多挑战，包括易受遮挡影响、状态空间高维性、缺乏显著视觉特征以及传感器噪声等。为了解决这些问题，作者提出了一个能够克服这些限制并提高DLOs感知准确性的新方案。

Method: UniStateDLO采用条件生成模型形式来解决单帧状态估计与跨帧状态跟踪任务，利用扩散模型的强大功能来捕捉部分观测与高维DLO状态之间的复杂映射关系。整个系统仅依靠大规模合成数据集进行训练，实现了无需任何真实世界训练数据的零样本迁移能力。

Result: 综合仿真及实际测试表明，在面对大量遮挡情况下，UniStateDLO不仅在状态估计方面优于其他最先进基准，在状态跟踪上也表现优异，能够实时生成全局平滑且局部精确的DLO状态预测。此外，将其作为闭环DLO操控系统的前端模块后，进一步证明了其支持复杂受限3D环境中稳定反馈控制的能力。

Conclusion: 通过引入UniStateDLO，研究者们开发出一种高效且鲁棒的DLO感知解决方案，特别适用于存在严重遮挡及其他挑战性条件下的应用场景。

Abstract: Perception of deformable linear objects (DLOs), such as cables, ropes, and wires, is the cornerstone for successful downstream manipulation. Although vision-based methods have been extensively explored, they remain highly vulnerable to occlusions that commonly arise in constrained manipulation environments due to surrounding obstacles, large and varying deformations, and limited viewpoints. Moreover, the high dimensionality of the state space, the lack of distinctive visual features, and the presence of sensor noises further compound the challenges of reliable DLO perception. To address these open issues, this paper presents UniStateDLO, the first complete DLO perception pipeline with deep-learning methods that achieves robust performance under severe occlusion, covering both single-frame state estimation and cross-frame state tracking from partial point clouds. Both tasks are formulated as conditional generative problems, leveraging the strong capability of diffusion models to capture the complex mapping between highly partial observations and high-dimensional DLO states. UniStateDLO effectively handles a wide range of occlusion patterns, including initial occlusion, self-occlusion, and occlusion caused by multiple objects. In addition, it exhibits strong data efficiency as the entire network is trained solely on a large-scale synthetic dataset, enabling zero-shot sim-to-real generalization without any real-world training data. Comprehensive simulation and real-world experiments demonstrate that UniStateDLO outperforms all state-of-the-art baselines in both estimation and tracking, producing globally smooth yet locally precise DLO state predictions in real time, even under substantial occlusions. Its integration as the front-end module in a closed-loop DLO manipulation system further demonstrates its ability to support stable feedback control in complex, constrained 3-D environments.

</details>


### [20] [Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes](https://arxiv.org/abs/2512.17846)
*Carlos Vélez García,Miguel Cazorla,Jorge Pomares*

Main category: cs.RO

TL;DR: 本文提出了一种名为Planning as Descent (PaD)的框架，用于离线目标条件强化学习。通过学习一个基于整个潜在轨迹的目标条件能量函数来代替直接学习策略或显式规划器，并且在训练和推理过程中使用相同的计算流程减少模型间的不匹配。该方法在OGBench立方体操作任务上实现了最先进的性能，特别是在处理噪声数据时表现出更高的成功率和计划效率。


<details>
  <summary>Details</summary>
Motivation: 传统的离线目标条件强化学习方法往往依赖于直接学习策略或者明确的规划器，这可能导致训练与测试之间的不匹配问题。为了解决这个问题，作者提出了Planning as Descent (PaD)，它通过学习一个针对整个潜在轨迹的目标条件能量函数来评估未来路径的可能性，从而实现更稳健有效的规划。

Method: PaD框架通过自监督后见之明目标重标记进行训练，以围绕规划动态塑造能量景观。在推理阶段，则通过对多个候选轨迹进行基于不同时间假设的细化，并选择低能量、同时平衡可行性和效率的计划方案。值得注意的是，在训练和推理期间采用了相同的计算过程，有助于减少因采用解耦建模管道而常见的训练-测试不一致问题。

Result: 实验结果显示，当仅使用狭窄专家演示进行训练时，PaD达到了95%的成功率，远超之前方法最高68%的表现。此外，即使是在含有噪声和次优的数据集上训练，PaD仍能进一步提高成功率并优化计划效率，证明了验证驱动型规划方法的优势。

Conclusion: 研究结果表明，学会评估和改进轨迹提供了一个对于离线无奖励规划来说比直接学习策略更为健壮的选择。这种新方法不仅提高了规划任务的成功率，而且在面对质量较低的数据时也表现出了很好的鲁棒性。

Abstract: We present Planning as Descent (PaD), a framework for offline goal-conditioned reinforcement learning that grounds trajectory synthesis in verification. Instead of learning a policy or explicit planner, PaD learns a goal-conditioned energy function over entire latent trajectories, assigning low energy to feasible, goal-consistent futures. Planning is realized as gradient-based refinement in this energy landscape, using identical computation during training and inference to reduce train-test mismatch common in decoupled modeling pipelines.
  PaD is trained via self-supervised hindsight goal relabeling, shaping the energy landscape around the planning dynamics. At inference, multiple trajectory candidates are refined under different temporal hypotheses, and low-energy plans balancing feasibility and efficiency are selected.
  We evaluate PaD on OGBench cube manipulation tasks. When trained on narrow expert demonstrations, PaD achieves state-of-the-art 95\% success, strongly outperforming prior methods that peak at 68\%. Remarkably, training on noisy, suboptimal data further improves success and plan efficiency, highlighting the benefits of verification-driven planning. Our results suggest learning to evaluate and refine trajectories provides a robust alternative to direct policy learning for offline, reward-free planning.

</details>
