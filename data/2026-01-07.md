<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Movement Primitives in Robotics: A Comprehensive Survey](https://arxiv.org/abs/2601.02379)
*Nolan B. Gutierrez,William J. Beksi*

Main category: cs.RO

TL;DR: 本综述文章全面概述了运动基元方法及其在机器人技术中的应用，旨在为从业者提供这些框架在机器人上下文中的使用信息。


<details>
  <summary>Details</summary>
Motivation: 研究者们发现生物系统通过一系列连续的运动片段来执行复杂任务，这启发了他们识别出适合于自动生成自主系统（如机器人）运动指令的基本构建块——运动基元。

Method: 本文按照时间顺序提供了运动基元方法及应用的百科全书式概览，并将运动基元框架作为表示通过人类演示获得的机器人控制轨迹的一种方式来介绍。

Result: 运动基元能够在轨迹级别上编码基本动作，解决机器人学中的难题；同时，该综述也探讨了成功运用运动基元的应用实例以及在实际应用中遇到的问题与挑战。

Conclusion: 综述旨在对主要的运动基元框架进行系统性回顾并分析其优缺点、突出成功的应用案例，并讨论在机器人技术领域内应用运动基元时存在的开放问题和实践挑战。

Abstract: Biological systems exhibit a continuous stream of movements, consisting of sequential segments, that allow them to perform complex tasks in a creative and versatile fashion. This observation has led researchers towards identifying elementary building blocks of motion known as movement primitives, which are well-suited for generating motor commands in autonomous systems, such as robots. In this survey, we provide an encyclopedic overview of movement primitive approaches and applications in chronological order. Concretely, we present movement primitive frameworks as a way of representing robotic control trajectories acquired through human demonstrations. Within the area of robotics, movement primitives can encode basic motions at the trajectory level, such as how a robot would grasp a cup or the sequence of motions necessary to toss a ball. Furthermore, movement primitives have been developed with the desirable analytical properties of a spring-damper system, probabilistic coupling of multiple demonstrations, using neural networks in high-dimensional systems, and more, to address difficult challenges in robotics. Although movement primitives have widespread application to a variety of fields, the goal of this survey is to inform practitioners on the use of these frameworks in the context of robotics. Specifically, we aim to (i) present a systematic review of major movement primitive frameworks and examine their strengths and weaknesses; (ii) highlight applications that have successfully made use of movement primitives; and (iii) examine open questions and discuss practical challenges when applying movement primitives in robotics.

</details>


### [2] [InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation](https://arxiv.org/abs/2601.02456)
*Junhao Cai,Zetao Cai,Jiafei Cao,Yilun Chen,Zeyu He,Lei Jiang,Hang Li,Hengjie Li,Yang Li,Yufei Liu,Yanan Lu,Qi Lv,Haoxiang Ma,Jiangmiao Pang,Yu Qiao,Zherui Qiu,Yanqing Shen,Xu Shi,Yang Tian,Bolun Wang,Hanqing Wang,Jiaheng Wang,Tai Wang,Xueyuan Wei,Chao Wu,Yiman Xie,Boyang Xing,Yuqiang Yang,Yuyin Yang,Qiaojun Yu,Feng Yuan,Jia Zeng,Jingjing Zhang,Shenghan Zhang,Shi Zhang,Zhuoma Zhaxi,Bowen Zhou,Yuanzhen Zhou,Yunsong Zhou,Hongrui Zhu,Yangkun Zhu,Yuchen Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种名为InternVLA-A1的模型，该模型通过统一的Mixture-of-Transformers架构协调三个专家（场景理解、视觉预见生成和动作执行），旨在将语义理解和动态预测能力结合起来。在真实世界机器人任务和模拟基准测试中，InternVLA-A1的表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action (VLA) 模型虽然在语义理解上表现出色，但缺乏推断物理世界动态的能力；而基于World Models的方法尽管尝试通过视频预测来解决这一问题，却往往缺乏语义基础且处理预测错误时表现脆弱。为了解决这些问题，并结合语义理解和动态预测能力，提出了新的模型。

Method: 采用了一个统一的Mixture-of-Transformers架构，该架构协调了三个专家：一个负责场景理解，一个负责视觉预见生成，另一个负责动作执行。这些组件通过统一的掩码自注意力机制无缝交互。基于InternVL3和Qwen3-VL，以2B和3B参数规模实例化了InternVLA-A1模型。使用混合合成-真实数据集进行预训练。

Result: 在涵盖12个真实世界机器人任务和模拟基准测试中的评估显示，InternVLA-A1显著优于领先的模型如pi0和GR00T N1.5，在日常任务中提高了14.5%，在动态设置下如传送带分拣任务中提升了40%-73.3%。

Conclusion: InternVLA-A1成功地将高级语义理解和强大的动态预测能力结合起来，提供了一种在多种应用场景下表现优异的新方法。

Abstract: Prevalent Vision-Language-Action (VLA) models are typically built upon Multimodal Large Language Models (MLLMs) and demonstrate exceptional proficiency in semantic understanding, but they inherently lack the capability to deduce physical world dynamics. Consequently, recent approaches have shifted toward World Models, typically formulated via video prediction; however, these methods often suffer from a lack of semantic grounding and exhibit brittleness when handling prediction errors. To synergize semantic understanding with dynamic predictive capabilities, we present InternVLA-A1. This model employs a unified Mixture-of-Transformers architecture, coordinating three experts for scene understanding, visual foresight generation, and action execution. These components interact seamlessly through a unified masked self-attention mechanism. Building upon InternVL3 and Qwen3-VL, we instantiate InternVLA-A1 at 2B and 3B parameter scales. We pre-train these models on hybrid synthetic-real datasets spanning InternData-A1 and Agibot-World, covering over 533M frames. This hybrid training strategy effectively harnesses the diversity of synthetic simulation data while minimizing the sim-to-real gap. We evaluated InternVLA-A1 across 12 real-world robotic tasks and simulation benchmark. It significantly outperforms leading models like pi0 and GR00T N1.5, achieving a 14.5\% improvement in daily tasks and a 40\%-73.3\% boost in dynamic settings, such as conveyor belt sorting.

</details>


### [3] [Learning and Optimizing the Efficacy of Spatio-Temporal Task Allocation under Temporal and Resource Constraints](https://arxiv.org/abs/2601.02505)
*Jiazhen Liu,Glen Neville,Jinwoo Park,Sonia Chernova,Harish Ravichandar*

Main category: cs.RO

TL;DR: 本文提出了一种新的多机器人系统问题分类——STEAM，以及一种解决该问题的新算法E-ITAGS。E-ITAGS通过交错任务分配、调度和路径规划来优化任务性能并遵守时间预算。此外，它还利用了可实现性感知的主动学习模块有效地学习特征效能图。实验表明，E-ITAGS在满足资源和时空约束的同时生成了比基线更高的效能分配，并且其主动学习方法在数据和计算效率之间建立了原则性的权衡。


<details>
  <summary>Details</summary>
Motivation: 复杂的多机器人任务需要异构团队共同优化任务分配、调度和路径规划以提高团队表现。现有方法通常采用二元成功-失败模型，但未充分考虑特定任务分配对性能影响的具体程度。为此，作者提出了STEAM问题分类，旨在明确建模不同能力组合对于任务执行效果的影响（即特征效能图），同时考虑空间与时间上的限制条件。

Method: 为了解决STEAM问题，研究者开发了一个名为Efficacy-optimized Incremental Task Allocation Graph Search (E-ITAGS)的新算法。E-ITAGS通过交替进行任务指派、计划安排及路线规划来达到最佳化任务执行效果的目的，并确保不超过给定的时间上限。考虑到直接定义特征效能图可能存在困难，E-ITAGS内嵌了一个能够意识到实际可行性的主动学习组件，用以高效地估计这些效能图。

Result: 通过详细的数值仿真及在紧急响应场景下的实验验证，E-ITAGS相比其他基准方法能够产生更高效的分配方案，同时严格遵守了资源限制和时空约束条件。此外，研究表明所提出的主动学习策略不仅样本效率高，而且在数据收集量与计算成本之间找到了合理的平衡点。

Conclusion: 本研究证明了E-ITAGS算法在处理复杂多机器人任务时的有效性，特别是在面对严格的时空约束条件下寻找最优解方面。该方法不仅提高了任务完成的质量，还展示了如何通过智能学习机制降低对先验知识的需求，从而使得系统更加灵活适应各种应用场景。

Abstract: Complex multi-robot missions often require heterogeneous teams to jointly optimize task allocation, scheduling, and path planning to improve team performance under strict constraints. We formalize these complexities into a new class of problems, dubbed Spatio-Temporal Efficacy-optimized Allocation for Multi-robot systems (STEAM). STEAM builds upon trait-based frameworks that model robots using their capabilities (e.g., payload and speed), but goes beyond the typical binary success-failure model by explicitly modeling the efficacy of allocations as trait-efficacy maps. These maps encode how the aggregated capabilities assigned to a task determine performance. Further, STEAM accommodates spatio-temporal constraints, including a user-specified time budget (i.e., maximum makespan). To solve STEAM problems, we contribute a novel algorithm named Efficacy-optimized Incremental Task Allocation Graph Search (E-ITAGS) that simultaneously optimizes task performance and respects time budgets by interleaving task allocation, scheduling, and path planning. Motivated by the fact that trait-efficacy maps are difficult, if not impossible, to specify, E-ITAGS efficiently learns them using a realizability-aware active learning module. Our approach is realizability-aware since it explicitly accounts for the fact that not all combinations of traits are realizable by the robots available during learning. Further, we derive experimentally-validated bounds on E-ITAGS' suboptimality with respect to efficacy. Detailed numerical simulations and experiments using an emergency response domain demonstrate that E-ITAGS generates allocations of higher efficacy compared to baselines, while respecting resource and spatio-temporal constraints. We also show that our active learning approach is sample efficient and establishes a principled tradeoff between data and computational efficiency.

</details>


### [4] [Making Infeasible Tasks Feasible: Planning to Reconfigure Disconnected 3D Environments with Movable Objects](https://arxiv.org/abs/2601.02645)
*Samarth Kalluraya,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 本文提出了一种名为BRiDGE的规划器，它能在3D环境中通过移动物体创建新的可通行路径，解决机器人在不连通环境中的导航问题。


<details>
  <summary>Details</summary>
Motivation: 现有的路径规划方法假设目标区域是可达的，但在实际中，当环境不连通时这一假设往往失败。因此，研究者们考虑了由形成不同可导航支撑面的对象组成的已知3D环境，并且这些对象可能是不可移动或可移动的。为了完成机器人必须到达位于无法达到的高平面的目标区域的任务，需要让机器人与环境互动，重新排列可移动物体以创建新的可通行连接。

Method: 研究者开发了BRiDGE（基于块的不连通3D几何环境中的重配置），这是一种基于采样的规划器，能够逐步构建跨越机器人和物体配置的树，计算出可行计划，指定要移动哪些物体、放置在哪里以及顺序，同时考虑到可移动物体数量有限。此外，还引入了非均匀采样策略来加速规划过程。

Result: 通过广泛的数值模拟和硬件实验验证了该方法的有效性，并证明了其概率完整性。

Conclusion: BRiDGE提供了一种有效的方法来处理3D环境中由于物理断开而难以直接解决的导航任务，通过智能地重新安排可移动障碍物来创建新的路径。

Abstract: Several planners have been developed to compute dynamically feasible, collision-free robot paths from an initial to a goal configuration. A key assumption in these works is that the goal region is reachable; an assumption that often fails in practice when environments are disconnected. Motivated by this limitation, we consider known 3D environments comprising objects, also called blocks, that form distinct navigable support surfaces (planes), and that are either non-movable (e.g., tables) or movable (e.g., boxes). These surfaces may be mutually disconnected due to height differences, holes, or lateral separations. Our focus is on tasks where the robot must reach a goal region residing on an elevated plane that is unreachable. Rather than declaring such tasks infeasible, an effective strategy is to enable the robot to interact with the environment, rearranging movable objects to create new traversable connections; a problem known as Navigation Among Movable Objects (NAMO). Existing NAMO planners typically address 2D environments, where obstacles are pushed aside to clear a path. These methods cannot directly handle the considered 3D setting; in such cases, obstacles must be placed strategically to bridge these physical disconnections. We address this challenge by developing BRiDGE (Block-based Reconfiguration in Disconnected 3D Geometric Environments), a sampling-based planner that incrementally builds trees over robot and object configurations to compute feasible plans specifying which objects to move, where to place them, and in what order, while accounting for a limited number of movable objects. To accelerate planning, we introduce non-uniform sampling strategies. We show that our method is probabilistically complete and we provide extensive numerical and hardware experiments validating its effectiveness.

</details>


### [5] [Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search](https://arxiv.org/abs/2601.02649)
*Jiangyi Fang,Bowen Zhou,Haotian Wang,Xin Zhu,Leye Wang*

Main category: cs.RO

TL;DR: 本文提出了一种结合模型预测控制（MPC）和蒙特卡洛树搜索（MCTS）框架的方法，用于解决在线3D装箱问题。通过利用前瞻信息并设计辅助奖励来惩罚长期空间浪费，该方法在实际数据集上表现出色，特别是在分布变化情况下，相比现有最先进方法有超过10%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习方法虽然在3D装箱任务中表现良好，但难以适应因不同批次货物连续到达而产生的短期分布变化，导致性能下降。文章认为利用现代物流系统中的短期前瞻信息是解决这一问题的关键。

Method: 将带有前瞻包裹信息的在线3D装箱问题建模为一个模型预测控制(MPC)问题，并采用修改后的蒙特卡洛树搜索(MCTS)框架进行求解。框架中使用了动态探索先验机制来自适应地平衡学习到的RL策略与稳健随机策略之间的关系；同时设计了一个额外奖励项以减少单个放置动作引起的长远空间浪费。

Result: 广泛的实验结果表明，在真实世界的数据集上，所提出的方法相较于当前最先进的基线方法而言，于分布变化条件下实现了超过10%的增益、在线部署时平均改进了4%，最好情况下甚至超过了8%。

Conclusion: 研究表明，通过结合MPC和MCTS以及引入前瞻信息和特定奖励机制的新方法能够有效提高在线3D装箱任务的表现，特别是在应对货物批次间存在显著差异时展现出更强鲁棒性。

Abstract: Online 3D Bin Packing (3D-BP) with robotic arms is crucial for reducing transportation and labor costs in modern logistics. While Deep Reinforcement Learning (DRL) has shown strong performance, it often fails to adapt to real-world short-term distribution shifts, which arise as different batches of goods arrive sequentially, causing performance drops. We argue that the short-term lookahead information available in modern logistics systems is key to mitigating this issue, especially during distribution shifts. We formulate online 3D-BP with lookahead parcels as a Model Predictive Control (MPC) problem and adapt the Monte Carlo Tree Search (MCTS) framework to solve it. Our framework employs a dynamic exploration prior that automatically balances a learned RL policy and a robust random policy based on the lookahead characteristics. Additionally, we design an auxiliary reward to penalize long-term spatial waste from individual placements. Extensive experiments on real-world datasets show that our method consistently outperforms state-of-the-art baselines, achieving over 10\% gains under distributional shifts, 4\% average improvement in online deployment, and up to more than 8\% in the best case--demonstrating the effectiveness of our framework.

</details>


### [6] [Learning to Nudge: A Scalable Barrier Function Framework for Safe Robot Interaction in Dense Clutter](https://arxiv.org/abs/2601.02686)
*Haixin Jin,Nikhil Uday Shinde,Soofiyan Atar,Hongzhan Yu,Dylan Hirsch,Sicun Gao,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 本文提出了一种密集接触屏障函数（Dense Contact Barrier Functions, DCBF），通过学习一个可组合的对象中心函数来隐式地捕捉物理交互中产生的安全约束，从而绕过了显式建模多对象动力学的计算复杂性。此方法能够在线性扩展的同时跨任务转移，无需重新训练，并在密集杂乱环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统安全框架将接触视为不安全因素，限制了机器人在日常密集环境中的操作能力。随着物体数量的增加，基于模型的安全操作方法变得难以计算；而学习的方法通常将安全性与手头的任务绑定在一起，使得它们很难在不进行再训练的情况下转移到新任务上。

Method: 研究者们介绍了一种称为密集接触屏障函数(DCBF)的新方法。这种方法通过离线学习少量物体间的相互作用，来学习一个以物体为中心、可以组合使用的函数，该函数能够隐含地捕获由物理交互引起的安全约束条件。在运行时，这种学到的DCBF可以在任意物体集合之间组合，生成一个全局性的安全过滤器，它能够线性扩展并且无需重新训练即可跨任务使用。

Result: 通过在模拟实验中，在密集杂乱环境下验证了该方法的有效性，证明了其能够在适合的场景下实现无碰撞导航和安全的高接触度交互。

Conclusion: Dense Contact Barrier Functions 提供了一种新的途径，让机器人能够在密集且充满障碍物的环境中安全地导航和操作，同时保持了良好的可扩展性和跨任务适应性。

Abstract: Robots operating in everyday environments must navigate and manipulate within densely cluttered spaces, where physical contact with surrounding objects is unavoidable. Traditional safety frameworks treat contact as unsafe, restricting robots to collision avoidance and limiting their ability to function in dense, everyday settings. As the number of objects grows, model-based approaches for safe manipulation become computationally intractable; meanwhile, learned methods typically tie safety to the task at hand, making them hard to transfer to new tasks without retraining. In this work we introduce Dense Contact Barrier Functions(DCBF). Our approach bypasses the computational complexity of explicitly modeling multi-object dynamics by instead learning a composable, object-centric function that implicitly captures the safety constraints arising from physical interactions. Trained offline on interactions with a few objects, the learned DCBFcomposes across arbitrary object sets at runtime, producing a single global safety filter that scales linearly and transfers across tasks without retraining. We validate our approach through simulated experiments in dense clutter, demonstrating its ability to enable collision-free navigation and safe, contact-rich interaction in suitable settings.

</details>


### [7] [Analysis of Various Manipulator Configurations Based on Multi-Objective Black-Box Optimization](https://arxiv.org/abs/2601.02704)
*Kento Kawaharazuka,Keita Yoneda,Takahiro Hattori,Shintaro Inoue,Kei Okada*

Main category: cs.RO

TL;DR: 本文通过对末端执行器可达性和关节扭矩的多目标优化，探讨了操作臂的最佳结构，并分析了现有操作臂结构在优化采样结果中的位置，为未来的设计提供了见解。


<details>
  <summary>Details</summary>
Motivation: 由于现有的6自由度和7自由度操作臂的关节配置和连杆长度比例是基于经验确定的，而且不同机器人之间存在差异，因此需要研究来讨论哪种结构是最优的操作臂结构。

Method: 采用多目标优化方法，从末端执行器可达性和关节扭矩两个角度出发，寻找最优操作臂结构。

Result: 得到了一系列优化后的操作臂结构样本，并将现有操作臂结构与之对比，明确了现有设计在优化空间中的位置。

Conclusion: 通过多目标优化可以更好地理解不同操作臂结构之间的差异以及它们相对于最优解的位置，为未来操作臂的设计提供指导。

Abstract: Various 6-degree-of-freedom (DOF) and 7-DOF manipulators have been developed to date. Over a long history, their joint configurations and link length ratios have been determined empirically. In recent years, the development of robotic foundation models has become increasingly active, leading to the continuous proposal of various manipulators to support these models. However, none of these manipulators share exactly the same structure, as the order of joints and the ratio of link lengths differ among robots. Therefore, in order to discuss the optimal structure of a manipulator, we performed multi-objective optimization from the perspectives of end-effector reachability and joint torque. We analyze where existing manipulator structures stand within the sampling results of the optimization and provide insights for future manipulator design.

</details>


### [8] [Loop Closure using AnyLoc Visual Place Recognition in DPV-SLAM](https://arxiv.org/abs/2601.02723)
*Wenzheng Zhang,Kazuki Adachi,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 本文提出了一种改进DPV-SLAM中回环闭合性能的方法，通过结合基于学习的视觉地点识别技术AnyLoc来替代传统的Bag of Visual Words方法，并引入了自适应机制调整相似性阈值。实验表明该方法在室内和室外数据集上都显著提高了回环闭合的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统视觉SLAM系统中使用的手工特征依赖性强、对视点变化和光照条件敏感的问题，研究者们提出了新的方案以提高回环闭合的准确性与一致性。

Method: 本文介绍了一种将基于深度学习的位置识别技术AnyLoc整合进DPV-SLAM框架的方法，用以取代原有的BoVW回环检测方式。此外，还设计了一个可根据环境状况自动调节相似度阈值的自适应机制。

Result: 实验证明，在不同类型的场景下，所提方法相较于原始DPV-SLAM能够实现更高的回环闭合精度及更强的鲁棒性表现。

Conclusion: 提出的结合AnyLoc与动态阈值调整机制的方法为现代SLAM系统提供了一种实用且可扩展的解决方案，有效提升了回环闭合性能。

Abstract: Loop closure is crucial for maintaining the accuracy and consistency of visual SLAM. We propose a method to improve loop closure performance in DPV-SLAM. Our approach integrates AnyLoc, a learning-based visual place recognition technique, as a replacement for the classical Bag of Visual Words (BoVW) loop detection method. In contrast to BoVW, which relies on handcrafted features, AnyLoc utilizes deep feature representations, enabling more robust image retrieval across diverse viewpoints and lighting conditions. Furthermore, we propose an adaptive mechanism that dynamically adjusts similarity threshold based on environmental conditions, removing the need for manual tuning. Experiments on both indoor and outdoor datasets demonstrate that our method significantly outperforms the original DPV-SLAM in terms of loop closure accuracy and robustness. The proposed method offers a practical and scalable solution for enhancing loop closure performance in modern SLAM systems.

</details>


### [9] [Optimizing Control-Friendly Trajectories with Self-Supervised Residual Learning](https://arxiv.org/abs/2601.02738)
*Kexin Guo,Zihan Yang,Yuhang Liu,Jindou Jia,Xiang Yu*

Main category: cs.RO

TL;DR: 本文提出了一种自监督残差学习和轨迹优化框架，用于解决现代复杂机器人系统中由于存在残余物理效应而难以准确跟踪激进轨迹的问题。通过学习未知动态效应并将其作为名义动力学的残差，形成混合模型，并开发了轨迹优化器以计算最优参考轨迹，从而输出能够被精确跟踪的激进运动。


<details>
  <summary>Details</summary>
Motivation: 对于现代复杂的机器人系统，现实世界的物理学只能在一定程度上进行解析建模。因此，在控制器合成过程中，由于存在残留的物理特性，准确地跟踪激进的轨迹可能会变得困难。为了解决这一问题，本文提出了一个自监督残差学习与轨迹优化框架。

Method: 首先，学习未知动态效应对闭环模型的影响，并将其视为名义动力学的残差，共同形成一个混合模型。然后展示了使用仅轨迹级数据实现带解析梯度的学习是可能的，同时能享受具有任意积分步长的准确长期预测。接着，开发了一个轨迹优化器来计算带有最小化残差物理的最优参考轨迹。

Result: 利用混合动力学，所提出的优化器输出可以被精确跟踪的激进动作。四旋翼无人机的敏捷飞行实验表明，该方法能够生成易于后续控制层面处理的轨迹。

Conclusion: 本文介绍的方法通过结合自监督残差学习和轨迹优化，有效解决了因残余物理效应导致的轨迹跟踪难题，使得复杂机器人系统能够更准确地执行激进的动作。

Abstract: Real-world physics can only be analytically modeled with a certain level of precision for modern intricate robotic systems. As a result, tracking aggressive trajectories accurately could be challenging due to the existence of residual physics during controller synthesis. This paper presents a self-supervised residual learning and trajectory optimization framework to address the aforementioned challenges. At first, unknown dynamic effects on the closed-loop model are learned and treated as residuals of the nominal dynamics, jointly forming a hybrid model. We show that learning with analytic gradients can be achieved using only trajectory-level data while enjoying accurate long-horizon prediction with an arbitrary integration step size. Subsequently, a trajectory optimizer is developed to compute the optimal reference trajectory with the residual physics along it minimized. It ends up with trajectories that are friendly to the following control level. The agile flight of quadrotors illustrates that by utilizing the hybrid dynamics, the proposed optimizer outputs aggressive motions that can be precisely tracked.

</details>


### [10] [Unified Meta-Representation and Feedback Calibration for General Disturbance Estimation](https://arxiv.org/abs/2601.02762)
*Zihan Yang,Jindou Jia,Meng Wang,Yuhang Liu,Kexin Guo,Xiang Yu*

Main category: cs.RO

TL;DR: 本文提出了一种基于元学习和反馈校准在线适应的通用扰动估计框架，能有效估计快速变化的非结构性扰动。


<details>
  <summary>Details</summary>
Motivation: 现有基于元学习的方法需要环境结构的共享表示，对于现实中的非结构性扰动缺乏灵活性；此外，表示误差和分布偏移会导致预测准确性大幅下降。

Method: 通过从过去观测值的有限时间窗口中提取特征，学习一个无需预设结构假设就能有效捕捉一般非结构性扰动的统一表示。随后，通过状态反馈机制校准在线适应过程，以减少来自表示和泛化限制的学习残差。

Result: 理论分析表明，在线学习误差和扰动估计误差可以同时收敛。通过统一的元表示，该框架能够有效地估计多个快速变化的扰动，四旋翼飞行实验对此进行了演示。

Conclusion: 提出的新框架在处理未知时变扰动方面展现出良好的性能与潜力，为现代机器人应用中的精确控制提供了新思路。

Abstract: Precise control in modern robotic applications is always an open issue due to unknown time-varying disturbances. Existing meta-learning-based approaches require a shared representation of environmental structures, which lack flexibility for realistic non-structural disturbances. Besides, representation error and the distribution shifts can lead to heavy degradation in prediction accuracy. This work presents a generalizable disturbance estimation framework that builds on meta-learning and feedback-calibrated online adaptation. By extracting features from a finite time window of past observations, a unified representation that effectively captures general non-structural disturbances can be learned without predefined structural assumptions. The online adaptation process is subsequently calibrated by a state-feedback mechanism to attenuate the learning residual originating from the representation and generalizability limitations. Theoretical analysis shows that simultaneous convergence of both the online learning error and the disturbance estimation error can be achieved. Through the unified meta-representation, our framework effectively estimates multiple rapidly changing disturbances, as demonstrated by quadrotor flight experiments. See the project page for video, supplementary material and code: https://nonstructural-metalearn.github.io.

</details>


### [11] [Advancing Assistive Robotics: Multi-Modal Navigation and Biophysical Monitoring for Next-Generation Wheelchairs](https://arxiv.org/abs/2601.02766)
*Md. Anowar Hossain,Mohd. Ehsanul Hoque*

Main category: cs.RO

TL;DR: 本文介绍了一种新型的多模式电动轮椅控制系统，该系统集成了四种控制接口（操纵杆、语音、手势和眼电图）与生命体征监测框架，并通过云端传输生理数据给护理人员。实验结果显示了高准确率的命令识别以及低延迟，为辅助机器人技术中的关键挑战提供了解决方案，并符合安全标准。


<details>
  <summary>Details</summary>
Motivation: 为了提高残疾人士如ALS患者、中风后偏瘫者及痴呆症患者的移动能力，本文提出了一种新的多模态电动轮椅控制系统，旨在满足患者需求的同时允许无缝切换控制模式，并结合实时生命体征监测来增强独立性和监护能力。

Method: 设计并实现了一个集成有四种互补界面（操纵杆、语音、手部动作和眼电图）以及连续生命体征监测框架的多模态EPW控制系统。通过与临床参考设备进行两点校准，评估了生物物理传感器的准确性；并通过20名行动不便参与者的实验评价了不同控制方式下的命令识别精度和闭环延迟。

Result: 对于操纵杆控制达到了99%的命令识别准确度，语音控制为97±2%，手势控制为95±3%，平均闭环延迟为20±0.5毫秒。同时，心率、皮肤温度和血氧饱和度的测量误差分别不超过2次/分钟、0.5摄氏度和1%。

Conclusion: 提出的原型系统解决了辅助机器人领域的一些关键问题，符合ISO 7176-31和IEC 80601-2-78安全标准，并为未来的自适应机器学习改进奠定了基础。

Abstract: Assistive electric-powered wheelchairs (EPWs) have become essential mobility aids for people with disabilities such as amyotrophic lateral sclerosis (ALS), post-stroke hemiplegia, and dementia-related mobility impairment. This work presents a novel multi-modal EPW control system designed to prioritize patient needs while allowing seamless switching between control modes. Four complementary interfaces, namely joystick, speech, hand gesture, and electrooculography (EOG), are integrated with a continuous vital sign monitoring framework measuring heart rate variability, oxygen saturation (SpO2), and skin temperature. This combination enables greater patient independence while allowing caregivers to maintain real-time supervision and early intervention capability.
  Two-point calibration of the biophysical sensors against clinical reference devices resulted in root mean square errors of at most 2 bpm for heart rate, 0.5 degree Celsius for skin temperature, and 1 percent for SpO2. Experimental evaluation involved twenty participants with mobility impairments executing a total of 500 indoor navigation commands. The achieved command recognition accuracies were 99 percent for joystick control, 97 percent plus or minus 2 percent for speech, and 95 percent plus or minus 3 percent for hand gesture, with an average closed-loop latency of 20 plus or minus 0.5 milliseconds. Caregivers receive real-time alerts through an Android application following encrypted cloud transmission of physiological data. By integrating multi-modal mobility control with cloud-enabled health monitoring and reporting latency and energy budgets, the proposed prototype addresses key challenges in assistive robotics, contributes toward compliance with ISO 7176-31 and IEC 80601-2-78 safety standards, and establishes a foundation for future adaptive machine learning enhancements.

</details>


### [12] [M-SEVIQ: A Multi-band Stereo Event Visual-Inertial Quadruped-based Dataset for Perception under Rapid Motion and Challenging Illumination](https://arxiv.org/abs/2601.02777)
*Jingcheng Cao,Chaoran Xiong,Jianmin Song,Shang Yan,Jiachen Liu,Ling Pei*

Main category: cs.RO

TL;DR: 本文介绍了一个名为M-SEVIQ的数据集，它是一个多波段立体事件视觉和惯性四足机器人数据集，旨在解决快速移动和复杂光照条件下使用事件相机进行鲁棒感知的问题。


<details>
  <summary>Details</summary>
Motivation: 在腿式机器人的敏捷运动中，传统的基于帧的摄像机由于产生模糊图像（特别是在低光条件下）而往往表现不佳。相比之下，事件相机能够异步捕捉亮度变化，提供低延迟、高时间分辨率和高动态范围，使其更适合于快速移动和具有挑战性的光照条件下的稳健感知。然而，现有的事件相机数据集在各种照明条件下对立体配置和多波段感知领域的支持有限。为了解决这一差距，作者们提出了M-SEVIQ数据集。

Method: M-SEVIQ数据集是通过配备有立体事件相机、基于帧的摄像机、惯性测量单元(IMU)以及关节编码器的Unitree Go2收集而成。该数据集包含了超过30个在不同速度水平、光照波长和光照条件下捕获的真实世界序列，并提供了全面的校准数据，包括内部参数、外部参数及时序对齐信息，以促进准确的传感器融合与基准测试。

Result: M-SEVIQ数据集可以用来支持在具有挑战性环境中的敏捷机器人感知、传感器融合、语义分割及多模态视觉研究。

Conclusion: M-SEVIQ数据集填补了现有事件相机数据集中关于立体配置及多波段感知领域在多样化光照条件下的空白，为提高快速移动或复杂光照条件下的机器人视觉感知能力提供了重要资源。

Abstract: Agile locomotion in legged robots poses significant challenges for visual perception. Traditional frame-based cameras often fail in these scenarios for producing blurred images, particularly under low-light conditions. In contrast, event cameras capture changes in brightness asynchronously, offering low latency, high temporal resolution, and high dynamic range. These advantages make them suitable for robust perception during rapid motion and under challenging illumination. However, existing event camera datasets exhibit limitations in stereo configurations and multi-band sensing domains under various illumination conditions. To address this gap, we present M-SEVIQ, a multi-band stereo event visual and inertial quadruped dataset collected using a Unitree Go2 equipped with stereo event cameras, a frame-based camera, an inertial measurement unit (IMU), and joint encoders. This dataset contains more than 30 real-world sequences captured across different velocity levels, illumination wavelengths, and lighting conditions. In addition, comprehensive calibration data, including intrinsic, extrinsic, and temporal alignments, are provided to facilitate accurate sensor fusion and benchmarking. Our M-SEVIQ can be used to support research in agile robot perception, sensor fusion, semantic segmentation and multi-modal vision in challenging environments.

</details>


### [13] [Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation](https://arxiv.org/abs/2601.02778)
*Haoyu Dong,Zhengmao He,Yang Li,Zhibin Li,Xinyu Yi,Zhe Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种实用的仿真到现实强化学习框架，利用密集触觉反馈和关节扭矩感应来调节物理交互。通过快速触觉模拟、电流到扭矩校准及执行器动态建模，实现了无需微调即可在真实机器人手上直接部署策略，并展示了可控抓握力跟踪和物体再定位两种关键技能。


<details>
  <summary>Details</summary>
Motivation: 由于接触丰富的物理环境和不完美的驱动问题，直接在真实硬件上部署能够控制类人灵巧手的控制策略仍然很困难。

Method: 开发了一个基于不对称actor-critic PPO管道的sim-to-real RL框架，该框架结合了密集触觉反馈与关节扭矩感应以显式地调整物理交互。引入了计算效率高的触觉模拟、从电机电流到关节扭矩的映射校准以及执行器动力学建模等技术来促进有效的模拟到实际迁移。

Result: 所提出的策略能够在没有对机器人进行微调的情况下稳健地执行两种基本技能：(1) 基于命令的可控抓握力追踪；(2) 手中物体的重新定向。

Conclusion: 通过将触觉与扭矩结合在观察空间中并有效建模感知/致动过程，该系统提供了一种实现可靠灵巧操作的实际解决方案。据我们所知，这是首次完全在模拟环境中训练并在真实硬件上零样本转移成功的多指灵巧手可控抓取演示。

Abstract: Human-like dexterous hands with multiple fingers offer human-level manipulation capabilities, but training control policies that can directly deploy on real hardware remains difficult due to contact-rich physics and imperfect actuation. We close this gap with a practical sim-to-real reinforcement learning (RL) framework that utilizes dense tactile feedback combined with joint torque sensing to explicitly regulate physical interactions. To enable effective sim-to-real transfer, we introduce (i) a computationally fast tactile simulation that computes distances between dense virtual tactile units and the object via parallel forward kinematics, providing high-rate, high-resolution touch signals needed by RL; (ii) a current-to-torque calibration that eliminates the need for torque sensors on dexterous hands by mapping motor current to joint torque; and (iii) actuator dynamics modeling to bridge the actuation gaps with randomization of non-ideal effects such as backlash, torque-speed saturation. Using an asymmetric actor-critic PPO pipeline trained entirely in simulation, our policies deploy directly to a five-finger hand. The resulting policies demonstrated two essential skills: (1) command-based, controllable grasp force tracking, and (2) reorientation of objects in the hand, both of which were robustly executed without fine-tuning on the robot. By combining tactile and torque in the observation space with effective sensing/actuation modeling, our system provides a practical solution to achieve reliable dexterous manipulation. To our knowledge, this is the first demonstration of controllable grasping on a multi-finger dexterous hand trained entirely in simulation and transferred zero-shot on real hardware.

</details>


### [14] [Reinforcement Learning for Follow-the-Leader Robotic Endoscopic Navigation via Synthetic Data](https://arxiv.org/abs/2601.02798)
*Sicong Gao,Chen Qian,Laurence Xian,Liao Wu,Maurice Pagnucco,Yang Song*

Main category: cs.RO

TL;DR: 本文提出了一种基于视觉的深度强化学习框架，用于内窥镜机器人的自主导航，并通过单目深度估计减少与肠壁的接触。该方法在肠道环境模拟中进行了训练和评估，提高了深度估计精度并降低了导航J指数。


<details>
  <summary>Details</summary>
Motivation: 为了解决内窥镜机器人在狭窄管状环境中探索时避免与内壁接触这一长期存在的挑战，以及减轻患者不适的问题。

Method: 开发了一个基于柔性连续体结构的跟随式内窥镜机器人，并提出了一个由单目深度估计引导的视觉深度强化学习框架。使用NVIDIA Omniverse构建了逼真的肠道模拟环境来训练和评估自主导航策略，同时利用NVIDIA Replicator生成合成图像以微调Depth Anything模型，从而实现仅用单个单目相机就能对肠道环境进行密集三维感知。此外，引入了几何意识奖励和惩罚机制来提高腔道跟踪准确性。

Result: 相比原始Depth Anything模型，本方法将$δ_{1}$深度精度提高了39.2%，且相对于次优方法而言，导航J指数减少了0.67。这些结果表明所提方法具有鲁棒性和有效性。

Conclusion: 提出的基于视觉的深度强化学习框架显著提升了内窥镜机器人在复杂肠道环境中自主导航的能力，减少了与肠壁不必要的接触，有助于改善患者的舒适度。

Abstract: Autonomous navigation is crucial for both medical and industrial endoscopic robots, enabling safe and efficient exploration of narrow tubular environments without continuous human intervention, where avoiding contact with the inner walls has been a longstanding challenge for prior approaches. We present a follow-the-leader endoscopic robot based on a flexible continuum structure designed to minimize contact between the endoscope body and intestinal walls, thereby reducing patient discomfort. To achieve this objective, we propose a vision-based deep reinforcement learning framework guided by monocular depth estimation. A realistic intestinal simulation environment was constructed in \textit{NVIDIA Omniverse} to train and evaluate autonomous navigation strategies. Furthermore, thousands of synthetic intraluminal images were generated using NVIDIA Replicator to fine-tune the Depth Anything model, enabling dense three-dimensional perception of the intestinal environment with a single monocular camera. Subsequently, we introduce a geometry-aware reward and penalty mechanism to enable accurate lumen tracking. Compared with the original Depth Anything model, our method improves $δ_{1}$ depth accuracy by 39.2% and reduces the navigation J-index by 0.67 relative to the second-best method, demonstrating the robustness and effectiveness of the proposed approach.

</details>


### [15] [Soft Responsive Materials Enhance Humanoid Safety](https://arxiv.org/abs/2601.02857)
*Chunzheng Wang,Yiyuan Zhang,Annan Tang,Ziqiu Zeng,Haoran Chen,Quan Gao,Zixuan Zhuang,Boyu Li,Zhilin Xiong,Aoqian Zhang,Ce Hao,Siyuan Luo,Tongyang Zhao,Cecilia Laschi,Fan Shi*

Main category: cs.RO

TL;DR: 本研究提出了一种软-刚性协同设计框架，利用基于非牛顿流体的软响应材料来提高人形机器人的安全性。该材料在正常交互中保持柔顺，但在受到冲击时迅速硬化，吸收和消散因跌倒而产生的力。通过物理模拟指导保护器的位置和厚度，并学习主动跌倒策略。实验表明，这种保护器可以显著降低最大冲击力，允许机器人反复跌落而不损坏硬件，从而提高了机器人鲁棒性和环境安全性。


<details>
  <summary>Details</summary>
Motivation: 目前，人形机器人作为人类中心环境中的通用平台，其应用受限于易摔倒的问题以及金属塑料结构对周围人员和环境构成的风险。

Method: 采用一种结合了非牛顿流体基软响应材料的软硬共设计框架，这类材料在日常互动中保持柔软而在遭遇碰撞时快速硬化以吸收并分散由跌倒引起的力。同时，使用基于物理学的仿真来确定保护装置的最佳位置与厚度，并支持学习如何采取积极的跌倒应对策略。

Result: 将此保护方案应用于一个42公斤重的真实尺寸人形机器人上后，发现它能够显著减少峰值撞击力，并且使得机器人能够在没有硬件损伤的情况下承受多次跌落，包括从3米高度落下及沿着长楼梯滚落等情况。

Conclusion: 通过整合响应性材料、结构共设计与基于学习的控制方法，这项工作促进了既安全又适合工业应用的人形机器人的发展。

Abstract: Humanoid robots are envisioned as general-purpose platforms in human-centered environments, yet their deployment is limited by vulnerability to falls and the risks posed by rigid metal-plastic structures to people and surroundings. We introduce a soft-rigid co-design framework that leverages non-Newtonian fluid-based soft responsive materials to enhance humanoid safety. The material remains compliant during normal interaction but rapidly stiffens under impact, absorbing and dissipating fall-induced forces. Physics-based simulations guide protector placement and thickness and enable learning of active fall policies. Applied to a 42 kg life-size humanoid, the protector markedly reduces peak impact and allows repeated falls without hardware damage, including drops from 3 m and tumbles down long staircases. Across diverse scenarios, the approach improves robot robustness and environmental safety. By uniting responsive materials, structural co-design, and learning-based control, this work advances interact-safe, industry-ready humanoid robots.

</details>


### [16] [Warm-Starting Collision-Free Model Predictive Control With Object-Centric Diffusion](https://arxiv.org/abs/2601.02873)
*Arthur Haffemayer,Alexandre Chapin,Armand Jordana,Krzysztof Wojciechowski,Florent Lamiraux,Nicolas Mansard,Vladimir Petrik*

Main category: cs.RO

TL;DR: 本文提出了一种结合基于扩散模型的预热启动和碰撞感知模型预测控制器（MPC）的方法，通过利用以物体为中心的场景表示来生成在复杂环境中既可靠又高效的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 在复杂的环境中执行任务需要能够预测并避免碰撞同时保持精确控制。传统的基于优化的控制器可以强制物理约束，但在存在许多障碍物的情况下难以快速产生可行解；而扩散模型虽然能围绕障碍物生成多样化的轨迹，但先前的方法缺乏一种通用且有效的方式来让它们根据场景结构进行条件化。

Method: 本方法采用一种基于扩散变换器的技术，该技术可以根据系统状态、任务需求及周围环境进行调整，并使用以物体为中心的注意力机制提供紧凑的障碍物表示，适用于控制。采样的轨迹随后通过一个最优控制问题得到改进，该问题实施了刚体动力学与带符号距离的碰撞约束，从而实现实时可行的运动。

Result: 在基准测试任务中，这种混合方法相比基于采样的规划器或任何单独组件都取得了显著更高的成功率和更低的延迟。真实机器人实验验证了MPC支持下的可靠性和安全性执行。

Conclusion: 结合基于扩散的预热启动和碰撞感知MPC为在严格时间限制下于杂乱环境中实现高效安全的动作生成提供了一个有效解决方案。

Abstract: Acting in cluttered environments requires predicting and avoiding collisions while still achieving precise control. Conventional optimization-based controllers can enforce physical constraints, but they struggle to produce feasible solutions quickly when many obstacles are present. Diffusion models can generate diverse trajectories around obstacles, yet prior approaches lacked a general and efficient way to condition them on scene structure. In this paper, we show that combining diffusion-based warm-starting conditioned with a latent object-centric representation of the scene and with a collision-aware model predictive controller (MPC) yields reliable and efficient motion generation under strict time limits. Our approach conditions a diffusion transformer on the system state, task, and surroundings, using an object-centric slot attention mechanism to provide a compact obstacle representation suitable for control. The sampled trajectories are refined by an optimal control problem that enforces rigid-body dynamics and signed-distance collision constraints, producing feasible motions in real time. On benchmark tasks, this hybrid method achieved markedly higher success rates and lower latency than sampling-based planners or either component alone. Real-robot experiments with a torque-controlled Panda confirm reliable and safe execution with MPC.

</details>


### [17] [LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments](https://arxiv.org/abs/2601.02905)
*Sara Micol Ferraina,Michele Brienza,Francesco Argenziano,Emanuele Musumeci,Vincenzo Suriani,Domenico D. Bloisi,Daniele Nardi*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级的开放词汇3D场景图LOST-3DSG，用于在现实环境中跟踪动态物体。该方法基于word2vec和句子嵌入采用语义方式来跟踪实体，避免了存储密集CLIP视觉特征的需求。实验结果表明，LOST-3DSG在动态物体跟踪方面表现出色且高效。


<details>
  <summary>Details</summary>
Motivation: 现有的物体跟踪方法因依赖于重型基础模型而效率低下。为了克服这一局限性，研究者们旨在开发一种更轻便、高效的解决方案，能够在不牺牲性能的前提下减少对高维视觉嵌入的依赖。

Method: 本研究提出了LOST-3DSG，这是一种利用word2vec与句子嵌入技术实现的轻量级开放词汇3D场景图方案。它通过语义手段追踪实体，允许使用开放式词汇表，并且不需要保存大量的CLIP视觉特征数据。

Result: 通过在一个真实的三维环境中使用TIAGo机器人进行定性和定量实验评估，LOST-3DSG展现出了在动态对象跟踪方面的有效性和效率。

Conclusion: LOST-3DSG作为一种创新的方法，在保持良好跟踪效果的同时显著提高了处理速度和资源利用率，为动态环境下的物体跟踪提供了新的思路。

Abstract: Tracking objects that move within dynamic environments is a core challenge in robotics. Recent research has advanced this topic significantly; however, many existing approaches remain inefficient due to their reliance on heavy foundation models. To address this limitation, we propose LOST-3DSG, a lightweight open-vocabulary 3D scene graph designed to track dynamic objects in real-world environments. Our method adopts a semantic approach to entity tracking based on word2vec and sentence embeddings, enabling an open-vocabulary representation while avoiding the necessity of storing dense CLIP visual features. As a result, LOST-3DSG achieves superior performance compared to approaches that rely on high-dimensional visual embeddings. We evaluate our method through qualitative and quantitative experiments conducted in a real 3D environment using a TIAGo robot. The results demonstrate the effectiveness and efficiency of LOST-3DSG in dynamic object tracking. Code and supplementary material are publicly available on the project website at https://lab-rococo-sapienza.github.io/lost-3dsg/.

</details>


### [18] [Parameter-Robust MPPI for Safe Online Learning of Unknown Parameters](https://arxiv.org/abs/2601.02948)
*Matti Vahs,Jaeyoun Choi,Niklas Schmid,Jana Tumova,Chuchu Fan*

Main category: cs.RO

TL;DR: 本文提出了一种名为PRMPPI控制的框架，该框架结合了在线参数学习和概率安全约束，通过模拟和硬件实验展示了比基线方法更高的成功率、更低的跟踪误差以及更准确的参数估计。


<details>
  <summary>Details</summary>
Motivation: 为了确保机器人在动态环境中即使关键物理参数不确定或随时间变化时也能保持安全，提出了一个能够集成在线参数学习与概率安全约束的新框架。

Method: 使用Stein变分梯度下降来维护基于粒子的参数信念，利用共形预测评估安全约束，并行优化名义性能驱动轨迹和安全导向备份轨迹。

Result: 仿真和硬件实验表明，该控制器相比基线具有更高的成功率、较低的跟踪误差及更加精确的参数估计。

Conclusion: 提出的PRMPPI控制框架能够在保证安全的同时提高机器人的性能表现，特别是在参数学习过程中显示出谨慎性，并随着参数的学习而逐渐改善性能。

Abstract: Robots deployed in dynamic environments must remain safe even when key physical parameters are uncertain or change over time. We propose Parameter-Robust Model Predictive Path Integral (PRMPPI) control, a framework that integrates online parameter learning with probabilistic safety constraints. PRMPPI maintains a particle-based belief over parameters via Stein Variational Gradient Descent, evaluates safety constraints using Conformal Prediction, and optimizes both a nominal performance-driven and a safety-focused backup trajectory in parallel. This yields a controller that is cautious at first, improves performance as parameters are learned, and ensures safety throughout. Simulation and hardware experiments demonstrate higher success rates, lower tracking error, and more accurate parameter estimates than baselines.

</details>


### [19] [Learning to Act Robustly with View-Invariant Latent Actions](https://arxiv.org/abs/2601.02994)
*Youngjoon Jeong,Junha Chun,Taesup Kim*

Main category: cs.RO

TL;DR: 提出了一种名为VILA的方法，它通过建模捕捉轨迹间转换模式的潜在动作来学习基于物理动态的视角不变表示。实验表明，基于VILA的策略能够有效泛化到未见视角，并且很好地迁移到新任务上。


<details>
  <summary>Details</summary>
Motivation: 基于视觉的机器人策略往往难以应对即使是轻微的视角变化，这在现实世界中尤其成问题，因为视角变化是不可避免的，且会严重影响策略的表现。现有的方法通常依赖于场景级别的多视角观察来学习不变性，但这些方法主要依赖视觉外观而忽略了对于鲁棒泛化至关重要的物理动态。

Method: 提出了View-Invariant Latent Action (VILA) 方法，该方法通过建模一个捕捉轨迹间过渡模式的潜在动作来学习基于物理动力学的视角不变表征。VILA使用基于真实动作序列的动作引导目标来对齐不同视角下的这些潜在动作。

Result: 仿真和现实世界的实验表明，基于VILA的策略能有效地推广到未见过的视角，并且可以很好地转移到新的任务上。

Conclusion: VILA作为一种强大的预训练框架被提出来，它通过提高鲁棒性和下游学习表现来解决视角变化给基于视觉的机器人策略带来的挑战。

Abstract: Vision-based robotic policies often struggle with even minor viewpoint changes, underscoring the need for view-invariant visual representations. This challenge becomes more pronounced in real-world settings, where viewpoint variability is unavoidable and can significantly disrupt policy performance. Existing methods typically learn invariance from multi-view observations at the scene level, but such approaches rely on visual appearance and fail to incorporate the physical dynamics essential for robust generalization. We propose View-Invariant Latent Action (VILA), which models a latent action capturing transition patterns across trajectories to learn view-invariant representations grounded in physical dynamics. VILA aligns these latent actions across viewpoints using an action-guided objective based on ground-truth action sequences. Experiments in both simulation and the real world show that VILA-based policies generalize effectively to unseen viewpoints and transfer well to new tasks, establishing VILA as a strong pretraining framework that improves robustness and downstream learning performance.

</details>


### [20] [A Bi-directional Adaptive Framework for Agile UAV Landing](https://arxiv.org/abs/2601.03037)
*Chunhui Zhao,Xirui Kao,Yilin Lu,Yang Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种双向合作着陆框架，通过将移动平台视为着陆过程中的积极参与者而非被动目标，从而打破了传统的'先跟踪后下降'模式。该方法实现了对准和下降阶段的并行化处理，并通过优化四旋翼飞行器的轨迹规划来减少能耗，最终提高了在复杂和时间受限任务中自主恢复的效率、精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的无人机自动着陆方法对于高度动态环境下的应用显得不够高效，主要因为它们遵循一种'先跟踪后下降'的范式，这使得无人机需要执行复杂的顺序动作。这种做法限制了四旋翼无人机的操作灵活性。

Method: 提出了一个双向合作着陆框架，其中移动平台被视作着陆过程中积极互动的一部分，而不是单纯的被动目标。该框架通过使移动平台主动调整其表面倾斜角度以创建最佳稳定终端姿态给接近中的四旋翼机，同时优化了四旋翼机的时间最优且动态可行轨迹生成流程，旨在最小化能量消耗。

Result: 实验结果表明，在动态场景下验证了该框架的有效性，显著提升了四旋翼无人机在复杂及时间紧迫任务中自主恢复时的效率、精确度以及鲁棒性。

Conclusion: 本研究介绍了一种新的双向协作着陆机制，通过改变传统着陆策略，允许移动平台与四旋翼无人机之间进行更有效的交互，从而改善了无人机在高速变化环境中的着陆性能。

Abstract: Autonomous landing on mobile platforms is crucial for extending quadcopter operational flexibility, yet conventional methods are often too inefficient for highly dynamic scenarios. The core limitation lies in the prevalent ``track-then-descend'' paradigm, which treats the platform as a passive target and forces the quadcopter to perform complex, sequential maneuvers. This paper challenges that paradigm by introducing a bi-directional cooperative landing framework that redefines the roles of the vehicle and the platform. The essential innovation is transforming the problem from a single-agent tracking challenge into a coupled system optimization. Our key insight is that the mobile platform is not merely a target, but an active agent in the landing process. It proactively tilts its surface to create an optimal, stable terminal attitude for the approaching quadcopter. This active cooperation fundamentally breaks the sequential model by parallelizing the alignment and descent phases. Concurrently, the quadcopter's planning pipeline focuses on generating a time-optimal and dynamically feasible trajectory that minimizes energy consumption. This bi-directional coordination allows the system to execute the recovery in an agile manner, characterized by aggressive trajectory tracking and rapid state synchronization within transient windows. The framework's effectiveness, validated in dynamic scenarios, significantly improves the efficiency, precision, and robustness of autonomous quadrotor recovery in complex and time-constrained missions.

</details>


### [21] [Validating Generalist Robots with Situation Calculus and STL Falsification](https://arxiv.org/abs/2601.03038)
*Changwen Li,Rongjie Yan,Chih-Hong Cheng,Jian Zhang*

Main category: cs.RO

TL;DR: 提出了一种结合抽象推理与具体系统验证的两层验证框架，用于验证多功能机器人的任务执行情况。


<details>
  <summary>Details</summary>
Motivation: 由于每项任务都有其自身的操作环境和正确性规范，这超出了传统验证方法的假设范围，因此对能够理解自然语言指令并执行多样化操作的通用机器人进行验证具有挑战性。

Method: 该研究提出了一种两层验证框架：在抽象层面使用情境演算建模世界，并推导出最弱前置条件，从而实现约束感知组合测试；在具体层面，则是将这些配置实例化以进行基于仿真的验证，并利用STL监控。

Result: 实验表明，这种框架能够在NVIDIA GR00T控制器上有效地发现失败案例，展示了它在验证通用目的机器人自主性方面的潜力。

Conclusion: 此两层验证框架为解决通用型机器人面临的验证难题提供了有效途径，通过结合抽象分析与具体的仿真验证，能够帮助识别潜在的问题区域。

Abstract: Generalist robots are becoming a reality, capable of interpreting natural language instructions and executing diverse operations. However, their validation remains challenging because each task induces its own operational context and correctness specification, exceeding the assumptions of traditional validation methods. We propose a two-layer validation framework that combines abstract reasoning with concrete system falsification. At the abstract layer, situation calculus models the world and derives weakest preconditions, enabling constraint-aware combinatorial testing to systematically generate diverse, semantically valid world-task configurations with controllable coverage strength. At the concrete layer, these configurations are instantiated for simulation-based falsification with STL monitoring. Experiments on tabletop manipulation tasks show that our framework effectively uncovers failure cases in the NVIDIA GR00T controller, demonstrating its promise for validating general-purpose robot autonomy.

</details>


### [22] [SOP: A Scalable Online Post-Training System for Vision-Language-Action Models](https://arxiv.org/abs/2601.03044)
*Mingjie Pan,Siyuan Feng,Qinglin Zhang,Xinchen Li,Jianheng Song,Chendi Qu,Yi Wang,Chuankang Li,Ziyu Xiong,Zhi Chen,Yi Liu,Jianlan Luo*

Main category: cs.RO

TL;DR: 本文提出了一种可扩展的在线后训练系统SOP，该系统能够使通用视觉-语言-动作模型在物理世界中进行在线、分布式、多任务后训练。通过将执行和学习紧密结合，机器人队列持续向中央云端学习器提供在线策略经验和人工干预信号，并异步接收更新后的策略，从而支持快速在线修正、并行部署以扩大经验收集范围，并在适应过程中保持通用性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作（VLA）模型通过大规模预训练实现了强大的泛化能力，但现实世界的部署还需要专家级别的任务熟练度。现有的VLA模型后训练方法通常是离线的、单个机器人的或特定于任务的，这限制了有效的在线策略适应性和从真实世界互动中可扩展学习的能力。

Method: 研究者们开发了一个名为Scalable Online Post-training (SOP) 的系统，它允许直接在物理世界中对通用VLA模型进行在线、分布式的多任务后训练。SOP系统通过一个闭环架构紧密地结合了执行与学习过程，在此过程中，一队机器人不断地向中央云端学习器发送在线策略体验及人类干预信号，并异步获取更新后的策略。

Result: 实验表明，SOP显著提高了大型预训练VLA模型在一系列现实世界操作任务中的表现，如布料折叠、盒子组装和杂货补货等，同时保持了跨任务单一共享策略的有效性。有效后训练可在几小时内通过真实世界交互实现，且性能几乎随着舰队中机器人数量呈线性增长。

Conclusion: 研究结果表明，将在线学习与舰队规模部署紧密结合对于在物理世界中高效、可靠地扩展通用机器人策略的后训练至关重要。

Abstract: Vision-language-action (VLA) models achieve strong generalization through large-scale pre-training, but real-world deployment requires expert-level task proficiency in addition to broad generality. Existing post-training approaches for VLA models are typically offline, single-robot, or task-specific, limiting effective on-policy adaptation and scalable learning from real-world interaction. We introduce a Scalable Online Post-training (SOP) system that enables online, distributed, multi-task post-training of generalist VLA models directly in the physical world. SOP tightly couples execution and learning through a closed-loop architecture in which a fleet of robots continuously streams on-policy experience and human intervention signals to a centralized cloud learner, and asynchronously receives updated policies. This design supports prompt on-policy correction, scales experience collection through parallel deployment, and preserves generality during adaptation. SOP is agnostic to the choice of post-training algorithm; we instantiate it with both interactive imitation learning (HG-DAgger) and reinforcement learning (RECAP). Across a range of real-world manipulation tasks including cloth folding, box assembly, and grocery restocking, we show that SOP substantially improves the performance of large pretrained VLA models while maintaining a single shared policy across tasks. Effective post-training can be achieved within hours of real-world interaction, and performance scales near-linearly with the number of robots in the fleet. These results suggest that tightly coupling online learning with fleet-scale deployment is instrumental to enabling efficient, reliable, and scalable post-training of generalist robot policies in the physical world.

</details>


### [23] [HEXAR: a Hierarchical Explainability Architecture for Robots](https://arxiv.org/abs/2601.03070)
*Tamlin Love,Ferran Gebellí,Pradip Pramanick,Antonio Andriella,Guillem Alenyà,Anais Garrell,Raquel Ros,Silvia Rossi*

Main category: cs.RO

TL;DR: 介绍了一种新的机器人解释框架HEXAR，它采用分层插件式方法生成关于机器人系统的解释。通过在家庭环境中执行辅助任务的TIAGo机器人上实施和评估，与端到端和聚合基线方法相比，HEXAR在根本原因识别、错误信息排除和运行时方面表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统变得越来越复杂，对可解释决策的需求变得至关重要。现有的机器人解释性方法要么专注于单个模块而难以从高级行为的角度进行查询，要么采取整体方法而不利用机器人架构的模块化。为了克服这些限制，提出了HEXAR框架。

Method: HEXAR是一种新颖的框架，提供了一个即插即用的分层方法来为机器人系统生成解释。该框架由专门的组件解释器组成，使用多种解释技术（如基于LLM的推理、因果模型、特征重要性等）针对特定的机器人模块，并由一个解释选择器协调，以根据给定查询选择最合适的一个。

Result: 在180种场景-查询变体中，HEXAR在根因识别、错误信息排除以及运行时间方面明显优于端到端和聚合基准方法。

Conclusion: HEXAR为透明自主系统的发展提供了有希望的方向，在提高机器人决策过程的理解性和透明度方面表现出了显著的优势。

Abstract: As robotic systems become increasingly complex, the need for explainable decision-making becomes critical. Existing explainability approaches in robotics typically either focus on individual modules, which can be difficult to query from the perspective of high-level behaviour, or employ monolithic approaches, which do not exploit the modularity of robotic architectures. We present HEXAR (Hierarchical EXplainability Architecture for Robots), a novel framework that provides a plug-in, hierarchical approach to generate explanations about robotic systems. HEXAR consists of specialised component explainers using diverse explanation techniques (e.g., LLM-based reasoning, causal models, feature importance, etc) tailored to specific robot modules, orchestrated by an explainer selector that chooses the most appropriate one for a given query. We implement and evaluate HEXAR on a TIAGo robot performing assistive tasks in a home environment, comparing it against end-to-end and aggregated baseline approaches across 180 scenario-query variations. We observe that HEXAR significantly outperforms baselines in root cause identification, incorrect information exclusion, and runtime, offering a promising direction for transparent autonomous systems.

</details>


### [24] [Dual-quaternion learning control for autonomous vehicle trajectory tracking with safety guarantees](https://arxiv.org/abs/2601.03097)
*Omayra Yago Nieto,Alexandre Anahory Simoes,Juan I. Giribet,Leonardo Colombo*

Main category: cs.RO

TL;DR: 提出了一种基于学习的轨迹跟踪控制器，用于运动可以被描述为$\mathrm{SE}(3)$上的自主机器人平台。该控制器在双四元数框架中构建，并在速度层面操作，通过高斯过程回归集成到几何反馈律中，以在线学习和补偿未知的状态依赖干扰和建模不完善问题，同时保持刚体运动的代数结构和耦合特性。


<details>
  <summary>Details</summary>
Motivation: 针对自主机器人系统中存在的传感器引起的干扰、未建模的致动耦合以及环境不确定性等问题，开发一种不需要显式参数模型的学习型控制器，能够在线学习并补偿这些未知影响，从而实现鲁棒的姿态控制。

Method: 使用双四元数框架设计控制器，在速度层面上直接控制角速度和线速度；采用高斯过程（GP）回归技术来学习和补偿姿态与位置上未知且状态相关的扰动及建模缺陷；通过Lyapunov分析方法证明了在有界GP不确定性下的姿态跟踪误差的概率最终有界性，提供了形式化的稳定性保证。

Result: 仿真结果显示，在存在真实局部扰动的情况下，包括由磁力计扰动引起的相关旋转和平移效应，所提出的控制器能够实现准确平滑的轨迹跟踪。这表明结合几何建模与概率学习的方法对于实现自主机器人系统的鲁棒性和数据效率高的姿态控制具有潜力。

Conclusion: 本文介绍了一种基于学习的轨迹跟踪控制器，它利用高斯过程回归和几何反馈定律来实时补偿未知扰动和建模误差，适用于多种类型的自主移动机器人。研究表明，该方法不仅能够维持刚体运动固有的代数结构和耦合属性，而且还能提供正式的稳定性保障，并在模拟实验中展示了良好的性能。

Abstract: We propose a learning-based trajectory tracking controller for autonomous robotic platforms whose motion can be described kinematically on $\mathrm{SE}(3)$. The controller is formulated in the dual quaternion framework and operates at the velocity level, assuming direct command of angular and linear velocities, as is standard in many aerial vehicles and omnidirectional mobile robots. Gaussian Process (GP) regression is integrated into a geometric feedback law to learn and compensate online for unknown, state-dependent disturbances and modeling imperfections affecting both attitude and position, while preserving the algebraic structure and coupling properties inherent to rigid-body motion.
  The proposed approach does not rely on explicit parametric models of the unknown effects, making it well-suited for robotic systems subject to sensor-induced disturbances, unmodeled actuation couplings, and environmental uncertainties. A Lyapunov-based analysis establishes probabilistic ultimate boundedness of the pose tracking error under bounded GP uncertainty, providing formal stability guarantees for the learning-based controller.
  Simulation results demonstrate accurate and smooth trajectory tracking in the presence of realistic, localized disturbances, including correlated rotational and translational effects arising from magnetometer perturbations. These results illustrate the potential of combining geometric modeling and probabilistic learning to achieve robust, data-efficient pose control for autonomous robotic systems.

</details>


### [25] [A High-Fidelity Digital Twin for Robotic Manipulation Based on 3D Gaussian Splatting](https://arxiv.org/abs/2601.03200)
*Ziyang Sun,Lingfan Bao,Tianhu Peng,Jingcheng Sun,Chengxu Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种基于3D高斯点云（3DGS）的实用框架，能够从稀疏RGB输入中快速构建高质量的数字孪生模型，并通过引入基于过滤器的几何转换方法生成可用于碰撞检测的模型，从而支持在非结构化环境中的鲁棒操作。


<details>
  <summary>Details</summary>
Motivation: 现有的数字孪生开发方法存在重建速度慢、视觉逼真度有限以及难以将照片级真实感模型转换为规划所需的碰撞几何体等问题。为了促进模拟到现实世界的转移，提高机器人执行任务时的可靠性和交互性，需要一种新的方法来构建高质量的数字孪生模型。

Method: 该研究使用3D高斯点云技术进行快速且具有照片级真实感的重建作为统一场景表示；结合可见性感知语义融合以实现准确的三维标注；并通过高效过滤器基几何转换方法无缝集成至Unity-ROS2-MoveIt物理引擎中产生可碰撞检测模型。

Result: 实验表明，在Franka Emika Panda机器人执行拾取与放置任务时，增强后的几何精度有效支持了实际试验中的稳健操作。这证明了基于3DGS并丰富了语义和几何一致性的数字孪生提供了一条从感知到操作的快速、可靠且可扩展路径。

Conclusion: 基于3DGS的数字孪生模型通过增加语义和几何一致性，为从感知到操作提供了快速、可靠且可扩展的方法，特别是在处理非结构化环境中表现出了显著优势。

Abstract: Developing high-fidelity, interactive digital twins is crucial for enabling closed-loop motion planning and reliable real-world robot execution, which are essential to advancing sim-to-real transfer. However, existing approaches often suffer from slow reconstruction, limited visual fidelity, and difficulties in converting photorealistic models into planning-ready collision geometry. We present a practical framework that constructs high-quality digital twins within minutes from sparse RGB inputs. Our system employs 3D Gaussian Splatting (3DGS) for fast, photorealistic reconstruction as a unified scene representation. We enhance 3DGS with visibility-aware semantic fusion for accurate 3D labelling and introduce an efficient, filter-based geometry conversion method to produce collision-ready models seamlessly integrated with a Unity-ROS2-MoveIt physics engine. In experiments with a Franka Emika Panda robot performing pick-and-place tasks, we demonstrate that this enhanced geometric accuracy effectively supports robust manipulation in real-world trials. These results demonstrate that 3DGS-based digital twins, enriched with semantic and geometric consistency, offer a fast, reliable, and scalable path from perception to manipulation in unstructured environments.

</details>
