{"id": "2601.09838", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09838", "abs": "https://arxiv.org/abs/2601.09838", "authors": ["Leonie Dyck", "Aiko Galetzka", "Maximilian Noller", "Anna-Lena Rinke", "Jutta Bormann", "Jekaterina Miller", "Michelle Hochbaum", "Julia Siemann", "J\u00f6rdis Alboth", "Andre Berwinkel", "Johanna Luz", "Britta Kley-Zobel", "Marcine Cyrys", "Nora Fl\u00f6ttmann", "Ariane Vogeler", "Mariia Melnikova", "Ira-Katharina Petras", "Michael Siniatchkin", "Winfried Barthlen", "Anna-Lisa Vollmer"], "title": "Interprofessional and Agile Development of Mobirobot: A Socially Assistive Robot for Pediatric Therapy Across Clinical and Therapeutic Settings", "comment": "submitted to Frontiers in Digital Health", "summary": "Introduction: Socially assistive robots hold promise for enhancing therapeutic engagement in paediatric clinical settings. However, their successful implementation requires not only technical robustness but also context-sensitive, co-designed solutions. This paper presents Mobirobot, a socially assistive robot developed to support mobilisation in children recovering from trauma, fractures, or depressive disorders through personalised exercise programmes.\n  Methods: An agile, human-centred development approach guided the iterative design of Mobirobot. Multidisciplinary clinical teams and end users were involved throughout the co-development process, which focused on early integration into real-world paediatric surgical and psychiatric settings. The robot, based on the NAO platform, features a simple setup, adaptable exercise routines with interactive guidance, motivational dialogue, and a graphical user interface (GUI) for monitoring and no-code system feedback.\n  Results: Deployment in hospital environments enabled the identification of key design requirements and usability constraints. Stakeholder feedback led to refinements in interaction design, movement capabilities, and technical configuration. A feasibility study is currently underway to assess acceptance, usability, and perceived therapeutic benefit, with data collection including questionnaires, behavioural observations, and staff-patient interviews.\n  Discussion: Mobirobot demonstrates how multiprofessional, stakeholder-led development can yield a socially assistive system suited for dynamic inpatient settings. Early-stage findings underscore the importance of contextual integration, robustness, and minimal-intrusion design. While challenges such as sensor limitations and patient recruitment remain, the platform offers a promising foundation for further research and clinical application.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMobirobot\u7684\u793e\u4f1a\u8f85\u52a9\u673a\u5668\u4eba\uff0c\u5b83\u901a\u8fc7\u4e2a\u6027\u5316\u8fd0\u52a8\u8ba1\u5212\u652f\u6301\u513f\u7ae5\u4ece\u521b\u4f24\u3001\u9aa8\u6298\u6216\u6291\u90c1\u969c\u788d\u4e2d\u6062\u590d\u3002\u8be5\u673a\u5668\u4eba\u7684\u5f00\u53d1\u91c7\u7528\u4e86\u654f\u6377\u7684\u4eba\u672c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u7684\u513f\u79d1\u5916\u79d1\u548c\u7cbe\u795e\u79d1\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u65e9\u671f\u6574\u5408\u3002\u76ee\u524d\u6b63\u5728\u8fdb\u884c\u4e00\u9879\u53ef\u884c\u6027\u7814\u7a76\u4ee5\u8bc4\u4f30\u63a5\u53d7\u5ea6\u3001\u53ef\u7528\u6027\u548c\u611f\u77e5\u6cbb\u7597\u6548\u76ca\u3002", "motivation": "\u793e\u4f1a\u8f85\u52a9\u673a\u5668\u4eba\u6709\u671b\u63d0\u9ad8\u513f\u79d1\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u6cbb\u7597\u53c2\u4e0e\u5ea6\u3002\u7136\u800c\uff0c\u5b83\u4eec\u7684\u6210\u529f\u5b9e\u65bd\u4e0d\u4ec5\u9700\u8981\u6280\u672f\u4e0a\u7684\u7a33\u5065\u6027\uff0c\u8fd8\u9700\u8981\u5177\u6709\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u7684\u5171\u540c\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u654f\u6377\u7684\u4eba\u672c\u5f00\u53d1\u65b9\u6cd5\u6307\u5bfc\u4e86Mobirobot\u7684\u8fed\u4ee3\u8bbe\u8ba1\u3002\u6574\u4e2a\u5171\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u90fd\u6d89\u53ca\u591a\u5b66\u79d1\u4e34\u5e8a\u56e2\u961f\u548c\u6700\u7ec8\u7528\u6237\uff0c\u91cd\u70b9\u662f\u5c3d\u65e9\u6574\u5408\u5230\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u513f\u79d1\u5916\u79d1\u4e0e\u7cbe\u795e\u79d1\u573a\u666f\u91cc\u3002\u57fa\u4e8eNAO\u5e73\u53f0\u7684\u673a\u5668\u4eba\u5177\u5907\u7b80\u6613\u8bbe\u7f6e\u3001\u53ef\u8c03\u6574\u7684\u8fd0\u52a8\u7a0b\u5e8f\u3001\u4e92\u52a8\u5f15\u5bfc\u3001\u6fc0\u52b1\u5bf9\u8bdd\u4ee5\u53ca\u7528\u4e8e\u76d1\u63a7\u548c\u65e0\u4ee3\u7801\u7cfb\u7edf\u53cd\u9988\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u3002", "result": "\u5728\u533b\u9662\u73af\u5883\u4e2d\u90e8\u7f72\u5e2e\u52a9\u8bc6\u522b\u4e86\u5173\u952e\u7684\u8bbe\u8ba1\u8981\u6c42\u548c\u53ef\u7528\u6027\u9650\u5236\u3002\u5229\u76ca\u76f8\u5173\u8005\u7684\u53cd\u9988\u4fc3\u8fdb\u4e86\u4ea4\u4e92\u8bbe\u8ba1\u3001\u79fb\u52a8\u80fd\u529b\u548c\u6280\u672f\u914d\u7f6e\u65b9\u9762\u7684\u6539\u8fdb\u3002\u5f53\u524d\u6b63\u5728\u5f00\u5c55\u4e00\u9879\u53ef\u884c\u6027\u7814\u7a76\u6765\u8bc4\u4f30\u63a5\u53d7\u5ea6\u3001\u53ef\u7528\u6027\u548c\u611f\u77e5\u6cbb\u7597\u6548\u679c\uff0c\u6570\u636e\u6536\u96c6\u5305\u62ec\u95ee\u5377\u8c03\u67e5\u3001\u884c\u4e3a\u89c2\u5bdf\u4ee5\u53ca\u533b\u62a4\u4eba\u5458-\u60a3\u8005\u8bbf\u8c08\u3002", "conclusion": "Mobirobot\u5c55\u793a\u4e86\u591a\u4e13\u4e1a\u3001\u7531\u5229\u76ca\u76f8\u5173\u8005\u4e3b\u5bfc\u7684\u53d1\u5c55\u5982\u4f55\u80fd\u591f\u4ea7\u751f\u9002\u5408\u52a8\u6001\u4f4f\u9662\u73af\u5883\u7684\u793e\u4f1a\u8f85\u52a9\u7cfb\u7edf\u3002\u521d\u671f\u53d1\u73b0\u5f3a\u8c03\u4e86\u60c5\u5883\u6574\u5408\u3001\u7a33\u5065\u6027\u53ca\u6700\u5c0f\u4fb5\u5165\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002\u5c3d\u7ba1\u5b58\u5728\u8bf8\u5982\u4f20\u611f\u5668\u5c40\u9650\u6027\u548c\u60a3\u8005\u62db\u52df\u7b49\u6311\u6218\uff0c\u4f46\u8be5\u5e73\u53f0\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u57fa\u7840\u3002"}}
{"id": "2601.09856", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09856", "abs": "https://arxiv.org/abs/2601.09856", "authors": ["Andrew Stratton", "Phani Teja Singamaneni", "Pranav Goyal", "Rachid Alami", "Christoforos Mavrogiannis"], "title": "How Human Motion Prediction Quality Shapes Social Robot Navigation Performance in Constrained Spaces", "comment": null, "summary": "Motivated by the vision of integrating mobile robots closer to humans in warehouses, hospitals, manufacturing plants, and the home, we focus on robot navigation in dynamic and spatially constrained environments. Ensuring human safety, comfort, and efficiency in such settings requires that robots are endowed with a model of how humans move around them. Human motion prediction around robots is especially challenging due to the stochasticity of human behavior, differences in user preferences, and data scarcity. In this work, we perform a methodical investigation of the effects of human motion prediction quality on robot navigation performance, as well as human productivity and impressions. We design a scenario involving robot navigation among two human subjects in a constrained workspace and instantiate it in a user study ($N=80$) involving two different robot platforms, conducted across two sites from different world regions. Key findings include evidence that: 1) the widely adopted average displacement error is not a reliable predictor of robot navigation performance and human impressions; 2) the common assumption of human cooperation breaks down in constrained environments, with users often not reciprocating robot cooperation, and causing performance degradations; 3) more efficient robot navigation often comes at the expense of human efficiency and comfort.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4eba\u7c7b\u8fd0\u52a8\u9884\u6d4b\u8d28\u91cf\u5bf9\u673a\u5668\u4eba\u5bfc\u822a\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\u4e0d\u662f\u53ef\u9760\u7684\u6027\u80fd\u9884\u6d4b\u6307\u6807\uff0c\u4e14\u5728\u53d7\u9650\u73af\u5883\u4e2d\u4eba\u7c7b\u5408\u4f5c\u7684\u5047\u8bbe\u4e0d\u6210\u7acb\uff0c\u66f4\u9ad8\u6548\u7684\u673a\u5668\u4eba\u5bfc\u822a\u5f80\u5f80\u727a\u7272\u4e86\u4eba\u7c7b\u6548\u7387\u548c\u8212\u9002\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u79fb\u52a8\u673a\u5668\u4eba\u66f4\u597d\u5730\u878d\u5165\u4ed3\u5e93\u3001\u533b\u9662\u3001\u5236\u9020\u5382\u548c\u5bb6\u5ead\u7b49\u73af\u5883\u4e2d\uff0c\u5e76\u786e\u4fdd\u5728\u8fd9\u4e9b\u573a\u666f\u4e2d\u7684\u4eba\u7c7b\u5b89\u5168\u3001\u8212\u9002\u548c\u6548\u7387\uff0c\u9700\u8981\u8d4b\u4e88\u673a\u5668\u4eba\u4e00\u79cd\u7406\u89e3\u4eba\u7c7b\u5982\u4f55\u5728\u5176\u5468\u56f4\u79fb\u52a8\u7684\u6a21\u578b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u4eba\u7c7b\u884c\u4e3a\u7684\u968f\u673a\u6027\u3001\u7528\u6237\u504f\u597d\u7684\u5dee\u5f02\u4ee5\u53ca\u6570\u636e\u7a00\u7f3a\u7b49\u95ee\u9898\uff0c\u4f7f\u5f97\u56f4\u7ed5\u673a\u5668\u4eba\u7684\u4eba\u5458\u6d41\u52a8\u9884\u6d4b\u53d8\u5f97\u7279\u522b\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6d89\u53ca\u4e24\u4e2a\u53d7\u8bd5\u8005\u5728\u53d7\u9650\u5de5\u4f5c\u7a7a\u95f4\u4e2d\u4e0e\u673a\u5668\u4eba\u5bfc\u822a\u7684\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\uff08N=80\uff09\u6765\u5b9e\u65bd\uff0c\u8be5\u7814\u7a76\u4f7f\u7528\u4e86\u4e24\u79cd\u4e0d\u540c\u7684\u673a\u5668\u4eba\u5e73\u53f0\uff0c\u5728\u6765\u81ea\u4e0d\u540c\u4e16\u754c\u533a\u57df\u7684\u4e24\u4e2a\u5730\u70b9\u8fdb\u884c\u3002", "result": "1) \u5e7f\u6cdb\u91c7\u7528\u7684\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\u5e76\u4e0d\u662f\u673a\u5668\u4eba\u5bfc\u822a\u6027\u80fd\u548c\u4eba\u5370\u8c61\u7684\u53ef\u9760\u9884\u6d4b\u56e0\u5b50\uff1b2) \u5728\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u4eba\u4eec\u901a\u5e38\u4e0d\u4f1a\u54cd\u5e94\u673a\u5668\u4eba\u7684\u5408\u4f5c\u5c1d\u8bd5\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u8fd9\u6253\u7834\u4e86\u5173\u4e8e\u4eba\u7c7b\u4f1a\u5408\u4f5c\u7684\u4e00\u822c\u5047\u8bbe\uff1b3) \u673a\u5668\u4eba\u5bfc\u822a\u6548\u7387\u7684\u63d0\u9ad8\u5f80\u5f80\u662f\u4ee5\u727a\u7272\u4eba\u7c7b\u6548\u7387\u548c\u8212\u9002\u5ea6\u4e3a\u4ee3\u4ef7\u7684\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5f00\u53d1\u7528\u4e8e\u52a8\u6001\u53ca\u7a7a\u95f4\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u7cfb\u7edf\u65f6\uff0c\u9700\u8981\u66f4\u52a0\u7ec6\u81f4\u5730\u8003\u8651\u4eba\u7c7b\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u8bc4\u4f30\u673a\u5668\u4eba\u5bfc\u822a\u6027\u80fd\u7684\u6807\u51c6\u63d0\u51fa\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u6307\u51fa\u4ec5\u4f9d\u8d56\u4e8e\u6280\u672f\u6307\u6807\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5168\u9762\u8bc4\u4ef7\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.09920", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09920", "abs": "https://arxiv.org/abs/2601.09920", "authors": ["Ruopeng Huang", "Boyu Yang", "Wenlong Gui", "Jeremy Morgan", "Erdem Biyik", "Jiachen Li"], "title": "SyncTwin: Fast Digital Twin Construction and Synchronization for Safe Robotic Grasping", "comment": null, "summary": "Accurate and safe grasping under dynamic and visually occluded conditions remains a core challenge in real-world robotic manipulation. We present SyncTwin, a digital twin framework that unifies fast 3D scene reconstruction and real-to-sim synchronization for robust and safety-aware grasping in such environments. In the offline stage, we employ VGGT to rapidly reconstruct object-level 3D assets from RGB images, forming a reusable geometry library for simulation. During execution, SyncTwin continuously synchronizes the digital twin by tracking real-world object states via point cloud segmentation updates and aligning them through colored-ICP registration. The updated twin enables motion planners to compute collision-free and dynamically feasible trajectories in simulation, which are safely executed on the real robot through a closed real-to-sim-to-real loop. Experiments in dynamic and occluded scenes show that SyncTwin improves grasp accuracy and motion safety, demonstrating the effectiveness of digital-twin synchronization for real-world robotic execution.", "AI": {"tldr": "SyncTwin\u662f\u4e00\u4e2a\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5feb\u901f3D\u573a\u666f\u91cd\u5efa\u548c\u5b9e\u65f6\u4eff\u771f\u540c\u6b65\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u5728\u52a8\u6001\u548c\u89c6\u89c9\u906e\u6321\u6761\u4ef6\u4e0b\u7684\u51c6\u786e\u4e14\u5b89\u5168\u7684\u6293\u53d6\u3002\u901a\u8fc7VGGT\u4eceRGB\u56fe\u50cf\u4e2d\u5feb\u901f\u91cd\u5efa\u7269\u4f53\u7ea7\u522b\u76843D\u8d44\u4ea7\uff0c\u5e76\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u6301\u7eed\u66f4\u65b0\u6570\u5b57\u5b6a\u751f\u4f53\u6765\u8ddf\u8e2a\u771f\u5b9e\u4e16\u754c\u7269\u4f53\u7684\u72b6\u6001\uff0c\u4ece\u800c\u5141\u8bb8\u8fd0\u52a8\u89c4\u5212\u5668\u8ba1\u7b97\u65e0\u78b0\u649e\u53ca\u52a8\u6001\u53ef\u884c\u7684\u8f68\u8ff9\uff0c\u8fdb\u800c\u63d0\u9ad8\u6293\u53d6\u7cbe\u5ea6\u548c\u8fd0\u52a8\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\uff0c\u5728\u52a8\u6001\u548c\u89c6\u7ebf\u53d7\u963b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7cbe\u786e\u4e14\u5b89\u5168\u7684\u6293\u63e1\u4ecd\u662f\u4e00\u5927\u6311\u6218\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u5e76\u63d0\u9ad8\u6293\u63e1\u51c6\u786e\u6027\u4e0e\u5b89\u5168\u6027\uff0c\u63d0\u51fa\u4e86SyncTwin\u6846\u67b6\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSyncTwin\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u5feb\u901f3D\u573a\u666f\u91cd\u5efa\uff08\u4f7f\u7528VGGT\u4eceRGB\u56fe\u50cf\u91cd\u5efa\u5bf9\u8c61\u7ea73D\u8d44\u4ea7\uff09\u4ee5\u53ca\u901a\u8fc7\u70b9\u4e91\u5206\u5272\u66f4\u65b0\u548c\u5f69\u8272ICP\u914d\u51c6\u5b9e\u73b0\u7684\u771f\u5b9e\u5230\u6a21\u62df\u540c\u6b65\u673a\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u51e0\u4f55\u5e93\u7528\u4e8e\u6a21\u62df\uff0c\u5e76\u901a\u8fc7\u95ed\u73af\u63a7\u5236\u786e\u4fdd\u865a\u62df\u73af\u5883\u4e2d\u89c4\u5212\u51fa\u7684\u52a8\u4f5c\u80fd\u591f\u5b89\u5168\u5730\u5e94\u7528\u4e8e\u5b9e\u9645\u673a\u5668\u4eba\u4e0a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u52a8\u6001\u548c\u906e\u6321\u573a\u666f\u4e0b\uff0cSyncTwin\u80fd\u591f\u663e\u8457\u63d0\u5347\u6293\u63e1\u7cbe\u5ea6\u548c\u52a8\u4f5c\u5b89\u5168\u6027\uff0c\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u540c\u6b65\u65b9\u6cd5\u5bf9\u4e8e\u6539\u5584\u73b0\u5b9e\u4e16\u754c\u4e2d\u673a\u5668\u4eba\u6267\u884c\u4efb\u52a1\u7684\u6709\u6548\u6027\u3002", "conclusion": "SyncTwin\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u52a8\u6001\u548c\u89c6\u7ebf\u53d7\u963b\u73af\u5883\u4e0b\u673a\u5668\u4eba\u6293\u63e1\u64cd\u4f5c\u4e2d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5c06\u5feb\u901f3D\u91cd\u5efa\u4e0e\u5b9e\u65f6\u4eff\u771f\u540c\u6b65\u76f8\u7ed3\u5408\uff0c\u63d0\u9ad8\u4e86\u6293\u63e1\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2601.09988", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09988", "abs": "https://arxiv.org/abs/2601.09988", "authors": ["Hojung Choi", "Yifan Hou", "Chuer Pan", "Seongheon Hong", "Austin Patel", "Xiaomeng Xu", "Mark R. Cutkosky", "Shuran Song"], "title": "In-the-Wild Compliant Manipulation with UMI-FT", "comment": "submitted to ICRA 2026", "summary": "Many manipulation tasks require careful force modulation. With insufficient force the task may fail, while excessive force could cause damage. The high cost, bulky size and fragility of commercial force/torque (F/T) sensors have limited large-scale, force-aware policy learning. We introduce UMI-FT, a handheld data-collection platform that mounts compact, six-axis force/torque sensors on each finger, enabling finger-level wrench measurements alongside RGB, depth, and pose. Using the multimodal data collected from this device, we train an adaptive compliance policy that predicts position targets, grasp force, and stiffness for execution on standard compliance controllers. In evaluations on three contact-rich, force-sensitive tasks (whiteboard wiping, skewering zucchini, and lightbulb insertion), UMI-FT enables policies that reliably regulate external contact forces and internal grasp forces, outperforming baselines that lack compliance or force sensing. UMI-FT offers a scalable path to learning compliant manipulation from in-the-wild demonstrations. We open-source the hardware and software to facilitate broader adoption at:https://umi-ft.github.io/.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u624b\u6301\u6570\u636e\u6536\u96c6\u5e73\u53f0UMI-FT\uff0c\u5b83\u5728\u6bcf\u4e2a\u624b\u6307\u4e0a\u5b89\u88c5\u4e86\u7d27\u51d1\u578b\u516d\u8f74\u529b/\u626d\u77e9\u4f20\u611f\u5668\uff0c\u53ef\u4ee5\u6d4b\u91cf\u6307\u7ea7\u529b\u77e9\uff0c\u5e76\u7ed3\u5408RGB\u3001\u6df1\u5ea6\u548c\u59ff\u6001\u6570\u636e\u3002\u57fa\u4e8e\u8fd9\u4e9b\u591a\u6a21\u6001\u6570\u636e\u8bad\u7ec3\u51fa\u7684\u81ea\u9002\u5e94\u987a\u5e94\u6027\u7b56\u7565\uff0c\u5728\u63a5\u89e6\u4e30\u5bcc\u4e14\u5bf9\u529b\u91cf\u654f\u611f\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u7f3a\u4e4f\u987a\u5e94\u6027\u6216\u529b\u91cf\u611f\u77e5\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u64cd\u4f5c\u4efb\u52a1\u9700\u8981\u7cbe\u7ec6\u7684\u529b\u91cf\u8c03\u8282\uff0c\u4f46\u5546\u7528F/T\u4f20\u611f\u5668\u7684\u6210\u672c\u9ad8\u3001\u4f53\u79ef\u5927\u53ca\u6613\u788e\u6027\u9650\u5236\u4e86\u5927\u89c4\u6a21\u529b\u91cf\u611f\u77e5\u7b56\u7565\u7684\u5b66\u4e60\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86UMI-FT\u5e73\u53f0\u3002", "method": "\u901a\u8fc7\u4e00\u4e2a\u540d\u4e3aUMI-FT\u7684\u624b\u6301\u8bbe\u5907\u6765\u6536\u96c6\u5305\u542bRGB\u56fe\u50cf\u3001\u6df1\u5ea6\u4fe1\u606f\u3001\u4f4d\u59ff\u4ee5\u53ca\u6307\u7ea7\u529b\u77e9\u6d4b\u91cf\u7684\u6570\u636e\u3002\u4f7f\u7528\u8fd9\u4e9b\u591a\u6a21\u6001\u6570\u636e\u8bad\u7ec3\u80fd\u591f\u9884\u6d4b\u4f4d\u7f6e\u76ee\u6807\u3001\u6293\u63e1\u529b\u548c\u521a\u5ea6\u7684\u81ea\u9002\u5e94\u987a\u5e94\u6027\u7b56\u7565\uff0c\u4ee5\u4fbf\u4e8e\u5728\u6807\u51c6\u987a\u5e94\u63a7\u5236\u5668\u4e0a\u6267\u884c\u3002", "result": "\u5728\u767d\u677f\u64e6\u62ed\u3001\u7a7f\u523a\u897f\u846b\u82a6\u548c\u706f\u6ce1\u63d2\u5165\u8fd9\u4e09\u9879\u63a5\u89e6\u5bc6\u96c6\u4e14\u5bf9\u529b\u91cf\u654f\u611f\u7684\u4efb\u52a1\u6d4b\u8bd5\u4e2d\uff0cUMI-FT\u652f\u6301\u7684\u7b56\u7565\u80fd\u53ef\u9760\u5730\u8c03\u8282\u5916\u90e8\u63a5\u89e6\u529b\u548c\u5185\u90e8\u6293\u63e1\u529b\uff0c\u8868\u73b0\u4f18\u4e8e\u6ca1\u6709\u987a\u5e94\u6027\u6216\u529b\u91cf\u611f\u77e5\u80fd\u529b\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "UMI-FT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u91ce\u5916\u6f14\u793a\u5b66\u4e60\u987a\u5e94\u6027\u64cd\u63a7\u7684\u53ef\u6269\u5c55\u8def\u5f84\uff0c\u5e76\u4e14\u5176\u786c\u4ef6\u548c\u8f6f\u4ef6\u5df2\u5f00\u6e90\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002"}}
{"id": "2601.10116", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10116", "abs": "https://arxiv.org/abs/2601.10116", "authors": ["Xintong Zhang", "Junfeng Chen", "Yuxiao Zhu", "Bing Luo", "Meng Guo"], "title": "CoCoPlan: Adaptive Coordination and Communication for Multi-robot Systems in Dynamic and Unknown Environments", "comment": "8 pages, 8 figures, published to RA-L", "summary": "Multi-robot systems can greatly enhance efficiency through coordination and collaboration, yet in practice, full-time communication is rarely available and interactions are constrained to close-range exchanges. Existing methods either maintain all-time connectivity, rely on fixed schedules, or adopt pairwise protocols, but none adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination. To address this gap, we propose CoCoPlan, a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication. Our approach integrates a branch-and-bound architecture that jointly encodes task assignments and communication events, an adaptive objective function that balances task efficiency against communication latency, and a communication event optimization module that strategically determines when, where and how the global connectivity should be re-established. Extensive experiments demonstrate that it outperforms state-of-the-art methods by achieving a 22.4% higher task completion rate, reducing communication overhead by 58.6%, and improving the scalability by supporting up to 100 robots in dynamic environments. Hardware experiments include the complex 2D office environment and large-scale 3D disaster-response scenario.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoCoPlan\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u540c\u65f6\u4f18\u5316\u4e86\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u534f\u4f5c\u4efb\u52a1\u89c4\u5212\u548c\u56e2\u961f\u95f4\u65ad\u901a\u4fe1\u3002\u901a\u8fc7\u96c6\u6210\u5206\u652f\u5b9a\u754c\u67b6\u6784\u3001\u81ea\u9002\u5e94\u76ee\u6807\u51fd\u6570\u4ee5\u53ca\u901a\u4fe1\u4e8b\u4ef6\u4f18\u5316\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u3001\u964d\u4f4e\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u652f\u6301\u591a\u8fbe100\u4e2a\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u64cd\u4f5c\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u65b9\u6cd5\u5728\u6709\u9650\u901a\u4fe1\u6761\u4ef6\u4e0b\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u52a8\u6001\u65f6\u7a7a\u4efb\u52a1\u5206\u5e03\uff0c\u5bfc\u81f4\u534f\u8c03\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86CoCoPlan\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u4efb\u52a1\u5206\u914d\u4e0e\u901a\u4fe1\u4e8b\u4ef6\u7684\u7f16\u7801\u3001\u5e73\u8861\u4efb\u52a1\u6548\u7387\u4e0e\u901a\u4fe1\u5ef6\u8fdf\u7684\u81ea\u9002\u5e94\u76ee\u6807\u51fd\u6570\uff0c\u4ee5\u53ca\u7528\u4e8e\u7b56\u7565\u6027\u786e\u5b9a\u5168\u5c40\u8fde\u63a5\u5e94\u4f55\u65f6\u4f55\u5730\u91cd\u65b0\u5efa\u7acb\u7684\u901a\u4fe1\u4e8b\u4ef6\u4f18\u5316\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u9ad8\u4e8622.4%\uff0c\u901a\u4fe1\u5f00\u9500\u51cf\u5c11\u4e8658.6%\uff0c\u5e76\u4e14\u80fd\u591f\u652f\u6301\u591a\u8fbe100\u4e2a\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8fd0\u884c\u3002\u786c\u4ef6\u5b9e\u9a8c\u6db5\u76d6\u4e86\u590d\u6742\u76842D\u529e\u516c\u73af\u5883\u548c\u5927\u89c4\u6a213D\u707e\u5bb3\u54cd\u5e94\u573a\u666f\u3002", "conclusion": "CoCoPlan\u4e3a\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u6210\u672c\uff0c\u5e76\u4e14\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2601.10208", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10208", "abs": "https://arxiv.org/abs/2601.10208", "authors": ["Shuangshan Nors Li", "J. Nathan Kutz"], "title": "Terrain-Adaptive Mobile 3D Printing with Hierarchical Control", "comment": "Submitted to the 43rd International Symposium on Automation and Robotics in Construction (ISARC 2026)", "summary": "Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI module learns terrain-to-perturbation mappings from IMU, vision, and depth sensors, enabling proactive compensation rather than reactive correction. This intelligence is embedded into a three-layer control architecture: path planning, predictive chassis-manipulator coordination, and precision hardware execution. Through outdoor experiments on terrain with slopes and surface irregularities, we demonstrate sub-centimeter printing accuracy while maintaining full platform mobility. This AI-hardware integration establishes a practical foundation for autonomous construction in unstructured environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408AI\u9a71\u52a8\u7684\u5e72\u6270\u9884\u6d4b\u3001\u591a\u6a21\u6001\u4f20\u611f\u5668\u878d\u5408\u548c\u5206\u5c42\u786c\u4ef6\u63a7\u5236\u7684\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u89c4\u5219\u5730\u5f62\u4e0a\u7684\u79fb\u52a83D\u6253\u5370\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e9a\u5398\u7c73\u7ea7\u7684\u6253\u5370\u7cbe\u5ea6\u548c\u5e73\u53f0\u7684\u5b8c\u5168\u673a\u52a8\u6027\u3002", "motivation": "\u79fb\u52a83D\u6253\u5370\u5728\u975e\u7ed3\u6784\u5316\u5730\u5f62\u4e0a\u9762\u4e34\u5e73\u53f0\u79fb\u52a8\u6027\u548c\u6c89\u79ef\u7cbe\u5ea6\u4e4b\u95f4\u7684\u77db\u76fe\u3002\u73b0\u6709\u57fa\u4e8e\u9f99\u95e8\u67b6\u7684\u7cfb\u7edf\u867d\u7136\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u79fb\u52a8\u6027\uff1b\u800c\u79fb\u52a8\u5e73\u53f0\u5219\u96be\u4ee5\u5728\u4e0d\u5e73\u5766\u5730\u9762\u4e0a\u7ef4\u6301\u6253\u5370\u8d28\u91cf\u3002", "method": "\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u7d27\u5bc6\u7ed3\u5408AI\u9a71\u52a8\u5e72\u6270\u9884\u6d4b\u4e0e\u591a\u6a21\u6001\u4f20\u611f\u5668\uff08IMU\u3001\u89c6\u89c9\u53ca\u6df1\u5ea6\u4f20\u611f\u5668\uff09\u878d\u5408\u4ee5\u53ca\u5c42\u7ea7\u786c\u4ef6\u63a7\u5236\u4e8e\u4e00\u4f53\u7684\u95ed\u73af\u611f\u77e5-\u5b66\u4e60-\u6267\u884c\u7cfb\u7edf\u3002\u6b64\u667a\u80fd\u6a21\u5757\u4ece\u4f20\u611f\u5668\u6570\u636e\u4e2d\u5b66\u4e60\u5730\u5f62\u5230\u6270\u52a8\u6620\u5c04\uff0c\u4ece\u800c\u80fd\u591f\u8fdb\u884c\u4e3b\u52a8\u8865\u507f\u800c\u975e\u88ab\u52a8\u6821\u6b63\uff0c\u5e76\u5c06\u8fd9\u4e00\u667a\u80fd\u96c6\u6210\u5230\u4e86\u4e00\u4e2a\u4e09\u5c42\u63a7\u5236\u67b6\u6784\u4e2d\uff1a\u8def\u5f84\u89c4\u5212\u3001\u9884\u6d4b\u6027\u7684\u5e95\u76d8-\u673a\u68b0\u81c2\u534f\u8c03\u4ee5\u53ca\u7cbe\u786e\u786c\u4ef6\u6267\u884c\u3002", "result": "\u901a\u8fc7\u5728\u5177\u6709\u5761\u5ea6\u548c\u8868\u9762\u4e0d\u89c4\u5219\u6027\u7684\u6237\u5916\u5730\u5f62\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u4fdd\u6301\u5e73\u53f0\u5b8c\u5168\u673a\u52a8\u6027\u7684\u540c\u65f6\uff0c\u4e5f\u80fd\u8fbe\u5230\u4e9a\u5398\u7c73\u7ea7\u522b\u7684\u6253\u5370\u51c6\u786e\u5ea6\u3002", "conclusion": "\u8fd9\u79cdAI-\u786c\u4ef6\u96c6\u6210\u65b9\u6cd5\u4e3a\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u5efa\u9020\u5960\u5b9a\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2601.10225", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10225", "abs": "https://arxiv.org/abs/2601.10225", "authors": ["Dongwook Kwak", "Geonhee Cho", "Jiook Chung", "Jinkyu Yang"], "title": "A Unified Framework for Kinematic Simulation of Rigid Foldable Structures", "comment": "34 pages (20 pages main text), 11 figures (7 in main text, 4 in appendix)", "summary": "Origami-inspired structures with rigid panels now span thick, kirigami, and multi-sheet realizations, making unified kinematic analysis essential. Yet a general method that consolidates their loop constraints has been lacking. We present an automated approach that generates the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS). From a minimally extended data schema, the tool constructs the facet-hinge graph, extracts a minimum cycle basis that captures all constraints, and assembles a velocity-level constraint matrix via screw theory that encodes coupled rotation and translation loop closure. The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u4efb\u610f\u521a\u6027\u53ef\u6298\u53e0\u7ed3\u6784\u7684Pfaffian\u7ea6\u675f\u77e9\u9635\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u9762-\u94f0\u94fe\u56fe\u548c\u63d0\u53d6\u6700\u5c0f\u5faa\u73af\u57fa\u6765\u6355\u6349\u6240\u6709\u7ea6\u675f\uff0c\u5e76\u5229\u7528\u87ba\u65cb\u7406\u8bba\u7ec4\u88c5\u4e00\u4e2a\u901f\u5ea6\u7ea7\u7ea6\u675f\u77e9\u9635\uff0c\u4ece\u800c\u7b80\u5316\u4e86\u590d\u6742\u7684\u7ea6\u675f\u8ba1\u7b97\u3002", "motivation": "\u7531\u4e8e\u53d7\u5230\u6298\u7eb8\u542f\u53d1\u7684\u7ed3\u6784\u73b0\u5728\u5305\u62ec\u539a\u5b9e\u3001\u526a\u7eb8\u53ca\u591a\u5c42\u5b9e\u73b0\u65b9\u5f0f\uff0c\u56e0\u6b64\u7edf\u4e00\u7684\u52a8\u529b\u5b66\u5206\u6790\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4f46\u76ee\u524d\u7f3a\u4e4f\u4e00\u79cd\u53ef\u4ee5\u6574\u5408\u8fd9\u4e9b\u73af\u8def\u7ea6\u675f\u7684\u4e00\u822c\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u4ece\u6700\u5c0f\u6269\u5c55\u7684\u6570\u636e\u6a21\u5f0f\u5f00\u59cb\uff0c\u6784\u9020\u9762-\u94f0\u94fe\u56fe\uff0c\u63d0\u53d6\u80fd\u591f\u6355\u6349\u6240\u6709\u7ea6\u675f\u6761\u4ef6\u7684\u6700\u5c0f\u5faa\u73af\u57fa\uff0c\u5e76\u901a\u8fc7\u87ba\u65cb\u7406\u8bba\u5728\u901f\u5ea6\u5c42\u9762\u7ec4\u88c5\u7ea6\u675f\u77e9\u9635\u4ee5\u7f16\u7801\u8026\u5408\u65cb\u8f6c\u548c\u5e73\u79fb\u95ed\u5408\u73af\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u591a\u79cd\u521a\u6027\u53ef\u6298\u53e0\u7ed3\u6784\u4e2d\u8ba1\u7b97\u5e76\u53ef\u89c6\u5316\u5c55\u5f00\u4e0e\u6298\u53e0\u8fd0\u52a8\uff0c\u540c\u65f6\u907f\u514d\u4e86\u7e41\u7410\u4e14\u5bb9\u6613\u51fa\u9519\u7684\u7ea6\u675f\u8ba1\u7b97\u8fc7\u7a0b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9488\u5bf9\u4efb\u610f\u521a\u6027\u53ef\u6298\u53e0\u7ed3\u6784\u8fdb\u884c\u52a8\u529b\u5b66\u5206\u6790\u7684\u6709\u6548\u624b\u6bb5\uff0c\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u5185\u8bbe\u8ba1\u4e0e\u5206\u6790\u5de5\u4f5c\u7684\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2601.10268", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10268", "abs": "https://arxiv.org/abs/2601.10268", "authors": ["Eszter Birtalan", "Mikl\u00f3s Koller"], "title": "The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation", "comment": "13 pages, 6 figures, 2 tables", "summary": "Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available space. We used simulations to evaluate 6 different tactile sensor configurations with different densities and layouts, based on their impact on reinforcement learning. Our two-setup system allows for robust results that are not dependent on the use of a given physics simulator, robotic hand model or machine learning algorithm. Our results show setup-specific, as well as generalized effects across the 6 sensorized simulations, and we identify one configuration as consistently yielding the best performance across both setups. These results could help future research aimed at robotic hand designs, including prostheses.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u8bc4\u4f30\u4e866\u79cd\u4e0d\u540c\u5bc6\u5ea6\u548c\u5e03\u5c40\u7684\u89e6\u89c9\u4f20\u611f\u5668\u914d\u7f6e\u5bf9\u5f3a\u5316\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u786e\u5b9a\u4e86\u4e00\u79cd\u5728\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u6700\u4f73\u7684\u914d\u7f6e\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u673a\u5668\u4eba\u624b\u8bbe\u8ba1\u5305\u62ec\u5047\u80a2\u7684\u7814\u7a76\u3002", "motivation": "\u89e6\u89c9\u4f20\u611f\u5668\u4e3a\u673a\u5668\u4eba\u63d0\u4f9b\u63a5\u89e6\u8868\u9762\u7684\u76f4\u63a5\u4fe1\u606f\uff0c\u5bf9\u4e8e\u63d0\u9ad8\u6293\u63e1\u7a33\u5b9a\u6027\u5c24\u5176\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u5927\u591a\u6570\u673a\u5668\u4eba\u624b\u8bbe\u8ba1\u4e2d\uff0c\u8fd9\u4e9b\u4f20\u611f\u5668\u7684\u5bc6\u5ea6\u548c\u5e03\u5c40\u5dee\u5f02\u5f88\u5927\uff0c\u4e14\u5f80\u5f80\u5360\u7528\u4e86\u5927\u90e8\u5206\u53ef\u7528\u7a7a\u95f4\u3002", "method": "\u4f7f\u7528\u6a21\u62df\u6765\u8bc4\u4f306\u79cd\u4e0d\u540c\u5bc6\u5ea6\u548c\u5e03\u5c40\u7684\u89e6\u89c9\u4f20\u611f\u5668\u914d\u7f6e\uff0c\u5e76\u57fa\u4e8e\u5b83\u4eec\u5bf9\u5f3a\u5316\u5b66\u4e60\u7684\u5f71\u54cd\u8fdb\u884c\u6bd4\u8f83\u3002\u91c7\u7528\u4e24\u5957\u7cfb\u7edf\u4ee5\u786e\u4fdd\u7ed3\u679c\u4e0d\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u7269\u7406\u6a21\u62df\u5668\u3001\u673a\u5668\u4eba\u624b\u6a21\u578b\u6216\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e86\u7279\u5b9a\u8bbe\u7f6e\u53ca\u8de8\u516d\u79cd\u4f20\u611f\u6a21\u62df\u7684\u4e00\u822c\u6027\u5f71\u54cd\uff0c\u5e76\u8bc6\u522b\u51fa\u4e00\u79cd\u914d\u7f6e\u5728\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u8868\u73b0\u51fa\u6700\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u7279\u5b9a\u89e6\u89c9\u4f20\u611f\u5668\u914d\u7f6e\u80fd\u591f\u663e\u8457\u63d0\u5347\u673a\u5668\u4eba\u624b\uff08\u542b\u5047\u80a2\uff09\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2601.10340", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10340", "abs": "https://arxiv.org/abs/2601.10340", "authors": ["David Morilla-Cabello", "Eduardo Montijano"], "title": "CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing", "comment": null, "summary": "Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u8bed\u4e49\u611f\u77e5\u6846\u67b6CHORAL\uff0c\u7528\u4e8e\u534f\u8c03\u5f02\u6784\u673a\u5668\u4eba\u56e2\u961f\u6267\u884c\u590d\u6742\u73af\u5883\u76d1\u6d4b\u4efb\u52a1\u3002\u901a\u8fc7\u4fa6\u5bdf\u98de\u884c\u6784\u5efa\u5ea6\u91cf-\u8bed\u4e49\u5730\u56fe\uff0c\u8bc6\u522b\u9700\u8981\u66f4\u4ed4\u7ec6\u68c0\u67e5\u7684\u533a\u57df\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u5e73\u53f0\u89c4\u5212\u57fa\u4e8e\u80fd\u529b\u7684\u8def\u5f84\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89c4\u5212\u66f4\u5b89\u5168\u3001\u9ad8\u6548\u7684\u8def\u7ebf\u3002", "motivation": "\u5728\u4f7f\u7528\u5f02\u6784\u673a\u5668\u4eba\u56e2\u961f\u76d1\u63a7\u5927\u578b\u3001\u672a\u77e5\u548c\u590d\u6742\u73af\u5883\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5047\u8bbe\u540c\u8d28\u5316\u56e2\u961f\u6216\u53ea\u5173\u6ce8\u79bb\u6563\u4efb\u52a1\u517c\u5bb9\u6027\uff0c\u800c\u6ca1\u6709\u5145\u5206\u6574\u5408\u573a\u666f\u7406\u89e3\u5230\u8def\u7531\u51b3\u7b56\u4e2d\uff0c\u9650\u5236\u4e86\u9002\u5e94\u73af\u5883\u53ca\u5229\u7528\u5404\u673a\u5668\u4eba\u4f18\u52bf\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aCHORAL\u7684\u96c6\u6210\u8bed\u4e49\u611f\u77e5\u6846\u67b6\uff0c\u9996\u5148\u901a\u8fc7\u4fa6\u5bdf\u98de\u884c\u521b\u5efa\u4e00\u4e2a\u5ea6\u91cf-\u8bed\u4e49\u5730\u56fe\uff0c\u7136\u540e\u5229\u7528\u8be5\u5730\u56fe\u6765\u786e\u5b9a\u9700\u8981\u8fdb\u4e00\u6b65\u68c0\u67e5\u7684\u533a\u57df\uff0c\u5e76\u4e3a\u6bcf\u79cd\u7c7b\u578b\u7684\u673a\u5668\u4eba\u8bbe\u8ba1\u7b26\u5408\u5176\u80fd\u529b\u7279\u70b9\u7684\u8def\u5f84\u3002\u8fd9\u4e9b\u4fe1\u606f\u88ab\u6574\u5408\u8fdb\u4e00\u4e2a\u5f02\u6784\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u516c\u5f0f\u4e2d\uff0c\u5171\u540c\u5206\u914d\u68c0\u67e5\u4efb\u52a1\u5e76\u8ba1\u7b97\u673a\u5668\u4eba\u8f68\u8ff9\u3002", "result": "\u4eff\u771f\u4e0e\u5b9e\u9645\u68c0\u9a8c\u4efb\u52a1\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u901a\u8fc7\u660e\u786e\u8003\u8651\u6bcf\u4e2a\u5e73\u53f0\u7684\u5bfc\u822a\u80fd\u529b\u6765\u89c4\u5212\u66f4\u52a0\u5b89\u5168\u4e14\u9ad8\u6548\u7684\u8def\u5f84\u3002", "conclusion": "\u63d0\u51fa\u7684CHORAL\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5f02\u6784\u673a\u5668\u4eba\u56e2\u961f\u5728\u590d\u6742\u73af\u5883\u4e2d\u6267\u884c\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u6574\u5408\u573a\u666f\u7406\u89e3\u548c\u673a\u5668\u4eba\u7684\u7279\u5b9a\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u4efb\u52a1\u5206\u914d\u4e0e\u8def\u5f84\u89c4\u5212\u3002"}}
{"id": "2601.10365", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10365", "abs": "https://arxiv.org/abs/2601.10365", "authors": ["Yan Liu", "Tao Yu", "Haolin Song", "Hongbo Zhu", "Nianzong Hu", "Yuzhi Hao", "Xiuyong Yao", "Xizhe Zang", "Hua Chen", "Jie Zhao"], "title": "FastStair: Learning to Run Up Stairs with Humanoid Robots", "comment": null, "summary": "Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition.", "AI": {"tldr": "FastStair, a planner-guided, multi-stage learning framework, combines the strengths of model-based foothold planning and model-free reinforcement learning to achieve fast and stable stair ascent for humanoid robots. It was successfully deployed on the Oli robot, enabling it to ascend stairs at high speeds, and won first place in the Canton Tower Robot Run Up Competition.", "motivation": "The motivation behind this paper is to address the challenge faced by humanoid robots in running up stairs, which requires both high agility and strict stability. The authors aim to integrate the benefits of model-free reinforcement learning (for dynamic locomotion) and model-based foothold planning (for ensuring contact feasibility and stability) to create a solution that can enable fast and safe stair ascent for robots.", "method": "The method introduced is FastStair, a planner-guided, multi-stage learning framework. It incorporates a parallel model-based foothold planner into the RL training loop to promote exploration towards feasible contacts and pretrain a safety-focused base policy. To reduce conservatism from the planner and adapt to different speed requirements, the base policy undergoes fine-tuning to become speed-specialized experts, followed by integration through Low-Rank Adaptation (LoRA) for smooth operation across various speeds.", "result": "The resulting controller was implemented on the Oli humanoid robot, allowing it to ascend stairs stably at commanded speeds reaching 1.65 m/s. Moreover, the robot managed to traverse a 33-step spiral staircase with a 17 cm rise per step in just 12 seconds, showcasing its capability for robust, high-speed performance on long staircases. This approach also secured the championship in the Canton Tower Robot Run Up Competition.", "conclusion": "FastStair effectively merges the advantages of model-based and model-free techniques, leading to significant advancements in enabling humanoid robots to run up stairs quickly and safely. The demonstrated success in both controlled experiments and a real-world competition highlights the potential of this approach for enhancing robotic mobility in complex environments."}}
