<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Leveraging Foundation Models for Enhancing Robot Perception and Action](https://arxiv.org/abs/2510.26855)
*Reihaneh Mirjalili*

Main category: cs.RO

TL;DR: 本论文探讨了如何系统地利用基础模型来增强机器人在非结构化环境中的定位、交互和操作能力，通过四个核心研究方向构建了一个具有语义感知的机器人智能框架。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人在非结构化环境下的适应性和效率，本研究旨在探索基础模型对于提升机器人能力的作用，特别是针对定位、交互与操控等关键挑战。

Method: 研究工作围绕四个核心问题展开，每个问题都针对机器人技术中的一个基本难题，同时这些研究共同作用于形成一个统一的语义感知机器人智能架构。

Result: 虽然摘要中没有给出具体结果，但可以推测出这项工作的目标是开发一套能够使机器人更好地理解和应对周围世界的系统方法。

Conclusion: 通过结合基础模型的应用，本文提出了一种新途径以增强机器人在复杂且变化多端的现实世界中的表现。

Abstract: This thesis investigates how foundation models can be systematically
leveraged to enhance robotic capabilities, enabling more effective
localization, interaction, and manipulation in unstructured environments. The
work is structured around four core lines of inquiry, each addressing a
fundamental challenge in robotics while collectively contributing to a cohesive
framework for semantics-aware robotic intelligence.

</details>


### [2] [NaviTrace: Evaluating Embodied Navigation of Vision-Language Models](https://arxiv.org/abs/2510.26909)
*Tim Windecker,Manthan Patel,Moritz Reuss,Richard Schwarzkopf,Cesar Cadena,Rudolf Lioutikov,Marco Hutter,Jonas Frey*

Main category: cs.RO

TL;DR: 该论文提出了NaviTrace，一个高质量的视觉问答基准，用于评估视觉-语言模型在导航任务中的性能。通过结合动态时间规整距离、目标端点误差和基于每像素语义的具身条件惩罚，NaviTrace采用了一种新的语义感知轨迹评分方法来评价模型表现，并揭示了现有模型与人类性能之间的差距主要在于空间定位和目标定位能力不足。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型在多种任务中表现出色且具有很好的泛化性，但将这些基础模型整合到机器人导航系统时，面临着实际测试成本高、仿真过于简化以及基准测试有限的问题。因此需要一个能够有效评估这些模型导航能力的新基准。

Method: 创建了名为NaviTrace的基准，它要求模型根据给定的指令和具身类型（人、腿式机器人、轮式机器人、自行车）生成2D导航路径。此基准包含1000个场景和超过3000条专家路径，并使用新提出的语义感知轨迹得分对八个最先进的视觉-语言模型进行了系统评估。

Result: 研究发现，当前先进的视觉-语言模型在导航任务上的表现与人类相比存在明显差距，尤其是在空间定位和目标定位方面。NaviTrace为现实世界中的机器人导航提供了一个可扩展且可重复的评估标准。

Conclusion: NaviTrace作为一项新的基准测试，不仅为视觉-语言模型在导航任务中的性能提供了更全面准确的评估手段，还指出了现有模型在特定方面存在的不足之处，为未来的研究方向提供了参考。

Abstract: Vision-language models demonstrate unprecedented performance and
generalization across a wide range of tasks and scenarios. Integrating these
foundation models into robotic navigation systems opens pathways toward
building general-purpose robots. Yet, evaluating these models' navigation
capabilities remains constrained by costly real-world trials, overly simplified
simulations, and limited benchmarks. We introduce NaviTrace, a high-quality
Visual Question Answering benchmark where a model receives an instruction and
embodiment type (human, legged robot, wheeled robot, bicycle) and must output a
2D navigation trace in image space. Across 1000 scenarios and more than 3000
expert traces, we systematically evaluate eight state-of-the-art VLMs using a
newly introduced semantic-aware trace score. This metric combines Dynamic Time
Warping distance, goal endpoint error, and embodiment-conditioned penalties
derived from per-pixel semantics and correlates with human preferences. Our
evaluation reveals consistent gap to human performance caused by poor spatial
grounding and goal localization. NaviTrace establishes a scalable and
reproducible benchmark for real-world robotic navigation. The benchmark and
leaderboard can be found at
https://leggedrobotics.github.io/navitrace_webpage/.

</details>


### [3] [Heterogeneous Robot Collaboration in Unstructured Environments with Grounded Generative Intelligence](https://arxiv.org/abs/2510.26915)
*Zachary Ravichandran,Fernando Cladera,Ankit Prabhu,Jason Hughes,Varun Murali,Camillo Taylor,George J. Pappas,Vijay Kumar*

Main category: cs.RO

TL;DR: 本文提出了一种名为SPINE-HT的框架，该框架通过三阶段过程将大型语言模型（LLM）的推理能力与异构机器人团队的实际能力相结合，以在不确定、开放世界的环境中执行复杂的任务。实验表明，该方法相比以前的方法具有更高的成功率。


<details>
  <summary>Details</summary>
Motivation: 异构机器人团队在现实环境中运行时，往往需要完成需要协作和适应在线获取信息的复杂任务。由于这些团队经常在没有先验地图的非结构化环境中工作，因此子任务必须基于机器人的能力和物理世界来设定。虽然异构团队通常为固定规格设计，但生成式智能技术开启了能够用自然语言描述并完成广泛使命的可能性。然而，当前依赖于大型语言模型（LLM）的团队合作方法通常假定环境是结构良好且已知的，这限制了它们在非结构化环境中的应用。

Method: 提出了SPINE-HT框架，该框架通过三个阶段的过程解决了上述局限性：首先根据描述任务目标和团队能力的语言规范，由LLM生成具体的子任务，并验证其可行性；然后根据如可通行性或感知等能力将子任务分配给各个机器人，并根据在线操作期间收集的反馈进行细化。

Result: 仿真实验中，在闭环感知与控制条件下，该框架的成功率几乎是之前使用LLM的异构团队方案的两倍。实际测试中，使用Clearpath Jackal, Clearpath Husky, Boston Dynamics Spot以及高空UAV组成的团队，在需要考虑机器人能力和利用在线反馈调整子任务的任务上达到了87%的成功率。

Conclusion: 研究证明了SPINE-HT框架在使异构机器人团队能够在非结构化环境中有效执行复杂任务方面的有效性，展示了相对于现有方法的优势。

Abstract: Heterogeneous robot teams operating in realistic settings often must
accomplish complex missions requiring collaboration and adaptation to
information acquired online. Because robot teams frequently operate in
unstructured environments -- uncertain, open-world settings without prior maps
-- subtasks must be grounded in robot capabilities and the physical world.
While heterogeneous teams have typically been designed for fixed
specifications, generative intelligence opens the possibility of teams that can
accomplish a wide range of missions described in natural language. However,
current large language model (LLM)-enabled teaming methods typically assume
well-structured and known environments, limiting deployment in unstructured
environments. We present SPINE-HT, a framework that addresses these limitations
by grounding the reasoning abilities of LLMs in the context of a heterogeneous
robot team through a three-stage process. Given language specifications
describing mission goals and team capabilities, an LLM generates grounded
subtasks which are validated for feasibility. Subtasks are then assigned to
robots based on capabilities such as traversability or perception and refined
given feedback collected during online operation. In simulation experiments
with closed-loop perception and control, our framework achieves nearly twice
the success rate compared to prior LLM-enabled heterogeneous teaming
approaches. In real-world experiments with a Clearpath Jackal, a Clearpath
Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an
87\% success rate in missions requiring reasoning about robot capabilities and
refining subtasks with online feedback. More information is provided at
https://zacravichandran.github.io/SPINE-HT.

</details>


### [4] [RepV: Safety-Separable Latent Spaces for Scalable Neurosymbolic Plan Verification](https://arxiv.org/abs/2510.26935)
*Yunhao Yang,Neel P. Bhatt,Pranay Samineni,Rohan Siva,Zhanyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: 我们提出了一种名为RepV的神经符号验证器，它通过学习一个使安全和不安全计划线性可分的潜在空间来统一形式方法与深度学习方法。RepV能够基于其在潜在空间中的位置提供概率性的验证正确性保证，并且在不同的规划领域中提高了规则遵守的预测准确性，同时只需要添加少于0.2M的参数。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统进入安全关键领域，确保它们的行为符合明确定义的规则仍然是一个挑战。虽然形式化方法提供了可证明的保证，但需要手工制作的时间逻辑规范，这限制了表达性和易用性；而深度学习方法虽然允许评估自然语言约束下的计划，但其决策过程不够透明，可能导致严重的错误分类。因此，研究者开发了RepV来解决这些问题。

Method: RepV是一种神经符号验证器，它从由现成模型检查器标记的一小部分种子计划开始训练。该验证器使用轻量级投影器将每个计划及其语言模型生成的理由嵌入到低维空间中，在这个空间里安全和不安全的计划是线性可分的。然后，通过冻结的线性边界对未见过的自然语言规则进行一次性前向传递以验证合规性。此外，RepV还根据项目在潜在空间中的位置提供了一个关于正确验证可能性的概率性保证。

Result: 实验结果表明，与基线方法相比，RepV在不同规划领域内提高了高达15%的合规性预测准确率，而且只增加了不到0.2M的参数。另外，基于提供的保证驱动改进框架，在无需人工标注的情况下改善了规划者的规则遵守情况，并且表现优于常规微调基线。

Conclusion: 研究表明，像RepV这样的安全可分离潜在空间为可靠的神经符号计划验证提供了一个可扩展、即插即用的基础组件。

Abstract: As AI systems migrate to safety-critical domains, verifying that their
actions comply with well-defined rules remains a challenge. Formal methods
provide provable guarantees but demand hand-crafted temporal-logic
specifications, offering limited expressiveness and accessibility. Deep
learning approaches enable evaluation of plans against natural-language
constraints, yet their opaque decision process invites misclassifications with
potentially severe consequences. We introduce RepV, a neurosymbolic verifier
that unifies both views by learning a latent space where safe and unsafe plans
are linearly separable. Starting from a modest seed set of plans labeled by an
off-the-shelf model checker, RepV trains a lightweight projector that embeds
each plan, together with a language model-generated rationale, into a
low-dimensional space; a frozen linear boundary then verifies compliance for
unseen natural-language rules in a single forward pass.
  Beyond binary classification, RepV provides a probabilistic guarantee on the
likelihood of correct verification based on its position in the latent space.
This guarantee enables a guarantee-driven refinement of the planner, improving
rule compliance without human annotations. Empirical evaluations show that RepV
improves compliance prediction accuracy by up to 15% compared to baseline
methods while adding fewer than 0.2M parameters. Furthermore, our refinement
framework outperforms ordinary fine-tuning baselines across various planning
domains. These results show that safety-separable latent spaces offer a
scalable, plug-and-play primitive for reliable neurosymbolic plan verification.
Code and data are available at: https://repv-project.github.io/.

</details>


### [5] [A Hermetic, Transparent Soft Growing Vine Robot System for Pipe Inspection](https://arxiv.org/abs/2510.27010)
*William E. Heap,Yimeng Qin,Kai Hammond,Anish Bayya,Haonon Kong,Allison M. Okamura*

Main category: cs.RO

TL;DR: 本文介绍了一种用于管道内部视觉检测和绘图的密封透明藤蔓机器人系统，该系统在实际废水管道条件评估和绘图任务中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 管道老化修复需要对管道深处进行准确的状态评估和绘图。现有的软生长藤蔓机器人系统虽然适合在狭窄弯曲的路径中导航，但受限于复杂的子系统，并且缺乏在真实工业环境中的验证。

Method: 设计并实现了一种密封透明的藤蔓机器人系统，所有机械和电气组件都封装在一个柔软、气密且透明的身体内。为了适应这种封闭式的设计，开发了一个能够被动适应的封闭尖端安装座。

Result: 通过在实际废水管道中的状态评估和绘图任务验证了密封透明藤蔓机器人系统的概念。

Conclusion: 这项工作通过开发和展示一个坚固、简洁并且经过实地验证的系统，推进了软生长藤蔓机器人在管道检查中的应用。

Abstract: Rehabilitation of aging pipes requires accurate condition assessment and
mapping far into the pipe interiors. Soft growing vine robot systems are
particularly promising for navigating confined, sinuous paths such as in pipes,
but are currently limited by complex subsystems and a lack of validation in
real-world industrial settings. In this paper, we introduce the concept and
implementation of a hermetic and transparent vine robot system for visual
condition assessment and mapping within non-branching pipes. This design
encloses all mechanical and electrical components within the vine robot's soft,
airtight, and transparent body, protecting them from environmental interference
while enabling visual sensing. Because this approach requires an enclosed
mechanism for transporting sensors, we developed, modeled, and tested a
passively adapting enclosed tip mount. Finally, we validated the hermetic and
transparent vine robot system concept through a real-world condition assessment
and mapping task in a wastewater pipe. This work advances the use of
soft-growing vine robots in pipe inspection by developing and demonstrating a
robust, streamlined, field-validated system suitable for continued development
and deployment.

</details>


### [6] [A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics](https://arxiv.org/abs/2510.27033)
*Simindokht Jahangard,Mehrzad Mohammadi,Abhinav Dhall,Hamid Rezatofighi*

Main category: cs.RO

TL;DR: 提出了一种新的神经符号框架，结合全景图像和3D点云信息来提高视觉语言模型在细粒度空间推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在感知任务上表现出色，但在细粒度的空间推理方面存在困难，主要因为它们依赖于基于关联的隐式推理且仅依靠图像数据。为了解决这个问题，并更好地理解物体间的关系及其在复杂环境中的交互作用，特别是在机器人领域内，研究者们开发了这一新方法。

Method: 该方法引入了一个神经符号框架，该框架同时利用了全景图像与3D点云的信息，通过将神经感知与符号推理相结合的方式，明确地建模空间及逻辑关系。它包括一个用于检测实体并提取属性的感知模块，以及一个构建结构化场景图以支持精确、可解释查询的推理模块。

Result: 在JRDB-Reasoning数据集上的评估表明，所提出的方法在拥挤的人造环境中表现出更优的性能和可靠性，同时保持了轻量级的设计，适合于机器人技术和具身AI应用。

Conclusion: 这项工作展示了一种创新性的解决方案，能够有效提升视觉-语言模型处理复杂空间推理问题的能力，尤其适用于需要准确理解和导航周围世界的机器人技术。

Abstract: Visual reasoning, particularly spatial reasoning, is a challenging cognitive
task that requires understanding object relationships and their interactions
within complex environments, especially in robotics domain. Existing
vision_language models (VLMs) excel at perception tasks but struggle with
fine-grained spatial reasoning due to their implicit, correlation-driven
reasoning and reliance solely on images. We propose a novel neuro_symbolic
framework that integrates both panoramic-image and 3D point cloud information,
combining neural perception with symbolic reasoning to explicitly model spatial
and logical relationships. Our framework consists of a perception module for
detecting entities and extracting attributes, and a reasoning module that
constructs a structured scene graph to support precise, interpretable queries.
Evaluated on the JRDB-Reasoning dataset, our approach demonstrates superior
performance and reliability in crowded, human_built environments while
maintaining a lightweight design suitable for robotics and embodied AI
applications.

</details>


### [7] [SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation](https://arxiv.org/abs/2510.27048)
*Eric T. Chang,Peter Ballentine,Zhanpeng He,Do-Gon Kim,Kai Jiang,Hua-Hsuan Liang,Joaquin Palacios,William Wang,Pedro Piacenza,Ioannis Kymissis,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 本文介绍了一种名为SpikeATac的多模态触觉手指，它结合了动态响应（PVDF）和静态转换方法（电容式），用于实现敏感的触摸感应，并通过与基于学习的框架结合，实现了对易碎物体的精细操作。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够快速、敏感地响应接触开始和结束的多模态触觉传感器，以支持机器人手在抓握脆弱、可变形物体时能迅速而细腻地停止，同时探索这种传感器如何通过学习框架提高机器人的灵巧性。

Method: 设计并实现了SpikeATac，一个拥有16个taxel的PVDF薄膜，采样率高达4kHz，以及一个静态转导方式（电容式）。利用强化学习从人类反馈中学习，并结合触觉奖励来微调策略以调节力量。

Result: SpikeATac展示了其在抓握脆弱物品时快速且细腻停止的能力。此外，当应用于灵活的多指机器人手上时，通过学习框架，它还能够实现之前未达成的复杂灵巧任务：在手中操纵脆弱物体。

Conclusion: SpikeATac作为一种新型多模态触觉传感器，不仅提高了对细微触感变化的捕捉能力，而且通过与先进的学习算法相结合，在执行需要高度灵巧性和丰富接触的任务方面展现出了巨大潜力。

Abstract: In this work, we introduce SpikeATac, a multimodal tactile finger combining a
taxelized and highly sensitive dynamic response (PVDF) with a static
transduction method (capacitive) for multimodal touch sensing. Named for its
`spiky' response, SpikeATac's 16-taxel PVDF film sampled at 4 kHz provides
fast, sensitive dynamic signals to the very onset and breaking of contact. We
characterize the sensitivity of the different modalities, and show that
SpikeATac provides the ability to stop quickly and delicately when grasping
fragile, deformable objects. Beyond parallel grasping, we show that SpikeATac
can be used in a learning-based framework to achieve new capabilities on a
dexterous multifingered robot hand. We use a learning recipe that combines
reinforcement learning from human feedback with tactile-based rewards to
fine-tune the behavior of a policy to modulate force. Our hardware platform and
learning pipeline together enable a difficult dexterous and contact-rich task
that has not previously been achieved: in-hand manipulation of fragile objects.
Videos are available at
\href{https://roamlab.github.io/spikeatac/}{roamlab.github.io/spikeatac}.

</details>


### [8] [Learning Generalizable Visuomotor Policy through Dynamics-Alignment](https://arxiv.org/abs/2510.27114)
*Dohyeok Lee,Jung Min Lee,Munkyung Kim,Seokhun Ju,Jin Woo Koo,Kyungjae Lee,Dohyeong Kim,TaeHyun Cho,Jungwoo Lee*

Main category: cs.RO

TL;DR: 本文提出了一种名为Dynamics-Aligned Flow Matching Policy (DAP)的新方法，通过将动力学预测整合到策略学习中，使机器人在现实世界中的操作任务上表现出更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 行为克隆方法由于超出专家演示的数据支持有限而存在泛化性差的问题。虽然最近利用视频预测模型的方法通过从大规模数据集中学习丰富的时空表示取得了有希望的结果，但这些模型学习的是与动作无关的动力学，无法区分不同的控制输入，限制了它们在精确操作任务中的实用性，并且需要大量的预训练数据集。

Method: 提出了一种新的架构，即Dynamics-Aligned Flow Matching Policy (DAP)，该架构允许策略和动力学模型在动作生成过程中提供相互纠正反馈，从而实现自我修正并提高泛化能力。

Result: 实验验证表明，在现实世界的机器人操作任务上，该方法的泛化性能优于基线方法，尤其是在包括视觉干扰和光照变化在内的OOD场景下表现出了特别的鲁棒性。

Conclusion: DAP方法通过结合动力学预测和策略学习，提高了机器人在不同条件下的适应性和执行精度，为解决现有行为克隆技术局限性提供了有效途径。

Abstract: Behavior cloning methods for robot learning suffer from poor generalization
due to limited data support beyond expert demonstrations. Recent approaches
leveraging video prediction models have shown promising results by learning
rich spatiotemporal representations from large-scale datasets. However, these
models learn action-agnostic dynamics that cannot distinguish between different
control inputs, limiting their utility for precise manipulation tasks and
requiring large pretraining datasets. We propose a Dynamics-Aligned Flow
Matching Policy (DAP) that integrates dynamics prediction into policy learning.
Our method introduces a novel architecture where policy and dynamics models
provide mutual corrective feedback during action generation, enabling
self-correction and improved generalization. Empirical validation demonstrates
generalization performance superior to baseline methods on real-world robotic
manipulation tasks, showing particular robustness in OOD scenarios including
visual distractions and lighting variations.

</details>


### [9] [Confined Space Underwater Positioning Using Collaborative Robots](https://arxiv.org/abs/2510.27151)
*Xueliang Cheng,Kanzhong Yao,Andrew West,Ognjen Marjanovic,Barry Lennox,Keir Groves*

Main category: cs.RO

TL;DR: 本文介绍了一种名为CAP（协作水下定位）系统，通过集成协作机器人技术和传感器融合来克服现有水下机器人在受限和杂乱空间中定位的难题。该系统利用一个移动的水面车辆作为引导者，帮助水下机器人进行定位，无需依赖固定的基础设施或环境特征即可实现高精度定位。实验结果表明，其实时定位误差仅为70毫米。


<details>
  <summary>Details</summary>
Motivation: 现有的水下机器人定位系统大多设计用于开阔水域，在工业环境中由于覆盖范围有限、依赖外部设施及需要丰富的环境特征而表现不佳。多路径效应导致信号质量下降，进一步降低了准确性和可靠性。为了解决这些问题，并推动水下机器人技术的发展，提出了本研究。

Method: 研究提出了一种名为CAP的新系统，它结合了协作机器人技术和传感器融合方法。该系统采用“母舰”概念，使用一个可移动的表面车辆作为领导者来协助水下机器人的定位，即使是在没有GPS信号且环境非常受限的情况下也能工作。

Result: 通过在一个大型测试池中的重复自主任务验证了系统的有效性，使用CAP提供的位置估计来进行实时轨迹控制。实验结果显示平均欧几里得距离误差仅为70毫米，证明了其在不需固定基础设施、广泛校准或特定环境特征条件下实现高精度定位的能力。

Conclusion: CAP系统通过先进的移动机器人传感技术和领导-跟随控制策略，为无基础设施的水下精确定位提供了一个重大突破。这标志着向更加实用和高效的水下自动化操作迈出了重要一步。

Abstract: Positioning of underwater robots in confined and cluttered spaces remains a
key challenge for field operations. Existing systems are mostly designed for
large, open-water environments and struggle in industrial settings due to poor
coverage, reliance on external infrastructure, and the need for feature-rich
surroundings. Multipath effects from continuous sound reflections further
degrade signal quality, reducing accuracy and reliability. Accurate and easily
deployable positioning is essential for repeatable autonomous missions;
however, this requirement has created a technological bottleneck limiting
underwater robotic deployment. This paper presents the Collaborative Aquatic
Positioning (CAP) system, which integrates collaborative robotics and sensor
fusion to overcome these limitations. Inspired by the "mother-ship" concept,
the surface vehicle acts as a mobile leader to assist in positioning a
submerged robot, enabling localization even in GPS-denied and highly
constrained environments. The system is validated in a large test tank through
repeatable autonomous missions using CAP's position estimates for real-time
trajectory control. Experimental results demonstrate a mean Euclidean distance
(MED) error of 70 mm, achieved in real time without requiring fixed
infrastructure, extensive calibration, or environmental features. CAP leverages
advances in mobile robot sensing and leader-follower control to deliver a step
change in accurate, practical, and infrastructure-free underwater localization.

</details>


### [10] [MobiDock: Design and Control of A Modular Self Reconfigurable Bimanual Mobile Manipulator via Robotic Docking](https://arxiv.org/abs/2510.27178)
*Xuan-Thuan Nguyen,Khac Nam Nguyen,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Hoang Hiep Ly,Tung D. Ta*

Main category: cs.RO

TL;DR: 本文提出了一种名为MobiDock的模块化自重构移动操作器系统，通过使两个独立机器人物理连接形成统一的双手机器人平台，从而简化了多机器人控制问题。实验结果表明，与两个独立合作的机器人相比，对接配置在动态稳定性和操作效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统，尤其是移动操作器，在协同工作时面临控制协调和动态稳定性方面的挑战。为了解决这个问题，研究提出了一个解决方案。

Method: 研究提出了MobiDock系统，该系统基于计算机视觉（使用AprilTag标记）和一种新的螺纹锁紧机制实现自主对接策略。

Result: 实验结果显示，对接后的配置在动态稳定性和操作效率上优于两个独立协作的机器人。具体来说，统一系统的均方根加速度和冲击值较低，角度精度更高，并且完成任务的速度明显更快。

Conclusion: 这些发现证实了物理重构是一种强大的设计原则，它简化了协同控制，提高了现实环境中复杂任务的稳定性和性能。

Abstract: Multi-robot systems, particularly mobile manipulators, face challenges in
control coordination and dynamic stability when working together. To address
this issue, this study proposes MobiDock, a modular self-reconfigurable mobile
manipulator system that allows two independent robots to physically connect and
form a unified mobile bimanual platform. This process helps transform a complex
multi-robot control problem into the management of a simpler, single system.
The system utilizes an autonomous docking strategy based on computer vision
with AprilTag markers and a new threaded screw-lock mechanism. Experimental
results show that the docked configuration demonstrates better performance in
dynamic stability and operational efficiency compared to two independently
cooperating robots. Specifically, the unified system has lower Root Mean Square
(RMS) Acceleration and Jerk values, higher angular precision, and completes
tasks significantly faster. These findings confirm that physical
reconfiguration is a powerful design principle that simplifies cooperative
control, improving stability and performance for complex tasks in real-world
environments.

</details>


### [11] [Hybrid Gripper Finger Enabling In-Grasp Friction Modulation Using Inflatable Silicone Pockets](https://arxiv.org/abs/2510.27184)
*Hoang Hiep Ly,Cong-Nhat Nguyen,Doan-Quang Tran,Quoc-Khanh Dang,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Xuan-Thuan Nguyen,Tung D. Ta*

Main category: cs.RO

TL;DR: 本文介绍了一种结合了刚性结构外壳和柔软可充气硅胶袋的混合夹爪手指，通过调节硅胶袋内部的气压来主动调节表面摩擦力。实验结果显示，这种设计能够稳定地举起重物或滑动物品，并且在处理易碎或可变形物品时减少了损坏的风险，提供了一个比单纯依赖高正压力更安全、更灵活的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统夹爪通常依靠施加高正压力来抓取物体，这可能会对物体造成损害。为了解决这一问题，本研究旨在开发一种能够通过调整摩擦力而非单纯增加夹持力来有效抓取具有不同机械特性的物体（如沉重、滑手或易碎物品）的新型夹爪。

Method: 提出了一种混合型夹爪手指设计，它结合了刚性的结构壳体与一个软质可充气硅胶口袋。通过控制硅胶口袋内的空气压力，可以主动调节夹爪表面的摩擦系数。

Result: 基础实验表明，随着内部压力的增加，有效摩擦系数也会相应提高。这使得夹爪能够在不增加夹持力度的情况下稳定提起重物和滑动物体；同时，在处理鸡蛋、水果及纸杯等脆弱或可变形物品时，通过增加摩擦而不是施加过大的力量，实现了最小化损伤的效果。

Conclusion: 采用可调摩擦系数设计的混合夹爪手指提供了一种更为稳固且安全的选择，相比仅依赖高正压力的传统方法而言，它提高了夹爪处理精细、脆弱以及多样化物体的能力。

Abstract: Grasping objects with diverse mechanical properties, such as heavy, slippery,
or fragile items, remains a significant challenge in robotics. Conventional
grippers often rely on applying high normal forces, which can cause damage to
objects. To address this limitation, we present a hybrid gripper finger that
combines a rigid structural shell with a soft, inflatable silicone pocket. The
gripper finger can actively modulate its surface friction by controlling the
internal air pressure of the silicone pocket. Results from fundamental
experiments indicate that increasing the internal pressure results in a
proportional increase in the effective coefficient of friction. This enables
the gripper to stably lift heavy and slippery objects without increasing the
gripping force and to handle fragile or deformable objects, such as eggs,
fruits, and paper cups, with minimal damage by increasing friction rather than
applying excessive force. The experimental results demonstrate that the hybrid
gripper finger with adaptable friction provides a robust and safer alternative
to relying solely on high normal forces, thereby enhancing the gripper
flexibility in handling delicate, fragile, and diverse objects.

</details>


### [12] [Vectorized Online POMDP Planning](https://arxiv.org/abs/2510.27191)
*Marcus Hoerger,Muhammad Sudrajat,Hanna Kurniawati*

Main category: cs.RO

TL;DR: 本文提出了一种新的并行在线求解器VOPP，用于解决部分可观测马尔可夫决策过程（POMDP）中的规划问题。通过将所有与规划相关的数据结构表示为张量集合，并实施全矢量化计算，VOPP消除了并行计算间的依赖性和同步瓶颈，比现有最先进的并行在线求解器至少提高了20倍的效率。


<details>
  <summary>Details</summary>
Motivation: 在机器人自主性中，处理部分可观测环境下的规划至关重要。尽管POMDP提供了一个强大的框架来应对这种问题，但其求解可以从当今硬件的大规模并行化中极大受益。然而，POMDP求解器的并行化遇到了挑战，因为它们依赖于动作上的数值优化与价值估计之间的交替进行，这导致了并行进程间存在依赖性和同步瓶颈。

Method: 提出了Vectorized Online POMDP Planner (VOPP)，这是一个新颖的并行在线求解器，利用了最近的一种POMDP公式，该公式解析地解决了部分优化组件的问题，仅留下期望值的估算需要数值计算。VOPP将所有与规划相关的数据结构表示为一组张量，并且将所有的规划步骤实现为基于此表示的完全矢量化计算。

Result: 实验结果表明，与现有的最先进的并行在线求解器相比，VOPP在计算接近最优解方面至少提高了20倍的效率。

Conclusion: VOPP通过消除并行计算间的依赖性和同步瓶颈，显著提高了POMDP求解的效率，代表了解决此类问题的新方法。

Abstract: Planning under partial observability is an essential capability of autonomous
robots. The Partially Observable Markov Decision Process (POMDP) provides a
powerful framework for planning under partial observability problems, capturing
the stochastic effects of actions and the limited information available through
noisy observations. POMDP solving could benefit tremendously from massive
parallelization of today's hardware, but parallelizing POMDP solvers has been
challenging. They rely on interleaving numerical optimization over actions with
the estimation of their values, which creates dependencies and synchronization
bottlenecks between parallel processes that can quickly offset the benefits of
parallelization. In this paper, we propose Vectorized Online POMDP Planner
(VOPP), a novel parallel online solver that leverages a recent POMDP
formulation that analytically solves part of the optimization component,
leaving only the estimation of expectations for numerical computation. VOPP
represents all data structures related to planning as a collection of tensors
and implements all planning steps as fully vectorized computations over this
representation. The result is a massively parallel solver with no dependencies
and synchronization bottlenecks between parallel computations. Experimental
results indicate that VOPP is at least 20X more efficient in computing
near-optimal solutions compared to an existing state-of-the-art parallel online
solver.

</details>


### [13] [A Modular and Scalable System Architecture for Heterogeneous UAV Swarms Using ROS 2 and PX4-Autopilot](https://arxiv.org/abs/2510.27327)
*Robert Pommeranz,Kevin Tebbe,Ralf Heynicke,Gerd Scholl*

Main category: cs.RO

TL;DR: 本文提出了一种基于PX4-Autopilot和ROS 2框架的异构集群反无人机系统（C-UASs）模块化可扩展架构，强调了通过为无人机每个组件引入独立的ROS 2节点来无缝集成硬件组件。该系统支持关键功能如领航跟随和编队飞行，并允许集成计算机视觉算法以检测和跟踪无人机。此外，还集成了地面站控制以协调集群操作。此架构已在Gazebo模拟环境及真实世界演示中得到验证。


<details>
  <summary>Details</summary>
Motivation: 随着无人机技术的发展，对于能够有效应对潜在威胁的反无人机系统需求日益增长。为此，本文旨在设计一种灵活、可扩展且易于集成不同硬件组件的解决方案，以提高反无人机系统的适应性和效率。

Method: 采用PX4-Autopilot与ROS 2作为基础框架构建了该系统。通过将每个无人机组件抽象为独立的ROS 2节点，实现了硬件之间的无缝集成。同时，利用软件抽象通信机制，使得即便更换底层通信技术也不会影响整体架构。系统内还加入了对领航跟随、编队飞行等功能的支持，并通过计算机视觉技术增强了目标识别能力。

Result: 开发出了一套适用于异构无人机集群的反无人机系统架构，不仅在Gazebo仿真环境中得到了充分测试，而且也在实际场景下进行了展示，证明了其可行性和有效性。

Conclusion: 所提出的基于PX4-Autopilot和ROS 2的反无人机系统架构展现出了良好的灵活性与扩展性，能够满足当前及未来一段时间内对抗无人机威胁的需求。它提供了一种新的思路和技术手段，有助于提升相关领域的技术水平。

Abstract: In this paper a modular and scalable architecture for heterogeneous
swarm-based Counter Unmanned Aerial Systems (C-UASs) built on PX4-Autopilot and
Robot Operating System 2 (ROS 2) framework is presented. The proposed
architecture emphasizes seamless integration of hardware components by
introducing independent ROS 2 nodes for each component of a Unmanned Aerial
Vehicle (UAV). Communication between swarm participants is abstracted in
software, allowing the use of various technologies without architectural
changes. Key functionalities are supported, e.g. leader following and formation
flight to maneuver the swarm. The system also allows computer vision algorithms
to be integrated for the detection and tracking of UAVs. Additionally, a ground
station control is integrated for the coordination of swarm operations.
Swarm-based Unmanned Aerial System (UAS) architecture is verified within a
Gazebo simulation environment but also in real-world demonstrations.

</details>


### [14] [Modified-Emergency Index (MEI): A Criticality Metric for Autonomous Driving in Lateral Conflict](https://arxiv.org/abs/2510.27333)
*Hao Cheng,Yanbo Jiang,Qingyuan Shi,Qingwen Meng,Keyu Chen,Wenhao Yu,Jianqiang Wang,Sifa Zheng*

Main category: cs.RO

TL;DR: 本文提出了一种改进的紧急指数（MEI），用于量化横向冲突中的避险努力，与现有指标相比，MEI能更精确地评估风险。通过对超过1500个高质量自动驾驶冲突案例的研究，证明了MEI在准确量化危险性和捕捉风险演变方面优于ACT和PET等常用指标。


<details>
  <summary>Details</summary>
Motivation: 当前针对自动驾驶安全性的评价方法主要集中在纵向冲突上，而对城市环境中常见的横向冲突的风险量化不够准确。为了提高自动驾驶车辆在城市环境下的安全性评估准确性，需要一种新的度量标准来更好地量化横向冲突中的风险。

Method: 提出了一种称为修改后的紧急指数（MEI）的新度量标准，该标准通过改进对于执行规避动作可用时间的估计，从而能够更加精确地量化风险。利用基于Argoverse-2的数据集验证了MEI的有效性，并将其性能与既定的ACT以及广泛使用的PET指标进行了比较。

Result: 研究结果表明，在准确量化危急性及捕捉风险变化方面，MEI始终优于ACT和PET等传统指标。此外，还从数据集中提取了超过1,500个高质量的自动驾驶冲突案例，其中包括超过500个关键事件以支持分析。

Conclusion: MEI作为一种有前景的度量标准，在评估城市环境下的横向冲突及加强自动驾驶的安全性评估框架方面展现出巨大潜力。

Abstract: Effective, reliable, and efficient evaluation of autonomous driving safety is
essential to demonstrate its trustworthiness. Criticality metrics provide an
objective means of assessing safety. However, as existing metrics primarily
target longitudinal conflicts, accurately quantifying the risks of lateral
conflicts - prevalent in urban settings - remains challenging. This paper
proposes the Modified-Emergency Index (MEI), a metric designed to quantify
evasive effort in lateral conflicts. Compared to the original Emergency Index
(EI), MEI refines the estimation of the time available for evasive maneuvers,
enabling more precise risk quantification. We validate MEI on a public lateral
conflict dataset based on Argoverse-2, from which we extract over 1,500
high-quality AV conflict cases, including more than 500 critical events. MEI is
then compared with the well-established ACT and the widely used PET metrics.
Results show that MEI consistently outperforms them in accurately quantifying
criticality and capturing risk evolution. Overall, these findings highlight MEI
as a promising metric for evaluating urban conflicts and enhancing the safety
assessment framework for autonomous driving. The open-source implementation is
available at https://github.com/AutoChengh/MEI.

</details>


### [15] [Towards a Multi-Embodied Grasping Agent](https://arxiv.org/abs/2510.27420)
*Roman Freiberg,Alexander Qualmann,Ngo Anh Vien,Gerhard Neumann*

Main category: cs.RO

TL;DR: 本文提出了一种数据高效的、基于流的等变抓取合成架构，能够处理不同类型的夹爪，并从夹爪和场景几何中推断出所有必要的信息。通过将所有模块转换为JAX并提供对场景、夹爪和抓取的批处理能力，实现了更平滑的学习过程、更高的性能以及更快的推理时间。


<details>
  <summary>Details</summary>
Motivation: 多体抓取研究的目标是开发出能够在多种夹爪设计上展示通用行为的方法。现有的方法通常隐式地学习机器人的运动结构，并且由于难以获取所需的大规模数据而面临挑战。

Method: 本研究介绍了一种新的数据高效、基于流的等变抓取合成架构，它能够适应不同自由度的各种夹爪类型，并能仅依靠夹爪与场景几何来有效利用基础的运动模型。此外，作者们将所有组件从头开始转换成JAX编程语言，并构建了一个可以在场景、夹爪及抓取动作之间进行批量处理的模型。

Result: 所提出的模型在学习过程中更加顺畅，表现出了更好的性能，并且拥有更快的推理速度。实验数据集包括了从人形手到平行偏航夹爪等多种类型的夹爪，共包含25,000个场景和20百万次抓取尝试。

Conclusion: 该研究成功地展示了如何通过采用数据高效型架构以及充分利用夹爪和场景几何信息来克服现有方法中的局限性，从而实现对于多样夹爪设计的支持。

Abstract: Multi-embodiment grasping focuses on developing approaches that exhibit
generalist behavior across diverse gripper designs. Existing methods often
learn the kinematic structure of the robot implicitly and face challenges due
to the difficulty of sourcing the required large-scale data. In this work, we
present a data-efficient, flow-based, equivariant grasp synthesis architecture
that can handle different gripper types with variable degrees of freedom and
successfully exploit the underlying kinematic model, deducing all necessary
information solely from the gripper and scene geometry. Unlike previous
equivariant grasping methods, we translated all modules from the ground up to
JAX and provide a model with batching capabilities over scenes, grippers, and
grasps, resulting in smoother learning, improved performance and faster
inference time. Our dataset encompasses grippers ranging from humanoid hands to
parallel yaw grippers and includes 25,000 scenes and 20 million grasps.

</details>


### [16] [Learning Soft Robotic Dynamics with Active Exploration](https://arxiv.org/abs/2510.27428)
*Hehui Zheng,Bhavya Sukhija,Chenhao Li,Klemens Iten,Andreas Krause,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出了一种名为SoftAE的不确定性感知主动探索框架，该框架能够自主学习软体机器人系统的任务无关且可泛化的动力学模型。通过在模拟和实际软体机器人平台上进行测试，相比随机探索和基于特定任务的模型强化学习方法，SoftAE能生成更精确的动力学模型，并在未见过的任务上实现更好的零样本控制能力。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其适应性和安全性，在非结构化环境中表现出色。然而，它们顺从、高维度以及非线性的动力学特性使得建模与控制变得非常困难。现有数据驱动的方法往往由于任务演示范围狭窄或随机探索效率低下而难以泛化。

Method: 引入了SoftAE，一种不确定性感知的主动探索框架，它利用概率集成模型来估计认识论不确定性，并积极引导探索朝向状态-动作空间中代表性不足的区域，从而在没有特定任务监督的情况下高效覆盖多样化的行为。

Result: SoftAE在三个模拟软体机器人平台（连续臂、流体中的关节鱼、具有混合驱动的肌肉骨骼腿）以及一个真实世界的气动连续软臂上进行了评估。与随机探索及针对特定任务的基于模型的强化forcement学习相比，SoftAE生成了更准确的动力学模型，对未见任务实现了优越的零样本控制，并在传感噪声、驱动延迟和非线性材料效应下保持了鲁棒性。

Conclusion: 这些结果表明，基于不确定性的主动探索可以为多样化的软体机器人形态产生可扩展、可重用的动力学模型，代表了朝着更加自主、适应性强以及数据效率更高的顺应性机器人控制迈出的一步。

Abstract: Soft robots offer unmatched adaptability and safety in unstructured
environments, yet their compliant, high-dimensional, and nonlinear dynamics
make modeling for control notoriously difficult. Existing data-driven
approaches often fail to generalize, constrained by narrowly focused task
demonstrations or inefficient random exploration. We introduce SoftAE, an
uncertainty-aware active exploration framework that autonomously learns
task-agnostic and generalizable dynamics models of soft robotic systems. SoftAE
employs probabilistic ensemble models to estimate epistemic uncertainty and
actively guides exploration toward underrepresented regions of the state-action
space, achieving efficient coverage of diverse behaviors without task-specific
supervision. We evaluate SoftAE on three simulated soft robotic platforms -- a
continuum arm, an articulated fish in fluid, and a musculoskeletal leg with
hybrid actuation -- and on a pneumatically actuated continuum soft arm in the
real world. Compared with random exploration and task-specific model-based
reinforcement learning, SoftAE produces more accurate dynamics models, enables
superior zero-shot control on unseen tasks, and maintains robustness under
sensing noise, actuation delays, and nonlinear material effects. These results
demonstrate that uncertainty-driven active exploration can yield scalable,
reusable dynamics models across diverse soft robotic morphologies, representing
a step toward more autonomous, adaptable, and data-efficient control in
compliant robots.

</details>


### [17] [Preliminary Prototyping of Avoidance Behaviors Triggered by a User's Physical Approach to a Robot](https://arxiv.org/abs/2510.27436)
*Tomoko Yonezawa,Hirotake Yamazoe,Atsuo Fujino,Daigo Suhara,Takaya Tamamoto,Yuto Nishiguchi*

Main category: cs.RO

TL;DR: 本研究探讨了机器人在人接近时如何根据内部拒绝状态和相应的回避行为（如撤退或推开）来模仿人类之间的互动。通过建模不适感的累积与消散作为人际距离的函数，并使用PAD情感模型中的支配轴驱动容忍度和超出极限后的回避行为，实现了从内部状态参数到耐受性动作以及超越界限后的回避行动的一致流程。


<details>
  <summary>Details</summary>
Motivation: 在人机交互中，人们经常需要身体上接近或接触机器人。然而，在人与人的互动中，人们对靠近的行为会根据关系和情境灵活地接受、拒绝或容忍。这项研究的动机是设计一种能够模仿这种自然反应的机器人，即当一个人过于接近时，机器人能够表现出拒绝的状态和相应的回避行为。

Method: 研究人员通过将不适感建模为一个随人际距离变化而积累和减少的过程，并基于PAD情感模型中的支配轴开发了容忍度（耐力）机制及一旦超过限度便触发的回避策略。这些行为及其强度被编程到了一只机械臂上，用于展示不同情境下的响应。

Result: 实验结果表明，从设定内部状态参数开始，可以实现不同程度的耐受性动作；当某个阈值被跨越时，则会触发明确的回避行为。这提供了一个从内部状态到外部行为表达的连贯流程。

Conclusion: 该研究成功地构建了一个能够模拟人类对物理接近反应的机器人系统，包括其内部状态的变化以及由此引发的具体物理行为。这一成果为未来更加自然流畅的人机交互奠定了基础。

Abstract: Human-robot interaction frequently involves physical proximity or contact. In
human-human settings, people flexibly accept, reject, or tolerate such
approaches depending on the relationship and context. We explore the design of
a robot's rejective internal state and corresponding avoidance behaviors, such
as withdrawing or pushing away, when a person approaches. We model the
accumulation and decay of discomfort as a function of interpersonal distance,
and implement tolerance (endurance) and limit-exceeding avoidance driven by the
Dominance axis of the PAD affect model. The behaviors and their intensities are
realized on an arm robot. Results illustrate a coherent pipeline from internal
state parameters to graded endurance motions and, once a limit is crossed, to
avoidance actions.

</details>


### [18] [Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs](https://arxiv.org/abs/2510.27558)
*Sushil Samuel Dinesh,Shinkyu Park*

Main category: cs.RO

TL;DR: 该论文提出了一种框架，利用预训练的基础模型进行机器人操作而无需特定领域的训练。通过一系列桌面机器人操作实验评估了该框架，结果表明其在构建基于现成基础模型的机器人操作系统方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发一种能够直接使用预训练的基础模型来执行机器人操作任务的方法，避免了针对特定领域重新训练模型的需求，从而提高了效率和通用性。

Method: 该方法通过集成现成的基础模型实现，结合来自基础模型的多模态感知与一个能够稳健完成任务排序的通用推理模型。此外，动态维护的场景图提供了空间意识，并支持对环境的一致性推理。

Result: 通过对一系列桌面机器人操作实验的结果分析，证明了所提出的框架在不需要额外特定领域训练的情况下，有效地利用了预训练模型来进行机器人操作任务。

Conclusion: 结论是，这种新框架为使用预训练的基础模型直接创建灵活且强大的机器人操作解决方案开辟了道路，显示出了在减少对特定领域适应性需求的同时提高系统性能的巨大潜力。

Abstract: This paper presents a framework that leverages pre-trained foundation models
for robotic manipulation without domain-specific training. The framework
integrates off-the-shelf models, combining multimodal perception from
foundation models with a general-purpose reasoning model capable of robust task
sequencing. Scene graphs, dynamically maintained within the framework, provide
spatial awareness and enable consistent reasoning about the environment. The
framework is evaluated through a series of tabletop robotic manipulation
experiments, and the results highlight its potential for building robotic
manipulation systems directly on top of off-the-shelf foundation models.

</details>
